0
00:00:05,360 --> 00:00:08,500
Hello and welcome to the open source security podcast with myself,

1
00:00:08,510 --> 00:00:10,659
Kurt Siefried and my partner in Thought Crime.

2
00:00:10,670 --> 00:00:11,229
Josh Bruss,

3
00:00:11,479 --> 00:00:14,090
man, you had a chance to fit something in with privacy.

4
00:00:14,100 --> 00:00:15,300
I'm, I'm really excited today.

5
00:00:15,510 --> 00:00:19,040
Well, I thought about saying privacy crime, but that's like that's Facebook's,

6
00:00:19,370 --> 00:00:19,600
you know,

7
00:00:20,120 --> 00:00:24,430
that's, that's why we're here today. I'm ecstatic. We have Hay Sukiya

8
00:00:25,149 --> 00:00:28,860
legislative activist at the Electronic Frontier Foundation here

9
00:00:28,870 --> 00:00:31,059
to talk to us about privacy in,

10
00:00:31,069 --> 00:00:32,250
in this electronic age.

11
00:00:32,259 --> 00:00:34,619
Haley. Thank you so much for joining us today.

12
00:00:34,770 --> 00:00:38,270
-- Thank you for having me. I'm really excited to be here.
-- We are. You have no idea.

13
00:00:38,279 --> 00:00:40,110
I'm giddy. It's, it's like Christmas.

14
00:00:40,119 --> 00:00:42,349
So I guess let's just start at the very

15
00:00:42,360 --> 00:00:44,720
beginning and why don't you explain who you are,

16
00:00:44,729 --> 00:00:48,729
what the eff is and just kind of lay out the state of privacy.

17
00:00:48,740 --> 00:00:50,470
And I know that's, that's a depressing topic.

18
00:00:50,479 --> 00:00:54,310
But like, let's start with the sad things and then we'll talk about why there's hope,

19
00:00:54,560 --> 00:00:55,950
of course happy to.

20
00:00:56,130 --> 00:00:56,790
Um,

21
00:00:56,930 --> 00:00:58,689
and you know, it is, it is depressing.

22
00:00:58,700 --> 00:01:00,229
But, uh, you know, that's why we,

23
00:01:00,240 --> 00:01:02,509
that's why we are here and why we keep doing this work.

24
00:01:02,520 --> 00:01:03,909
So, yeah, so,

25
00:01:04,669 --> 00:01:10,809
so, yeah, my name is Haley. I've been at the eff about three years and some change.

26
00:01:10,819 --> 00:01:16,489
Now before that, I was a newspaper reporter in technology at the Washington Post.

27
00:01:16,500 --> 00:01:19,180
And I bring that up because it's important as to how I got

28
00:01:19,190 --> 00:01:22,889
into this job and why I think about privacy the way I do.

29
00:01:23,160 --> 00:01:28,419
So basically what my job is is that I work on our activism team,

30
00:01:28,430 --> 00:01:32,550
which is the team that kind of explains all of our positions and

31
00:01:32,559 --> 00:01:35,819
tries to get people fired up for good things and you know,

32
00:01:35,830 --> 00:01:37,720
fired up for bad things that we want to fight.

33
00:01:37,730 --> 00:01:41,500
We call ourselves the propaganda arm of eff

34
00:01:43,410 --> 00:01:44,989
we have a sense of humor.

35
00:01:45,279 --> 00:01:50,089
So obviously, journalism to advocacy could be a really weird path.

36
00:01:50,099 --> 00:01:54,110
But although I'm certainly not the only one who's taken it at eff, but basically,

37
00:01:54,120 --> 00:01:59,069
I was at the post for eight years covering technology out of our business section.

38
00:01:59,080 --> 00:01:59,980
And

39
00:02:00,239 --> 00:02:02,639
I got into being in tech

40
00:02:02,754 --> 00:02:04,894
technology. Well, both because I'm, you know, like

41
00:02:05,114 --> 00:02:07,324
classic geek in terms of the,

42
00:02:07,334 --> 00:02:09,675
the things that I bought and the things that I was interested in.

43
00:02:09,684 --> 00:02:11,044
But also because I,

44
00:02:11,345 --> 00:02:12,865
I was an intern,

45
00:02:12,875 --> 00:02:15,235
a newspaper intern during the summer that

46
00:02:15,244 --> 00:02:18,134
they were talking about the health care debate

47
00:02:18,145 --> 00:02:20,854
in DC and got really interested in health

48
00:02:20,865 --> 00:02:23,645
privacy and that kind of policy conversation.

49
00:02:23,824 --> 00:02:28,895
And that grew into a larger interest in privacy policy in general.

50
00:02:28,904 --> 00:02:32,505
Because I could see even then even when I had my feature phone,

51
00:02:33,300 --> 00:02:36,139
that data and uh you know,

52
00:02:36,149 --> 00:02:40,320
all of all data collection and data use were going to be big issues.

53
00:02:40,330 --> 00:02:42,080
So got really interested in that.

54
00:02:42,199 --> 00:02:45,520
And then, you know, like I said, I spent eight years at the post, I wore a lot of hats.

55
00:02:45,529 --> 00:02:49,800
I did earnings reports. I did policy coverage. I did product reviews.

56
00:02:49,809 --> 00:02:51,080
I did a lot of stuff

57
00:02:51,259 --> 00:02:51,770
and

58
00:02:52,539 --> 00:02:56,889
in the last couple of years just found myself getting really frustrated being like,

59
00:02:56,899 --> 00:02:57,580
hey,

60
00:02:57,630 --> 00:03:01,880
Facebook or Google or plug in your company had this

61
00:03:01,889 --> 00:03:05,889
huge breach or they're doing this really shady thing.

62
00:03:06,160 --> 00:03:11,059
And then two months later, having to be like, and they had the best earnings ever.

63
00:03:12,240 --> 00:03:14,770
-- Yeah, everybody lived happily ever after.
-- Exactly.

64
00:03:14,789 --> 00:03:17,919
And it was so frustrating to me because

65
00:03:18,190 --> 00:03:19,669
not to mention that I would, you know,

66
00:03:19,679 --> 00:03:23,300
I would have an inbox full of questions from people who are just like,

67
00:03:23,460 --> 00:03:27,360
wait, they're doing what I don't understand. What should I be doing for myself?

68
00:03:27,369 --> 00:03:29,429
What should I be doing for my Children? And I'm like,

69
00:03:29,690 --> 00:03:30,360
I mean,

70
00:03:30,770 --> 00:03:35,470
I'm a what, like a, at this point, like a 27 year old childless reporter.

71
00:03:35,479 --> 00:03:39,350
Like, I don't know what you should do about your Children. I'm really sorry.

72
00:03:39,759 --> 00:03:45,839
And I was like, gosh, this scenario that we're in is so hard and really,

73
00:03:45,850 --> 00:03:48,229
I think there has to be some change

74
00:03:48,440 --> 00:03:51,229
and I found myself wanting to do advocacy that just wasn't really

75
00:03:51,240 --> 00:03:54,820
that appropriate for the journalism that I was trying to do.

76
00:03:54,990 --> 00:03:59,029
So, I thought, ok, what if I just, instead of having no opinions

77
00:03:59,529 --> 00:04:02,690
and being very neutral, went and had opinions for a living?

78
00:04:02,699 --> 00:04:03,979
And so that is when I went to

79
00:04:04,160 --> 00:04:04,169
e,

80
00:04:05,080 --> 00:04:05,770
that's awesome.

81
00:04:06,880 --> 00:04:10,070
So that's kind of the background on me and what I do and, you know,

82
00:04:10,080 --> 00:04:15,779
and how I got here in terms of what I do day to day and the layout of privacy right now.

83
00:04:15,789 --> 00:04:18,579
So privacy is in a really interesting position right now.

84
00:04:18,589 --> 00:04:21,970
Right before I got to eff California passed the

85
00:04:21,980 --> 00:04:24,750
California Consumer Privacy Act or the C CPA,

86
00:04:24,760 --> 00:04:27,899
which is sort of a first of its kind privacy law.

87
00:04:28,000 --> 00:04:28,700
It's

88
00:04:28,940 --> 00:04:29,660
decent.

89
00:04:29,899 --> 00:04:31,809
It's not perfect, but

90
00:04:32,089 --> 00:04:35,299
I have definitely fought hard to defend it from getting worse

91
00:04:36,329 --> 00:04:37,790
-- and then from
-- there,

92
00:04:37,899 --> 00:04:39,709
you mean, like they were trying to repeal it or something?

93
00:04:39,760 --> 00:04:42,109
Well, I mean, after it was passed,

94
00:04:42,279 --> 00:04:43,869
you know, it, it sets up some basic rights.

95
00:04:43,880 --> 00:04:46,500
So, you know, a right to know what information people have on you.

96
00:04:46,510 --> 00:04:50,149
A right to delete it, a right to opt out of the sale of that information.

97
00:04:50,160 --> 00:04:51,230
Some other things.

98
00:04:51,369 --> 00:04:55,049
There was a year between when it passed and when it

99
00:04:55,059 --> 00:04:57,910
went into effect and that was the year that I started

100
00:04:58,140 --> 00:05:02,149
and everyone came out of the woodwork to try and gut this thing.

101
00:05:02,160 --> 00:05:04,299
And like, those are pretty basic rights.

102
00:05:04,950 --> 00:05:04,970
Yeah.

103
00:05:05,739 --> 00:05:09,420
If you are asking somebody to borrow something or, you know,

104
00:05:09,429 --> 00:05:11,959
if you're asking somebody, a friend of yours for something,

105
00:05:11,970 --> 00:05:15,320
you would in fact ask them if you could have it first.

106
00:05:15,510 --> 00:05:18,059
If you could, if you needed to share it with somebody,

107
00:05:18,070 --> 00:05:21,619
you would ask them if you could share it, you would be happy if they,

108
00:05:21,670 --> 00:05:24,010
if you would happily accept if they asked for it

109
00:05:24,019 --> 00:05:26,779
back and yet somehow when it comes to our information,

110
00:05:26,790 --> 00:05:31,399
we can't quite get on board with sort of what I think is really basic politeness.

111
00:05:33,209 --> 00:05:33,339
Yeah,

112
00:05:33,489 --> 00:05:33,500
I

113
00:05:33,769 --> 00:05:35,940
guess I jumped ahead of myself a little bit.

114
00:05:37,329 --> 00:05:40,890
But, yeah, so after C CPA passed,

115
00:05:41,140 --> 00:05:41,630
um,

116
00:05:42,070 --> 00:05:45,899
you know, obviously in, at the federal level, uh, you know,

117
00:05:45,910 --> 00:05:48,160
they've been promising to be really serious about

118
00:05:48,170 --> 00:05:52,239
federal privacy legislation since I believe I started reporting

119
00:05:52,380 --> 00:05:53,890
and probably before that,

120
00:05:54,070 --> 00:05:57,309
so there hasn't been a lot of movement on the federal level,

121
00:05:57,320 --> 00:06:00,220
although I can talk about that about what we have seen as well,

122
00:06:01,170 --> 00:06:05,450
but we have seen a lot of action in the States because people looked at California

123
00:06:05,619 --> 00:06:06,769
and either they said,

124
00:06:06,880 --> 00:06:07,410
oh,

125
00:06:07,570 --> 00:06:08,179
I kind of want

126
00:06:08,279 --> 00:06:11,940
those protections in my state or as we're actually seeing happen

127
00:06:12,070 --> 00:06:13,260
more like, uh,

128
00:06:13,269 --> 00:06:16,760
businesses and chambers of commerce and folks who want to keep

129
00:06:16,769 --> 00:06:19,619
the status quo as it is when it comes to privacy,

130
00:06:19,630 --> 00:06:22,640
said, oh, well, we can't let that law get out,

131
00:06:22,790 --> 00:06:25,399
uh, out of its containment in California

132
00:06:25,570 --> 00:06:26,420
and so

133
00:06:26,529 --> 00:06:32,619
they have introduced really weak privacy bills across the country. Um that I spend

134
00:06:32,750 --> 00:06:34,380
the bulk of my time right now

135
00:06:34,640 --> 00:06:38,190
trying to stall uh improve

136
00:06:38,369 --> 00:06:39,279
kill

137
00:06:39,559 --> 00:06:41,239
or get alternatives to

138
00:06:41,359 --> 00:06:42,799
so on privacy.

139
00:06:43,390 --> 00:06:44,029
You know, it's,

140
00:06:44,040 --> 00:06:48,640
it's a lot of part of the beauty of being a state level activist is that

141
00:06:48,649 --> 00:06:53,950
you get to talk to people all across the country and um get to kind of articulate

142
00:06:54,220 --> 00:06:59,010
these issues for them and, and you know, kind of hear what's happening in,

143
00:06:59,019 --> 00:07:00,589
in places all across the country.

144
00:07:00,839 --> 00:07:04,329
The frustrating thing is that I do repeat myself a lot because

145
00:07:04,339 --> 00:07:07,750
I'm trying to influence policy debates in a number of states.

146
00:07:07,760 --> 00:07:11,980
So, all right, let me, let me reel us back just a little bit first. So

147
00:07:12,269 --> 00:07:17,019
what is the eff I'm sure many of us have heard of them, but I have a suspicion.

148
00:07:17,029 --> 00:07:22,299
There's what a lot of us think the eff is and then there's what the eff really is,

149
00:07:22,910 --> 00:07:26,200
right? We're not just a collection of cats talking about

150
00:07:27,250 --> 00:07:28,730
about internet issues,

151
00:07:29,049 --> 00:07:30,130
although, well, anyway,

152
00:07:31,290 --> 00:07:33,549
sure, sorry, I got, I got way ahead of myself.

153
00:07:33,559 --> 00:07:40,390
So eff the Electronic Frontier Foundation is a nonprofit dedicated to protecting

154
00:07:40,529 --> 00:07:46,899
human and civil rights in the digital age. We were founded in 1990. Our principal.

155
00:07:46,929 --> 00:07:49,529
Oh gosh, I sound like the Spanish inquisition. Sorry,

156
00:07:50,940 --> 00:07:51,559
this is great.

157
00:07:51,670 --> 00:07:54,299
This is great. I was going to say our principal issues are,

158
00:07:56,839 --> 00:07:56,869
yeah,

159
00:07:58,019 --> 00:08:02,890
are kind of the three pillars of our advocacy really are privacy.

160
00:08:02,899 --> 00:08:04,309
So protecting privacy,

161
00:08:04,410 --> 00:08:08,510
standing up against government surveillance and promoting innovation

162
00:08:08,609 --> 00:08:11,730
under that very broad set of issues.

163
00:08:11,739 --> 00:08:12,209
You know,

164
00:08:12,220 --> 00:08:16,380
I'm just trying to think in terms of issues that we've dealt most with in the States.

165
00:08:16,390 --> 00:08:18,140
You know, I mean, consumer privacy

166
00:08:18,263 --> 00:08:20,483
obviously comes up a lot

167
00:08:20,713 --> 00:08:24,562
uh anti-government surveillance. You know, we

168
00:08:24,743 --> 00:08:27,113
call for bans on government use of

169
00:08:27,122 --> 00:08:29,993
face recognition technology on the innovation side,

170
00:08:30,002 --> 00:08:32,222
you know, that means things like broadband access,

171
00:08:32,232 --> 00:08:34,732
that means things like copyright policy reform.

172
00:08:34,741 --> 00:08:38,482
So, you know, we get involved in a lot of policy fights

173
00:08:38,596 --> 00:08:42,255
and you know, we have a real kind of bottom up

174
00:08:42,515 --> 00:08:46,625
philosophy of consumer protection and consumer rights.

175
00:08:46,635 --> 00:08:53,276
In every case, we try to advocate for the user or the person, you know,

176
00:08:53,286 --> 00:08:55,856
I like to think of them as people rather than users.

177
00:08:55,866 --> 00:08:56,395
But,

178
00:08:59,570 --> 00:09:00,299
but you know,

179
00:09:00,309 --> 00:09:04,150
we advocate for the individual because obviously these are all

180
00:09:04,159 --> 00:09:06,409
policy fights where there is a lot of money,

181
00:09:06,419 --> 00:09:09,190
there are a lot of big businesses thrown around and

182
00:09:09,200 --> 00:09:12,340
oftentimes the individual is the one who gets trampled first.

183
00:09:12,510 --> 00:09:14,919
-- That's right, like the Lorax of the internet,
-- right?

184
00:09:17,130 --> 00:09:18,210
That's what we should,

185
00:09:18,390 --> 00:09:20,020
that's what we should call ourselves. Yeah,

186
00:09:21,760 --> 00:09:23,659
I would buy that t-shirt just by the way.

187
00:09:23,849 --> 00:09:24,380
But

188
00:09:25,070 --> 00:09:28,460
I, I love t-shirts. I'm not wearing my eff shirt today, but

189
00:09:28,630 --> 00:09:34,679
ok, cool. So now let's move ourselves over to privacy because I think privacy is

190
00:09:35,109 --> 00:09:38,700
so important and more and more people are paying attention and

191
00:09:38,979 --> 00:09:42,650
there's a lot going on that I think many of us don't even know about.

192
00:09:42,659 --> 00:09:45,559
But obviously that's why you're here to tell us.

193
00:09:46,302 --> 00:09:46,973
It's a big set up

194
00:09:47,513 --> 00:09:47,903
where you want it.

195
00:09:49,372 --> 00:09:50,072
Part of the fun.

196
00:09:50,572 --> 00:09:50,763
Yeah.

197
00:09:50,773 --> 00:09:52,562
So privacy obviously is, is,

198
00:09:52,572 --> 00:09:55,872
is a huge issue and I think you're absolutely right that

199
00:09:55,882 --> 00:09:59,562
it's risen in prominence in the past five or six years.

200
00:09:59,572 --> 00:10:01,562
I would say more people are thinking about it,

201
00:10:01,572 --> 00:10:03,643
more people are realizing they have to think about it.

202
00:10:03,653 --> 00:10:05,663
You know, when I think of privacy,

203
00:10:05,963 --> 00:10:07,682
it's, it's hard, it's a lot of things,

204
00:10:07,796 --> 00:10:09,765
right? But I generally think of

205
00:10:10,096 --> 00:10:14,325
the state of data collection, right? So how much information

206
00:10:14,606 --> 00:10:19,565
companies are gathering about us with and without our knowledge,

207
00:10:19,575 --> 00:10:21,026
I think about data use.

208
00:10:21,036 --> 00:10:26,335
So how they're actually, you know, some companies do just sit on troves of data,

209
00:10:26,466 --> 00:10:27,015
you know, smog

210
00:10:27,166 --> 00:10:29,135
like just because they never want to delete it.

211
00:10:29,799 --> 00:10:30,530
But

212
00:10:30,690 --> 00:10:33,539
often they're using that information either to

213
00:10:33,549 --> 00:10:36,549
build profiles about you um suggest,

214
00:10:36,559 --> 00:10:36,719
you know,

215
00:10:36,729 --> 00:10:39,780
things that you should be doing uh or products that you might

216
00:10:39,789 --> 00:10:43,020
want to buy or services that you might need in your life.

217
00:10:43,030 --> 00:10:46,020
Like Instagram for some reason, thinks I really need pillows.

218
00:10:46,030 --> 00:10:48,460
I don't know what that says about what I've been doing on Instagram.

219
00:10:50,270 --> 00:10:52,080
They're like you need to sleep Haley,

220
00:10:52,340 --> 00:10:52,799
right?

221
00:10:52,809 --> 00:10:55,750
To building profiles and making suggestions about things to do

222
00:10:55,760 --> 00:11:00,130
and then also how they share and sell that information.

223
00:11:00,140 --> 00:11:03,080
So how that information flows between companies

224
00:11:03,090 --> 00:11:05,460
and that's where it gets really messy.

225
00:11:05,469 --> 00:11:07,580
I mean, there are lots of places, I guess where it gets messy.

226
00:11:07,590 --> 00:11:10,219
But when we get to the share and sale of information to me,

227
00:11:10,229 --> 00:11:14,520
I find that to be the most opaque piece of this web, you know,

228
00:11:14,530 --> 00:11:17,710
the part that we have the least insight into because it's a lot of, you know,

229
00:11:17,719 --> 00:11:19,020
agreements between companies,

230
00:11:19,130 --> 00:11:22,909
things that are in public and things that I can't get a public records request on.

231
00:11:22,919 --> 00:11:24,109
But then of course,

232
00:11:24,119 --> 00:11:27,840
each of those companies then uses data in their own way and stores

233
00:11:27,849 --> 00:11:31,239
it in their own way and possibly shares it in their own way.

234
00:11:31,250 --> 00:11:36,260
And so it gets really out of control for people very quickly and, you know,

235
00:11:36,270 --> 00:11:39,109
in terms of so people are like, ok, so there's a lot of data,

236
00:11:39,119 --> 00:11:42,109
I get it like people are collecting information about me, you know,

237
00:11:42,119 --> 00:11:44,739
because every cookie wall that comes up, I'm like, yeah, whatever.

238
00:11:44,750 --> 00:11:45,950
Just like, let me read the thing.

239
00:11:46,619 --> 00:11:46,700
Yeah.

240
00:11:47,299 --> 00:11:49,599
So what's the big deal? And that is,

241
00:11:50,049 --> 00:11:54,130
it's both really difficult because as I said,

242
00:11:54,140 --> 00:11:56,760
it's really opaque and harms can be very

243
00:11:57,020 --> 00:11:58,030
societal.

244
00:11:58,219 --> 00:12:00,289
So, you know, you have things like,

245
00:12:00,530 --> 00:12:06,000
well, you know, when uh when companies are collecting information and they,

246
00:12:06,010 --> 00:12:08,289
you know, are trying to guess, for example,

247
00:12:08,299 --> 00:12:11,479
if you're worthy of a credit card or a business loan or a mortgage loan

248
00:12:11,715 --> 00:12:12,544
and,

249
00:12:12,684 --> 00:12:15,065
you know, they have decided, well, we,

250
00:12:15,075 --> 00:12:16,974
we aren't going to look at race but what if we look

251
00:12:16,984 --> 00:12:20,484
at zip code or place where you graduated from high school,

252
00:12:20,494 --> 00:12:23,765
that kind of thing that, you know, Tobias definitely gets

253
00:12:23,945 --> 00:12:24,705
into these

254
00:12:24,895 --> 00:12:30,744
uh, profiles, um, and has like serious discriminatory risks and, you know,

255
00:12:30,755 --> 00:12:32,974
that's kind of hard to uh

256
00:12:33,215 --> 00:12:35,734
particularize down to the individual. Right? Because

257
00:12:35,835 --> 00:12:36,945
you're like, well, but

258
00:12:37,229 --> 00:12:40,169
it's because they have so much information, you know, it's hard to,

259
00:12:40,690 --> 00:12:43,020
I mean, as with data breaches, right? It's like,

260
00:12:43,190 --> 00:12:44,890
you know, your data was breached,

261
00:12:44,900 --> 00:12:48,900
but it's hard for you to connect like a particular instance of, uh you know,

262
00:12:48,909 --> 00:12:52,010
somebody maybe trying to use your credit card to a particular breach.

263
00:12:52,270 --> 00:12:54,390
Like you can't be like, oh, I got this notice from Visa.

264
00:12:54,400 --> 00:12:58,890
It's because of Target's Breach, right? It's hard to draw that line.

265
00:12:59,020 --> 00:13:01,859
-- Well,
-- except when it's like Home Depot and it's millions of us.

266
00:13:03,190 --> 00:13:06,969
Well, especially when it's like a bunch of really big breaches all at once.

267
00:13:06,979 --> 00:13:08,559
It's like it could have been any of them.

268
00:13:11,190 --> 00:13:14,140
You can't like, put a little ink tag on your, I mean, you know,

269
00:13:14,859 --> 00:13:15,250
in your,

270
00:13:15,260 --> 00:13:18,030
in your mind on the data that got breached out of Target

271
00:13:18,039 --> 00:13:21,099
or Home Depot and see it come back to you unfortunately.

272
00:13:21,109 --> 00:13:23,270
So that can be a little hard for people to conceptualize.

273
00:13:23,280 --> 00:13:27,380
But people do get the idea of like weird ads that follow you on the

274
00:13:27,390 --> 00:13:32,659
internet of like that weird ad maybe being seen by somebody else in your family.

275
00:13:32,669 --> 00:13:35,219
There's the classic. Now example of,

276
00:13:35,349 --> 00:13:39,539
I don't mean to pick on Target. It's just what's in my, it must be the Minnesota in me.

277
00:13:40,900 --> 00:13:44,280
But, you know, there was a girl who was looking, she was pregnant.

278
00:13:44,289 --> 00:13:45,500
She hadn't told anybody,

279
00:13:45,510 --> 00:13:51,700
she particularly hadn't told her father who was upset when he got a mailer in, in his,

280
00:13:51,710 --> 00:13:52,099
you know,

281
00:13:52,109 --> 00:13:55,190
in the mail from Target saying someone in your house is

282
00:13:55,200 --> 00:13:58,840
pregnant here are our deals and then got really mad,

283
00:13:58,849 --> 00:13:59,969
told Target about it.

284
00:13:59,979 --> 00:14:03,539
And then later had to be like, uh, so she's pregnant and she didn't tell me.

285
00:14:03,809 --> 00:14:04,229
Right.

286
00:14:04,239 --> 00:14:07,469
That's probably not how you want your parents to find out that you're pregnant.

287
00:14:08,799 --> 00:14:10,330
There are definitely situations where that

288
00:14:10,340 --> 00:14:12,340
would probably be actually really dangerous,

289
00:14:12,549 --> 00:14:14,570
you know, to a person in that situation.

290
00:14:14,840 --> 00:14:15,469
So

291
00:14:16,109 --> 00:14:18,739
privacy is kind of all, all of these things.

292
00:14:18,750 --> 00:14:23,440
It's, uh, it's related to advertising, it's related to data sharing agreements.

293
00:14:23,450 --> 00:14:24,659
It's related to

294
00:14:25,030 --> 00:14:29,380
the very web that we, uh, that we swim around in all day

295
00:14:29,580 --> 00:14:31,559
and the kind of information that we shed.

296
00:14:31,570 --> 00:14:34,440
So one thing I'm wondering because I mean, I've basically been involved, you know,

297
00:14:34,450 --> 00:14:36,059
with like, for example, the cipher

298
00:14:36,200 --> 00:14:38,349
punks, the eff since, well, the late nineties.

299
00:14:38,359 --> 00:14:40,599
And honestly, I've sort of given up on privacy as

300
00:14:40,969 --> 00:14:46,099
the way I think of privacy was, I think from, say roughly about 1950 to 1980

301
00:14:46,450 --> 00:14:47,479
maybe 1990 ish.

302
00:14:47,809 --> 00:14:48,200
But

303
00:14:48,929 --> 00:14:51,659
just, especially with the internet being so heavily driven by advertising,

304
00:14:51,669 --> 00:14:55,210
it seems there's this just ridiculous set of incentives for businesses

305
00:14:55,440 --> 00:14:55,950
to

306
00:14:56,809 --> 00:14:59,270
just be super anti privacy and,

307
00:14:59,409 --> 00:15:03,659
you know, poorly monetize people's data through advertising, another

308
00:15:04,140 --> 00:15:06,489
not very effective or efficient behaviors.

309
00:15:06,789 --> 00:15:07,270
And

310
00:15:07,599 --> 00:15:10,479
like, when I look at that, it's like, I just, how do we compete with that? Right.

311
00:15:10,489 --> 00:15:13,349
I've seen many companies try to do privacy based offerings

312
00:15:13,609 --> 00:15:17,650
and they've, like, all failed. And I guess like, so we have, do we legislate it?

313
00:15:17,659 --> 00:15:19,460
Do we get the government to care? Because,

314
00:15:20,039 --> 00:15:22,059
like, I don't think I've ever seen a company

315
00:15:22,330 --> 00:15:24,190
voluntarily do the right thing.

316
00:15:24,400 --> 00:15:24,570
Great

317
00:15:24,719 --> 00:15:25,219
question. Yeah.

318
00:15:25,229 --> 00:15:26,239
So I think, you know,

319
00:15:26,250 --> 00:15:32,969
eff in general we're very wary about legislation but on consumer privacy, you know,

320
00:15:32,979 --> 00:15:37,340
before I, before I got here they had a real shift because they said, ok,

321
00:15:37,830 --> 00:15:41,770
how much more proof do we need that companies are? And you're absolutely right.

322
00:15:41,780 --> 00:15:43,090
It's about incentives, right.

323
00:15:43,099 --> 00:15:43,330
I,

324
00:15:43,340 --> 00:15:45,419
I don't like to actually think of the companies

325
00:15:45,429 --> 00:15:48,090
as being evil because I think that's not super helpful

326
00:15:48,359 --> 00:15:50,130
in changing behavior. Right.

327
00:15:50,140 --> 00:15:53,460
It's like, how do we get these companies incentives to change?

328
00:15:53,469 --> 00:15:55,210
And you're right, right. Now, they're just

329
00:15:55,619 --> 00:15:56,500
extractive, right?

330
00:15:56,510 --> 00:16:00,559
I mean, the idea is that you just get all the information that you possibly can,

331
00:16:00,570 --> 00:16:03,840
you monetize every little bit of it and you never let any of it go

332
00:16:04,090 --> 00:16:06,039
and that is the profit model.

333
00:16:06,049 --> 00:16:12,789
And so what we are trying to accomplish with legislation is, I mean, several things,

334
00:16:12,799 --> 00:16:12,989
right?

335
00:16:13,000 --> 00:16:14,640
But it's, it's getting

336
00:16:15,044 --> 00:16:17,094
rules in place to just be like, look,

337
00:16:17,244 --> 00:16:20,205
you shouldn't collect more information than you need to like,

338
00:16:20,215 --> 00:16:23,005
do the thing that you're trying to do, right.

339
00:16:23,015 --> 00:16:26,224
So to provide the good or service that you're, that you're trying to provide,

340
00:16:26,234 --> 00:16:28,765
so that limits new information that comes in,

341
00:16:29,005 --> 00:16:32,744
right? We're trying to get people to erase their information more, right?

342
00:16:32,755 --> 00:16:34,385
The kind of set,

343
00:16:34,900 --> 00:16:37,619
well, gosh, set retention periods in the first place,

344
00:16:37,630 --> 00:16:40,159
but lower them in as many cases as possible.

345
00:16:40,169 --> 00:16:42,880
And we're trying to get people to just, you know,

346
00:16:42,979 --> 00:16:45,719
uh if you're going to sell or share the information,

347
00:16:45,729 --> 00:16:47,679
just let me know and let me say yes or no,

348
00:16:47,690 --> 00:16:50,520
I totally understand the sort of we call it privacy, nihilism.

349
00:16:50,530 --> 00:16:52,119
And I have my days I tell you

350
00:16:53,739 --> 00:16:56,989
that you're expressing, but the truth is that when it comes to advertising,

351
00:16:57,000 --> 00:16:59,849
especially they're relying on new information, right?

352
00:16:59,859 --> 00:17:02,210
They need new information all of the time.

353
00:17:02,289 --> 00:17:07,430
And so we actually as consumers have more power than we think in,

354
00:17:07,439 --> 00:17:11,319
in terms of controlling the inflow of that information.

355
00:17:11,368 --> 00:17:11,880
And

356
00:17:12,010 --> 00:17:15,390
you know, I mean, speaking for myself, like I'm 35.

357
00:17:15,569 --> 00:17:19,848
So information on me even three years ago or, you know,

358
00:17:19,858 --> 00:17:23,300
10 years ago would not be useful in terms of targeting me right now.

359
00:17:23,310 --> 00:17:24,699
I lived a very different life.

360
00:17:24,839 --> 00:17:26,530
And so, you know, they, they're all,

361
00:17:26,540 --> 00:17:28,900
they always need new information to do the things that they're

362
00:17:28,910 --> 00:17:31,349
doing otherwise they wouldn't be fighting my loss so hard.

363
00:17:33,300 --> 00:17:37,160
So, III, I think you just said something that's really interesting

364
00:17:37,290 --> 00:17:39,839
talking about the information from a couple of years ago.

365
00:17:39,849 --> 00:17:42,670
So the eff has a podcast called How To Fix The Internet,

366
00:17:42,680 --> 00:17:44,020
which I'll put a link in the show notes.

367
00:17:44,030 --> 00:17:46,439
It's, and it's my favorite podcast by far.

368
00:17:47,410 --> 00:17:47,839
And

369
00:17:48,390 --> 00:17:51,380
the latest episode I listened to, I think I might be a couple behind.

370
00:17:51,390 --> 00:17:52,939
I don't remember the title of it, but

371
00:17:53,140 --> 00:17:56,010
the, the guest they had on was saying that

372
00:17:56,290 --> 00:17:57,479
he was

373
00:17:57,630 --> 00:18:01,339
an alcoholic in the past and the internet still is

374
00:18:01,349 --> 00:18:05,530
trying to sell him alcohol even though he's clean and,

375
00:18:05,540 --> 00:18:06,780
and doesn't drink anymore.

376
00:18:06,790 --> 00:18:10,530
But like the, the ads are trying so hard, even though that's

377
00:18:11,199 --> 00:18:13,739
in the past and not something he's interested in.

378
00:18:13,750 --> 00:18:15,719
And I'd never really considered that.

379
00:18:15,729 --> 00:18:19,079
But this concept of all this data that people have on you, I

380
00:18:19,469 --> 00:18:19,890
should say people,

381
00:18:19,900 --> 00:18:24,270
all this data companies have on you doesn't necessarily apply to who you are today.

382
00:18:24,280 --> 00:18:27,780
-- And that's kind of horrifying in some ways. Yeah.
-- I mean, that is true.

383
00:18:27,790 --> 00:18:31,119
I think, you know what we're seeing there is a, is a lag, right.

384
00:18:31,130 --> 00:18:32,900
Obviously they're still collecting new

385
00:18:33,430 --> 00:18:35,150
about him that, that, you know, could,

386
00:18:35,160 --> 00:18:37,079
could maybe change the way that he likes it ads.

387
00:18:37,089 --> 00:18:38,030
But you're absolutely right.

388
00:18:38,219 --> 00:18:38,810
And that is,

389
00:18:39,030 --> 00:18:40,670
that is to what we're talking about when

390
00:18:40,680 --> 00:18:42,949
we're talking about building profiles of people.

391
00:18:42,959 --> 00:18:45,810
So either outdated information can follow you around,

392
00:18:45,819 --> 00:18:48,349
incorrect information can follow you around.

393
00:18:48,650 --> 00:18:49,150
Um

394
00:18:50,079 --> 00:18:52,520
Like Google used to guess that based on my love of

395
00:18:52,530 --> 00:18:55,390
business news that I was like a 60 year old man,

396
00:18:57,439 --> 00:18:58,819
which rude.

397
00:18:59,829 --> 00:19:03,859
So I remember when GDPR came out and, you know, everybody in like,

398
00:19:04,189 --> 00:19:04,930
was it

399
00:19:05,069 --> 00:19:05,079
a

400
00:19:05,189 --> 00:19:07,910
no, it was a Dutch privacy legislation predate GDPR.

401
00:19:07,920 --> 00:19:10,400
Anyways, everybody in Holland got like these little cards in the mail,

402
00:19:10,510 --> 00:19:13,650
you know, saying this company or this church or whatever has data on you.

403
00:19:13,660 --> 00:19:14,780
Did you know that kind of thing?

404
00:19:15,050 --> 00:19:16,839
And I'm just thinking like, for example,

405
00:19:16,849 --> 00:19:18,959
I worked for a company that was acquired by a much bigger company and they

406
00:19:18,969 --> 00:19:20,390
wanted to do background checks on everybody

407
00:19:20,400 --> 00:19:22,109
and because I was Canadian not American,

408
00:19:22,119 --> 00:19:23,689
you know, they couldn't just do it right.

409
00:19:23,699 --> 00:19:26,280
They actually had to kind of get my permission and I'm like, ok, well,

410
00:19:26,380 --> 00:19:28,569
I'll, I'll do it if I get to see the data and they're like, what?

411
00:19:28,579 --> 00:19:30,670
And I'm like, I would like to make sure the date is correct. And

412
00:19:30,790 --> 00:19:34,459
what was shocking is apparently nobody had ever asked this before to like

413
00:19:34,770 --> 00:19:36,170
valid. You know what I mean? Like,

414
00:19:36,275 --> 00:19:39,055
yeah, you can do a background check on me. Sure. I'm, I'm sure it's right. You know,

415
00:19:39,265 --> 00:19:41,125
that's, which strikes me as insane

416
00:19:41,305 --> 00:19:43,435
and, and there was actually a major factual error on it.

417
00:19:43,444 --> 00:19:47,714
There was this weird $500 credit instrument that both myself and my bank had.

418
00:19:47,724 --> 00:19:49,714
We, we could not figure out what they were talking about.

419
00:19:50,395 --> 00:19:53,064
But I'm, I'm kind of wondering because that doesn't really scale, right?

420
00:19:53,074 --> 00:19:54,775
Because if every single company that holds data

421
00:19:54,785 --> 00:19:57,375
on me kind of asked me for permission,

422
00:19:58,099 --> 00:19:59,859
you know, that's going to be 100 like I

423
00:20:00,069 --> 00:20:01,520
don't want to spend time doing that.

424
00:20:02,579 --> 00:20:05,180
Like I guess what I'm saying is II I kind

425
00:20:05,189 --> 00:20:07,400
of don't want to force this on the individual because

426
00:20:07,560 --> 00:20:08,089
like,

427
00:20:08,290 --> 00:20:12,439
-- you know, I'd like to do other things with my life than manage my data.
-- Right?

428
00:20:12,680 --> 00:20:15,000
And again, I think a totally valid point. So

429
00:20:15,810 --> 00:20:16,270
yes,

430
00:20:16,599 --> 00:20:19,140
-- ideally what we
-- like, how do we fix that?

431
00:20:20,069 --> 00:20:20,739
Oh

432
00:20:21,380 --> 00:20:22,920
I mean, I think no matter how we fix it,

433
00:20:22,930 --> 00:20:27,130
you're right that there will be a really difficult period where people

434
00:20:27,140 --> 00:20:29,579
are getting a ton of notices and I don't love that,

435
00:20:29,589 --> 00:20:30,339
but that

436
00:20:30,439 --> 00:20:32,300
is part of what comes with change.

437
00:20:33,300 --> 00:20:34,349
But I think

438
00:20:34,479 --> 00:20:38,760
so the way that we think about it is which right now we're basically an opt out

439
00:20:38,869 --> 00:20:41,359
kind of society when it comes to data, right?

440
00:20:41,369 --> 00:20:45,000
So people, right, you go to a site and they're like, hey,

441
00:20:45,010 --> 00:20:46,500
we're collecting information on you.

442
00:20:46,510 --> 00:20:50,239
If you don't like that, tell us to stop. I mean, if you even get that right?

443
00:20:50,410 --> 00:20:54,199
And what we're hoping is that people will see the benefit of an opt

444
00:20:54,425 --> 00:20:57,135
in now. There are still ways that

445
00:20:57,244 --> 00:21:00,935
that is so, you know, so that they have to ask before they collect.

446
00:21:00,944 --> 00:21:05,875
Um, and so in that way, over time, you know, you're at least not

447
00:21:06,265 --> 00:21:09,234
making new relationships with companies you've never heard of, uh,

448
00:21:09,385 --> 00:21:11,094
-- you know, without your knowledge.
-- Oh, yeah.

449
00:21:11,104 --> 00:21:13,824
No, I got AAA data breach notice in the mail.

450
00:21:13,834 --> 00:21:15,194
Uh, there was a thing in Canada where this,

451
00:21:15,755 --> 00:21:18,555
so when you get a furnace like a furnace for your house,

452
00:21:18,854 --> 00:21:21,545
the warranty stuff is actually sold off to like

453
00:21:21,555 --> 00:21:23,464
a third party company that basically does like,

454
00:21:23,709 --> 00:21:27,410
like it's like stock market level of tranches of reselling this.

455
00:21:27,420 --> 00:21:29,790
You know what I mean? It's like a whole financial gobbledygook

456
00:21:29,900 --> 00:21:30,280
thing.

457
00:21:30,459 --> 00:21:32,800
And so this company I've never heard of got breached.

458
00:21:32,810 --> 00:21:37,060
And well, I got a notice in the mail saying my data had been breached and I've,

459
00:21:37,069 --> 00:21:40,589
I've never even heard of this company or never meant to do business with them.

460
00:21:40,599 --> 00:21:42,050
You know, I just needed a furnace.

461
00:21:43,109 --> 00:21:44,650
How dare you need a furnace

462
00:21:46,250 --> 00:21:46,890
in Canada?

463
00:21:48,969 --> 00:21:52,119
Yeah. So we are hoping to kind of flip to an opt

464
00:21:52,229 --> 00:21:56,949
in regime or barring that because there's obviously a lot of political

465
00:21:56,959 --> 00:22:00,660
unease shall we say about switching to that kind of model,

466
00:22:00,670 --> 00:22:04,770
getting people to recognize things like browser signals so that, you know, I mean,

467
00:22:04,780 --> 00:22:05,439
it's hard to use,

468
00:22:05,449 --> 00:22:09,050
do not track as a as an example because to people who

469
00:22:09,060 --> 00:22:12,910
know all about that long saga because obviously do not track,

470
00:22:12,920 --> 00:22:14,709
did not live up to our hopes.

471
00:22:14,719 --> 00:22:16,130
But there is a hope that we

472
00:22:16,243 --> 00:22:19,312
do something like do not track in a browser signal to say,

473
00:22:19,442 --> 00:22:22,422
OK, this signal I'm sending is saying that I,

474
00:22:22,672 --> 00:22:26,542
you know, opt out of the sale or collection of my information

475
00:22:26,713 --> 00:22:29,182
and that companies will have to recognize those

476
00:22:29,192 --> 00:22:31,493
signals as opt out requests so that it's not

477
00:22:31,672 --> 00:22:35,262
so much on the, on the individual to manage their privacy.

478
00:22:35,272 --> 00:22:36,902
Because I think you're absolutely right,

479
00:22:36,912 --> 00:22:40,383
kind of the way that the industry exists now

480
00:22:40,392 --> 00:22:43,442
and the way that the solutions that are politically,

481
00:22:43,576 --> 00:22:45,556
politically feasible to push through it still puts a

482
00:22:45,566 --> 00:22:48,495
lot of burden on um on the individual,

483
00:22:48,505 --> 00:22:51,475
which is a real concern I have as well.

484
00:22:51,485 --> 00:22:55,956
Ok. So let's, let's talk about that for a minute because you're doing some work.

485
00:22:55,965 --> 00:23:00,515
I, I read an article that you and some other folks from the eff wrote

486
00:23:00,686 --> 00:23:03,796
about Washington State has a privacy bill

487
00:23:03,995 --> 00:23:04,595
that

488
00:23:04,946 --> 00:23:06,196
from what I read,

489
00:23:06,416 --> 00:23:10,836
it is hilariously bad. I, I think, I mean, this is the challenge though, is

490
00:23:11,270 --> 00:23:14,290
all of these organizations are

491
00:23:14,530 --> 00:23:19,400
working their best to create these bills that make sure

492
00:23:20,109 --> 00:23:21,790
no one gets real privacy.

493
00:23:22,180 --> 00:23:23,050
That is true.

494
00:23:23,260 --> 00:23:28,050
Um So the Microsoft bill that you point to, it's a, it's a couple of years old now,

495
00:23:28,060 --> 00:23:30,239
but it just keeps coming back like,

496
00:23:30,540 --> 00:23:32,410
like my least favorite zombie.

497
00:23:32,680 --> 00:23:33,510
Um

498
00:23:33,859 --> 00:23:36,260
And uh yeah, it's it's weak.

499
00:23:36,270 --> 00:23:42,739
I mean, it is essentially um it was uh written in Washington State, which is,

500
00:23:42,750 --> 00:23:46,349
of course the home of a lot of big tech companies, notably Microsoft,

501
00:23:46,359 --> 00:23:51,739
which plays a very good state level state legislator ground game.

502
00:23:51,750 --> 00:23:52,540
And

503
00:23:52,680 --> 00:23:58,135
you know, they, they come in and they say, look, we understand the need to,

504
00:23:58,145 --> 00:23:59,925
to address privacy.

505
00:24:00,025 --> 00:24:01,145
You know, I can't, I,

506
00:24:01,314 --> 00:24:02,854
I can't even tell you how many

507
00:24:03,104 --> 00:24:03,614
like

508
00:24:03,805 --> 00:24:04,814
really

509
00:24:04,984 --> 00:24:06,594
awful businesses I've heard say,

510
00:24:06,604 --> 00:24:09,265
but privacy is at the heart of everything we do and I'm like,

511
00:24:09,275 --> 00:24:12,854
no managing risk is at the heart of everything you do.

512
00:24:12,944 --> 00:24:14,964
You don't care about privacy.

513
00:24:16,560 --> 00:24:17,150
That's right.

514
00:24:17,319 --> 00:24:18,010
Anyway,

515
00:24:18,239 --> 00:24:22,349
you know, and they come in and they say, look, we have this privacy bill.

516
00:24:22,359 --> 00:24:25,069
It says it's a privacy protection act right at the top,

517
00:24:25,359 --> 00:24:26,369
right. You know. Right.

518
00:24:26,699 --> 00:24:27,349
Right in the head

519
00:24:29,089 --> 00:24:32,170
and it proceeds to say like, you know,

520
00:24:32,319 --> 00:24:34,619
yes, we will give you the rights to know,

521
00:24:35,069 --> 00:24:35,760
know what

522
00:24:36,055 --> 00:24:37,385
information we have on you.

523
00:24:37,604 --> 00:24:42,435
And if you prove who you are, maybe we'll let you opt out if you ask us to delete it,

524
00:24:42,444 --> 00:24:45,555
we will consider your request and let you know.

525
00:24:45,564 --> 00:24:47,005
-- That's actually
-- a big thing because like,

526
00:24:47,015 --> 00:24:50,694
I'm actually the deep like on the DPO for the Cloud Secure Alliance.

527
00:24:50,814 --> 00:24:54,025
And I remember we have a person who works for the

528
00:24:54,035 --> 00:24:55,854
CS A who actually used to be at a regulator.

529
00:24:56,130 --> 00:24:59,329
And I remember asking him like, so if somebody sends a GDPR right?

530
00:24:59,339 --> 00:25:00,869
To be forgotten request.

531
00:25:01,180 --> 00:25:04,800
Like, from the email address they're asking us to delete. I'm like, that's easy.

532
00:25:04,810 --> 00:25:08,469
Right. You know, Bob Smith at gmail.com, please delete my email. Cool.

533
00:25:08,479 --> 00:25:09,189
But, you know,

534
00:25:09,400 --> 00:25:12,589
if they ask for like, Bob Smith to be deleted, I'm like, how do we,

535
00:25:12,599 --> 00:25:13,520
how do we verify that?

536
00:25:13,530 --> 00:25:16,119
Because, like, I, I don't know what an Estonian passport looks like

537
00:25:16,489 --> 00:25:18,060
and I don't want to ask for more info

538
00:25:18,479 --> 00:25:19,199
and I'm like,

539
00:25:19,329 --> 00:25:20,280
I'm just

540
00:25:20,420 --> 00:25:21,819
like, what do we do? Right.

541
00:25:21,829 --> 00:25:23,380
And he's like, ah, just do your best and, you know,

542
00:25:23,390 --> 00:25:25,099
we'll just delete stuff because we don't really care.

543
00:25:25,109 --> 00:25:26,260
We just want to get rid of it and,

544
00:25:26,430 --> 00:25:28,819
you know, not annoy people but from a company's point of view.

545
00:25:28,829 --> 00:25:31,589
Like, there's, well, I love this, there's actually four curtsy free

546
00:25:31,760 --> 00:25:34,369
on the planet and all of us work in tech and

547
00:25:34,380 --> 00:25:36,920
are roughly the same age and just basically white guys,

548
00:25:37,099 --> 00:25:38,599
you know, there's one in California,

549
00:25:38,609 --> 00:25:41,400
one in the Western US and one in Germany and myself.

550
00:25:41,410 --> 00:25:42,000
And it's like,

551
00:25:42,219 --> 00:25:42,920
yeah, I mean,

552
00:25:43,219 --> 00:25:45,520
so I kind of get it from the company's perspective of

553
00:25:45,739 --> 00:25:48,640
like, we can't just delete every Bob Smith in the database, right?

554
00:25:48,650 --> 00:25:52,199
But I don't want to necessarily, like, send them my passport so I can

555
00:25:52,640 --> 00:25:54,189
opt out of some online advertising.

556
00:25:54,780 --> 00:25:58,810
And so how like, is there some balance there that is actually sane or is it just

557
00:25:59,089 --> 00:26:02,109
like, is it one of those problems that's so hard. There is no good solution.

558
00:26:02,119 --> 00:26:04,469
Let me see. I feel like it's somewhere in the middle.

559
00:26:04,479 --> 00:26:06,630
But, I mean, I mean, you do raise a good point. I mean,

560
00:26:06,800 --> 00:26:10,020
I am lucky in that. Or, or unlucky. I don't know, in that

561
00:26:10,140 --> 00:26:11,949
I'm the only, as far as I can tell Haley Sky, I,

562
00:26:12,209 --> 00:26:14,140
out there it's a very odd combination of

563
00:26:14,300 --> 00:26:14,739
things.

564
00:26:15,140 --> 00:26:15,819
But,

565
00:26:15,939 --> 00:26:19,400
uh, you know, a lot of times when we, when we are talking about, you know,

566
00:26:19,410 --> 00:26:21,770
this does come up and I mean, I tend to be a little glib,

567
00:26:21,780 --> 00:26:24,079
but I do understand that there are compliance

568
00:26:24,089 --> 00:26:26,079
issues and that those are real and that,

569
00:26:26,170 --> 00:26:27,750
that people, um,

570
00:26:28,349 --> 00:26:31,819
that companies in many cases would like to protect privacy

571
00:26:31,829 --> 00:26:34,180
because they kind of like on an individual level,

572
00:26:34,189 --> 00:26:37,109
get it, but don't know necessarily how to operationalize it.

573
00:26:37,119 --> 00:26:41,189
So a lot of times when we are talking about opt out requests, I think,

574
00:26:41,430 --> 00:26:43,680
you know, of course, it depends on the request.

575
00:26:43,689 --> 00:26:47,650
Like if it's an opt out of sale or if it's a, you know, a question of deletion,

576
00:26:47,660 --> 00:26:48,849
then I think,

577
00:26:49,160 --> 00:26:51,770
you know, we are ok with, um,

578
00:26:52,150 --> 00:26:54,910
certainly using the information you have on somebody.

579
00:26:54,920 --> 00:26:57,609
So if you have an account or something, right, if it's tied to an account

580
00:26:57,839 --> 00:27:03,569
to, uh, to verify and make sure that, you know, you're not deleting

581
00:27:03,739 --> 00:27:05,099
something that, um,

582
00:27:05,739 --> 00:27:07,439
that, you know, somebody Impersonating

583
00:27:07,650 --> 00:27:11,219
someone would like you to delete, but generally when it comes to things like an

584
00:27:11,650 --> 00:27:13,089
opt out of sale, right?

585
00:27:13,099 --> 00:27:18,859
That's a pretty low, like the, the harm of getting it wrong is fairly low stakes,

586
00:27:18,869 --> 00:27:19,199
right?

587
00:27:19,569 --> 00:27:20,239
So,

588
00:27:20,420 --> 00:27:24,229
uh or sorry, opt out of collection or yeah, or sale. So, um

589
00:27:24,349 --> 00:27:26,560
that is kind of how we look at it because while I

590
00:27:26,569 --> 00:27:29,359
am sympathetic that you have to verify who a person is.

591
00:27:29,540 --> 00:27:31,619
We have seen companies um

592
00:27:31,760 --> 00:27:34,640
under California's law say, ok, well,

593
00:27:34,650 --> 00:27:38,540
if you want to opt out of the collection of data, then I need a notary,

594
00:27:38,550 --> 00:27:40,979
I need you to like write this request and get a notary

595
00:27:41,310 --> 00:27:41,880
and

596
00:27:42,510 --> 00:27:44,050
that is a high bar.

597
00:27:45,430 --> 00:27:48,109
Well, it's funny you mentioned that because actually two days ago, there was a,

598
00:27:48,119 --> 00:27:51,489
a really big article here, essentially um old person.

599
00:27:51,689 --> 00:27:53,969
Uh they got a power of attorney over the old person because you know,

600
00:27:53,979 --> 00:27:56,810
they're going senile and they were trying to cancel a

601
00:27:56,900 --> 00:27:59,349
credit card for this old person and the company wanted

602
00:27:59,689 --> 00:28:01,060
notarized copies

603
00:28:01,380 --> 00:28:01,930
and

604
00:28:02,180 --> 00:28:05,900
the original copy of the power of attorney which like that's insane.

605
00:28:05,910 --> 00:28:08,250
You, you cannot send the original document, right?

606
00:28:08,260 --> 00:28:10,209
Like that's you're not letting that out of your control.

607
00:28:10,579 --> 00:28:13,859
And what I loved is that the, the article pointed out, especially in Alberta,

608
00:28:13,989 --> 00:28:15,979
like if you live in a small town, you

609
00:28:16,170 --> 00:28:17,439
don't have a notary

610
00:28:17,920 --> 00:28:21,040
like and I take that for granted, I live in a big city. I need a notary.

611
00:28:21,050 --> 00:28:22,550
I can get one in like half an hour.

612
00:28:23,020 --> 00:28:25,280
But, yeah, if you live in a small town or out in the sticks,

613
00:28:25,680 --> 00:28:28,160
like you, you, you just can't do that

614
00:28:28,410 --> 00:28:29,459
reasonably right.

615
00:28:29,469 --> 00:28:31,339
Or if you live in Alaska, I kind of wonder,

616
00:28:31,349 --> 00:28:33,089
is it sometimes are these companies doing this in good

617
00:28:33,099 --> 00:28:35,319
faith or are they kind of playing those games to,

618
00:28:35,329 --> 00:28:35,560
you know?

619
00:28:35,569 --> 00:28:39,020
Oh, we, we made this reasonable request. That's really kind of not reasonable.

620
00:28:39,619 --> 00:28:40,160
I mean,

621
00:28:40,839 --> 00:28:45,239
I try not to assume malice in all cases, but I do think

622
00:28:45,579 --> 00:28:46,239
that,

623
00:28:46,959 --> 00:28:48,959
you know, often they're getting, I mean, I think,

624
00:28:49,349 --> 00:28:52,300
you know, they're trying to cover their butts in the way that they think is,

625
00:28:52,310 --> 00:28:53,750
is the safest for them.

626
00:28:53,760 --> 00:28:54,800
In a lot of cases.

627
00:28:54,810 --> 00:28:59,050
I think in a lot of cases, they are hoping that if they make the request, you know,

628
00:28:59,060 --> 00:28:59,400
if they,

629
00:28:59,410 --> 00:29:03,839
if they make the request complicated enough that most people aren't going to

630
00:29:04,359 --> 00:29:09,020
pursue it and that means less work for them. As I said again, I try not to assume

631
00:29:09,250 --> 00:29:09,839
malice.

632
00:29:09,849 --> 00:29:13,439
I try not to say companies are evil, but I think there are,

633
00:29:13,449 --> 00:29:19,329
they are motivated to set things up in ways that make it difficult to engage with

634
00:29:19,849 --> 00:29:21,270
exercise of some of these rights.

635
00:29:21,280 --> 00:29:23,310
And that is why when we're, you know,

636
00:29:23,319 --> 00:29:27,310
when we're looking at crafting legislation that we really do try to be,

637
00:29:27,319 --> 00:29:28,719
you don't want to be too prescriptive, right?

638
00:29:28,729 --> 00:29:31,329
You don't want to be like you have to use this software which

639
00:29:31,339 --> 00:29:35,239
will inevitably become obsolete two years after the passage of this law.

640
00:29:36,280 --> 00:29:36,900
But

641
00:29:37,189 --> 00:29:40,469
you do want to be as specific as you can to make sure that, you know,

642
00:29:40,479 --> 00:29:44,040
people can't game the system either by trying to

643
00:29:44,050 --> 00:29:46,849
be either by trying to be thorough or by,

644
00:29:46,859 --> 00:29:47,030
you know,

645
00:29:47,040 --> 00:29:49,869
just trying to make sure that people aren't really going to be able to use the,

646
00:29:49,900 --> 00:29:51,790
the few rights that we are able to get through

647
00:29:52,680 --> 00:29:56,069
-- the
-- classic beware of leopard problem. All right.

648
00:29:56,079 --> 00:30:00,630
So I want to kind of steer us in, in two final directions.

649
00:30:00,640 --> 00:30:03,459
First of all, I would like to understand, kind of,

650
00:30:03,819 --> 00:30:08,140
we hinted at all this policy talk and regulation from the government.

651
00:30:08,150 --> 00:30:11,119
And I'm curious like what is actually happening right now

652
00:30:11,319 --> 00:30:13,640
that we should know about from the

653
00:30:13,790 --> 00:30:17,459
just kind of the, the government policy, legislative perspective.

654
00:30:18,069 --> 00:30:22,709
I alluded to not a lot of stuff going on at the federal level, you know,

655
00:30:22,719 --> 00:30:27,295
in some ways that's fair, in some ways it's not, I think as a, as a DC, uh exile,

656
00:30:27,305 --> 00:30:29,915
I have an interesting view of the city,

657
00:30:30,084 --> 00:30:31,675
but, you know, uh

658
00:30:31,885 --> 00:30:35,114
we are seeing better, at least drafts emerge.

659
00:30:35,125 --> 00:30:40,755
I think we're seeing a lot of good, good ideas finally getting put into legislation.

660
00:30:40,935 --> 00:30:42,594
So even if it doesn't have

661
00:30:42,724 --> 00:30:42,734
a,

662
00:30:43,040 --> 00:30:45,380
you know, a chance of passing imminently,

663
00:30:45,390 --> 00:30:47,500
I think we are moving the needle a little bit.

664
00:30:47,510 --> 00:30:49,839
And it's been really interesting to see, you know,

665
00:30:49,849 --> 00:30:53,939
there's been a market backlash against big tech.

666
00:30:53,949 --> 00:30:55,420
And it's been interesting to see,

667
00:30:55,709 --> 00:31:00,859
you know, that's not always a good thing from our, from our issue set because I think,

668
00:31:00,869 --> 00:31:04,640
uh, you see a lot of attempts to crack down on free expression and, you know,

669
00:31:04,650 --> 00:31:08,170
a lot of like, weird security suggestions that come up.

670
00:31:08,180 --> 00:31:10,369
They're like, anyway, I won't get into that.

671
00:31:10,550 --> 00:31:14,050
But on privacy, I think we are seeing, you know,

672
00:31:14,060 --> 00:31:17,449
people hearing lawmakers hearing from people

673
00:31:17,562 --> 00:31:21,142
that, um, you know, they're really frustrated with the way that companies are

674
00:31:21,243 --> 00:31:24,213
collecting and using their information and wanting to

675
00:31:24,223 --> 00:31:25,983
kind of reset that balance a little bit.

676
00:31:26,152 --> 00:31:29,503
And so there are some good ideas even if they are imminently passing.

677
00:31:29,512 --> 00:31:31,103
Now, speaking of imminently passing,

678
00:31:31,123 --> 00:31:36,142
this fight has really been at the state level for several years and right now,

679
00:31:36,152 --> 00:31:39,292
like in a little bit of time, I'm going to go speak

680
00:31:39,416 --> 00:31:43,395
Maryland. I sent a letter to Ohio this week.

681
00:31:43,406 --> 00:31:48,686
Uh, you know, we're talking to Alaska, we're talking to my home state of Minnesota.

682
00:31:48,696 --> 00:31:49,355
You know, we're,

683
00:31:49,485 --> 00:31:52,796
we're talking to a lot of folks who are looking at privacy bills.

684
00:31:52,806 --> 00:31:56,566
You know, some of them are these kinds of cynical, you know,

685
00:31:56,576 --> 00:31:58,946
let's make this compliance focus,

686
00:31:58,956 --> 00:32:01,196
let's make business friendly privacy legislation.

687
00:32:01,579 --> 00:32:03,719
I'm sure there is some

688
00:32:04,050 --> 00:32:06,880
world where business friendly privacy legislation lives,

689
00:32:06,890 --> 00:32:09,719
but it is not the kind of models that they're putting forward, right?

690
00:32:09,729 --> 00:32:11,810
What they're saying is we want what

691
00:32:11,819 --> 00:32:14,859
they mean by business friendly privacy legislation is

692
00:32:14,979 --> 00:32:18,400
businesses get to keep doing what they want, but they have to like,

693
00:32:18,410 --> 00:32:20,500
say that they care about privacy, right?

694
00:32:20,510 --> 00:32:22,119
They have to like give,

695
00:32:22,130 --> 00:32:26,479
they have to do audits that nobody should see internally about the

696
00:32:26,589 --> 00:32:28,849
privacy practices. You know, they

697
00:32:29,380 --> 00:32:32,859
don't have to comply with this privacy law

698
00:32:32,869 --> 00:32:34,729
if they comply with a totally different law,

699
00:32:34,739 --> 00:32:36,000
that is not about privacy.

700
00:32:36,010 --> 00:32:36,489
So

701
00:32:36,790 --> 00:32:38,089
there are some,

702
00:32:38,189 --> 00:32:42,010
a lot of tricks that we're seeing and we are seeing those pop up all over the place.

703
00:32:42,020 --> 00:32:44,969
Last year in Virginia, we lost a really hard battle.

704
00:32:44,979 --> 00:32:50,430
They, they brought up what they call the their privacy act. I think it's the VD CPA.

705
00:32:50,439 --> 00:32:51,489
And I can't remember

706
00:32:51,599 --> 00:32:55,040
there are a lot of CS and P's and A's in my acronym world

707
00:32:55,050 --> 00:32:57,170
and I sometimes get mixed up about

708
00:32:57,180 --> 00:32:59,180
whether they're privacy or protection or personal.

709
00:32:59,290 --> 00:33:01,140
But Virginia passed a law

710
00:33:01,280 --> 00:33:05,459
that was really bad. I wrote about it. I called it an empty privacy law.

711
00:33:05,619 --> 00:33:07,550
I stand by that and we're seeing it pop

712
00:33:07,560 --> 00:33:10,849
up in statehouses all over the country from some,

713
00:33:11,239 --> 00:33:15,849
some lawmakers who say, well, I hear my constituents talking about privacy,

714
00:33:15,859 --> 00:33:16,500
but I'm really

715
00:33:16,719 --> 00:33:20,349
about what it means for businesses. And so I'm just going to run this Virginia law,

716
00:33:20,489 --> 00:33:21,579
others saying like

717
00:33:21,760 --> 00:33:23,530
I care, but I don't

718
00:33:23,859 --> 00:33:27,989
know enough about privacy and this law exists. So I'm going to start here.

719
00:33:28,000 --> 00:33:30,829
So we've had a lot of conversations. I mean, privacy is

720
00:33:31,119 --> 00:33:33,910
really complicated, especially in law.

721
00:33:34,439 --> 00:33:36,910
And, you know, we have some very clear

722
00:33:37,250 --> 00:33:41,500
priorities of what we want, namely we want strong enforcement because I think we

723
00:33:41,619 --> 00:33:46,339
think laws are only as good as their teeth. And so if somebody breaks them, we want,

724
00:33:46,479 --> 00:33:48,959
you know, individuals to have the right to sue that company, you know,

725
00:33:48,969 --> 00:33:51,780
if they violated the law, if they violated their privacy,

726
00:33:51,790 --> 00:33:54,829
and we want that coupled with strong public enforcement.

727
00:33:54,839 --> 00:33:59,020
So, you know, a, a well funded attorney general's office or in California,

728
00:33:59,030 --> 00:34:01,979
we have a new privacy agency that's just getting off the ground.

729
00:34:01,989 --> 00:34:05,739
-- It'll be really interesting to see how that goes. So,
-- ok, so

730
00:34:05,849 --> 00:34:06,640
wrapping up,

731
00:34:07,189 --> 00:34:08,478
I'm a normal person.

732
00:34:09,178 --> 00:34:15,717
-- What can I do? So
-- certainly to change things, you can see, you know, I mean,

733
00:34:15,868 --> 00:34:19,458
I hate to like plug our own site but you can see if uh

734
00:34:19,569 --> 00:34:22,467
-- yeah, if
-- no way, plug away everyone listening, go

735
00:34:22,668 --> 00:34:25,717
join the eff right now. It's like the greatest organization.

736
00:34:25,728 --> 00:34:27,079
So there I did it for you.

737
00:34:28,569 --> 00:34:30,299
Thank you. I appreciate that.

738
00:34:30,608 --> 00:34:31,958
So, yeah, you know, we put up,

739
00:34:31,967 --> 00:34:35,148
we put up actions all the time about things that are happening in,

740
00:34:35,158 --> 00:34:35,839
in people's states.

741
00:34:35,849 --> 00:34:39,039
If you see, for example, if you're in Ohio right now,

742
00:34:39,248 --> 00:34:44,478
um it'd be great if you could tell them that the Ohio Personal Privacy Act is not good,

743
00:34:44,840 --> 00:34:47,379
right? So you can, you can take actions like that.

744
00:34:47,389 --> 00:34:52,219
Um We also to plug, um you know, to plug us again, we have the Electric

745
00:34:52,458 --> 00:34:53,949
Electronic Frontier Alliance,

746
00:34:53,958 --> 00:34:57,229
which is a loose federation of um of grassroots

747
00:34:57,239 --> 00:34:59,379
groups across the country that we work with.

748
00:34:59,389 --> 00:35:03,070
You know, there really are eyes and ears on the ground. In, in,

749
00:35:03,330 --> 00:35:05,580
in States. I could not do my job without them.

750
00:35:05,689 --> 00:35:09,080
Um If you're interested in, in that you can join that. And, you know, as,

751
00:35:09,280 --> 00:35:12,040
as you hear, privacy come up probably on your

752
00:35:12,156 --> 00:35:15,656
local news, right? Because as I said, this fight really is at the state level,

753
00:35:15,797 --> 00:35:19,376
you know, get engaged, think about it. Um you know, send

754
00:35:19,527 --> 00:35:23,146
emails to your lawmakers. It's amazing to me

755
00:35:23,267 --> 00:35:26,626
how much a constituent email matters to a

756
00:35:26,636 --> 00:35:29,777
lot of these particularly state lawmakers because they,

757
00:35:29,886 --> 00:35:33,166
they don't get to hear from their own people that often and that, that goes far.

758
00:35:33,177 --> 00:35:35,076
So if you are passionate about these issues,

759
00:35:35,287 --> 00:35:39,457
engage it, it really is, it seems scary but

760
00:35:39,583 --> 00:35:40,674
the the

761
00:35:40,823 --> 00:35:43,214
there's a very low chance that it'll blow back on you in a,

762
00:35:43,224 --> 00:35:46,424
in a bad way and there's a lot of chance that, um you know,

763
00:35:46,434 --> 00:35:48,694
if you get the ear of your lawmaker

764
00:35:48,823 --> 00:35:51,394
that and they are your uh they are your

765
00:35:51,404 --> 00:35:54,563
representative that they will at least listen to you.

766
00:35:54,624 --> 00:35:58,204
Absolutely. And I'm going to also plug, we actually you mentioned the,

767
00:35:58,354 --> 00:35:59,773
what was it, the Electronic

768
00:36:00,053 --> 00:36:01,964
Frontier Alliance? I think you called it

769
00:36:02,724 --> 00:36:02,783
a

770
00:36:03,013 --> 00:36:03,483
correct.

771
00:36:03,783 --> 00:36:06,914
We, we the E fa we had a guest

772
00:36:07,160 --> 00:36:10,611
it's been probably a year now. Uh, Chris Whelan from restore the Fourth Minnesota.

773
00:36:10,621 --> 00:36:11,910
I'll put a link in the show notes to that,

774
00:36:11,920 --> 00:36:14,020
which I'd highly recommend anyone go and listen to.

775
00:36:14,031 --> 00:36:19,670
And I, I think we sometimes forget how powerful our voice can be at a local level.

776
00:36:19,680 --> 00:36:20,510
Federally.

777
00:36:20,730 --> 00:36:25,270
It probably is very quiet, but locally we can be very, very loud.

778
00:36:25,281 --> 00:36:28,230
And so I love that advice and I feel like that is,

779
00:36:28,500 --> 00:36:31,791
-- that's a great place for all of us
-- to start. A little bit. Goes a long way.

780
00:36:31,841 --> 00:36:32,631
Absolutely.

781
00:36:32,641 --> 00:36:34,391
Absolutely. This has been,

782
00:36:34,730 --> 00:36:35,700
oh my goodness. I,

783
00:36:36,189 --> 00:36:36,250
I

784
00:36:36,360 --> 00:36:39,929
feel like I could talk to you for hours. I won't, but this has been

785
00:36:40,239 --> 00:36:41,669
an absolute treat. Haley.

786
00:36:41,679 --> 00:36:44,469
I want to thank you so very much for coming in and chatting with us.

787
00:36:44,479 --> 00:36:46,350
This I, I'm, I'm, I'm ecstatic.

788
00:36:46,649 --> 00:36:47,729
So, ok,

789
00:36:47,899 --> 00:36:49,330
thank you everyone for listening.

790
00:36:49,340 --> 00:36:52,310
There'll be a bunch of show notes, go hit those up, follow the links,

791
00:36:52,320 --> 00:36:54,250
join the eff do all those things

792
00:36:54,419 --> 00:36:58,580
and you can go to open source security podcast.com for the show notes.

793
00:36:58,780 --> 00:36:59,260
You can use

794
00:36:59,580 --> 00:37:02,250
a Podos as podcast. Hashtag hit us up on social media.

795
00:37:02,600 --> 00:37:06,260
-- Haley and Kurt have marvelous, rest of your days. Thanks
-- for having me.

796
00:37:06,320 --> 00:37:07,719
-- Thank
-- you everybody. Thanks

797
00:37:07,729 --> 00:37:09,969
again Haley and thank you, everyone. Bye bye.