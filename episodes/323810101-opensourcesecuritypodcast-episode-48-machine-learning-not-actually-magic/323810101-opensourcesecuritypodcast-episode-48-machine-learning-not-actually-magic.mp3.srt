0
00:00:05,190 --> 00:00:09,630
Hello and welcome to the open source security podcast episode 48 with myself,

1
00:00:09,640 --> 00:00:12,020
Kurt Siefried and my partner in crime, Josh Bresser.

2
00:00:12,189 --> 00:00:16,709
And today Kurt, we have a special guest. We've got a fellow I work with at Elastic.

3
00:00:16,719 --> 00:00:17,440
His name is Mike MCC.

4
00:00:17,620 --> 00:00:19,930
Say hi, Mike. Hey guys, pleasure to be here today.

5
00:00:19,940 --> 00:00:22,649
And today we're going to talk about machine learning

6
00:00:22,659 --> 00:00:25,409
because Mike is our resident machine learning guy.

7
00:00:25,430 --> 00:00:26,649
And so I guess Mike,

8
00:00:26,659 --> 00:00:29,680
why don't you explain kind of a little bit about yourself where you came from,

9
00:00:29,690 --> 00:00:30,540
how you got here

10
00:00:30,920 --> 00:00:34,220
and, and what you know, and then we can, I guess dive right in and,

11
00:00:34,229 --> 00:00:35,619
and learn all about machine learning.

12
00:00:35,840 --> 00:00:36,860
Sounds good guys.

13
00:00:36,869 --> 00:00:39,029
Well, uh as you mentioned, Josh,

14
00:00:39,040 --> 00:00:42,970
we work together at Elastic right now and uh I joined up uh

15
00:00:43,090 --> 00:00:45,590
Elastic because I had come from a company called

16
00:00:46,000 --> 00:00:46,799
Pret and uh pret

17
00:00:47,110 --> 00:00:50,740
had been working for a number of years developing machine learning technology

18
00:00:51,119 --> 00:00:52,369
and we at Pret

19
00:00:52,720 --> 00:00:54,200
had developed

20
00:00:54,509 --> 00:00:55,819
a product that was

21
00:00:56,110 --> 00:00:59,790
marketing, we called the Behavioral Analytics for the Elastic Stack.

22
00:00:59,799 --> 00:01:01,180
Uh It was a way to take the pre

23
00:01:01,419 --> 00:01:05,970
machine learning engine and operate on data that was indexed in elastic search.

24
00:01:06,339 --> 00:01:09,239
And uh the elastic team uh saw it and they liked

25
00:01:09,250 --> 00:01:12,230
it so much that we ended up uh joining forces.

26
00:01:12,370 --> 00:01:15,199
So I got to elastic uh through the pre

27
00:01:15,419 --> 00:01:16,080
path.

28
00:01:16,480 --> 00:01:20,870
And uh so, but my, my background before pre learnt um was uh you know,

29
00:01:20,879 --> 00:01:25,599
developing uh security products, uh network intrusion prevention, DD OS defense,

30
00:01:25,610 --> 00:01:28,910
uh lawfully authorized electronic surveillance and SIM products.

31
00:01:29,190 --> 00:01:32,180
And so I actually came to pre learnt to help uh apply

32
00:01:32,290 --> 00:01:34,250
the machine learning technology that the pre

33
00:01:34,389 --> 00:01:35,349
team had developed

34
00:01:35,610 --> 00:01:40,949
uh into security use cases. And so here at Elastic, I get to continue to do that.

35
00:01:41,129 --> 00:01:43,830
-- So
-- you just said something that, that confuses and scares me.

36
00:01:43,839 --> 00:01:46,430
You said they've been doing machine learning for a long time.

37
00:01:46,440 --> 00:01:48,000
This is brand new, isn't it?

38
00:01:48,680 --> 00:01:49,819
Yeah. Yeah.

39
00:01:49,959 --> 00:01:50,529
So

40
00:01:50,680 --> 00:01:50,690
uh

41
00:01:51,379 --> 00:01:52,269
no,

42
00:01:52,860 --> 00:01:53,599
it's funny.

43
00:01:53,610 --> 00:01:55,669
Um machine learning, you know, a lot of the,

44
00:01:55,680 --> 00:01:59,319
a lot of the basic concepts are based on uh classical statistics

45
00:01:59,330 --> 00:02:02,480
and stuff that's been around even since the 19 forties and fifties.

46
00:02:02,809 --> 00:02:06,959
Uh And, and uh what, what's really new is the way to

47
00:02:07,080 --> 00:02:11,639
implement uh some of these techniques in, in ways that are robust to the, you know,

48
00:02:11,649 --> 00:02:15,479
today's data, time series data that comes at extremely high rates and

49
00:02:15,660 --> 00:02:18,399
large volumes. And uh so um

50
00:02:19,289 --> 00:02:21,610
yeah, so it's, it's what's old is new,

51
00:02:21,970 --> 00:02:22,929
you gotta love it.

52
00:02:23,300 --> 00:02:26,500
So one question I have, what sort of is the cut off?

53
00:02:26,509 --> 00:02:30,029
Like where does it become machine learning and say, stop being a,

54
00:02:30,309 --> 00:02:31,979
an overgrown pearl script?

55
00:02:34,360 --> 00:02:36,750
Uh It, it's, it's a great question because if, if you, you know,

56
00:02:36,759 --> 00:02:39,360
if you double click into that, um a lot of times you say, well,

57
00:02:39,369 --> 00:02:41,520
what are you using statistics or machine learning?

58
00:02:41,529 --> 00:02:46,190
And uh you know, it, it isn't, it isn't a black or white, it's, it's an evolution.

59
00:02:46,639 --> 00:02:49,320
So generally, um you know, machine learning uh is,

60
00:02:49,330 --> 00:02:52,779
is when the uh it is software at the end of the day,

61
00:02:53,020 --> 00:02:57,520
uh and what it's doing is it's able to adapt, uh it's, it's um

62
00:02:57,720 --> 00:03:02,100
uh it's able to adapt to the, it's able to learn from data uh that,

63
00:03:02,110 --> 00:03:03,740
that it is operating on

64
00:03:03,910 --> 00:03:06,630
and then operate differently on subsequent data based

65
00:03:06,639 --> 00:03:08,190
on what it learned from previous data.

66
00:03:08,279 --> 00:03:10,789
Why don't we back that up for a second, Mike and just

67
00:03:10,919 --> 00:03:12,089
give us like the, the,

68
00:03:12,100 --> 00:03:17,270
the 32nd elevator pitch of what is machine learning for those who,

69
00:03:17,279 --> 00:03:18,460
who maybe don't know and let's face it.

70
00:03:18,470 --> 00:03:20,089
A lot of people don't because I know even,

71
00:03:20,100 --> 00:03:23,839
I don't totally understand necessarily like statistics, machine learning,

72
00:03:23,850 --> 00:03:24,899
artificial intelligence.

73
00:03:24,910 --> 00:03:26,970
What is what? No idea. So, Phil,

74
00:03:28,020 --> 00:03:28,600
sure.

75
00:03:28,610 --> 00:03:33,199
Um II, I don't believe there's any single taxonomy that's accepted by everyone.

76
00:03:33,210 --> 00:03:36,240
So I'll certainly give you the perspective that I have.

77
00:03:36,350 --> 00:03:36,800
Uh

78
00:03:37,039 --> 00:03:42,360
So, you know, artificial intelligence uh is an extremely broad,

79
00:03:42,369 --> 00:03:44,740
technological and philosophical topic

80
00:03:44,860 --> 00:03:48,639
uh that, that uh can get outside the scope of this podcast.

81
00:03:48,899 --> 00:03:50,539
But within artificial

82
00:03:50,690 --> 00:03:50,869
intelligence

83
00:03:51,119 --> 00:03:52,410
is outside the scope of this,

84
00:03:53,929 --> 00:03:56,479
we have no low point, feel free.

85
00:03:57,720 --> 00:03:59,740
But uh within, within the scope,

86
00:03:59,750 --> 00:04:02,369
you can think of 11 discipline of artificial

87
00:04:02,380 --> 00:04:04,779
intelligence uh might be that of machine learning.

88
00:04:05,139 --> 00:04:09,080
Uh And so uh machine learning itself has many, many categories.

89
00:04:09,089 --> 00:04:11,470
Uh You may have heard of things like neural networks.

90
00:04:11,679 --> 00:04:15,059
Uh You talk heard, heard of things like supervised machine learning,

91
00:04:15,240 --> 00:04:16,320
uh semi

92
00:04:16,500 --> 00:04:19,220
supervised machine learning, unsupervised machine learning.

93
00:04:19,298 --> 00:04:23,274
Uh Those are all discipline within machine learning. So I'm a hierarchical guy.

94
00:04:23,285 --> 00:04:25,994
I like the things I think of things as top down.

95
00:04:26,054 --> 00:04:26,964
So uh I,

96
00:04:26,975 --> 00:04:30,285
I uh exclude a lot of artificial intelligence to come up

97
00:04:30,295 --> 00:04:32,684
with the bucket of things that fall into machine learning.

98
00:04:32,885 --> 00:04:35,885
And then um we, we talk about those in some detail.

99
00:04:36,125 --> 00:04:40,125
So when we are talking about machine learning in the context of

100
00:04:40,940 --> 00:04:44,290
the software for doing things like threat detection,

101
00:04:44,480 --> 00:04:44,920
uh We're,

102
00:04:44,929 --> 00:04:47,220
we're talking about a couple of branches that

103
00:04:47,230 --> 00:04:49,920
are probably coming closer to things like um

104
00:04:50,130 --> 00:04:50,709
uh semi

105
00:04:50,880 --> 00:04:52,859
supervised or unsupervised machine learning.

106
00:04:53,679 --> 00:04:56,500
-- Um And so,
-- so can can you explain

107
00:04:56,670 --> 00:05:00,450
what kind of what is unsupervised, supervised and semi

108
00:05:00,619 --> 00:05:01,760
supervised machine learning?

109
00:05:02,369 --> 00:05:03,040
Yes.

110
00:05:03,339 --> 00:05:09,239
So the 11 of the concepts in machine learning is uh whether or

111
00:05:09,250 --> 00:05:14,970
not the the data on which the algorithms operate has been marked up,

112
00:05:15,359 --> 00:05:17,989
uh marked up with ground truth information

113
00:05:18,179 --> 00:05:20,910
so that it represents uh a known state

114
00:05:21,290 --> 00:05:21,709
uh

115
00:05:22,040 --> 00:05:26,130
algorithms that operate on marked up data and then build from that

116
00:05:26,529 --> 00:05:31,269
analysis a model that they can apply to subsequent unmarked up data.

117
00:05:31,510 --> 00:05:34,029
Uh That is a technique called supervised machine learning.

118
00:05:34,309 --> 00:05:37,570
So, supervised machine learning generally requires this pre

119
00:05:38,309 --> 00:05:39,089
marked up

120
00:05:39,220 --> 00:05:41,809
corpus of data from which the um

121
00:05:41,989 --> 00:05:44,049
uh software can build models.

122
00:05:44,390 --> 00:05:46,850
So that would be like say having your email trained

123
00:05:46,859 --> 00:05:49,119
on a bunch of ham and a bunch of spam.

124
00:05:49,459 --> 00:05:51,399
Yeah, that's, that's a very good example or,

125
00:05:51,410 --> 00:05:55,089
or another one is uh in the use of malware detection

126
00:05:55,440 --> 00:05:59,589
uh right, having a sample of a million examples of malware,

127
00:05:59,600 --> 00:06:02,619
a million executables and then running your algorithms

128
00:06:02,630 --> 00:06:05,339
across that entire corpus and learning from it.

129
00:06:05,350 --> 00:06:09,320
What are the similarities between malware taking that model

130
00:06:09,329 --> 00:06:12,100
that you've derived from that analysis of marked up data

131
00:06:12,279 --> 00:06:13,500
and then applying that to new

132
00:06:13,609 --> 00:06:17,109
executables to see if you can determine whether or not their malware.

133
00:06:17,119 --> 00:06:20,209
That that's a good example of the supervised machine learning as well.

134
00:06:20,410 --> 00:06:23,179
-- OK.
-- Nice. That makes sense to me. But that also occurs to me.

135
00:06:23,190 --> 00:06:24,820
This is kind of that cat and mouse game, right?

136
00:06:24,829 --> 00:06:28,040
Where the malware authors and the spammers are always

137
00:06:28,049 --> 00:06:31,320
changing things so they can get around your rules,

138
00:06:31,329 --> 00:06:31,670
right?

139
00:06:32,820 --> 00:06:35,579
They Yeah, so that they get around your your algorithms.

140
00:06:35,589 --> 00:06:37,940
Uh And in fact that exact thing happens.

141
00:06:37,950 --> 00:06:42,540
So, so uh let's take the the case I brought up of malware analysis of,

142
00:06:42,549 --> 00:06:44,790
of determining whether or not an algorithm.

143
00:06:44,799 --> 00:06:45,390
Uh Excuse me,

144
00:06:45,399 --> 00:06:50,799
an executable is um malware based on applying these learned models uh to it.

145
00:06:51,290 --> 00:06:55,119
So I saw a presentation um probably six months ago

146
00:06:55,250 --> 00:07:00,160
where um basically a malware developer um got a hold of that software,

147
00:07:00,450 --> 00:07:04,809
uh built his malware and just kept running it through and making modifications to it

148
00:07:04,820 --> 00:07:08,769
till he found a variation of the malware that was not triggered by that algorithm.

149
00:07:08,950 --> 00:07:12,750
-- And then of course, he went ahead and did what he wanted to do with that
-- version.

150
00:07:13,100 --> 00:07:14,470
Nice. That's awesome.

151
00:07:14,829 --> 00:07:17,239
So, well, I've seen similar things with spam assassin.

152
00:07:17,250 --> 00:07:19,910
I mean, I've seen a ton of email that scores 4.9

153
00:07:20,250 --> 00:07:23,790
and the default for spam Assassin to mark something with spam is five. So

154
00:07:24,589 --> 00:07:24,790
yeah,

155
00:07:26,359 --> 00:07:28,350
that makes sense for supervised machine learning, right?

156
00:07:29,000 --> 00:07:32,420
Yeah, that, that, that's a perfect explanation. Thank you. So what is semi

157
00:07:32,579 --> 00:07:33,739
supervised? Now,

158
00:07:33,950 --> 00:07:36,019
how about how about if we start with unsupervised

159
00:07:36,170 --> 00:07:36,890
and then we'll

160
00:07:37,170 --> 00:07:38,649
get the hybrid in the middle.

161
00:07:40,420 --> 00:07:44,179
So unsupervised machine learning is generally defined as that,

162
00:07:44,190 --> 00:07:46,220
that does not require

163
00:07:46,570 --> 00:07:49,489
marked up ground truth data to start with.

164
00:07:49,760 --> 00:07:52,920
So it it learns on the fly from the actual data

165
00:07:52,929 --> 00:07:56,140
that's being analyzed and it builds its models uh you know,

166
00:07:56,149 --> 00:07:59,739
based on the data as it's being analyzed and then simultaneously

167
00:07:59,750 --> 00:08:04,700
or there very shortly thereafter is are able to make determinations of

168
00:08:04,980 --> 00:08:10,700
whether or not the the data um uh meets certain criteria or is anomalous or you know,

169
00:08:10,709 --> 00:08:13,579
has some characteristics uh that, that are learned from the data.

170
00:08:14,149 --> 00:08:18,690
So the the benefit of unsupervised machine learning is that it

171
00:08:18,700 --> 00:08:21,510
is operating on the actual data that is to be analyzed.

172
00:08:21,519 --> 00:08:23,329
So it's learning from the actual data,

173
00:08:23,649 --> 00:08:26,890
uh it doesn't have to learn from this artificial train set.

174
00:08:27,190 --> 00:08:28,609
Uh And then um

175
00:08:29,570 --> 00:08:32,950
it is able to, so with supervised machine learning switching back,

176
00:08:32,960 --> 00:08:34,789
one of the challenges you have is that if the

177
00:08:34,799 --> 00:08:37,590
training data isn't exactly the same as the actual data,

178
00:08:37,599 --> 00:08:40,799
then you get drift between the model that was developed and the

179
00:08:40,808 --> 00:08:44,580
actual signals that you want to be analyzing from time to time,

180
00:08:44,590 --> 00:08:47,219
you have to go back and do some retraining.

181
00:08:48,250 --> 00:08:51,549
Whereas the approach that unsupervised machine learning takes is that it sort of

182
00:08:52,000 --> 00:08:55,219
sounds like uh college, but it's continuous online learning.

183
00:08:55,289 --> 00:08:58,789
So as new data appears, it's constantly updating the model.

184
00:08:58,799 --> 00:09:02,549
So the model has a a temporal characteristic of being representative

185
00:09:02,559 --> 00:09:05,229
of the data now or at least very very recently.

186
00:09:05,239 --> 00:09:08,130
But I I guess the challenge there though is you need

187
00:09:08,140 --> 00:09:11,830
a corpus of past data to essentially feed the machine,

188
00:09:11,840 --> 00:09:12,190
right?

189
00:09:13,049 --> 00:09:14,270
Or, or you just wait.

190
00:09:14,280 --> 00:09:18,250
So um you know, you can start to start it now and as the data comes in,

191
00:09:18,260 --> 00:09:19,770
you build it up over time,

192
00:09:20,119 --> 00:09:23,190
uh most good techniques will have the ability to do both.

193
00:09:23,349 --> 00:09:24,799
So what you do is um you know,

194
00:09:24,809 --> 00:09:28,479
the benefit of the analysis is that uh it certainly as it's applied

195
00:09:28,489 --> 00:09:32,710
to security is the ability to operate on data in near real time.

196
00:09:33,219 --> 00:09:34,020
Uh However,

197
00:09:34,030 --> 00:09:37,960
uh when I start my machine learning job and I want to look for some uh unusual

198
00:09:37,969 --> 00:09:41,799
behaviors then uh I don't want to have to wait for two weeks to get any results.

199
00:09:41,809 --> 00:09:44,080
Right. Well, I could even see it. I mean, you think,

200
00:09:44,219 --> 00:09:48,260
I know uh listening to conversations with, with some of our machine learning folks,

201
00:09:48,270 --> 00:09:51,799
the Black Friday problem always comes up where

202
00:09:51,940 --> 00:09:53,400
you kind of train

203
00:09:53,650 --> 00:09:55,179
your, your algorithm for,

204
00:09:55,190 --> 00:09:57,530
let's say normal use and then something like Black Friday

205
00:09:57,539 --> 00:09:59,570
hits and all the rules get thrown out the window,

206
00:09:59,580 --> 00:09:59,919
right?

207
00:10:00,130 --> 00:10:01,789
So uh it's a great question.

208
00:10:01,799 --> 00:10:05,869
That's, that's something that is in a oxymoron is called the uh you know,

209
00:10:05,880 --> 00:10:09,960
the the expected anomaly uh and, and things happen.

210
00:10:10,039 --> 00:10:13,109
So the answer is uh those expected anomalies are,

211
00:10:13,119 --> 00:10:15,349
are really the exceptions to the rule.

212
00:10:15,359 --> 00:10:18,700
So um it is, it really isn't possible to model those.

213
00:10:18,710 --> 00:10:21,469
So what you want to make sure is that those events don't dis

214
00:10:22,054 --> 00:10:26,034
your model so much that they're providing skewed results.

215
00:10:27,094 --> 00:10:31,895
And so a few techniques are used um good techniques of unsupervised

216
00:10:31,905 --> 00:10:34,344
machine learning modeling are able to

217
00:10:34,354 --> 00:10:36,604
identify when something is highly anomalous,

218
00:10:36,684 --> 00:10:36,715
in

219
00:10:36,815 --> 00:10:43,344
essence, the more unusual it is the less likely it should be to affect the model.

220
00:10:43,979 --> 00:10:46,400
Uh And so that um things may

221
00:10:46,530 --> 00:10:50,650
be skewed for a short time period after Black Friday, but then they're,

222
00:10:50,789 --> 00:10:55,119
the models would converge back and, and they would um you know, return to normal

223
00:10:55,429 --> 00:10:58,280
the general technique on how you get around the Black Friday issue.

224
00:10:59,150 --> 00:11:02,770
So one question I have is, is I understand how unsupervised learning could,

225
00:11:02,780 --> 00:11:04,559
for example, you know, get you

226
00:11:05,070 --> 00:11:08,859
sort of like this is the weird anomalous data that doesn't fit with the rest of it,

227
00:11:08,869 --> 00:11:09,090
right?

228
00:11:09,099 --> 00:11:12,179
Like 99% of the stuff is this and 1% of it is like

229
00:11:12,409 --> 00:11:13,260
not this,

230
00:11:13,460 --> 00:11:13,880
but

231
00:11:14,130 --> 00:11:17,210
you know, how do you apply that to a like for the sake of argument, you,

232
00:11:17,219 --> 00:11:19,330
you want to build something that recognizes cats.

233
00:11:20,119 --> 00:11:22,070
Can you do that with unsupervised learning?

234
00:11:22,080 --> 00:11:23,690
Because at some point, how would that thing

235
00:11:24,159 --> 00:11:27,659
learn or you know, you'd have to tell it at some point what a cat is to some degree,

236
00:11:27,669 --> 00:11:28,049
right?

237
00:11:28,929 --> 00:11:29,190
Yeah.

238
00:11:29,200 --> 00:11:30,739
So uh so generally not,

239
00:11:30,750 --> 00:11:34,270
so the the unsupervised machine learning techniques that we'll be talking

240
00:11:34,280 --> 00:11:38,169
about relative to security are operating on uh time series data.

241
00:11:38,429 --> 00:11:41,909
So this would be either numeric or categorical data that has a time stamp.

242
00:11:41,919 --> 00:11:48,190
Um It is not operating on uh images or uh other, other types of constructs uh that

243
00:11:48,510 --> 00:11:52,210
to which the the the greater problem of machine learning can be applied,

244
00:11:52,219 --> 00:11:57,030
but not the um uh the unsupervised things like neural networks, for example,

245
00:11:57,039 --> 00:12:00,289
could be used as, as part of image recognition

246
00:12:00,840 --> 00:12:03,780
uh based on certain um marked up data sets of

247
00:12:03,789 --> 00:12:07,619
images and other techniques that try to hybridize that to

248
00:12:07,750 --> 00:12:10,750
help you just uh uh basically specify characteristics

249
00:12:10,760 --> 00:12:13,119
and then find images that contain those characteristics.

250
00:12:13,289 --> 00:12:17,979
Well, and I think this is actually an important point to focus on Mike is that at, at,

251
00:12:17,989 --> 00:12:20,380
at elastic, the work you're working on is

252
00:12:20,799 --> 00:12:22,179
it's not magic.

253
00:12:22,190 --> 00:12:25,840
It, we have a very defined scope where it's when you say time series data,

254
00:12:25,849 --> 00:12:27,820
you're basically talking about logs.

255
00:12:28,159 --> 00:12:31,960
And the idea is to look at the logs using machine learning for security anomalies.

256
00:12:31,969 --> 00:12:32,260
Right.

257
00:12:32,380 --> 00:12:33,419
Yep. That is correct.

258
00:12:33,429 --> 00:12:35,429
We're talking about the application of machine learning in

259
00:12:35,440 --> 00:12:38,940
the form of automated anomaly detection applied to time

260
00:12:38,950 --> 00:12:41,270
series data which as you correctly point out are

261
00:12:41,280 --> 00:12:44,760
mostly logs or at least also numerical metrics,

262
00:12:44,770 --> 00:12:46,549
which you could argue are also logs.

263
00:12:46,559 --> 00:12:48,679
-- Sure,
-- sure. Which, which I think is

264
00:12:49,169 --> 00:12:52,929
that's where I feel like I get confused sometimes is when

265
00:12:52,940 --> 00:12:55,960
we talk about something like artificial intelligence or machine learning,

266
00:12:55,969 --> 00:12:56,739
I think people

267
00:12:57,070 --> 00:13:00,969
naturally assume this is essentially magic math that can do anything.

268
00:13:00,979 --> 00:13:03,049
But in like in our case

269
00:13:03,280 --> 00:13:03,969
where

270
00:13:04,219 --> 00:13:08,469
we're scoping it to a point that it's useful because I think this is like anything.

271
00:13:08,479 --> 00:13:12,919
-- If you scope it too broadly, you end up with, with nothing. Right. Exactly.
-- Exactly.

272
00:13:12,929 --> 00:13:14,359
So this is uh indeed,

273
00:13:14,510 --> 00:13:16,369
you know, that's why we think of a huge funnel,

274
00:13:16,380 --> 00:13:19,705
we had artificial intelligence at the top and then we have machine learning.

275
00:13:19,716 --> 00:13:20,435
Uh you know,

276
00:13:20,445 --> 00:13:22,585
next level down and then we have unsupervised

277
00:13:22,596 --> 00:13:24,265
machine learning on the next level down.

278
00:13:24,466 --> 00:13:26,205
And then what we got is the actual

279
00:13:26,216 --> 00:13:29,116
outputs is automated anomaly detection and time series data

280
00:13:29,245 --> 00:13:30,786
as a practical application of

281
00:13:31,245 --> 00:13:32,875
-- unsupervised machine learning.
-- Right. Right. Right.

282
00:13:33,085 --> 00:13:34,455
And, and I think that makes sense.

283
00:13:34,466 --> 00:13:36,866
Now, the one thing you have not explained to us yet with the

284
00:13:37,202 --> 00:13:40,921
supervised machine learning is which I'm still trying to figure out.

285
00:13:41,182 --> 00:13:41,711
All right,

286
00:13:41,721 --> 00:13:46,081
so let's say you're using unsupervised machine learning to detect anomalies,

287
00:13:46,091 --> 00:13:48,581
anomalous activity, either in values, frequencies,

288
00:13:48,591 --> 00:13:52,901
counts or things are statistically rare or things are different than one another.

289
00:13:53,192 --> 00:13:54,341
And you identify

290
00:13:54,471 --> 00:13:57,091
um this set of unusual

291
00:13:57,572 --> 00:13:58,702
behaviors in the data.

292
00:13:59,559 --> 00:14:02,580
But let's say you have lots of unusual things.

293
00:14:02,590 --> 00:14:06,320
Um let's say we're applying this technology to

294
00:14:06,750 --> 00:14:08,229
fraud detection.

295
00:14:08,479 --> 00:14:11,340
And let's say you had uh payment card transactions and you

296
00:14:11,349 --> 00:14:14,909
wanted to find a way to score those transactions to find,

297
00:14:14,919 --> 00:14:17,650
to give a good indicator as to which ones might be fraudulent.

298
00:14:18,000 --> 00:14:21,289
You would use unsupervised machine learning to find things like

299
00:14:22,070 --> 00:14:28,570
unusual um amounts of the transaction, unusual locations for that card,

300
00:14:28,969 --> 00:14:31,770
uh unusual times of day for the purchase.

301
00:14:31,780 --> 00:14:34,440
Those are all unusual things that are anomalies.

302
00:14:34,809 --> 00:14:37,140
But in order to put those together and to

303
00:14:37,150 --> 00:14:40,650
find out which ones predict the fraudulent transactions,

304
00:14:40,659 --> 00:14:44,609
what you really need is some confirmed fraudulent transactions.

305
00:14:44,940 --> 00:14:51,650
And so the technique of applying multiple observed anomalies towards a score adds a

306
00:14:51,809 --> 00:14:53,940
sort of a marked up data set, right?

307
00:14:53,950 --> 00:14:58,640
You get some, here's, here's 1000 transactions and these 100 were fraudulent.

308
00:14:58,650 --> 00:15:00,479
If that is verified truth,

309
00:15:00,489 --> 00:15:05,159
then what you do is you build a construct called a classifier which tries to map the

310
00:15:05,270 --> 00:15:07,419
observations of anomalies that you've seen

311
00:15:07,429 --> 00:15:09,969
from your unsupervised machine learning onto

312
00:15:10,200 --> 00:15:12,059
the marked up data set.

313
00:15:12,070 --> 00:15:15,369
So that you come up with essentially a formula for taking

314
00:15:15,380 --> 00:15:19,409
the level of unusualness of the things you've observed and finding out

315
00:15:19,729 --> 00:15:22,750
a waiting factor that will produce a score that

316
00:15:22,760 --> 00:15:25,489
will predict the fraudulent nature of a transaction.

317
00:15:26,280 --> 00:15:27,929
So that would be an example of semi

318
00:15:28,109 --> 00:15:29,489
supervised that's using

319
00:15:29,599 --> 00:15:30,890
unsupervised elements,

320
00:15:30,900 --> 00:15:33,080
but it does have some marked up data on the output

321
00:15:33,090 --> 00:15:35,669
that a score or a weighting can be used to create.

322
00:15:35,679 --> 00:15:37,869
-- So
-- essentially just you're creating a feedback loop.

323
00:15:38,169 --> 00:15:38,369
Yeah,

324
00:15:38,630 --> 00:15:39,280
that's right.

325
00:15:39,500 --> 00:15:40,510
OK. Well, that makes sense.

326
00:15:40,809 --> 00:15:44,119
So I guess the inevitable question now is

327
00:15:44,400 --> 00:15:44,780
we,

328
00:15:44,789 --> 00:15:48,140
we started out with why is machine learning not necessarily

329
00:15:48,150 --> 00:15:50,059
A I which it sounds like it kind of is,

330
00:15:50,419 --> 00:15:50,919
but the,

331
00:15:51,090 --> 00:15:52,729
the question on everyone's mind,

332
00:15:52,739 --> 00:15:55,489
I'm sure is is can the machine learning algorithms

333
00:15:55,500 --> 00:15:57,770
become self aware and take over the world,

334
00:15:59,119 --> 00:16:00,679
the philosophical parts of

335
00:16:00,859 --> 00:16:00,880
our?

336
00:16:02,159 --> 00:16:02,190
OK.

337
00:16:03,760 --> 00:16:04,219
So

338
00:16:04,400 --> 00:16:05,210
um

339
00:16:05,419 --> 00:16:07,659
so, so I I tend to uh

340
00:16:08,630 --> 00:16:11,000
have less, less opinions in that area.

341
00:16:11,010 --> 00:16:14,200
Uh It's not, it's not a concern that I, that I worry about so

342
00:16:15,989 --> 00:16:17,109
-- I can sleep at night.
-- Yeah.

343
00:16:17,929 --> 00:16:20,049
Well, and just one example of this too is, I mean,

344
00:16:20,059 --> 00:16:22,099
these things don't have to take over the world to cause a problem.

345
00:16:22,109 --> 00:16:23,580
This actually came up

346
00:16:23,950 --> 00:16:25,409
yesterday. Um,

347
00:16:25,809 --> 00:16:26,469
so this, uh,

348
00:16:26,609 --> 00:16:31,270
this Canadian couple bought airline tickets, uh, from Canada to Portugal and back

349
00:16:31,460 --> 00:16:35,150
on their credit card. They got to Portugal. Ok. And then when they tried to go home,

350
00:16:35,359 --> 00:16:35,419
uh,

351
00:16:35,429 --> 00:16:37,500
they were told that the purchase was fraudulent

352
00:16:37,510 --> 00:16:39,349
and that their airline tickets had been yanked.

353
00:16:40,169 --> 00:16:41,150
-- That's terrible
-- halfway

354
00:16:41,789 --> 00:16:42,229
through.

355
00:16:42,750 --> 00:16:46,250
Yeah, they were in Portugal, they went to the airport, they tried to, you know,

356
00:16:46,260 --> 00:16:48,690
check in and they were told that their airline tickets had been

357
00:16:48,909 --> 00:16:52,239
essentially, you know, too bad. So sad, good luck with that.

358
00:16:52,650 --> 00:16:55,630
Uh So they ended up having to buy one way tickets for like six grand.

359
00:16:56,580 --> 00:16:58,200
Uh And then it wasn't until, you know,

360
00:16:58,210 --> 00:17:01,549
the CBC news contacted Air Canada that Air Canada finally was like, oh yeah,

361
00:17:01,559 --> 00:17:03,130
we should probably refund you.

362
00:17:03,140 --> 00:17:03,809
So, yeah.

363
00:17:03,820 --> 00:17:06,800
Anyway, so, I mean, that's, I mean, that's a great example of obviously, you know,

364
00:17:06,810 --> 00:17:10,959
some sort of, they claim it was some fraud detection thing that like, oh, sorry,

365
00:17:10,969 --> 00:17:12,239
false positive, you know.

366
00:17:12,250 --> 00:17:14,530
Um, but that's a great example of, you know, where it has

367
00:17:14,780 --> 00:17:17,680
or it can have a really significant real world impact,

368
00:17:18,118 --> 00:17:20,449
you know, and doesn't have to kill anybody, but it's, you know,

369
00:17:20,459 --> 00:17:21,520
really inconvenient.

370
00:17:21,530 --> 00:17:26,449
Ok. So this story leads to a place I, I wanted to get us eventually is

371
00:17:26,890 --> 00:17:27,618
so

372
00:17:28,020 --> 00:17:31,219
when we look at machine learning, especially in the context of security,

373
00:17:31,560 --> 00:17:34,660
it, it sounds like in this case, their fraud detection was very slow

374
00:17:34,869 --> 00:17:35,459
and

375
00:17:35,660 --> 00:17:38,900
often when you're under attack, very slow is very bad.

376
00:17:39,630 --> 00:17:40,589
And so

377
00:17:41,010 --> 00:17:43,500
the, the, the one thing I I always love to think about

378
00:17:44,020 --> 00:17:46,050
and this is kind of for you to comment on here, Mike is

379
00:17:46,160 --> 00:17:48,569
people used to actually read security logs

380
00:17:48,880 --> 00:17:49,349
and

381
00:17:49,459 --> 00:17:53,089
they totally can't anymore because everyone's generating so many of them,

382
00:17:53,099 --> 00:17:54,109
it's not even funny.

383
00:17:54,119 --> 00:17:58,099
And then I guess this kind of brings us to machine learning can give us

384
00:17:58,109 --> 00:18:00,719
the power to essentially do analysis and

385
00:18:00,729 --> 00:18:03,609
detection instantaneously or very close to it.

386
00:18:03,619 --> 00:18:04,170
Correct.

387
00:18:04,939 --> 00:18:08,310
That's right. That's right. It's uh that is the power of,

388
00:18:08,640 --> 00:18:13,609
you know, the, the cliche and the buzzword of big data. You know, it's the ability to

389
00:18:13,790 --> 00:18:15,109
uh index, you know,

390
00:18:15,119 --> 00:18:17,829
massive amounts of data and then perform analysis on

391
00:18:17,839 --> 00:18:19,670
it and then find ways to aggregate it,

392
00:18:19,680 --> 00:18:25,099
visualize it and then uh uh perhaps uh notify people when certain things take place.

393
00:18:25,109 --> 00:18:27,380
So that that is exactly what we're we're talking about.

394
00:18:27,390 --> 00:18:30,530
And the ability to do that in near real time, meaning, you know,

395
00:18:30,540 --> 00:18:36,219
meaning seconds to minutes after it actually happens is extremely valuable.

396
00:18:36,680 --> 00:18:40,280
Uh as, as I'm sure you guys know, and you've probably discussed before, you know,

397
00:18:40,290 --> 00:18:42,699
the, the lag period between when

398
00:18:42,800 --> 00:18:44,439
data breaches uh uh are,

399
00:18:44,449 --> 00:18:46,920
are taking place or when the compromise takes

400
00:18:46,930 --> 00:18:49,199
place and when the organization that's affected,

401
00:18:49,209 --> 00:18:51,209
learns about it is, you know, is massive.

402
00:18:51,219 --> 00:18:52,859
Right. It's, it's months long.

403
00:18:53,150 --> 00:18:57,599
And so if you can prove that down to, uh, you know, down to hours or minutes, uh,

404
00:18:57,609 --> 00:19:00,900
even though it's not traditionally millisecond real time,

405
00:19:00,910 --> 00:19:02,650
it still has massive value.

406
00:19:03,079 --> 00:19:07,119
Well, and I think not only that this is, I, I, I'll let you kind of plug a demo.

407
00:19:07,130 --> 00:19:09,050
I know you worked on at one point was

408
00:19:09,270 --> 00:19:13,569
it's rare for an attacker to kind of only do one thing and get in, right.

409
00:19:13,579 --> 00:19:17,079
There's often many, many signs of compromise. And I know for elastic

410
00:19:17,229 --> 00:19:17,719
con

411
00:19:18,040 --> 00:19:20,089
you guys put together a machine learning demo

412
00:19:20,250 --> 00:19:23,079
that use some of the fancy bear data

413
00:19:23,189 --> 00:19:25,640
showing off kind of kind of what happened.

414
00:19:25,650 --> 00:19:28,180
Can you, can you explain what you guys did because it's, it's super cool.

415
00:19:28,260 --> 00:19:30,459
So, um so a couple things um

416
00:19:30,770 --> 00:19:31,489
the

417
00:19:32,500 --> 00:19:34,770
machine learning. So, so there's um

418
00:19:35,170 --> 00:19:38,290
you know, there's threat indicator lists that are,

419
00:19:38,300 --> 00:19:41,589
it's good to know if uh entities within your infrastructure are

420
00:19:41,599 --> 00:19:46,339
visiting um network locations that are known to be associated with,

421
00:19:46,349 --> 00:19:47,449
with threat activity.

422
00:19:47,459 --> 00:19:48,640
So that that's good to know.

423
00:19:49,040 --> 00:19:51,869
Uh But what is also good to know is

424
00:19:51,880 --> 00:19:55,239
when entities in your organization are behaving unusually.

425
00:19:55,670 --> 00:19:58,959
And so the de the demo that we put together combined both of those

426
00:19:59,229 --> 00:19:59,250
uh

427
00:19:59,390 --> 00:20:03,369
and, and it was a storyline. So the the attack progression started

428
00:20:03,500 --> 00:20:07,569
with a computer uh in our uh network that

429
00:20:07,780 --> 00:20:11,270
indeed was visiting sites that were known to be associated with threat activity.

430
00:20:11,280 --> 00:20:15,329
Uh And, and we had records of that captured in the logs because, um,

431
00:20:15,339 --> 00:20:18,010
we were able to match the destination IP address

432
00:20:18,119 --> 00:20:21,079
to which the network connection was targeting,

433
00:20:21,239 --> 00:20:22,819
uh against the threat list.

434
00:20:23,099 --> 00:20:26,609
Um, but by itself, that isn't necessarily something you'd alert on.

435
00:20:26,619 --> 00:20:28,819
Um, but it's just something good to notice.

436
00:20:29,449 --> 00:20:32,790
And in our demo, what we did is much later in the process,

437
00:20:33,489 --> 00:20:35,589
we found that that system was performing

438
00:20:35,599 --> 00:20:38,619
behaviors that appeared to be data exfiltration

439
00:20:38,790 --> 00:20:41,969
uh by sneaking out data over the uh DNS protocol.

440
00:20:42,180 --> 00:20:45,790
And so during the course of the demonstration, we had machine learning

441
00:20:45,939 --> 00:20:48,420
uh automated anomaly detection, say, hey,

442
00:20:48,430 --> 00:20:50,989
something really unusual is happening uh on the DNS

443
00:20:51,000 --> 00:20:54,089
protocol and this workstation is responsible for it.

444
00:20:54,369 --> 00:20:55,790
And upon investigation,

445
00:20:55,800 --> 00:20:59,479
we went backwards and looked through the data that we had the security log data.

446
00:20:59,489 --> 00:21:01,150
And sure enough, looking back,

447
00:21:01,160 --> 00:21:05,150
we were able to establish that the bad behavior started with this initial visit,

448
00:21:05,160 --> 00:21:08,829
visit to the IP address associated with the threat activity.

449
00:21:08,839 --> 00:21:12,680
That's cool. Well, and then didn't you guys manage to kind of link

450
00:21:12,939 --> 00:21:16,260
two machines together due to some sort of activity that,

451
00:21:16,270 --> 00:21:18,229
that a human almost certainly would not have found?

452
00:21:18,400 --> 00:21:23,989
Yeah, we used uh uh this, this technique as a form of graph analysis

453
00:21:24,430 --> 00:21:28,900
uh which allows you to visualize all the activity that we had in the logs

454
00:21:29,209 --> 00:21:30,530
uh between the

455
00:21:30,930 --> 00:21:36,349
the, the workstation that was detected, performing this anomalous DNS behavior

456
00:21:36,449 --> 00:21:37,459
we look to see,

457
00:21:37,469 --> 00:21:42,270
was there any commonality between the sites that it visited and

458
00:21:42,280 --> 00:21:46,489
uh sites that other systems in our network may have visited?

459
00:21:46,790 --> 00:21:50,089
And sure enough, um you know, the system that was doing, the exfiltration

460
00:21:50,349 --> 00:21:53,760
has visited sites that uh only one or two other

461
00:21:53,770 --> 00:21:56,930
systems within the organization had also visited in common.

462
00:21:57,060 --> 00:21:58,689
And uh they were,

463
00:21:58,699 --> 00:22:01,400
um one of those sites was associated with the

464
00:22:01,410 --> 00:22:04,670
same country to which the threat activity was seen.

465
00:22:04,770 --> 00:22:08,349
And so visually, being able to identify this, he said, aha, I

466
00:22:08,459 --> 00:22:09,979
may not have seen ext

467
00:22:10,089 --> 00:22:10,380
activity

468
00:22:10,665 --> 00:22:12,155
from workstation number two,

469
00:22:12,165 --> 00:22:14,454
but I sure as heck am gonna go investigate

470
00:22:14,464 --> 00:22:16,354
it first to make sure that doesn't happen next.

471
00:22:16,454 --> 00:22:17,074
Right. Right.

472
00:22:17,084 --> 00:22:22,714
Which kind of brings us into the new universe of something known as thread hunting.

473
00:22:22,724 --> 00:22:23,194
Right. E

474
00:22:23,425 --> 00:22:24,655
exactly.

475
00:22:24,875 --> 00:22:28,454
You know, traditionally because of the very problem you brought up, Josh, you know,

476
00:22:28,464 --> 00:22:32,255
it used to be practical to go ahead and look at security logs and,

477
00:22:32,265 --> 00:22:34,084
and have humans parse them and read them.

478
00:22:34,459 --> 00:22:37,199
Um, we, we're, we're to the point where that's, that's just not,

479
00:22:37,209 --> 00:22:38,339
not possible anymore.

480
00:22:38,349 --> 00:22:43,900
So the way that we progressed within security operations was to introduce

481
00:22:44,079 --> 00:22:44,849
automation

482
00:22:45,000 --> 00:22:48,530
and the basic forms of automation was in the rules.

483
00:22:48,540 --> 00:22:52,859
I write rules that say, uh, you know, look at all my log data and if you see

484
00:22:53,140 --> 00:22:57,160
anything that looks like this or the number of these that exceed a threshold.

485
00:22:57,170 --> 00:22:59,959
Uh For example, the number of bytes outbound from any

486
00:23:00,150 --> 00:23:03,939
client in my network. If it exceeds 10 megabytes, I want to know about it.

487
00:23:04,180 --> 00:23:07,890
And these attempts at automation were absolutely necessary because

488
00:23:07,900 --> 00:23:10,319
the volume of security log data had increased.

489
00:23:10,810 --> 00:23:11,349
But

490
00:23:11,849 --> 00:23:15,609
the rules themselves were not actually that great. They were noisy.

491
00:23:15,619 --> 00:23:17,770
They generated a lot of false positive alerts

492
00:23:17,930 --> 00:23:21,780
and I spent a lot of time investigating rules rather than looking at security logs.

493
00:23:21,790 --> 00:23:24,069
I was ruling out, you know, false positives.

494
00:23:24,410 --> 00:23:25,459
And, and so

495
00:23:25,699 --> 00:23:27,449
what we're, we're talking about, you know,

496
00:23:27,459 --> 00:23:29,939
that's how threatened monitoring uh came about.

497
00:23:30,099 --> 00:23:32,020
And so this machine learning technology

498
00:23:32,239 --> 00:23:35,390
that we are talking about today can really help

499
00:23:35,505 --> 00:23:40,125
automate that further and, and make monitoring much, much more high fidelity

500
00:23:40,364 --> 00:23:43,444
in terms of finding the unusual things that are uh

501
00:23:43,454 --> 00:23:45,614
would have been very difficult to write rules for.

502
00:23:45,625 --> 00:23:46,055
Right.

503
00:23:46,064 --> 00:23:46,964
So I guess here's the,

504
00:23:46,974 --> 00:23:50,104
the magic question is you mentioned false

505
00:23:50,114 --> 00:23:52,505
positives and anyone who's ever looked in any

506
00:23:52,515 --> 00:23:55,854
sort of logs or any sort of rules for their SIM or what not,

507
00:23:55,864 --> 00:23:56,244
is

508
00:23:56,474 --> 00:23:59,084
the false positive rate is abysmal.

509
00:23:59,410 --> 00:24:02,810
So now have you guys done any research into kind of how the

510
00:24:02,819 --> 00:24:06,849
machine learning false positive rate compared to the I I guess static rule,

511
00:24:06,859 --> 00:24:08,589
false positive rate you'd normally see.

512
00:24:08,650 --> 00:24:10,430
So we have we have a couple of examples.

513
00:24:10,439 --> 00:24:11,010
In fact, it's,

514
00:24:11,020 --> 00:24:13,430
it's really similar to the one I was just talking about

515
00:24:13,439 --> 00:24:16,150
if you look at logs that come from uh web proxy,

516
00:24:16,160 --> 00:24:18,319
uh let's take this as an enterprise, web proxy,

517
00:24:18,329 --> 00:24:21,670
which means any user in the enterprise that wants to go to the internet,

518
00:24:21,719 --> 00:24:25,790
uh makes the requests to the proxy first and then the proxy will

519
00:24:25,800 --> 00:24:28,949
either uh not let your request go through or let it go through.

520
00:24:29,459 --> 00:24:34,680
Logs from proxies are great sources of analysis for rules of all sorts.

521
00:24:35,119 --> 00:24:38,250
So traditional security information and event management product,

522
00:24:38,260 --> 00:24:42,719
a SIM product had a rule and dashboard set up that took those

523
00:24:42,729 --> 00:24:46,560
logs and looked at the sum of the outbound bytes for a given entity

524
00:24:46,849 --> 00:24:49,630
and triggered a rule if you see anybody over.

525
00:24:49,640 --> 00:24:54,109
Um I can't remember if it was 100 megabytes uh in a daytime,

526
00:24:54,119 --> 00:24:57,030
then uh run this analysis every day and let me know if,

527
00:24:57,040 --> 00:25:01,750
if someone had this kind of volume of external bytes in the outbound direction.

528
00:25:02,329 --> 00:25:02,829
So we,

529
00:25:02,839 --> 00:25:06,180
we got the opportunity to see the results from this running on a 30,000 seat

530
00:25:06,189 --> 00:25:11,510
enterprise and the number of alerts triggered by that rule as it was in,

531
00:25:11,520 --> 00:25:12,510
in a given day

532
00:25:12,619 --> 00:25:14,310
was around 8000.

533
00:25:15,880 --> 00:25:16,369
So

534
00:25:16,739 --> 00:25:21,229
how did you, you can't deal with that? Right. So it was, it was just uh unusable.

535
00:25:21,359 --> 00:25:23,619
Now, that was with the static threshold.

536
00:25:24,199 --> 00:25:28,099
Lots of SIMS have technology that use basic statistics, right?

537
00:25:28,109 --> 00:25:29,449
Which say, hey, you know what,

538
00:25:29,469 --> 00:25:33,780
why don't we run a running average or build a running average of what

539
00:25:33,790 --> 00:25:37,949
the number of bytes is over uh this time period of the analysis,

540
00:25:37,959 --> 00:25:39,060
which happen to be a day

541
00:25:39,319 --> 00:25:42,640
and then only flag an alert when you have uh you know,

542
00:25:42,650 --> 00:25:45,699
uh plus two standard deviations over the average,

543
00:25:45,709 --> 00:25:46,939
this running average that you have.

544
00:25:47,099 --> 00:25:47,579
And

545
00:25:47,790 --> 00:25:49,449
that was done with a traditional SIM

546
00:25:50,140 --> 00:25:54,430
and that reduced uh that reduced the number of alerts about eight fold.

547
00:25:54,479 --> 00:25:58,439
Uh So it got down from about 8000 to about 1000 in a given day,

548
00:25:58,449 --> 00:26:00,680
which is still completely insane though, right?

549
00:26:00,719 --> 00:26:00,750
In

550
00:26:00,869 --> 00:26:03,939
progress, but nobody wants to, to look at 1000.

551
00:26:04,410 --> 00:26:08,550
So we, we, we took the, the same, essentially the same logic rule.

552
00:26:08,750 --> 00:26:15,030
Uh But instead used machine learning to model what is the normal behavior

553
00:26:15,040 --> 00:26:18,469
of the sum of the outbound bytes as reported by this web proxy log

554
00:26:18,989 --> 00:26:23,520
at a given time and only flag us when things are significantly unusual.

555
00:26:23,869 --> 00:26:31,390
And so the in that case, um we got down to tens of alerts on, on a daily basis,

556
00:26:31,469 --> 00:26:35,849
including some that were highly unusual that would have snuck underneath both the

557
00:26:35,859 --> 00:26:40,199
moving average and the static threshold things that were really of investigation.

558
00:26:40,750 --> 00:26:43,300
So, so we're really talking about orders of magnitude, right?

559
00:26:43,310 --> 00:26:47,689
So we're going down from thousands to tens of alerts in a, in a given day.

560
00:26:47,780 --> 00:26:51,689
So at least a couple orders of magnitude and we've seen better results than that.

561
00:26:52,130 --> 00:26:54,729
Well, I feel like 10 is a number

562
00:26:54,979 --> 00:26:56,989
that a security team can handle.

563
00:26:57,310 --> 00:26:59,810
-- 1000 is not, right.
-- That's right.

564
00:27:00,380 --> 00:27:01,770
Wow, that, that's wild man.

565
00:27:01,780 --> 00:27:05,270
That, that sounds like an impressive false positive rate.

566
00:27:05,280 --> 00:27:07,199
Uh Although now, now let me say though,

567
00:27:07,209 --> 00:27:14,119
is how difficult when you talk about kind of these rules to decide what the the uh

568
00:27:14,380 --> 00:27:17,979
I guess thresholds are for your, your data use in this case is

569
00:27:18,369 --> 00:27:22,660
is this supervised? How I guess how do you define this rule? Right?

570
00:27:22,670 --> 00:27:24,359
Because you can't just kind of be say here

571
00:27:24,369 --> 00:27:27,359
magic machine learning algorithm figure out what's going on,

572
00:27:27,369 --> 00:27:27,640
right?

573
00:27:27,650 --> 00:27:29,719
Like a human has to set this up, right?

574
00:27:30,500 --> 00:27:31,140
Yeah. Yeah.

575
00:27:31,150 --> 00:27:33,150
So, so um there's a portion of,

576
00:27:33,160 --> 00:27:36,410
of machine learning that that is called uh feature selection.

577
00:27:36,890 --> 00:27:40,510
Um And that's basically just deciding which fields in the data and,

578
00:27:40,520 --> 00:27:42,439
and logs that you're gonna look at and you're gonna model.

579
00:27:42,810 --> 00:27:48,479
Uh So the the feature selection part is done by the analyst. So when you configure,

580
00:27:48,729 --> 00:27:50,790
um let us take the case of the

581
00:27:50,800 --> 00:27:52,989
unsupervised machine learning that we're talking about.

582
00:27:53,160 --> 00:27:54,680
You, you basically configure

583
00:27:54,800 --> 00:27:57,099
this basic element of machine learning called a job.

584
00:27:57,349 --> 00:28:01,109
And what you point out in that job is this is the index

585
00:28:01,219 --> 00:28:02,560
that we'd like to operate on.

586
00:28:02,569 --> 00:28:03,939
So this is the log source,

587
00:28:03,949 --> 00:28:07,380
these are the fields within the log that we'd like to do operations on.

588
00:28:07,640 --> 00:28:11,650
And you give general guidance as to which type of anomalies you'd like to look for.

589
00:28:11,989 --> 00:28:12,619
And that's it.

590
00:28:12,989 --> 00:28:16,890
And then you start the job and then the machine learning does all the rest.

591
00:28:16,959 --> 00:28:20,300
You do not specify model types. You don't specify

592
00:28:20,550 --> 00:28:24,660
uh averages, standard deviations, no statistics, no programming,

593
00:28:24,849 --> 00:28:26,979
uh no model instantiation.

594
00:28:26,989 --> 00:28:30,300
You basically just point it to the field and say, you know, go,

595
00:28:30,310 --> 00:28:31,630
go determine what's normal.

596
00:28:31,640 --> 00:28:33,430
And let me know if what actually happens

597
00:28:33,439 --> 00:28:35,239
is different than what you've determined is normal.

598
00:28:35,319 --> 00:28:36,380
That's really cool.

599
00:28:37,189 --> 00:28:37,619
Yeah, I

600
00:28:37,739 --> 00:28:37,910
love

601
00:28:38,050 --> 00:28:38,069
it.

602
00:28:38,530 --> 00:28:42,729
And you know, Josh, you bring up a great topic, which is the false positives.

603
00:28:43,000 --> 00:28:46,989
So when we talk about machine learning, because it is mathematics and statistics,

604
00:28:47,420 --> 00:28:50,660
there's usually um depending on who you're speaking to,

605
00:28:51,250 --> 00:28:54,479
um that you'll find two different definitions of false positive.

606
00:28:54,670 --> 00:28:56,140
The security guys are going to say

607
00:28:56,420 --> 00:29:01,140
was that an actual cyber attack? And that's their definition for a false positive.

608
00:29:01,160 --> 00:29:03,400
Whereas the mathematician will say,

609
00:29:03,989 --> 00:29:07,339
did that produce something that was truly statistically anomalous

610
00:29:07,989 --> 00:29:13,849
and a lot of times uh the answers are uh uh no and yes, respectively.

611
00:29:14,390 --> 00:29:14,770
So

612
00:29:14,880 --> 00:29:16,290
let me give an example of,

613
00:29:16,300 --> 00:29:20,369
of another situation that we run into with this machine learning in the security

614
00:29:20,630 --> 00:29:24,530
um realm. Uh We're looking for a different kind of ex filtration.

615
00:29:24,540 --> 00:29:28,209
Uh not, not with web proxies, but by looking at DNS logs.

616
00:29:29,099 --> 00:29:29,780
And so

617
00:29:29,920 --> 00:29:37,050
the analysis ran over a billion uh records a 30 day supply of DNS query.

618
00:29:37,060 --> 00:29:39,520
Uh questions coming from the client population,

619
00:29:39,530 --> 00:29:41,719
going to the DNS server and they got the logs

620
00:29:41,729 --> 00:29:44,680
back from the DNS server and performed analysis on them,

621
00:29:44,689 --> 00:29:45,630
looking for,

622
00:29:45,989 --> 00:29:48,239
looking for unusual behavior that might be associated

623
00:29:48,250 --> 00:29:50,630
with exfiltration of data over the DNS protocol.

624
00:29:50,900 --> 00:29:54,089
So the algorithms identified exactly four instances of high

625
00:29:54,119 --> 00:29:57,750
scoring anomalies that were related to DNS tunneling,

626
00:29:57,760 --> 00:29:59,800
which is, you know, the practice of sending data,

627
00:29:59,890 --> 00:30:02,189
non DNS data out over the DNS protocol.

628
00:30:02,199 --> 00:30:02,510
Sure.

629
00:30:03,150 --> 00:30:07,329
And so the company investigated those and it, and it turns out that

630
00:30:07,770 --> 00:30:09,560
there is an antivirus product. Uh Sophos

631
00:30:09,880 --> 00:30:14,890
antivirus uses this product called uh uses this protocol called SSS XL,

632
00:30:15,119 --> 00:30:17,609
uh which actually tunnels over the DNS protocol.

633
00:30:17,619 --> 00:30:21,089
It's how they do some of the live updates for some of the stuff that they work.

634
00:30:21,420 --> 00:30:26,770
So all four anomalies detected by the algorithms were verified to be actual

635
00:30:26,780 --> 00:30:32,209
DNS tunneling that was um running over this antivirus uh Softwares protocol.

636
00:30:32,520 --> 00:30:34,729
So, was that a false positive or not?

637
00:30:36,050 --> 00:30:37,310
So, I don't think so,

638
00:30:39,180 --> 00:30:39,209
but,

639
00:30:40,119 --> 00:30:43,119
oh, that was just antivirus software that wasn't really an attack.

640
00:30:43,430 --> 00:30:45,660
And so, you know, we, we took the position, look, look,

641
00:30:45,839 --> 00:30:48,540
you know, did would you have wanted to know about that?

642
00:30:48,949 --> 00:30:52,260
And so as it turns out, so we take the position that was not a false positive,

643
00:30:52,270 --> 00:30:53,420
that was a good detection.

644
00:30:53,520 --> 00:30:57,969
And in this case, here's why, so the company that had those results said,

645
00:30:58,109 --> 00:30:59,650
wait a minute, we don't use

646
00:30:59,880 --> 00:31:02,560
Sophos S XL and employees are not allowed to install

647
00:31:02,569 --> 00:31:05,099
their own antivirus or have their computers on the network.

648
00:31:05,109 --> 00:31:07,449
Give me the IP addresses of those four computers, please.

649
00:31:07,459 --> 00:31:10,150
And then they took off and they went and looked at it.

650
00:31:10,400 --> 00:31:11,670
So, you know, it was a,

651
00:31:11,680 --> 00:31:15,520
it was a good event but it wasn't necessarily a cyber attack in progress.

652
00:31:15,530 --> 00:31:16,520
-- Right.
-- Right. And

653
00:31:16,739 --> 00:31:18,579
let's face it too. I think

654
00:31:19,479 --> 00:31:20,770
in any enterprise,

655
00:31:20,780 --> 00:31:25,170
a significant number of your problems isn't necessarily direct attacks.

656
00:31:25,180 --> 00:31:29,469
It's people making a whole bunch of foolish mistakes that end badly. Right.

657
00:31:29,479 --> 00:31:33,489
And this gives you kind of an opportunity to identify some of those foolish mistakes

658
00:31:33,699 --> 00:31:35,609
prior to it starting on fire.

659
00:31:35,770 --> 00:31:37,369
Exactly. Exactly. Right.

660
00:31:37,550 --> 00:31:39,729
So why don't we change gears for a minute? And

661
00:31:40,160 --> 00:31:41,780
let's talk about wanna cry,

662
00:31:41,790 --> 00:31:46,180
which has been super exciting while using the word exciting in quotes, I guess.

663
00:31:46,189 --> 00:31:49,979
And how can something like machine learning assist us

664
00:31:50,239 --> 00:31:53,609
with, with something like this ransomware attack that's actually happening?

665
00:31:53,619 --> 00:31:53,780
Right.

666
00:31:53,790 --> 00:31:57,000
This is kind of let let's do some real world application

667
00:31:57,010 --> 00:31:59,939
to what is kind of magic technology to many people.

668
00:32:01,969 --> 00:32:06,510
Yeah. So, so um you know, the the the wanna cry is an example of ransomware.

669
00:32:06,520 --> 00:32:10,750
Um as, as you guys know, ransomware is not new, been around for a long time.

670
00:32:10,959 --> 00:32:14,030
Uh This was a particularly interesting one because it combined uh

671
00:32:14,530 --> 00:32:18,859
uh ransomware with, with uh worm type uh propagation.

672
00:32:19,010 --> 00:32:25,099
Uh Not unlike a lot of the worms we had 10 years ago um that were taking advantage of

673
00:32:25,319 --> 00:32:28,790
vulnerabilities in the the windows uh SMB service.

674
00:32:29,060 --> 00:32:33,920
So if you combined ransomware with worm, you get a rapidly spreading

675
00:32:34,130 --> 00:32:34,800
uh

676
00:32:36,589 --> 00:32:38,630
phenomenon like we we had with wanna crime.

677
00:32:39,130 --> 00:32:43,589
So the the question gets back, how do you detect things with machine learning?

678
00:32:43,599 --> 00:32:46,599
And let's take machine learning in the form of automated anomaly detection

679
00:32:46,729 --> 00:32:50,839
that might indicate the spread of more ransomware like this.

680
00:32:51,410 --> 00:32:51,550
Uh

681
00:32:51,650 --> 00:32:55,750
and again, by, by and themselves, ransomware is not new. Uh worms are not new.

682
00:32:56,040 --> 00:33:00,180
Uh How do you use these techniques to determine the presence of those two things?

683
00:33:00,900 --> 00:33:01,430
So

684
00:33:01,550 --> 00:33:03,130
what, what's unusual about it?

685
00:33:03,250 --> 00:33:06,619
So one of the things that is unusual in the spread of a worm

686
00:33:06,630 --> 00:33:10,689
ransomware or otherwise is whatever their scanning

687
00:33:10,699 --> 00:33:13,150
activity is for finding the next victims

688
00:33:13,310 --> 00:33:17,219
is, is probably unusual. In fact, it's almost always unusual.

689
00:33:17,540 --> 00:33:22,119
So taking a look at network traffic by protocol, for example,

690
00:33:22,160 --> 00:33:27,119
and building models on a protocol by protocol basis of what is the amount of

691
00:33:27,130 --> 00:33:32,599
activity uh normal basis hour of day and day of week modeled over periods of time

692
00:33:32,849 --> 00:33:34,050
and looking for anomalies.

693
00:33:34,060 --> 00:33:38,189
And that uh can be a very good early indicator of worm based activity.

694
00:33:38,199 --> 00:33:44,109
So you'd be finding uh you know, unusual amounts of uh requests for TCP 445.

695
00:33:44,250 --> 00:33:47,319
Uh that would be an indicator that, hey, something's going on strange here,

696
00:33:47,329 --> 00:33:48,540
better go investigate that.

697
00:33:48,680 --> 00:33:50,199
So that's, that's a simple example.

698
00:33:50,239 --> 00:33:53,780
I've seen some more elaborate ones uh that are looking

699
00:33:53,790 --> 00:33:57,030
at information coming from the file system on a computer.

700
00:33:57,609 --> 00:33:57,709
Um,

701
00:33:57,719 --> 00:34:00,670
it turns out that when ransomware is running

702
00:34:00,680 --> 00:34:04,160
the activity of encrypting the files on the disk

703
00:34:04,349 --> 00:34:05,910
is highly unusual.

704
00:34:05,920 --> 00:34:10,458
It is a uninterrupted sequence of file reads and writes that looks

705
00:34:10,469 --> 00:34:15,239
different than many of the activities that normally operate on a computer.

706
00:34:15,320 --> 00:34:18,030
So we, I have not seen these results but we,

707
00:34:18,040 --> 00:34:19,708
I know of a customer that is using uh

708
00:34:19,719 --> 00:34:23,620
unsupervised machine learning and anomaly detection on file system

709
00:34:23,978 --> 00:34:27,040
activity as reported by an agent running on their clients

710
00:34:27,070 --> 00:34:32,360
that is reportedly able to identify um the operation of

711
00:34:32,938 --> 00:34:36,770
crypto uh you know, ransomware within um a

712
00:34:37,080 --> 00:34:39,080
very small number of files.

713
00:34:39,090 --> 00:34:42,219
So while it wouldn't prevent the entire system, sorry,

714
00:34:42,228 --> 00:34:43,688
it would prevent the entire system.

715
00:34:43,699 --> 00:34:47,639
It doesn't protect every file, but it does detect this activity as being unusual.

716
00:34:47,978 --> 00:34:50,219
So that would be like another example that's a little

717
00:34:50,228 --> 00:34:52,918
bit on the newer end of the ransomware side.

718
00:34:52,929 --> 00:34:53,580
Right. Right.

719
00:34:53,590 --> 00:34:58,199
That, that sounds like it would be super heavy resource wise to, I guess,

720
00:34:58,209 --> 00:35:00,989
track and even process that volume of data.

721
00:35:01,729 --> 00:35:03,360
So it is, right. So

722
00:35:03,909 --> 00:35:07,040
in order to detect this, you'd want to have updates on, um, you know,

723
00:35:07,050 --> 00:35:10,330
pretty frequent rate coming from all of your end points.

724
00:35:10,729 --> 00:35:13,350
Let's say you even got, you know, every, um,

725
00:35:13,679 --> 00:35:17,760
twice a minute uh coming from each end point and you've got a big enterprise

726
00:35:17,770 --> 00:35:24,060
with tens of thousands of enterprises and the uh file activity is just one area.

727
00:35:24,070 --> 00:35:28,280
These agents you have today from some endpoint detection and response um software.

728
00:35:28,379 --> 00:35:29,780
They have all kinds of things.

729
00:35:29,790 --> 00:35:34,560
They have information in a whole tree of process related information, file system,

730
00:35:34,570 --> 00:35:36,000
physical device,

731
00:35:36,010 --> 00:35:39,260
uh memory and all these metrics and logs are coming

732
00:35:39,270 --> 00:35:41,580
in and it is just truly a massive problem.

733
00:35:41,949 --> 00:35:44,129
So you are right, in order to detect

734
00:35:44,850 --> 00:35:46,239
ransomware activity,

735
00:35:46,250 --> 00:35:50,030
you need to be able to have events coming from the end points at a high rate.

736
00:35:50,080 --> 00:35:53,889
They need to be able to be indexed very quickly into the

737
00:35:54,360 --> 00:35:57,139
uh analysis system. And then the

738
00:35:57,659 --> 00:35:58,379
analysis,

739
00:35:58,389 --> 00:36:00,010
the machine learning job would have to run on a

740
00:36:00,020 --> 00:36:03,000
very frequent basis to be able to detect that within,

741
00:36:03,010 --> 00:36:06,229
-- you know, within minutes of, of it actually beginning
-- right now.

742
00:36:06,239 --> 00:36:07,709
Now let me ask this though. OK.

743
00:36:07,719 --> 00:36:11,739
So let's say we, we see something like that in this context to

744
00:36:12,060 --> 00:36:15,399
would it be expected for an automation automated response or do

745
00:36:15,409 --> 00:36:17,199
you just kind of blink a light and tell the person,

746
00:36:17,209 --> 00:36:20,080
hey human, come, come check this out, something weird is going on?

747
00:36:20,939 --> 00:36:24,199
Um So that's a really big topic, the automated

748
00:36:24,479 --> 00:36:28,449
-- response.
-- And that also sounds like where things could really go sideways

749
00:36:28,840 --> 00:36:30,270
once you automate it.

750
00:36:30,469 --> 00:36:33,070
That, that generally is the reason why in my experience,

751
00:36:33,080 --> 00:36:37,189
most organizations have very limited if any uh automated responses.

752
00:36:37,860 --> 00:36:39,949
Um There's a couple of exceptions, but in this case,

753
00:36:39,959 --> 00:36:43,149
it would be letting somebody know, is the most likely scenario.

754
00:36:43,159 --> 00:36:43,669
Right.

755
00:36:43,770 --> 00:36:44,629
Yeah, I can,

756
00:36:45,149 --> 00:36:46,389
I can totally see that, that

757
00:36:46,719 --> 00:36:49,459
it's like when you always hear these stories about where

758
00:36:49,620 --> 00:36:53,000
there is, there's an antivirus program that, that detects itself,

759
00:36:53,010 --> 00:36:54,379
it's a virus and then it

760
00:36:54,659 --> 00:36:54,840
kind of

761
00:36:55,000 --> 00:36:56,379
self destructs or something

762
00:36:56,850 --> 00:36:57,409
because

763
00:36:57,909 --> 00:36:59,360
that's, that's wild.

764
00:37:00,239 --> 00:37:04,550
Interesting. So, I guess the, the next thing that, that's in my brain here is

765
00:37:04,659 --> 00:37:06,699
you, you've spoken at length,

766
00:37:06,709 --> 00:37:09,510
kind of about how all this stuff works and what's going on.

767
00:37:09,520 --> 00:37:09,959
And

768
00:37:10,270 --> 00:37:13,459
the thing that always comes back to me is the thought of

769
00:37:13,860 --> 00:37:14,419
when

770
00:37:14,610 --> 00:37:17,300
you look at spam will be my example here.

771
00:37:17,310 --> 00:37:20,260
Um And, and even, I guess viruses to, to a degree is they,

772
00:37:20,850 --> 00:37:24,899
they always find a way to get around this. But it sounds like with

773
00:37:25,040 --> 00:37:27,169
proper unsupervised machine learning,

774
00:37:27,179 --> 00:37:30,270
the ability to evade detection is going to be

775
00:37:30,439 --> 00:37:32,100
incredibly difficult.

776
00:37:32,209 --> 00:37:36,860
That is one advantage that the unsupervised machine learning may have over,

777
00:37:36,870 --> 00:37:38,989
you know, trained or supervised approaches.

778
00:37:39,000 --> 00:37:39,110
Uh is,

779
00:37:39,120 --> 00:37:41,860
is that because the models that are being

780
00:37:41,870 --> 00:37:44,469
used to determine whether or not things are unusual

781
00:37:44,689 --> 00:37:48,229
are specific to the environment in which they're running.

782
00:37:48,570 --> 00:37:53,169
Um It's very difficult for an adversary to do what we spoke about earlier,

783
00:37:53,179 --> 00:37:54,110
which is to, you know,

784
00:37:54,120 --> 00:37:57,550
run their malware against the the software model that everybody uses.

785
00:37:57,959 --> 00:38:00,750
And so it does have that advantage that makes it

786
00:38:00,760 --> 00:38:04,209
harder to evade it also has some characteristics that you

787
00:38:04,219 --> 00:38:07,189
could think of as being less favorable uh in the

788
00:38:07,199 --> 00:38:10,550
sense that let's say you start your unsupervised machine learning

789
00:38:10,659 --> 00:38:11,510
jobs

790
00:38:11,810 --> 00:38:17,189
in an environment that already has bad unusual behaviors uh that are going on.

791
00:38:17,199 --> 00:38:19,370
Um We talked already about data exfiltration.

792
00:38:19,379 --> 00:38:21,080
Let's say we started machine learning

793
00:38:21,320 --> 00:38:24,510
uh analysis running on the logs from my network,

794
00:38:24,520 --> 00:38:26,780
but my computer was infected and it was

795
00:38:26,790 --> 00:38:29,469
ex filtrating data continuously or every day.

796
00:38:29,479 --> 00:38:29,810
So,

797
00:38:29,820 --> 00:38:32,429
one of the things you have to watch out for is that the

798
00:38:32,439 --> 00:38:35,989
machine learning jobs could learn that that's normal and they would never raise,

799
00:38:36,000 --> 00:38:39,909
they would never raise uh any, any indication that something is unusual.

800
00:38:40,270 --> 00:38:42,610
I suppose that's, that's a really good point, isn't it?

801
00:38:43,330 --> 00:38:45,790
Yeah. So, but there's a solution to this,

802
00:38:45,959 --> 00:38:47,770
um, because the different types of

803
00:38:48,020 --> 00:38:50,169
machine learning jobs that can be run,

804
00:38:50,409 --> 00:38:53,280
uh include a couple of fundamental, um,

805
00:38:53,760 --> 00:38:56,129
anomaly detection techniques.

806
00:38:56,239 --> 00:38:59,620
So normally when we think of anomaly detection, we're, we're saying, hey,

807
00:38:59,629 --> 00:39:02,729
is Mike's computer operating differently now than it

808
00:39:02,989 --> 00:39:07,459
was predicted to be now at this time based on past behavior.

809
00:39:07,889 --> 00:39:09,840
So, in other words, if every day, you know,

810
00:39:09,850 --> 00:39:13,860
I do certain behaviors and I use DNS and I use HTP

811
00:39:14,070 --> 00:39:16,709
and the system learns what my normal behaviors are.

812
00:39:16,719 --> 00:39:20,060
If I start behaving differently, then it's gonna say, hey, anomaly,

813
00:39:20,070 --> 00:39:21,780
my system is behaving differently.

814
00:39:22,469 --> 00:39:26,370
So that's, we'll call that type of analysis, you know, individual entities,

815
00:39:26,379 --> 00:39:30,409
uh looking for uh deviations of behavior based on its learned past.

816
00:39:31,110 --> 00:39:31,570
So,

817
00:39:31,580 --> 00:39:33,739
that would have the characteristic that we just talked about

818
00:39:33,750 --> 00:39:35,870
that if I was behaving badly the whole time,

819
00:39:35,879 --> 00:39:37,070
it wouldn't be unusual.

820
00:39:37,820 --> 00:39:42,810
Another type of analysis that is commonly done is called the population analysis

821
00:39:43,179 --> 00:39:47,020
where we look at in aggregate in, in one analysis, the behavior

822
00:39:47,310 --> 00:39:50,239
of all the systems that are like

823
00:39:50,370 --> 00:39:51,739
uh within an environment.

824
00:39:51,840 --> 00:39:54,540
So in that case, we look at all the computers,

825
00:39:54,550 --> 00:39:57,060
Mikes and Josh's and Kurtz and everybody else and

826
00:39:57,070 --> 00:39:59,489
we'd have a population of those and you say,

827
00:39:59,500 --> 00:40:03,060
is any one of those entities acting differently than the others.

828
00:40:03,479 --> 00:40:08,100
So, unless all the other entities were infected in exfil trading,

829
00:40:08,350 --> 00:40:11,820
uh at least Mike's computer would stand out from that analysis that says, you know,

830
00:40:11,830 --> 00:40:14,239
Mike's computer is acting like it always does,

831
00:40:14,250 --> 00:40:18,260
but it's acting differently than the, the group of pure computers.

832
00:40:18,270 --> 00:40:22,020
-- Uh, that, that it's part of,
-- right? That sounds really useful.

833
00:40:22,030 --> 00:40:23,780
That's like very her mentality, right?

834
00:40:23,790 --> 00:40:26,610
Where we're looking for a, a across everything because,

835
00:40:26,729 --> 00:40:27,300
right, I mean,

836
00:40:27,469 --> 00:40:30,449
and so this is one of the things I always love is, for example,

837
00:40:30,459 --> 00:40:32,610
if you look at the security guy's computer, obviously,

838
00:40:32,620 --> 00:40:34,000
it's a train wreck all the time.

839
00:40:34,010 --> 00:40:35,280
And so that's not a good example.

840
00:40:35,290 --> 00:40:38,199
But you know, if, if you got like some random support guy

841
00:40:38,520 --> 00:40:40,760
that doing something really crazy, you know, there,

842
00:40:40,770 --> 00:40:42,610
there could be something weird going down there.

843
00:40:42,620 --> 00:40:44,959
So, I, I like that. Ah, that's cool.

844
00:40:45,320 --> 00:40:50,290
So we almost think of those as, you know, orthogonal analysis, right? So, uh, so, so

845
00:40:50,820 --> 00:40:51,679
like when we, we,

846
00:40:51,689 --> 00:40:55,300
we work with a customer to set up their collection of machine learning jobs,

847
00:40:55,330 --> 00:40:56,959
you're looking for both, uh,

848
00:40:56,969 --> 00:40:59,850
entities behaving unusually versus their past

849
00:40:59,860 --> 00:41:03,199
and entities behaving differently than their peers

850
00:41:03,489 --> 00:41:03,739
and

851
00:41:04,010 --> 00:41:05,280
constantly for each

852
00:41:05,459 --> 00:41:08,439
area of coverage that you'd like to get within the,

853
00:41:08,790 --> 00:41:11,360
you know, overall problem space of threat detection,

854
00:41:11,590 --> 00:41:12,739
uh, in each of those,

855
00:41:12,750 --> 00:41:14,310
if you have some jobs that are looking at

856
00:41:14,320 --> 00:41:17,939
individual behaviors and some jobs are looking at populations,

857
00:41:17,949 --> 00:41:19,850
you generally get good coverage and you don't,

858
00:41:20,080 --> 00:41:23,149
uh, you know, have the, the, the vulnerability of, of, uh,

859
00:41:23,159 --> 00:41:24,489
stuff that's been there forever.

860
00:41:24,500 --> 00:41:25,850
-- That's normal but
-- bad.

861
00:41:25,979 --> 00:41:28,189
Right. Right. Well, I mean, let's face it too.

862
00:41:28,199 --> 00:41:31,489
If you're in enterprise today, you have

863
00:41:32,120 --> 00:41:33,850
threat actors inside

864
00:41:34,090 --> 00:41:38,050
just period. There's no way around that. It's just, it's the way it is.

865
00:41:38,739 --> 00:41:40,399
That's cool, man. I love it.

866
00:41:40,530 --> 00:41:43,159
So, I guess, uh, we're, we're getting close to the end here.

867
00:41:43,169 --> 00:41:43,419
So,

868
00:41:43,429 --> 00:41:46,350
is there anything else you want to kind of fill

869
00:41:46,360 --> 00:41:48,239
anyone in or is there anything we missed or,

870
00:41:48,250 --> 00:41:51,080
or something we, we should have talked about that, that you can think of.

871
00:41:51,350 --> 00:41:53,639
-- I think
-- some of the, the really cool stuff.

872
00:41:53,649 --> 00:41:56,760
Um, so what we've been talking about so far is you using

873
00:41:57,020 --> 00:41:57,580
automated

874
00:41:57,879 --> 00:42:00,459
detection to detect things that are like, you know,

875
00:42:00,469 --> 00:42:02,330
you'd call them elementary attack behaviors.

876
00:42:02,340 --> 00:42:05,790
Right. They're data exfiltration. Yeah, that's a good one to know about,

877
00:42:05,919 --> 00:42:08,750
you could talk about unusual logins, like, you know,

878
00:42:08,760 --> 00:42:12,419
I saw a successful login but it was at an unusual time for that account.

879
00:42:12,520 --> 00:42:14,870
Those are, those are interesting. These are all good

880
00:42:15,580 --> 00:42:18,959
elementary tech behaviors that security people would like to know about. Right.

881
00:42:19,449 --> 00:42:23,679
But really the, the hard part is how do you stitch those together

882
00:42:23,929 --> 00:42:26,949
and identify attack progressions that may take place

883
00:42:26,959 --> 00:42:29,790
over days or even weeks or even longer.

884
00:42:30,139 --> 00:42:33,879
And um a lot of the capabilities that you know, that we,

885
00:42:33,889 --> 00:42:37,790
we get excited about the application of machine learning for threat

886
00:42:37,800 --> 00:42:41,540
detection is is to do just that um it's to take these

887
00:42:41,860 --> 00:42:45,919
elementary attack behaviors that we detect through this anomaly detection

888
00:42:46,129 --> 00:42:49,760
and then start to perform additional analysis on those.

889
00:42:50,409 --> 00:42:55,110
And uh in in a particular case of the solution from elastic,

890
00:42:55,120 --> 00:42:58,449
the way that we accomplish that is the anomaly detection results are

891
00:42:58,459 --> 00:43:03,360
written back into an index that itself can be analyzed and searched.

892
00:43:03,409 --> 00:43:05,770
So there's kind of this second level of analysis that

893
00:43:05,780 --> 00:43:08,219
can take place on the things that have been detected

894
00:43:08,510 --> 00:43:09,590
that um

895
00:43:09,830 --> 00:43:12,790
can be very helpful in correlating unusual

896
00:43:12,800 --> 00:43:15,429
activities across different entities within your organization.

897
00:43:15,770 --> 00:43:19,399
And that's where I think the the the future is on, uh you know,

898
00:43:19,409 --> 00:43:22,439
really doing some amazing detection that, you know,

899
00:43:22,449 --> 00:43:26,409
none of the adversaries would be able to predict because it's, it's all gonna

900
00:43:26,540 --> 00:43:29,330
be using machine learning and other types of analysis to find

901
00:43:29,340 --> 00:43:31,010
things that you probably didn't even think of in the,

902
00:43:31,405 --> 00:43:34,905
it sounds like you're literally looking for anomalies in the anomalies

903
00:43:35,135 --> 00:43:36,284
or at least relationships.

904
00:43:37,875 --> 00:43:38,475
That's awesome.

905
00:43:38,754 --> 00:43:43,324
I love it. I love it. Uh, Kurt, any last questions, isn't that always the,

906
00:43:43,584 --> 00:43:46,425
the truth where people in hindsight look at, you know, some

907
00:43:46,715 --> 00:43:49,935
attack or something and they're like, in hindsight it's really obvious,

908
00:43:50,254 --> 00:43:51,824
you know. But at the time it was like,

909
00:43:52,129 --> 00:43:55,080
yeah, it's like one outgoing DNS packet amongst 3 billion.

910
00:43:55,370 --> 00:43:55,590
Yeah.

911
00:43:55,750 --> 00:43:56,070
Yeah.

912
00:43:56,209 --> 00:43:59,179
And so, so I think, you know, going forth

913
00:43:59,659 --> 00:44:01,600
in the future, we're gonna, we're gonna see more, uh,

914
00:44:01,610 --> 00:44:06,709
I think more attention played on exactly what, what you just said is things that,

915
00:44:06,719 --> 00:44:09,919
that may be hiding in plain sight are obvious and,

916
00:44:09,969 --> 00:44:14,550
and how do you identify the patterns in those, uh to notice if they happen again,

917
00:44:14,719 --> 00:44:16,629
notice earlier sooner when they happen again?

918
00:44:17,010 --> 00:44:19,979
Awesome. I love it. I, I'm super excited about this.

919
00:44:19,989 --> 00:44:22,260
I, I can't wait to see where this industry goes in,

920
00:44:22,270 --> 00:44:23,949
in the next couple of years because, well,

921
00:44:23,959 --> 00:44:26,939
then I imagine in two years it's gonna look nothing like it does today,

922
00:44:27,610 --> 00:44:29,050
which is fantastic.

923
00:44:29,449 --> 00:44:29,830
-- All
-- right

924
00:44:29,949 --> 00:44:30,169
now.

925
00:44:30,820 --> 00:44:34,629
-- So it, it sure is. I, I agree. Josh.
-- Awesome. All right, cool.

926
00:44:34,639 --> 00:44:37,070
So we, we've come to the end and one of the,

927
00:44:37,080 --> 00:44:39,540
the silly things we like to do is what we call the lightning round.

928
00:44:39,610 --> 00:44:42,389
So we're gonna put you on the spot here, Mike I can ask you some, uh

929
00:44:42,919 --> 00:44:47,389
we'll say ridiculous and somewhat unrelated questions because it's fun to do and,

930
00:44:47,399 --> 00:44:48,149
and so we're gonna,

931
00:44:48,290 --> 00:44:50,149
we're gonna, we're gonna make you dance for your dinner here.

932
00:44:50,280 --> 00:44:50,770
So, Kurt,

933
00:44:50,879 --> 00:44:53,030
why don't, why don't you lead this off, man?

934
00:44:53,330 --> 00:44:56,530
All right. Uh Favorite star Trek, Captain Kirk Cooper cards.

935
00:44:57,800 --> 00:44:58,320
Kirk.

936
00:44:59,379 --> 00:45:00,120
Good answer.

937
00:45:00,489 --> 00:45:01,209
That is the correct, correct.

938
00:45:03,659 --> 00:45:06,000
It's always wrong and people get that one wrong and then

939
00:45:06,260 --> 00:45:06,810
alright. uh

940
00:45:07,419 --> 00:45:10,090
favorite uh uh benevolent A I

941
00:45:10,409 --> 00:45:11,239
um,

942
00:45:11,610 --> 00:45:13,320
let's see what really helps me,

943
00:45:14,100 --> 00:45:14,310
sir,

944
00:45:14,889 --> 00:45:15,169
sir.

945
00:45:15,800 --> 00:45:18,020
It's actually for real. That that's a good answer.

946
00:45:18,050 --> 00:45:20,120
This is something I was thinking about actually is

947
00:45:20,610 --> 00:45:23,320
if you have, if you look at science fiction,

948
00:45:23,449 --> 00:45:26,040
there are remarkably few benevolent A is, you know,

949
00:45:26,050 --> 00:45:29,439
you got like the Terminator and you've got Gladys from portal, you've got

950
00:45:30,040 --> 00:45:30,510
the, well,

951
00:45:30,520 --> 00:45:32,179
I guess the ship's computer in Star Trek is

952
00:45:32,189 --> 00:45:36,060
sometimes colossus from the Foran project is I would say

953
00:45:36,219 --> 00:45:38,260
somewhere in between. Yeah. Well, that's the thing right?

954
00:45:38,270 --> 00:45:42,979
In, in science fiction, the vast majority of a is, are uh evil, right?

955
00:45:42,989 --> 00:45:45,179
There aren't a lot of good ones which,

956
00:45:45,189 --> 00:45:49,219
which it's kind of scary that we've yet to come up with, with good examples of this.

957
00:45:49,229 --> 00:45:50,580
But, but anyway, anyway,

958
00:45:51,000 --> 00:45:53,659
we'll keep going. What, what is your favorite open source project?

959
00:45:53,669 --> 00:45:54,530
This should be an easy one

960
00:45:54,840 --> 00:45:57,489
elastic. There you go. That's the answer I was looking for.

961
00:45:58,830 --> 00:45:59,659
Nice and easy.

962
00:45:59,790 --> 00:46:01,699
And Kurt, I'll let you finish it up.

963
00:46:02,040 --> 00:46:03,739
Sorry. My browser just locked up. Oh, that's all right.

964
00:46:03,919 --> 00:46:06,379
We got, uh, so what's your favorite security standard, Mike?

965
00:46:06,389 --> 00:46:09,260
I know this is one of the things you actually deal with on a regular basis

966
00:46:09,949 --> 00:46:10,530
standards

967
00:46:12,080 --> 00:46:15,060
or, or at least favorite you could say. I don't know. Is there a difference?

968
00:46:16,600 --> 00:46:19,219
-- I like the, uh PC I data security standard.
-- There you go.

969
00:46:19,239 --> 00:46:21,409
Yeah, that's a good one actually PC I is not too bad.

970
00:46:21,959 --> 00:46:23,389
I think it was one of the first standards to

971
00:46:23,399 --> 00:46:25,810
actually take and to have the guts to actually write

972
00:46:25,820 --> 00:46:29,219
down some things that were prescriptive as lightweight as they

973
00:46:29,229 --> 00:46:31,879
were before that a lot of the regulations were all,

974
00:46:31,959 --> 00:46:36,060
you must have controls that, you know, blah, blah, blah, so abstract and

975
00:46:36,489 --> 00:46:39,479
it wasn't perfect, but at least had some guts to say, OK, look,

976
00:46:39,489 --> 00:46:41,820
you got to have controls in place, meaning

977
00:46:41,989 --> 00:46:45,340
you got to monitor stuff coming from your network ideas and your host ideas,

978
00:46:45,350 --> 00:46:45,679
you know?

979
00:46:45,689 --> 00:46:45,709
No,

980
00:46:46,560 --> 00:46:48,939
no, I totally get that. It's awesome.

981
00:46:49,290 --> 00:46:51,590
All right, cool. Well, Mike, thank you so much.

982
00:46:51,600 --> 00:46:54,310
This has been a blast and, and I guess maybe,

983
00:46:54,320 --> 00:46:58,060
maybe in a couple of months or so once the industry changes drastically, you want

984
00:46:58,280 --> 00:47:00,790
to come back and, and let us know what's going on.

985
00:47:01,459 --> 00:47:04,649
I'd love to. It's a pleasure. And thanks for inviting me along. Fantastic.

986
00:47:04,659 --> 00:47:06,120
All right, cool. So, so thank you, gentlemen.

987
00:47:06,129 --> 00:47:09,139
I'm gonna bring it home now is for those of you listening.

988
00:47:09,149 --> 00:47:12,000
If you want links to any of the things we spoke on today,

989
00:47:12,169 --> 00:47:14,489
you can visit open source security podcast.com.

990
00:47:14,500 --> 00:47:19,239
We've got links to Twitter and Facebook and, and any of the other random stories and,

991
00:47:19,250 --> 00:47:20,120
and whatnot

992
00:47:20,429 --> 00:47:21,280
that were covered.

993
00:47:21,290 --> 00:47:23,000
I guess if nothing else, Mike and Kurt,

994
00:47:23,010 --> 00:47:26,439
you guys have a fabulous rest of your days and until next time.

995
00:47:26,570 --> 00:47:27,389
Thanks everybody.

996
00:47:27,610 --> 00:47:28,139
Bye now.