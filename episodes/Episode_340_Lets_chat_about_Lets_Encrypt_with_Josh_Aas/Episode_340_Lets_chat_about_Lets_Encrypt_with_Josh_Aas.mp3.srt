0
00:00:05,380 --> 00:00:08,729
Hello and welcome to the open source security podcast with myself,

1
00:00:08,739 --> 00:00:10,710
Kurt Siefried and my partner in Thought Crime.

2
00:00:10,720 --> 00:00:11,529
Josh Bresser.

3
00:00:12,170 --> 00:00:13,119
I am

4
00:00:13,250 --> 00:00:13,880
so excited.

5
00:00:13,890 --> 00:00:18,229
We have, we have a repeat guest, one of the most amazing projects on the planet.

6
00:00:18,239 --> 00:00:19,579
So we have Josh O is the executive

7
00:00:19,590 --> 00:00:22,709
director of internet security Research Group ISRG,

8
00:00:22,780 --> 00:00:24,680
which is better known,

9
00:00:24,690 --> 00:00:27,559
we'll say by as let's encrypt even though that's not really your name.

10
00:00:27,799 --> 00:00:30,819
-- Josh. Welcome back to the show.
-- Thanks for having me

11
00:00:31,059 --> 00:00:31,969
-- looking forward to
-- it.

12
00:00:32,130 --> 00:00:33,169
We're so excited you were,

13
00:00:33,180 --> 00:00:36,979
you were on the show in May of 2018 and I'll put a

14
00:00:36,990 --> 00:00:39,979
link in the show notes to the first episode you did with us.

15
00:00:39,990 --> 00:00:40,349
But

16
00:00:40,500 --> 00:00:43,700
listening to that show was very surreal

17
00:00:43,830 --> 00:00:46,639
because let's encrypt was, I mean, you were four years old,

18
00:00:46,869 --> 00:00:47,979
which is not

19
00:00:48,389 --> 00:00:52,400
young necessarily, but it was really just starting I think to gain traction.

20
00:00:52,409 --> 00:00:54,819
We were, we discussed chrome

21
00:00:55,119 --> 00:01:00,080
adding the insecure icon for http websites which let's face

22
00:01:00,090 --> 00:01:01,950
it without let's encrypt that could have never happened.

23
00:01:02,150 --> 00:01:06,059
And it's just, it's very surreal listening to our discussion from what,

24
00:01:06,069 --> 00:01:06,400
what is that?

25
00:01:06,410 --> 00:01:07,620
That's four years ago now

26
00:01:07,750 --> 00:01:10,519
versus today. When, like,

27
00:01:10,669 --> 00:01:15,339
let's encrypt. You won. I mean, it's, it's no one even asked questions anymore.

28
00:01:15,349 --> 00:01:16,019
It's amazing.

29
00:01:16,230 --> 00:01:17,860
Yeah, we've had a lot of growth.

30
00:01:19,339 --> 00:01:23,339
We're up to, I think almost 300 million websites

31
00:01:23,779 --> 00:01:24,580
today.

32
00:01:24,730 --> 00:01:25,919
290 maybe.

33
00:01:26,779 --> 00:01:26,800
Yeah,

34
00:01:27,519 --> 00:01:28,639
there was, like,

35
00:01:28,650 --> 00:01:30,639
I think it can be summarized as there was a comment on

36
00:01:30,650 --> 00:01:33,500
hacker news pointing out that lets and crypt not only killed,

37
00:01:33,510 --> 00:01:35,260
like, a billion dollar certificate industry,

38
00:01:35,580 --> 00:01:38,620
but it replaced it with something that was better and free.

39
00:01:39,169 --> 00:01:40,080
Like straight up.

40
00:01:40,459 --> 00:01:43,839
We didn't set out to kill anything, but we didn't set out to make some things better.

41
00:01:43,849 --> 00:01:46,239
And I think we've succeeded in that stupid question.

42
00:01:46,250 --> 00:01:48,449
But why haven't the certificate authorities done some

43
00:01:48,459 --> 00:01:50,239
of these automation things that you've done like,

44
00:01:50,250 --> 00:01:50,650
seriously?

45
00:01:50,660 --> 00:01:53,699
Like, like not only are you free but you're easier, like,

46
00:01:53,709 --> 00:01:54,730
because I just set up cert bot

47
00:01:54,879 --> 00:01:55,199
and

48
00:01:55,900 --> 00:01:58,099
it's the wrong cool rotisserie. There's no step two.

49
00:01:59,269 --> 00:02:02,819
-- It just works.
-- Well, I should say first that I actually don't

50
00:02:03,290 --> 00:02:06,680
know that much about what other certificates are. Authorities are doing.

51
00:02:06,690 --> 00:02:08,869
I mean, we're pretty focused on what we're doing and we,

52
00:02:08,880 --> 00:02:11,100
we pay surprisingly little attention to

53
00:02:11,110 --> 00:02:13,380
what other certificate authorities are doing good

54
00:02:13,770 --> 00:02:17,419
-- in a normal sense. You know, we, they're
-- doing the same thing they were always doing.

55
00:02:17,429 --> 00:02:20,460
We love talking to them when we have chances to collaborate

56
00:02:20,470 --> 00:02:23,190
with them and we have some really good relationships with other cas

57
00:02:23,860 --> 00:02:27,660
um talking about the acne protocols that we use and I think they,

58
00:02:27,669 --> 00:02:29,320
they are definitely making progress.

59
00:02:29,330 --> 00:02:31,399
There are a good handful,

60
00:02:31,410 --> 00:02:35,919
if not most of the major cas support acne in some form or another these days.

61
00:02:36,199 --> 00:02:38,679
So I think the whole industry is moving forward.

62
00:02:39,199 --> 00:02:39,419
You know,

63
00:02:39,429 --> 00:02:43,080
we have the advantage of starting from scratch and being able to do whatever we want.

64
00:02:43,089 --> 00:02:47,039
No existing, you know, no existing subscribers, no contracts, no,

65
00:02:47,699 --> 00:02:49,850
you know, legacy tech that we built

66
00:02:49,960 --> 00:02:53,850
1020 years ago. So that's a pretty big advantage no matter who you are.

67
00:02:53,860 --> 00:02:55,559
And I think trying to move

68
00:02:55,729 --> 00:02:56,600
an existing,

69
00:02:56,770 --> 00:02:58,889
you know, billion dollar industry in another direction,

70
00:02:58,899 --> 00:03:00,880
that's a much harder task in some ways.

71
00:03:00,889 --> 00:03:01,320
So

72
00:03:01,789 --> 00:03:05,330
I think they're working on it and I'm glad to see them making some progress.

73
00:03:05,600 --> 00:03:07,479
Awesome. Absolutely. Ok.

74
00:03:07,490 --> 00:03:07,990
I don't,

75
00:03:08,000 --> 00:03:11,600
I don't even know where I want to start with this one because there's just so much, ah,

76
00:03:11,610 --> 00:03:12,440
you've done so much.

77
00:03:12,449 --> 00:03:14,559
It's absolutely amazing. II, I guess

78
00:03:14,990 --> 00:03:17,610
why don't we start with, give us the state

79
00:03:17,759 --> 00:03:18,449
of

80
00:03:18,789 --> 00:03:21,050
let's, and I'm gonna just call you lets and crypt from darling because that's

81
00:03:21,330 --> 00:03:23,690
what I have in my brain. So I'm gonna, I'm gonna give up

82
00:03:24,509 --> 00:03:27,410
just, just like, lay it out for us. Like, what do we look like today?

83
00:03:27,419 --> 00:03:31,580
What, like, how, how big are we talking, how many certificates are you issuing on a,

84
00:03:31,589 --> 00:03:32,630
on a regular basis?

85
00:03:32,639 --> 00:03:32,809
Just

86
00:03:33,070 --> 00:03:35,360
what is, what is the state of the universe?

87
00:03:35,479 --> 00:03:38,830
Sure. So we're serving almost 300 million websites today.

88
00:03:39,500 --> 00:03:42,399
2 9200 and 90 million, almost exactly.

89
00:03:42,800 --> 00:03:43,309
We do that

90
00:03:43,750 --> 00:03:46,889
with about 220 million active certificates.

91
00:03:46,899 --> 00:03:50,669
So, since you can have multiple websites per cert so active means,

92
00:03:51,259 --> 00:03:56,080
uh, we issued it and it has not yet expired and ours are valid for 90 days.

93
00:03:56,089 --> 00:03:57,580
You know, that, that's how we're doing,

94
00:03:57,589 --> 00:04:01,000
but how the web is doing is probably the more important issue.

95
00:04:01,009 --> 00:04:03,149
And back before we started,

96
00:04:03,369 --> 00:04:07,759
you know, in 2015, about 39% of all page loads on the web.

97
00:04:07,770 --> 00:04:10,169
So that's every page you load, not just website,

98
00:04:10,660 --> 00:04:14,240
you know, we're looking at what percentage of page loads are encrypted

99
00:04:14,750 --> 00:04:18,089
and it was about 39% right before we started issuing

100
00:04:18,100 --> 00:04:21,640
certs and today in the United States it's up to 93%

101
00:04:22,809 --> 00:04:25,890
in the, in the globally, it's up to 81%.

102
00:04:26,859 --> 00:04:29,769
So it's, we're living in a very different

103
00:04:30,769 --> 00:04:34,470
world on the web today and it's much safer for everybody.

104
00:04:34,480 --> 00:04:36,869
So this is, you know, this is what we set out to do,

105
00:04:37,109 --> 00:04:41,950
make the web much safer and do it fast. Where in web terms, five years is pretty fast.

106
00:04:41,959 --> 00:04:45,109
I mean, I guess we're up to seven years now, but the goal was to, you know,

107
00:04:45,119 --> 00:04:49,309
get as far as we can in a relatively quick time because we don't want to,

108
00:04:49,510 --> 00:04:53,510
-- people shouldn't have to wait 1020 years for security, you know.
-- Right.

109
00:04:53,829 --> 00:04:54,970
Oh, my goodness. Amazing.

110
00:04:55,119 --> 00:04:55,910
So, ok,

111
00:04:56,359 --> 00:04:58,450
so let's start with, I saw on your website,

112
00:04:58,459 --> 00:05:01,399
I looked at your kind of recent things that happened and you just received,

113
00:05:01,410 --> 00:05:03,380
I think a grant from the Ford Foundation

114
00:05:04,059 --> 00:05:05,820
and I, I that made me realize

115
00:05:06,100 --> 00:05:08,480
the work you do is not free, right?

116
00:05:08,640 --> 00:05:11,839
Someone is paying for this work. So explain to me

117
00:05:11,940 --> 00:05:15,119
what the kind of how are you paying for all this? Because obviously

118
00:05:15,359 --> 00:05:19,959
I can get free certificates, but they're free to me, they're not free to you. Right.

119
00:05:20,880 --> 00:05:21,440
Right.

120
00:05:21,630 --> 00:05:24,859
So we have roughly speaking three

121
00:05:25,690 --> 00:05:27,170
revenue streams,

122
00:05:28,299 --> 00:05:30,970
most of the money that is used to operate lots

123
00:05:30,980 --> 00:05:34,019
of crypt and other projects comes from corporate sponsorships.

124
00:05:34,029 --> 00:05:34,880
So that's

125
00:05:35,230 --> 00:05:38,799
corporations out there that recognize the work that we do is important

126
00:05:39,130 --> 00:05:41,929
and they make contributions to us.

127
00:05:41,940 --> 00:05:44,970
And so most of our revenue is corporate sponsorship,

128
00:05:45,040 --> 00:05:47,359
probably the second biggest category is grants.

129
00:05:47,369 --> 00:05:50,109
So that's like the Ford Foundation and some other stuff.

130
00:05:50,429 --> 00:05:52,480
And the third category is individual giving.

131
00:05:52,489 --> 00:05:54,799
So that's people who come on our website and

132
00:05:55,470 --> 00:05:58,049
you know, donate any amount of money that works for them.

133
00:05:59,109 --> 00:06:01,790
And there's some really great information about all this stuff.

134
00:06:01,799 --> 00:06:04,579
Like more than what I have on top of my head in this moment

135
00:06:05,000 --> 00:06:06,329
in our annual report.

136
00:06:06,670 --> 00:06:07,829
Um We have a team at, at,

137
00:06:07,839 --> 00:06:10,209
at our organization does a great job putting together

138
00:06:10,220 --> 00:06:12,290
that annual report that has a ton of information,

139
00:06:12,299 --> 00:06:14,750
including a breakdown of, of where we bring in money.

140
00:06:14,760 --> 00:06:15,559
And I think that's,

141
00:06:16,100 --> 00:06:17,600
I think that's still,

142
00:06:17,850 --> 00:06:20,190
you can get that. It's not too hard to find.

143
00:06:20,450 --> 00:06:21,500
-- Yeah, it'll
-- be in the show notes.

144
00:06:21,510 --> 00:06:24,309
So anyone, anyone interested should, should go totally check that out.

145
00:06:24,480 --> 00:06:25,329
Ok. So

146
00:06:25,440 --> 00:06:26,179
I guess

147
00:06:26,290 --> 00:06:30,779
I was not aware prior to, we'll say a couple of days ago when I figured it out that I,

148
00:06:30,790 --> 00:06:32,000
as a person can donate to.

149
00:06:32,010 --> 00:06:33,850
Let's encrypt. That is very cool.

150
00:06:33,859 --> 00:06:38,679
Actually, you can, and not only can you donate, but we're excited to team up with yo,

151
00:06:39,079 --> 00:06:40,079
this September

152
00:06:40,369 --> 00:06:43,309
so you can support a more secure web and bolt through your own

153
00:06:43,320 --> 00:06:46,269
security at the same time with an easy to use authentication key.

154
00:06:46,579 --> 00:06:50,339
So when you donate 50 or $50 or more by September 30th,

155
00:06:50,679 --> 00:06:53,230
you'll receive a coupon code for either a security key

156
00:06:53,239 --> 00:06:56,450
NFC or a security key C NFC from me.

157
00:06:56,989 --> 00:06:58,829
-- And that's for shipping in the United States
-- only.

158
00:06:58,980 --> 00:07:02,160
That's pretty awesome. I think those things cost more than $50.

159
00:07:02,459 --> 00:07:02,760
Yeah.

160
00:07:03,519 --> 00:07:05,519
Well, those ones, yeah, they're like 50 or 60.

161
00:07:05,529 --> 00:07:07,380
Yeah, they're worth every penny though. I mean,

162
00:07:07,910 --> 00:07:08,730
I use them, our

163
00:07:08,869 --> 00:07:10,040
staff uses them.

164
00:07:10,540 --> 00:07:12,579
They are a really important part of our security

165
00:07:12,589 --> 00:07:15,279
posture for the whole organization and lots encrypt.

166
00:07:15,290 --> 00:07:17,359
It, it's a great way to improve your own security.

167
00:07:17,369 --> 00:07:20,679
It makes, it's the best thing you can do to avoid getting fished.

168
00:07:21,660 --> 00:07:22,279
Yes.

169
00:07:23,260 --> 00:07:24,540
Yeah, we're, we're pretty big fans.

170
00:07:24,630 --> 00:07:27,480
We, uh, we'll say we've talked about it more than once or twice.

171
00:07:27,489 --> 00:07:28,959
-- So,
-- one thing I'm curious about and,

172
00:07:28,970 --> 00:07:32,299
and I don't really want specifics but kind of what are your major expenses?

173
00:07:32,309 --> 00:07:33,320
Because I know again, like,

174
00:07:33,429 --> 00:07:35,049
I remember back in the day when like

175
00:07:35,250 --> 00:07:37,630
coating a bunch of servers on 100 megabit

176
00:07:37,640 --> 00:07:40,720
line was horrifically expensive and like a server was

177
00:07:41,070 --> 00:07:42,109
lots of money.

178
00:07:42,579 --> 00:07:45,589
And now, like, if you spend 50 grand on a server, you basically get,

179
00:07:45,600 --> 00:07:48,369
what was the 19 eighties internet in a box?

180
00:07:48,869 --> 00:07:50,450
And like bandwidth wise,

181
00:07:50,880 --> 00:07:53,720
it's not free but it's not expensive anymore. So like,

182
00:07:53,869 --> 00:07:55,700
is it just people, is it?

183
00:07:56,850 --> 00:08:00,600
Yeah, by far our biggest expense is people. So salaries,

184
00:08:01,040 --> 00:08:05,309
um, in the organization in total, we have 22 or 23 people right now.

185
00:08:05,429 --> 00:08:10,230
And about 11 of those are engineers that work on lots encrypt.

186
00:08:10,239 --> 00:08:12,750
And so if we're talking about lots encrypt in particular,

187
00:08:13,079 --> 00:08:13,369
staff,

188
00:08:13,600 --> 00:08:17,440
staff salaries are by far the most expensive part of doing this, you know,

189
00:08:17,450 --> 00:08:18,380
good people,

190
00:08:18,760 --> 00:08:19,390
you got to pay them

191
00:08:20,480 --> 00:08:24,059
the rest of it. You know, it is not necessarily cheap but it's,

192
00:08:24,299 --> 00:08:26,859
you know, maybe a third of what the salaries cost, you know,

193
00:08:26,869 --> 00:08:28,709
I'm not sure I have the exact numbers here.

194
00:08:28,720 --> 00:08:31,070
But, you know, if salaries are 3 million, maybe the,

195
00:08:31,079 --> 00:08:33,109
the rest of the stuff like hardware and things

196
00:08:33,119 --> 00:08:35,299
like that are a million and change a year.

197
00:08:35,789 --> 00:08:37,080
So it's not, it's not.

198
00:08:37,390 --> 00:08:40,179
But when you, when you divide this out. You know, you're thinking about

199
00:08:40,369 --> 00:08:42,150
maybe $4 million a year to run.

200
00:08:42,159 --> 00:08:45,890
Let's encrypt itself that is not a lot of money to serve 300 million websites.

201
00:08:45,900 --> 00:08:46,700
That's like,

202
00:08:46,890 --> 00:08:48,179
let's straight up like a penny

203
00:08:48,559 --> 00:08:49,349
-- to
-- serve the

204
00:08:49,359 --> 00:08:50,200
internet.

205
00:08:50,210 --> 00:08:52,950
And I remember you specifically mentioned you could not even charge a penny for

206
00:08:52,960 --> 00:08:55,380
these things because then people would have to haul out a credit card except,

207
00:08:55,390 --> 00:08:55,859
oh, wait,

208
00:08:56,099 --> 00:08:59,580
can't have a credit card or that country has a blah, blah, blah or you know what I mean?

209
00:08:59,590 --> 00:08:59,789
And,

210
00:08:59,909 --> 00:09:03,659
and I was like, oh yeah, like even, even 1/10 of a penny would be too much because

211
00:09:04,010 --> 00:09:05,099
it would be a hassle, but

212
00:09:05,390 --> 00:09:06,729
it kind of blows my mind. But

213
00:09:06,880 --> 00:09:08,650
-- yeah,
-- yeah, we're trying to make it

214
00:09:08,789 --> 00:09:13,340
as easy as possible and price is part of that, you know, and as you said,

215
00:09:13,349 --> 00:09:16,210
it's not just the price, not the sticker price.

216
00:09:16,219 --> 00:09:18,059
It's the fact that going through billing

217
00:09:18,070 --> 00:09:20,770
motions introduces a lot of friction for people

218
00:09:21,070 --> 00:09:23,390
and makes things unavailable for a while

219
00:09:23,539 --> 00:09:25,469
when people give us money, that's a big deal to me.

220
00:09:25,479 --> 00:09:27,520
Like people can choose to spend their money in a million

221
00:09:27,530 --> 00:09:29,710
different ways and when they choose to give money to us,

222
00:09:29,719 --> 00:09:30,409
we really

223
00:09:30,700 --> 00:09:34,130
take that seriously and try to do the most good we possibly can with it.

224
00:09:34,200 --> 00:09:35,450
So one question,

225
00:09:35,700 --> 00:09:38,630
because I was actually kind of under the impression let's encrypt was just,

226
00:09:38,640 --> 00:09:40,030
let's encrypt, but it turns out.

227
00:09:40,039 --> 00:09:41,530
Lets encrypt is actually

228
00:09:41,700 --> 00:09:44,570
part of the internet security research group, which to be honest,

229
00:09:44,580 --> 00:09:46,770
I had to look up like Josh said, you know,

230
00:09:46,780 --> 00:09:48,710
like we're going to call you let and crypt because that's what,

231
00:09:49,130 --> 00:09:52,070
what we know you of. So what is the Internet security research group?

232
00:09:52,229 --> 00:09:52,549
So

233
00:09:52,710 --> 00:09:56,590
Isrg is the nonprofit that runs lots encrypt. So lots

234
00:09:56,700 --> 00:10:01,549
and crypt is not the name of a nonprofit. It's the name of a service that's run by Isrg.

235
00:10:01,900 --> 00:10:05,859
So originally Isrg was created to be the home for Lots encrypt.

236
00:10:05,869 --> 00:10:09,229
But the reason we didn't call it Lots encrypt is that we knew that in the future,

237
00:10:09,239 --> 00:10:11,099
we might do other things besides Lots.

238
00:10:11,169 --> 00:10:11,679
Encrypt,

239
00:10:12,159 --> 00:10:14,390
which turned out to be the case.

240
00:10:14,830 --> 00:10:18,739
So today, Isrg has three projects and the, the largest

241
00:10:18,840 --> 00:10:21,669
and most well known of those projects is Lots Encrypt.

242
00:10:22,159 --> 00:10:24,679
We have a second one called Divvy Up, which is

243
00:10:25,549 --> 00:10:26,450
helping to

244
00:10:26,750 --> 00:10:29,210
bring privacy, respecting metrics to the web.

245
00:10:29,320 --> 00:10:31,340
So that's deployed right now to help with a

246
00:10:31,349 --> 00:10:34,559
lot of COVID exposure notification applications around the world

247
00:10:34,929 --> 00:10:36,140
or we're providing,

248
00:10:36,380 --> 00:10:36,679
you know,

249
00:10:36,690 --> 00:10:39,510
a secure background to process a lot of the metrics

250
00:10:39,520 --> 00:10:42,049
that the systems use because we're asking people to,

251
00:10:42,059 --> 00:10:42,489
you know,

252
00:10:44,010 --> 00:10:45,739
trust us to collect some of the stuff.

253
00:10:45,750 --> 00:10:47,400
And then we got to do a really good job

254
00:10:47,409 --> 00:10:49,869
making sure we're not invading anyone's privacy with that.

255
00:10:49,880 --> 00:10:50,390
So

256
00:10:50,599 --> 00:10:52,750
Divvy Up is intended to take this

257
00:10:53,650 --> 00:10:57,150
work that we did to help out with the COVID situation and

258
00:10:57,650 --> 00:11:01,150
bring it to lots of lots of kinds of applications out there.

259
00:11:01,159 --> 00:11:03,369
So that could be web, could be mobile

260
00:11:03,549 --> 00:11:04,820
desktop, things like that.

261
00:11:04,830 --> 00:11:08,989
So we're trying to, to make metrics collection more privacy, respecting.

262
00:11:09,940 --> 00:11:11,440
Our third project is called Pro

263
00:11:11,690 --> 00:11:11,859
Simo.

264
00:11:11,880 --> 00:11:15,169
And that is where we are trying to bring memory safety to some of the

265
00:11:15,179 --> 00:11:17,890
most important services that uh software that

266
00:11:17,900 --> 00:11:19,809
we use when we're running our services.

267
00:11:20,260 --> 00:11:26,090
So when I say the most important stuff, I mean, like the Linux kernel, DNS, tlsntp,

268
00:11:26,099 --> 00:11:27,770
like the stuff that every,

269
00:11:28,510 --> 00:11:32,150
every computer, certainly every server is running out there.

270
00:11:32,950 --> 00:11:36,169
You know, most of that stuff is written in C it's not memory safe.

271
00:11:36,700 --> 00:11:38,690
You know, if you run a server,

272
00:11:38,700 --> 00:11:40,729
you're doing security updates all the time and

273
00:11:40,739 --> 00:11:43,070
a huge percent of that percentage of that,

274
00:11:43,080 --> 00:11:46,489
you know, maybe 70% is memory safety vulnerabilities.

275
00:11:46,500 --> 00:11:48,090
When you get an update on your phone,

276
00:11:48,750 --> 00:11:51,580
it is typically a long list of memory safety vulnerabilities.

277
00:11:51,590 --> 00:11:55,820
So I think we got to get away from C and go to safer languages. So the promo

278
00:11:56,099 --> 00:11:58,609
project is moving some of this really

279
00:11:58,619 --> 00:12:02,369
the most critical stuff to safer implementations.

280
00:12:02,380 --> 00:12:04,179
And then we want to use that at LS

281
00:12:04,330 --> 00:12:04,799
Encrypt

282
00:12:04,960 --> 00:12:05,119
and

283
00:12:05,359 --> 00:12:08,049
D, but we also want other people to use it as well.

284
00:12:08,179 --> 00:12:10,979
-- Well, it's
-- pretty clear to me that the last, over the last 20 years, well,

285
00:12:10,989 --> 00:12:15,820
now 25 years of the web that yes, he has, we can't fix it.

286
00:12:16,049 --> 00:12:16,150
Yeah,

287
00:12:16,320 --> 00:12:20,900
there's been a lot of effort put into things like static analysis and sandbox

288
00:12:21,010 --> 00:12:22,090
and fuzzing

289
00:12:22,349 --> 00:12:25,650
and that stuff is great because I do think you get a good bang for your buck there,

290
00:12:25,659 --> 00:12:29,409
but it doesn't solve the problem and it's kind of an expensive ongoing thing.

291
00:12:29,419 --> 00:12:33,809
Whereas if you can move to a safer language, yes, it's more work up front for sure.

292
00:12:34,299 --> 00:12:36,640
But you can more or less solve the problem and,

293
00:12:36,650 --> 00:12:39,119
and not have to pay the price going down the road.

294
00:12:39,130 --> 00:12:42,520
Well, and I think it's that traditional cat and mouse game, right? Where

295
00:12:42,679 --> 00:12:46,330
we created things like stack canaries and sandboxes

296
00:12:46,590 --> 00:12:49,239
and various memory checking

297
00:12:49,369 --> 00:12:50,489
libraries

298
00:12:50,849 --> 00:12:53,210
and that held off the Attackers for a while.

299
00:12:53,219 --> 00:12:57,109
But the Attackers have figured out how to go around a lot of it. It's still hard.

300
00:12:57,330 --> 00:12:57,799
But

301
00:12:58,099 --> 00:12:58,760
I think

302
00:12:59,119 --> 00:13:02,989
the, the the cat has caught the mouse again and now it's time to do something else.

303
00:13:03,000 --> 00:13:04,640
And, and I think this is,

304
00:13:05,049 --> 00:13:06,380
this is a brilliant project

305
00:13:06,520 --> 00:13:07,299
because

306
00:13:07,450 --> 00:13:12,200
you're right. C can't be used. And now we have things like Rust, right?

307
00:13:12,210 --> 00:13:15,859
That are memory safe and, and performing and are easy to integrate.

308
00:13:15,869 --> 00:13:17,669
So I'm really excited about proo

309
00:13:18,070 --> 00:13:20,669
I didn't know about your divvy up. I would like to talk

310
00:13:20,859 --> 00:13:23,820
about that for a few moments because I think this one is a

311
00:13:24,109 --> 00:13:27,409
-- really cool idea
-- divvy up is meant to,

312
00:13:27,580 --> 00:13:30,469
you know, if you want to collect information about a population,

313
00:13:30,479 --> 00:13:34,020
you typically have to go collect information about individuals and

314
00:13:34,030 --> 00:13:36,409
then sort of sum it up and get the averages.

315
00:13:37,299 --> 00:13:40,549
And the problem here is even if you don't want to know about individuals,

316
00:13:40,559 --> 00:13:42,260
you just want to know about the population,

317
00:13:42,309 --> 00:13:44,679
you normally have to ask a bunch of individuals

318
00:13:44,690 --> 00:13:47,080
questions in order to learn about the population.

319
00:13:47,650 --> 00:13:50,130
And so the goal here is to kind of let you have your cake and eat it

320
00:13:50,140 --> 00:13:52,580
too to get you the aggregate metrics that you

321
00:13:52,590 --> 00:13:56,380
want without actually collecting the data from individuals.

322
00:13:56,789 --> 00:14:00,380
So the way that this works, let's imagine a cell phone and, and to be clear,

323
00:14:00,909 --> 00:14:04,200
the cryptography and the things going on here are

324
00:14:04,659 --> 00:14:05,969
pretty advanced.

325
00:14:06,090 --> 00:14:06,760
And

326
00:14:07,039 --> 00:14:09,320
you know, I'm not an actual engineer who works on

327
00:14:09,640 --> 00:14:09,809
dup,

328
00:14:10,270 --> 00:14:13,770
they know a lot more than me and probably are smarter than me to boot.

329
00:14:14,280 --> 00:14:18,760
So there are limits to the depth here, but I will give you a pretty good overview.

330
00:14:18,770 --> 00:14:23,369
So let's say you have a cell phone app and you want to collect metrics about,

331
00:14:23,549 --> 00:14:27,429
you know, how many times somebody clicks on a certain button or might,

332
00:14:27,559 --> 00:14:29,179
you know, be, be like

333
00:14:30,359 --> 00:14:32,619
the frequency of something that they do.

334
00:14:32,780 --> 00:14:33,330
OK.

335
00:14:33,679 --> 00:14:34,340
So

336
00:14:35,049 --> 00:14:37,890
you'll start collecting a counter of that information on the

337
00:14:37,900 --> 00:14:39,940
phone so that it is still on your phone here.

338
00:14:40,000 --> 00:14:41,539
And then when you're ready to send it,

339
00:14:42,219 --> 00:14:45,880
your phone will apply some local anonym organization techniques.

340
00:14:45,890 --> 00:14:48,440
So for example, if you're looking for an average,

341
00:14:48,960 --> 00:14:52,440
the phone might change your data so that it's not exactly what you did,

342
00:14:52,450 --> 00:14:54,239
but it averages to the same thing.

343
00:14:54,369 --> 00:14:57,320
That's like a rough overview of that kind of technique.

344
00:14:57,590 --> 00:15:02,440
So we apply a little bit of fuzz on the phone before your data ever leaves the device.

345
00:15:02,960 --> 00:15:06,520
And then we basically split that data into two pieces

346
00:15:07,130 --> 00:15:10,469
and we encrypt the two pieces with two different encryption keys

347
00:15:10,760 --> 00:15:15,150
and one belongs to Isrg as divvy up and the other one belongs to someone else.

348
00:15:15,159 --> 00:15:17,700
So it could be you running your own provider, you

349
00:15:18,380 --> 00:15:21,570
it could be another provider like divvy up and then

350
00:15:21,580 --> 00:15:24,070
the data leaves your phone split up in two pieces.

351
00:15:24,080 --> 00:15:25,869
So it's had some local anonym organization

352
00:15:26,219 --> 00:15:27,789
and then it's split up

353
00:15:27,940 --> 00:15:31,140
and we cannot read the other half, they cannot read our half.

354
00:15:31,859 --> 00:15:33,539
So by the time we get the data,

355
00:15:34,510 --> 00:15:35,919
the data already,

356
00:15:36,650 --> 00:15:36,909
you know,

357
00:15:36,919 --> 00:15:40,739
we don't know what the original data on your phone was by the time it gets to us

358
00:15:41,390 --> 00:15:45,330
and we're playing in the same stuff from a bunch of other people.

359
00:15:45,340 --> 00:15:48,320
So we would call it a batch but a batch, you know, could be

360
00:15:49,270 --> 00:15:52,729
thousands of people or phones could be a million. I don't know,

361
00:15:52,900 --> 00:15:54,479
it's a batch, it's a bunch of people.

362
00:15:55,309 --> 00:15:59,380
And then we take this bit of the half of the data that this batch of people sent

363
00:15:59,390 --> 00:16:01,109
us and we sum it all together or we

364
00:16:01,119 --> 00:16:04,200
do whatever mathematical operation we're trying to figure out here

365
00:16:04,650 --> 00:16:06,929
could be averages, could be something else.

366
00:16:07,559 --> 00:16:09,539
And then we come up with the aggregate

367
00:16:10,169 --> 00:16:13,130
stats for that batch. But remember this is just half.

368
00:16:13,140 --> 00:16:16,469
So then we send what we call our partial aggregate

369
00:16:17,830 --> 00:16:18,760
to

370
00:16:19,270 --> 00:16:23,299
an aggregator that takes our partial aggregate and the other partial

371
00:16:23,309 --> 00:16:27,200
aggregate from the other provider and sort of sums that together.

372
00:16:27,599 --> 00:16:29,130
So you get the full aggregate,

373
00:16:29,710 --> 00:16:35,039
so you get the, you get the final stats about the population that you're looking for.

374
00:16:35,859 --> 00:16:37,700
But the data was

375
00:16:38,619 --> 00:16:42,400
not sensitive the moment I left your phone, right. So like

376
00:16:42,760 --> 00:16:43,940
let's div

377
00:16:44,090 --> 00:16:47,299
app never had enough data to know what you were doing and the

378
00:16:47,309 --> 00:16:49,880
other provider never had enough data to know what you were doing.

379
00:16:50,179 --> 00:16:52,330
And the APP provider at the end here who's

380
00:16:52,340 --> 00:16:54,359
looking at the stats never had your data either.

381
00:16:55,059 --> 00:16:55,760
So

382
00:16:56,099 --> 00:16:56,799
it's tricky.

383
00:16:56,809 --> 00:16:59,169
It's not the easiest thing to understand in the world, but it's a,

384
00:16:59,179 --> 00:17:03,340
it's a really important innovation that I think came out of, of Stanford

385
00:17:04,010 --> 00:17:04,739
and Mozilla

386
00:17:04,890 --> 00:17:08,608
spent a good amount of time championing it and we are hoping to

387
00:17:09,319 --> 00:17:10,500
take it the next step.

388
00:17:10,780 --> 00:17:11,290
And

389
00:17:12,078 --> 00:17:13,708
I don't think it's realistic to ask

390
00:17:14,009 --> 00:17:18,618
application makers and to stop collecting stats about populations.

391
00:17:18,628 --> 00:17:20,499
It's too important, they're not going to stop.

392
00:17:20,509 --> 00:17:24,138
We just need to try to make it safe and this is a really great mechanism for doing that.

393
00:17:24,520 --> 00:17:30,319
That is not what I understood at all that description is way cooler because

394
00:17:30,520 --> 00:17:33,859
you're not even sending sensitive data somewhere else.

395
00:17:33,869 --> 00:17:37,469
And I think if you think about data in the historic sense,

396
00:17:37,650 --> 00:17:42,010
it has always been about send sensitive data somewhere and

397
00:17:42,020 --> 00:17:44,300
we'll say trusted and I'm making ear quotes that,

398
00:17:44,310 --> 00:17:45,609
that no one can see and

399
00:17:45,750 --> 00:17:49,449
you have to rely on that trusted person to anonymize the data properly,

400
00:17:49,459 --> 00:17:50,420
which they never do.

401
00:17:50,589 --> 00:17:54,130
And studies have shown time and time again that it can be de anonymized

402
00:17:54,569 --> 00:17:55,260
easily.

403
00:17:55,439 --> 00:17:56,329
This is

404
00:17:56,560 --> 00:17:59,689
this is very, very cool and I think it makes way more sense.

405
00:17:59,939 --> 00:18:00,250
OK?

406
00:18:00,260 --> 00:18:00,930
So a perfect example,

407
00:18:00,939 --> 00:18:02,800
it's actually my marketing team wanted me to

408
00:18:02,810 --> 00:18:04,959
enable demographics on one of our websites.

409
00:18:04,969 --> 00:18:05,880
And I'm like, OK,

410
00:18:06,219 --> 00:18:06,770
and

411
00:18:07,140 --> 00:18:09,319
we actually don't want your information.

412
00:18:09,329 --> 00:18:12,319
We just want to know like what percentage are from this country,

413
00:18:12,329 --> 00:18:15,479
what percentage are on this type of device, what percentage, you know what I mean?

414
00:18:15,489 --> 00:18:17,619
Like we actually don't want to know stuff about you.

415
00:18:17,630 --> 00:18:21,400
And I'm, I'm also one of the DP OS data protection officers at the CS A. So I'm like

416
00:18:21,569 --> 00:18:22,640
very strongly,

417
00:18:22,650 --> 00:18:25,660
I don't want your data because then I have to take care of it and that's more work.

418
00:18:25,670 --> 00:18:26,739
And I don't like more work.

419
00:18:26,839 --> 00:18:29,040
In this case, it's not too bad because it's just, well,

420
00:18:29,050 --> 00:18:32,250
we get the data from Google and Google's just doing Google stuff.

421
00:18:32,260 --> 00:18:32,430
And

422
00:18:33,270 --> 00:18:34,170
but yeah, at the same time,

423
00:18:34,180 --> 00:18:37,270
these people have to trust Google not to leak it or to sell it or to whatever.

424
00:18:37,280 --> 00:18:38,239
And as we've learned, you know,

425
00:18:38,250 --> 00:18:41,989
from some other providers like maybe Facebook or whatever that,

426
00:18:42,209 --> 00:18:43,489
yeah, they're not so good at that,

427
00:18:43,729 --> 00:18:44,819
not so trustworthy.

428
00:18:45,189 --> 00:18:45,650
And

429
00:18:46,310 --> 00:18:50,239
this is a good example because like we absolutely need that aggregate data.

430
00:18:50,709 --> 00:18:54,290
And in our case, we very explicitly do not want the

431
00:18:54,609 --> 00:18:55,890
individual data.

432
00:18:56,189 --> 00:18:58,660
And I know enough about this to know that even if we like

433
00:18:59,119 --> 00:19:02,920
kind of. Well, perfect example, if only one person visits our website,

434
00:19:03,459 --> 00:19:04,150
that

435
00:19:04,380 --> 00:19:07,410
statistical aggregate is now one person, right? Like so

436
00:19:08,109 --> 00:19:12,229
yeah, I I we're not going to try and de mask anybody, but at the same time, obviously,

437
00:19:12,239 --> 00:19:14,180
that is, that's the thing that happens, right?

438
00:19:14,189 --> 00:19:17,040
Like that German researcher that was like, hey, look at this anonymous data, except

439
00:19:17,380 --> 00:19:19,989
you spend eight hours here at night and eight hours here during the day.

440
00:19:20,000 --> 00:19:22,310
Well, that's where you sleep and that's where you work and now we know who you are.

441
00:19:22,439 --> 00:19:24,339
Yeah, this is a win for everybody.

442
00:19:24,349 --> 00:19:27,420
You know, the the people who are getting their data collected

443
00:19:27,900 --> 00:19:28,510
are

444
00:19:29,030 --> 00:19:31,119
getting great privacy production here, right?

445
00:19:31,130 --> 00:19:35,380
Their data is basically not leaving their phone in a recognizable way.

446
00:19:35,900 --> 00:19:39,839
And the organizations are getting the insights without taking the data, right?

447
00:19:39,849 --> 00:19:42,439
It's much less of a liability for them. So

448
00:19:42,810 --> 00:19:46,670
if you're, you know, the legal department of the company wants to collect some data,

449
00:19:46,680 --> 00:19:49,270
you should love this because you're getting what you

450
00:19:49,280 --> 00:19:51,089
want and you are not paying the price.

451
00:19:51,099 --> 00:19:55,189
You know, you, you do not have this toxic data sitting on your server somewhere.

452
00:19:56,050 --> 00:19:59,510
No, I love the idea because we have like, like I've actually consistently

453
00:20:00,359 --> 00:20:00,390
at

454
00:20:00,729 --> 00:20:01,239
the CS A.

455
00:20:01,250 --> 00:20:03,810
We, we try to collect as little data as possible,

456
00:20:03,819 --> 00:20:05,959
so I don't have to protect that stuff because it's just,

457
00:20:06,130 --> 00:20:06,859
it's a pain,

458
00:20:07,400 --> 00:20:09,739
like it's a super pain and you have to protect it forever.

459
00:20:10,170 --> 00:20:12,630
And so, yeah, if I could have some magic system that would like,

460
00:20:13,010 --> 00:20:15,390
I get my aggregates and I don't have to have your name.

461
00:20:16,119 --> 00:20:17,109
Yeah, I would love that.

462
00:20:17,579 --> 00:20:20,349
Yeah. So the challenge here for us is that the,

463
00:20:20,550 --> 00:20:24,229
the cryptography and the system is actually fairly complex.

464
00:20:24,650 --> 00:20:25,790
You know, there's a document

465
00:20:26,160 --> 00:20:27,729
in the ITF working group

466
00:20:27,920 --> 00:20:31,089
where we're trying to standardize the stuff that lays it all out, but it,

467
00:20:31,300 --> 00:20:34,400
it's not that easy to understand and it's not that easy to implement.

468
00:20:34,689 --> 00:20:39,069
The challenge for us is how to take this thing that does something really amazing,

469
00:20:39,079 --> 00:20:40,290
but it's pretty complex

470
00:20:40,439 --> 00:20:43,079
and make it really simple for people to consume,

471
00:20:43,329 --> 00:20:45,479
you know, complex security

472
00:20:45,630 --> 00:20:47,400
and privacy technology

473
00:20:47,650 --> 00:20:52,189
does not have a good track record if it's not made really easy to use,

474
00:20:52,339 --> 00:20:53,119
you know, so

475
00:20:53,890 --> 00:20:55,670
we want to implement this stuff correctly.

476
00:20:55,680 --> 00:20:59,150
But the real challenge is packaging it so that when you want

477
00:20:59,160 --> 00:21:02,089
to use it for your website to collect some demographic information,

478
00:21:02,569 --> 00:21:05,109
you do not need to know how this thing works, right? Like

479
00:21:05,359 --> 00:21:07,390
it is our job to make sure that you do

480
00:21:07,400 --> 00:21:11,589
not need to know all these cryptographic details and anonym

481
00:21:11,699 --> 00:21:13,229
organization techniques that are happening.

482
00:21:13,520 --> 00:21:17,150
We want to give you a library that you can use on the web or the phone or whatever

483
00:21:17,670 --> 00:21:19,109
and just say, you know,

484
00:21:19,410 --> 00:21:21,359
here's a configuration blob for it.

485
00:21:21,459 --> 00:21:25,119
Here's how you feed data into the API and we will take care of the rest of it.

486
00:21:25,949 --> 00:21:29,449
Well, you've done it once before, so I have a strong suspicion, you'll do it again.

487
00:21:30,920 --> 00:21:34,750
-- I hope you're right.
-- This is exactly what people said about TLS certificates

488
00:21:34,900 --> 00:21:35,900
10 years ago.

489
00:21:37,140 --> 00:21:41,170
Googling, what is it? The keywords are Google open SSL create blah, blah, blah.

490
00:21:41,209 --> 00:21:43,530
And then hopefully you get the right one on stack overflow and then

491
00:21:43,739 --> 00:21:46,410
you realize it's a self signed key and not a CS R and then,

492
00:21:46,619 --> 00:21:48,680
and then you realize the CS R is screwed up because it added

493
00:21:48,689 --> 00:21:51,359
this field you don't need and then eventually you get it right?

494
00:21:52,670 --> 00:21:53,949
Alright. Alright. I want,

495
00:21:54,060 --> 00:21:56,839
before you run out of time, I do want to talk about

496
00:21:56,959 --> 00:21:57,849
it's pros.

497
00:21:58,219 --> 00:21:59,130
Is that pronounced correct?

498
00:22:00,074 --> 00:22:00,084
I

499
00:22:00,425 --> 00:22:00,685
think

500
00:22:01,025 --> 00:22:01,094
Simo,

501
00:22:02,224 --> 00:22:02,244
I

502
00:22:02,574 --> 00:22:05,035
believe, I believe it's an Italian word for next

503
00:22:05,244 --> 00:22:08,084
and I don't speak Italian so I could be butching the pronunciation.

504
00:22:09,724 --> 00:22:14,635
It's fine. It's fine. OK. This one I want to talk about a little bit because I think

505
00:22:14,765 --> 00:22:17,655
it is something near and dear to topics, Kurt and I have discussed,

506
00:22:17,665 --> 00:22:21,234
we'll say at length on this show over the however long we've been doing it and

507
00:22:21,724 --> 00:22:23,395
you, you touched on this a little while ago,

508
00:22:23,405 --> 00:22:25,944
but kind of memory safety and all the pitfalls and cucks

509
00:22:26,194 --> 00:22:27,224
and we all know that stuff.

510
00:22:27,489 --> 00:22:30,069
But I think the, the truly clever bit

511
00:22:30,599 --> 00:22:32,150
of what I understand

512
00:22:32,400 --> 00:22:33,030
is

513
00:22:33,800 --> 00:22:37,359
when we look at attempts to bring memory safety in the past,

514
00:22:37,369 --> 00:22:40,099
it has always been like a a lift and replace

515
00:22:40,339 --> 00:22:41,209
process, right?

516
00:22:41,219 --> 00:22:43,439
Where we're saying, oh, we're going to throw away this application,

517
00:22:43,449 --> 00:22:45,130
we're going to rewrite it in something else.

518
00:22:45,439 --> 00:22:47,130
And after a year of work,

519
00:22:47,140 --> 00:22:49,939
we have something much worse than the original and it's not uncommon

520
00:22:49,949 --> 00:22:51,920
at all to just be like it wasn't that bad after all,

521
00:22:51,930 --> 00:22:52,300
I guess.

522
00:22:52,310 --> 00:22:54,890
And we just kind of ignore the work we spent doing.

523
00:22:55,000 --> 00:22:58,819
Whereas the effort you're doing is not a lift and replace.

524
00:22:58,829 --> 00:23:04,489
It's a slowly replace the most sensitive portions of something as you go.

525
00:23:04,640 --> 00:23:06,500
And I guess we kind of end up with the ship

526
00:23:06,510 --> 00:23:10,030
of Theseus sort of situation where hopefully we eventually replace it.

527
00:23:10,040 --> 00:23:10,640
All right.

528
00:23:10,810 --> 00:23:12,699
-- Yeah,
-- that's roughly the plan there,

529
00:23:12,709 --> 00:23:15,819
there are different approaches that work better in different contexts.

530
00:23:15,829 --> 00:23:16,140
So

531
00:23:16,869 --> 00:23:19,369
what we really prefer is a modular approach where we

532
00:23:19,380 --> 00:23:21,469
look at a big piece of software and we say,

533
00:23:21,900 --> 00:23:26,239
you know, what is one module or one component of this where we can swap out

534
00:23:26,579 --> 00:23:31,530
a library written, see and swap something written rust as easily as possible

535
00:23:31,849 --> 00:23:34,890
and do that. Ideally with the support

536
00:23:35,489 --> 00:23:37,579
of the maintainers of the project, that's,

537
00:23:37,839 --> 00:23:40,969
that's the dream because not only are you delivering value

538
00:23:40,979 --> 00:23:43,589
much more quickly and not depending on something rewrite,

539
00:23:43,969 --> 00:23:46,569
but also you can focus on these libraries, right?

540
00:23:46,579 --> 00:23:48,910
So like a TLS library is a perfect example where

541
00:23:48,920 --> 00:23:50,719
if we put a lot of effort into building a great

542
00:23:50,989 --> 00:23:53,670
TLS library, we can swap that into a bunch of different things.

543
00:23:54,219 --> 00:23:54,959
So for example,

544
00:23:54,969 --> 00:23:58,550
we can swap our Russ TLS library into the curl utility and we

545
00:23:58,560 --> 00:24:02,599
can do the same thing into Apache ht pe the web server.

546
00:24:02,709 --> 00:24:05,349
So libraries are great because we can focus on something,

547
00:24:05,540 --> 00:24:08,239
make it a really high quality replacement and swap it in.

548
00:24:08,250 --> 00:24:10,410
And our strategy is also to put cap

549
00:24:10,670 --> 00:24:15,739
around the Rust libraries so that the people maintaining the software don't even

550
00:24:15,750 --> 00:24:20,219
need to learn Rust to swap out critical components for Rust components.

551
00:24:20,229 --> 00:24:22,300
That's definitely our our preferred strategy.

552
00:24:22,310 --> 00:24:26,900
But there are there are cases where not all software is modular or

553
00:24:27,140 --> 00:24:28,420
some software is

554
00:24:28,839 --> 00:24:31,819
relatively simple and it makes more sense to just

555
00:24:32,329 --> 00:24:33,069
rewrite it.

556
00:24:33,079 --> 00:24:36,380
So it's not the same approach in every context, but we definitely prefer modular.

557
00:24:36,630 --> 00:24:37,270
Sure. Sure.

558
00:24:37,479 --> 00:24:41,229
OK. So how does this actually happen? Because you mentioned the maintainers and

559
00:24:41,400 --> 00:24:43,739
is are the maintainers doing some of this work?

560
00:24:43,750 --> 00:24:47,349
Are you bringing in other developers to do this work? Are you doing the work?

561
00:24:47,359 --> 00:24:52,010
-- Like, I'm curious what this looks like.
-- For the most part, we do not do the work. We

562
00:24:52,150 --> 00:24:57,680
make strategies and do a bunch of coordinating work and we manage the contracts. So

563
00:24:57,959 --> 00:25:00,219
typically we figure out what we want to do and

564
00:25:00,229 --> 00:25:03,349
we do that by talking to maintainers and community members

565
00:25:03,719 --> 00:25:04,170
and

566
00:25:04,560 --> 00:25:07,650
people who know more about a specific piece of software than we do.

567
00:25:07,660 --> 00:25:08,770
And we come up with a plan

568
00:25:09,689 --> 00:25:12,949
and then when we're ready, when we have a really good plan that we're happy with,

569
00:25:13,119 --> 00:25:17,420
typically, we go out and see if we can pay the maintainers to do the work for us.

570
00:25:17,800 --> 00:25:18,280
Um

571
00:25:18,650 --> 00:25:22,660
Our, our goal is to try to provide financial assistance, to maintainers

572
00:25:23,109 --> 00:25:24,939
to do whatever work it is that we want

573
00:25:25,099 --> 00:25:26,790
in some cases that doesn't make sense.

574
00:25:26,800 --> 00:25:29,270
You know, some maintainers have full time jobs and they don't,

575
00:25:29,479 --> 00:25:30,390
you know, they're not going to

576
00:25:31,010 --> 00:25:33,380
take a year long contract to work on something.

577
00:25:33,680 --> 00:25:35,910
So then our next step is usually to say,

578
00:25:35,920 --> 00:25:40,410
are there other developers that are already a part of the project that you trust?

579
00:25:40,949 --> 00:25:41,619
Um

580
00:25:42,130 --> 00:25:42,400
You know,

581
00:25:42,410 --> 00:25:44,900
there are recommendations that you have since this is going to be a

582
00:25:44,910 --> 00:25:48,069
bunch of work on your project or the people you trust that we can

583
00:25:48,329 --> 00:25:49,939
financially support to do this work.

584
00:25:49,949 --> 00:25:50,829
And if that doesn't work out,

585
00:25:50,839 --> 00:25:53,939
then we'll help go and find contractors to do the work and

586
00:25:54,319 --> 00:25:58,130
help start a relationship between the contractors and the maintainers so that,

587
00:25:58,170 --> 00:26:00,750
you know, everybody's on the same page about what's happening.

588
00:26:00,760 --> 00:26:02,349
But generally speaking,

589
00:26:02,609 --> 00:26:04,589
the work that we do is done through contractors,

590
00:26:04,599 --> 00:26:06,949
whether that is the maintainers themselves or

591
00:26:07,420 --> 00:26:10,280
other contractors that we help find. And we have a really great,

592
00:26:10,469 --> 00:26:14,369
you know, pool of contractors to pull from after working on this for a while.

593
00:26:14,630 --> 00:26:16,439
Sorry, stupid question. So, for example, Russ,

594
00:26:16,790 --> 00:26:19,300
how do you pronounce that? Rust? Ls Russ TLS,

595
00:26:19,479 --> 00:26:19,650
Russell?

596
00:26:20,400 --> 00:26:20,780
Oh,

597
00:26:21,150 --> 00:26:22,760
I would not guess that Russell. Ok.

598
00:26:22,819 --> 00:26:23,510
So Russell's, I,

599
00:26:23,520 --> 00:26:27,619
I took a quick look and it says it's a fully drop in replacement for openness cell.

600
00:26:27,630 --> 00:26:28,280
Cool.

601
00:26:28,949 --> 00:26:33,130
How do you then actually go get people to use it because like I'm,

602
00:26:33,140 --> 00:26:36,250
I'm guessing it's not the default on any major Linux distribution yet.

603
00:26:36,260 --> 00:26:39,729
Like nobody's actually swapped out open SSL for Russell

604
00:26:40,219 --> 00:26:41,290
yet or have they

605
00:26:42,900 --> 00:26:44,349
people definitely have in a,

606
00:26:44,750 --> 00:26:46,699
in internal project.

607
00:26:46,709 --> 00:26:49,099
There may be external ones that I'm, I'm not aware of,

608
00:26:49,109 --> 00:26:50,780
but you got to build this stuff up.

609
00:26:50,790 --> 00:26:51,260
So

610
00:26:51,790 --> 00:26:56,920
there is a long list of companies and pieces of software using Russell already.

611
00:26:57,390 --> 00:27:00,680
Uh a lot of that stuff is internal, but there's, there's external stuff too.

612
00:27:00,689 --> 00:27:02,979
There are a lot of Rust based projects that want to

613
00:27:02,989 --> 00:27:05,819
use a Rust TLS library and that's a natural choice for them

614
00:27:07,540 --> 00:27:12,810
for us. You know, we are, our goal is to make it the default somewhere. Like ideally

615
00:27:13,270 --> 00:27:17,030
open SL cell will go away. And be replaced by Russells.

616
00:27:17,380 --> 00:27:19,439
And the reason is not, it's not because we think

617
00:27:20,319 --> 00:27:21,219
open SSL,

618
00:27:21,229 --> 00:27:25,280
the people behind that are bad or anything but open SSL is written in C and it's

619
00:27:25,660 --> 00:27:28,579
going to continue to have security problems like that.

620
00:27:29,689 --> 00:27:29,770
Yeah,

621
00:27:30,079 --> 00:27:33,930
there's a bit of a plato flaw for that and it probably needs to go away for that.

622
00:27:34,130 --> 00:27:36,189
So ultimately, if we want to make a default,

623
00:27:36,199 --> 00:27:37,650
we need to find a way to get it

624
00:27:37,660 --> 00:27:40,969
into Linux distributions and into larger pieces of software.

625
00:27:41,420 --> 00:27:45,349
So we started with an experiment to get it into curl. So we,

626
00:27:46,500 --> 00:27:47,160
you know,

627
00:27:47,680 --> 00:27:49,000
had the maintainer of curl

628
00:27:49,170 --> 00:27:53,199
work to replace the HEP library with a Russ Hep library.

629
00:27:53,520 --> 00:27:58,189
And then in this rare instance, we had one of the people who works with Isrg

630
00:27:58,619 --> 00:27:59,630
replace

631
00:28:00,010 --> 00:28:02,140
uh open SSL with Russell's

632
00:28:02,400 --> 00:28:02,589
in

633
00:28:02,859 --> 00:28:04,479
curl and, and do that work

634
00:28:05,199 --> 00:28:07,020
while the maintainer was doing the other work.

635
00:28:07,459 --> 00:28:14,619
So today you can go build Curl with mostly Rust networking. So Rust Hep, Rust DLS

636
00:28:15,430 --> 00:28:16,770
and our hope is that

637
00:28:18,000 --> 00:28:18,839
in the next

638
00:28:19,890 --> 00:28:23,569
distributions or anyone who is packing a machine up curl will say, hey,

639
00:28:23,739 --> 00:28:27,189
I have the choice now to build curl in a much more secure way. We

640
00:28:27,439 --> 00:28:29,030
wanted to make that choice.

641
00:28:29,300 --> 00:28:30,869
And that's how we would get in there.

642
00:28:31,930 --> 00:28:35,589
We did a similar thing with patchy HVD where we, you know,

643
00:28:36,390 --> 00:28:41,199
they provide SSL services in H DB through MOD SSL. It's an Apache module

644
00:28:41,689 --> 00:28:45,859
we wrote another module called MOD TLS. And that uses

645
00:28:46,089 --> 00:28:47,939
Russells as the TLS

646
00:28:48,599 --> 00:28:49,489
back end.

647
00:28:49,859 --> 00:28:55,290
So if you build H TBD, you can choose to build and run mod TL SS instead of MOD SSL.

648
00:28:55,579 --> 00:28:58,349
And we want to see more and more people make that choice over time,

649
00:28:58,359 --> 00:29:00,319
but it's on us to prove that this works well.

650
00:29:00,329 --> 00:29:03,089
Right? If we need to make a good quality implementation,

651
00:29:03,560 --> 00:29:06,500
it's going to have to live in the world a little while to get some

652
00:29:06,869 --> 00:29:08,989
testing and build up some confidence in it.

653
00:29:10,880 --> 00:29:15,030
Is it, is it a drop in replacement today for Openness Cell? Does it cover all the API

654
00:29:15,140 --> 00:29:15,699
S, do you know,

655
00:29:17,739 --> 00:29:20,760
chose not to duplicate open SSL API?

656
00:29:20,770 --> 00:29:24,479
And the reason for that is that the API of open SSL itself

657
00:29:25,229 --> 00:29:30,469
is responsible for about just as many security problems as C

658
00:29:31,260 --> 00:29:35,640
the reason is just that the open SSL API is too complicated

659
00:29:35,760 --> 00:29:36,640
and so

660
00:29:36,859 --> 00:29:40,680
you get a lot of vulnerability from people misusing the API itself.

661
00:29:41,290 --> 00:29:41,910
So

662
00:29:42,780 --> 00:29:46,160
normally we want to maintain API compatible and make it truly drop in.

663
00:29:46,170 --> 00:29:48,209
But in this case, it's just too,

664
00:29:48,219 --> 00:29:52,020
too bad for security and we chose just not duplicate that.

665
00:29:52,310 --> 00:29:52,739
Well, I mean,

666
00:29:52,750 --> 00:29:55,630
even open as a cell kind of admitted to it because Openness

667
00:29:55,640 --> 00:29:58,630
Cell 3.0 dropped some of the old API stuff is just like

668
00:29:58,739 --> 00:30:02,479
you, you shouldn't be touching this like it's an internal API only

669
00:30:02,609 --> 00:30:05,489
you as a end user should never touch this. So, I mean,

670
00:30:05,660 --> 00:30:07,949
even they acknowledge that their API is

671
00:30:08,150 --> 00:30:09,599
overly complicated and

672
00:30:09,800 --> 00:30:10,910
sometimes abused.

673
00:30:11,500 --> 00:30:15,280
Yeah. But in our experience changing API S has not been that much work.

674
00:30:15,290 --> 00:30:17,910
You know, we got some experience doing that with curl

675
00:30:18,390 --> 00:30:19,069
and

676
00:30:19,329 --> 00:30:20,560
it wasn't bad at all.

677
00:30:21,140 --> 00:30:25,560
-- Gotcha. Gotcha. That's fair. That's fair.
-- Well, the thing was sorry. But like

678
00:30:25,819 --> 00:30:28,449
my experience with open SSL over the last 20 plus years is like,

679
00:30:28,459 --> 00:30:29,469
I want to create certificates.

680
00:30:29,479 --> 00:30:30,810
I want to validate certificates.

681
00:30:31,410 --> 00:30:34,040
I want to establish a SSL or TLS connection

682
00:30:35,199 --> 00:30:37,979
and I really shouldn't be monkeying with the low level guts because

683
00:30:37,989 --> 00:30:40,060
every time I see people monkey with the low level guts,

684
00:30:40,400 --> 00:30:43,099
I end up assigning them a security vulnerability identifier.

685
00:30:44,229 --> 00:30:44,599
Yeah.

686
00:30:45,140 --> 00:30:48,939
So Russells doesn't do the like creating or there open SSL does

687
00:30:48,949 --> 00:30:52,250
so much stuff like it's a Swiss army isa of crypto tools.

688
00:30:52,260 --> 00:30:52,859
Really?

689
00:30:53,140 --> 00:30:56,089
Russell's is just a replacement for the TLS connection party.

690
00:30:56,229 --> 00:30:58,760
You know, it doesn't generate certificates and things like that.

691
00:30:59,219 --> 00:30:59,569
But

692
00:31:00,359 --> 00:31:02,880
-- maybe we'll get there someday. We'll see. Yeah, we,
-- we have CPA

693
00:31:03,160 --> 00:31:03,520
-- to
-- make sure

694
00:31:03,790 --> 00:31:06,219
I was gonna say we just use lots and crypt.

695
00:31:07,680 --> 00:31:07,959
Ok.

696
00:31:08,300 --> 00:31:11,430
Ok. We, we're about out of time here, Josh, this has been,

697
00:31:11,579 --> 00:31:16,390
this has been lovely and I guess I will give you the floor for the last word.

698
00:31:16,400 --> 00:31:20,170
So, is there anything you'd like the audience to know or any call to action or,

699
00:31:20,180 --> 00:31:21,449
or it's up to you?

700
00:31:21,699 --> 00:31:22,390
I think

701
00:31:22,839 --> 00:31:27,660
the thing that's been on my mind the most over the last few days is that on uh

702
00:31:28,199 --> 00:31:29,469
Friday. So

703
00:31:30,010 --> 00:31:31,579
about five days ago,

704
00:31:31,890 --> 00:31:32,849
we lost one of the co

705
00:31:32,959 --> 00:31:35,219
founders of Lots and Crypt. Um Peter

706
00:31:35,500 --> 00:31:37,420
Eckersley passed away,

707
00:31:38,300 --> 00:31:41,890
um sort of unexpectedly last Friday and it's been

708
00:31:41,900 --> 00:31:44,160
a big loss for our community and our organization.

709
00:31:44,170 --> 00:31:46,839
He was a really bright and kind individual and we

710
00:31:46,849 --> 00:31:48,959
love working with him to create lots and crypt.

711
00:31:49,349 --> 00:31:51,359
He did a lot for this and

712
00:31:51,969 --> 00:31:54,699
it's just a tough loss. Um He's a great person.

713
00:31:54,709 --> 00:31:57,109
There are a lot of tributes and stories about him online.

714
00:31:57,119 --> 00:31:58,400
If you want to go learn some more,

715
00:31:58,410 --> 00:32:01,469
I think he has a Wikipedia page that has some basic info too.

716
00:32:01,479 --> 00:32:01,790
So

717
00:32:02,920 --> 00:32:05,459
we're thinking about Peter and his family and

718
00:32:07,239 --> 00:32:07,989
it's tough time.

719
00:32:08,619 --> 00:32:11,760
Yeah. No, absolutely. And, and that's true. We should have led with that.

720
00:32:11,770 --> 00:32:15,160
I, I'm truly sorry for the loss. I know everyone I've spoken with.

721
00:32:15,170 --> 00:32:16,449
I, I did not know Peter but

722
00:32:16,880 --> 00:32:22,119
every person who knew him had has nothing but amazing, positive things to say.

723
00:32:22,130 --> 00:32:24,699
I, I also want to add the 11 bit I think is,

724
00:32:24,819 --> 00:32:28,479
it is a true testament to the work that the Letin Krip founders have done

725
00:32:28,609 --> 00:32:29,959
that. The organization

726
00:32:30,310 --> 00:32:34,829
it will live on for, for probably forever at, I mean, we'll put forever in quotes.

727
00:32:34,839 --> 00:32:35,079
But,

728
00:32:35,250 --> 00:32:35,890
you know, like,

729
00:32:35,900 --> 00:32:39,560
like it's a truly great organization and amazing in the work you're doing is,

730
00:32:39,569 --> 00:32:43,609
is just, it is the, the best II I told this to one of your people actually,

731
00:32:43,619 --> 00:32:44,609
when we were setting this up,

732
00:32:44,619 --> 00:32:46,890
it is the best thing that has ever happened to the internet.

733
00:32:46,900 --> 00:32:50,410
And, and I don't say that in Jest, like, it's absolutely 100% true.

734
00:32:50,420 --> 00:32:54,810
Your organization is one of the true jewels of humanity and,

735
00:32:54,819 --> 00:32:56,359
and thank you and everyone for it.

736
00:32:56,369 --> 00:32:57,250
It, it's amazing.

737
00:32:57,890 --> 00:32:58,319
Yeah.

738
00:32:58,890 --> 00:33:01,280
You know, Peter was a fantastic person and

739
00:33:01,589 --> 00:33:03,790
one of the best ways we can honor his memory is to

740
00:33:03,800 --> 00:33:06,489
do the best work we can for as long as we can.

741
00:33:06,880 --> 00:33:08,750
Absolutely. 100%

742
00:33:09,089 --> 00:33:09,719
awesome.

743
00:33:10,010 --> 00:33:10,510
Awesome.

744
00:33:10,520 --> 00:33:14,130
Well, Josh, I want to thank you so very much for coming and speaking with us,

745
00:33:14,140 --> 00:33:14,910
it has been

746
00:33:15,099 --> 00:33:17,979
an absolute pleasure and I can't wait to see what

747
00:33:17,989 --> 00:33:20,790
happens in the next four years when you come back

748
00:33:21,170 --> 00:33:23,000
and we'll see what, what other

749
00:33:23,680 --> 00:33:26,130
ridiculous challenges let's encrypt to solve that.

750
00:33:26,140 --> 00:33:29,910
No one else thought they could solve. So, thank you, everyone for listening.

751
00:33:29,920 --> 00:33:31,030
Thank you, Josh. Thank you, Kurt.

752
00:33:31,040 --> 00:33:33,739
Go to open source security podcast.com for the show notes.

753
00:33:33,750 --> 00:33:36,420
I'll have ample show notes from everything we've talked about today and you. Pando

754
00:33:36,810 --> 00:33:38,079
says podcast hashtag

755
00:33:38,329 --> 00:33:42,660
-- up on social media. Kurt and Josh have marvelous rest of your days.
-- Thank you.

756
00:33:42,719 --> 00:33:43,630
Thanks everybody.

757
00:33:43,880 --> 00:33:45,459
-- Thanks
-- everyone. Bye bye,

758
00:33:50,040 --> 00:33:50,099
the