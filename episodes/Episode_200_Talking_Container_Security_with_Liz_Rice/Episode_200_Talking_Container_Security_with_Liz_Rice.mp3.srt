0
00:00:05,300 --> 00:00:08,010
Hello and welcome to the open source security podcast

1
00:00:08,140 --> 00:00:11,319
with myself, Kurt Siefried and my partner in Thought Crime. Josh Bresser.

2
00:00:11,329 --> 00:00:15,760
Hello, Kurt and I am very excited. We have a repeat guest today.

3
00:00:15,770 --> 00:00:20,629
We have Liz Rice, who is the VP of open source engineering and Aqua Security.

4
00:00:20,639 --> 00:00:24,350
-- Say hello, Liz. Hello,
-- Liz. That's not what you meant, is it?

5
00:00:25,530 --> 00:00:27,549
That's perfect. I love it. I love it. And

6
00:00:27,690 --> 00:00:31,360
you are here today because you wrote another book, which is awesome.

7
00:00:31,370 --> 00:00:32,540
It's called Container Security.

8
00:00:32,549 --> 00:00:34,790
Why don't you tell us a little bit about what you've done?

9
00:00:35,049 --> 00:00:35,509
Yeah.

10
00:00:35,520 --> 00:00:38,110
So I suppose for a few years now,

11
00:00:38,119 --> 00:00:40,909
I've been doing quite a lot of presentations about how

12
00:00:41,064 --> 00:00:44,325
containers work and how to secure containers and,

13
00:00:44,334 --> 00:00:47,314
and various things that you can do to compromise containers.

14
00:00:47,325 --> 00:00:50,125
And I wanted to

15
00:00:50,294 --> 00:00:53,215
take the opportunity to sort of dive into that material a

16
00:00:53,224 --> 00:00:55,525
bit more deeply which you can do in a book.

17
00:00:55,694 --> 00:00:56,444
So

18
00:00:56,865 --> 00:01:00,365
it's called Container security. It's really

19
00:01:00,544 --> 00:01:04,084
a lot about how things work under the covers so that you

20
00:01:04,095 --> 00:01:07,894
can think about security more than it is a sort of guideline.

21
00:01:07,904 --> 00:01:09,355
It's, you know, it's not just like a

22
00:01:09,580 --> 00:01:13,739
list of things you should do. I want to try and get people to understand

23
00:01:13,849 --> 00:01:18,860
what it is that, you know, if they take a certain action or they use a particular tool,

24
00:01:18,870 --> 00:01:21,569
what it actually means for their containers.

25
00:01:21,639 --> 00:01:21,889
Sure.

26
00:01:22,089 --> 00:01:25,489
Now I will put a link in the show notes to the book.

27
00:01:25,550 --> 00:01:30,239
Aqua security has graciously made it available as a download for free. Right.

28
00:01:30,480 --> 00:01:31,480
Absolutely. Yeah.

29
00:01:31,623 --> 00:01:35,902
-- Yeah. Just the price of your contact details. But yes, it's,
-- it's true. Only

30
00:01:36,042 --> 00:01:38,943
free. Now. I want to start with. This

31
00:01:39,093 --> 00:01:42,042
is an o'reilly book and naturally if it's an o'reilly book,

32
00:01:42,053 --> 00:01:45,343
it has an animal on the front and yours is the armored catfish.

33
00:01:45,453 --> 00:01:49,292
I'm curious why that. And, and how does this process even work?

34
00:01:49,303 --> 00:01:51,663
Because I, I love the animals and I'm always curious,

35
00:01:51,773 --> 00:01:53,413
how did you get to where it is?

36
00:01:53,666 --> 00:01:56,905
So, as an author, you basically don't get any choice in it.

37
00:01:56,916 --> 00:02:00,536
They, um, they go through this huge process. It's really interesting.

38
00:02:00,545 --> 00:02:03,765
They source these, I guess Victorian era

39
00:02:03,886 --> 00:02:04,926
plates

40
00:02:05,185 --> 00:02:08,906
and they have artists that convert that into the form

41
00:02:08,916 --> 00:02:10,005
that they use on the front of the book.

42
00:02:10,015 --> 00:02:13,326
They've just started colorizing them as well and they're all unique.

43
00:02:13,335 --> 00:02:15,565
You know, they never reuse a plate again.

44
00:02:16,009 --> 00:02:19,589
And I think they, you know, find, you know, maybe they, they,

45
00:02:19,600 --> 00:02:22,580
they find a new book that's, well, not a new book, an old book,

46
00:02:22,589 --> 00:02:25,429
a new to them book that has a series of plates that they can use.

47
00:02:25,440 --> 00:02:28,070
And you know, people are constantly coming up and going, hey,

48
00:02:28,080 --> 00:02:29,910
I want a panda or whatever.

49
00:02:30,039 --> 00:02:30,740
And

50
00:02:31,110 --> 00:02:33,789
lovely though, that would be, they don't necessarily have,

51
00:02:33,800 --> 00:02:35,860
did pandas exist in Victorian Times,

52
00:02:37,919 --> 00:02:41,229
-- I'm pretty sure.
-- So actually I'll dig up some pictures as well.

53
00:02:41,240 --> 00:02:44,929
What you just reminded me of is I know that for example, elephants there would,

54
00:02:44,940 --> 00:02:48,679
people would draw pictures of elephants back in those days, never having seen one.

55
00:02:48,690 --> 00:02:50,240
They just would read a description of them.

56
00:02:50,250 --> 00:02:53,710
And so some of these pictures are absolutely hilarious. But wow, that's wild.

57
00:02:53,720 --> 00:02:54,660
They really are. And,

58
00:02:54,774 --> 00:02:57,945
and they would draw sketches and like somebody would see somebody else's sketch,

59
00:02:57,955 --> 00:03:00,925
you know, there would just be,

60
00:03:01,054 --> 00:03:01,824
you know, one.

61
00:03:01,835 --> 00:03:03,375
But you know, if I tried to draw an elephant,

62
00:03:03,384 --> 00:03:05,535
it might not look very much like an elephant.

63
00:03:05,544 --> 00:03:08,884
Then if you copied my elephant, you would end up with, you know,

64
00:03:08,895 --> 00:03:10,824
an anti to at best or something.

65
00:03:10,835 --> 00:03:11,615
And uh yeah,

66
00:03:12,220 --> 00:03:15,500
I have a suspicion. Our, our drawing skills are similar. K

67
00:03:15,910 --> 00:03:17,940
I was meaning more based on my drawing skills, but

68
00:03:18,789 --> 00:03:19,220
I'm,

69
00:03:19,360 --> 00:03:23,190
I'm not impressive. Wow, that's well, so, so you had no say in this animal.

70
00:03:23,199 --> 00:03:26,509
And so OK, I guess why armored catfish then? How did you get to that?

71
00:03:26,529 --> 00:03:29,679
-- So
-- they said we have picked an armored catfish for you.

72
00:03:29,690 --> 00:03:31,309
And I thought actually that's great.

73
00:03:31,320 --> 00:03:35,259
-- It is, it's a cool animal because
-- it's really, you know, relevant.

74
00:03:35,270 --> 00:03:39,110
It's armored it's secure. So I was pretty happy with that and I knew

75
00:03:39,212 --> 00:03:43,072
from previous discussions with, with the o'reilly folks really,

76
00:03:43,082 --> 00:03:44,022
you don't get to choose.

77
00:03:44,031 --> 00:03:49,231
So I, I embraced my armor catfish and I am actually really happy with it.

78
00:03:49,561 --> 00:03:50,981
No, I, I agree. It's a cool,

79
00:03:51,432 --> 00:03:55,412
ok. I read this book. I finished it up a couple of days ago and

80
00:03:55,641 --> 00:03:59,272
I, I want to give you just my, my general thoughts here because I think it's,

81
00:03:59,322 --> 00:04:00,572
it's worth reading.

82
00:04:00,582 --> 00:04:02,542
I think regardless of who you are,

83
00:04:02,552 --> 00:04:06,352
maybe in your container journey and I felt like you split it

84
00:04:06,563 --> 00:04:07,634
nicely where the beginning,

85
00:04:07,643 --> 00:04:10,184
but I would say the first half to three quarters of the book,

86
00:04:10,194 --> 00:04:14,074
you lay the foundation of what container security is.

87
00:04:14,373 --> 00:04:16,533
And I think that's hugely important

88
00:04:16,704 --> 00:04:19,074
because I feel like as security people,

89
00:04:19,084 --> 00:04:21,313
we take a lot of that information for granted.

90
00:04:21,324 --> 00:04:23,894
Thank you very much. Yeah, I, I think that's,

91
00:04:24,084 --> 00:04:27,924
that's very true. I think a lot of security.

92
00:04:27,933 --> 00:04:33,593
It sometimes revolves around checklists or instructions or best practices

93
00:04:33,696 --> 00:04:37,825
that may be completely correct or maybe for

94
00:04:37,835 --> 00:04:41,316
a particular environment aren't necessarily so applicable.

95
00:04:41,526 --> 00:04:43,915
And if people really understood what they're doing

96
00:04:43,925 --> 00:04:46,635
with those checklists or those guidelines or,

97
00:04:46,645 --> 00:04:49,835
or whatever, then they can make their own decisions about what's

98
00:04:50,006 --> 00:04:51,615
applicable and what isn't. So.

99
00:04:51,626 --> 00:04:52,776
Yeah, II,

100
00:04:52,805 --> 00:04:56,026
I also think it's just more interesting if you really understand what's happening,

101
00:04:56,036 --> 00:04:57,835
that's kind of more fun.

102
00:04:57,906 --> 00:04:59,196
Well, the thing I'm noticing

103
00:04:59,485 --> 00:05:00,835
is how do. I put this nicely.

104
00:05:00,937 --> 00:05:06,678
A lot of security people try to enforce the rules because those are the rules rather

105
00:05:06,687 --> 00:05:09,257
than enforcing the rules because they understand the

106
00:05:09,268 --> 00:05:12,118
why and why those rules are applicable.

107
00:05:12,127 --> 00:05:12,528
Absolutely.

108
00:05:13,018 --> 00:05:17,757
And so, yeah, your book covering sort of some of the why and the under the hood stuff.

109
00:05:17,768 --> 00:05:20,197
Yeah, I mean, it matters because I've seen people where, you know,

110
00:05:20,208 --> 00:05:21,997
they do containers in a certain way where it's like, yeah,

111
00:05:22,007 --> 00:05:24,847
we just don't care about this aspect of container security because

112
00:05:24,858 --> 00:05:28,187
it just doesn't matter for us because we engineered this other thing

113
00:05:28,618 --> 00:05:30,157
or it just doesn't matter or whatever.

114
00:05:30,619 --> 00:05:33,329
Yeah. And I've seen security people freak out and be like, you can't do it that one.

115
00:05:33,339 --> 00:05:36,019
It's like sometimes it's OK to cross the road without looking both ways

116
00:05:36,029 --> 00:05:38,549
when you're in the middle of a desert or whatever bad example.

117
00:05:38,559 --> 00:05:42,070
But this is the metaphor for things like, you know, running a container as route,

118
00:05:42,079 --> 00:05:44,459
which is generally speaking a very bad idea.

119
00:05:44,470 --> 00:05:46,660
But some listeners will be, you know,

120
00:05:46,670 --> 00:05:48,640
they will have a use case where they have to run as

121
00:05:48,649 --> 00:05:51,670
route or maybe they even have to run as privileged and ok,

122
00:05:51,679 --> 00:05:53,029
those use cases exist.

123
00:05:53,040 --> 00:05:55,959
That's actually one of my favorite examples because like Google, for example,

124
00:05:55,970 --> 00:05:58,910
very simply went cool, you can do whatever you want container,

125
00:05:59,019 --> 00:06:01,440
we're just going to wrap it in its own VM boom done.

126
00:06:01,450 --> 00:06:02,739
And, and so what I love is you know,

127
00:06:02,750 --> 00:06:04,809
every time there were these major container escapes.

128
00:06:04,820 --> 00:06:05,890
Google is kind of like, yeah, we,

129
00:06:05,899 --> 00:06:08,670
we don't care because you're stuck in your little VM anyways.

130
00:06:08,799 --> 00:06:10,109
Yeah. So, so they use G

131
00:06:10,209 --> 00:06:10,519
visor?

132
00:06:10,529 --> 00:06:10,679
I'm,

133
00:06:10,690 --> 00:06:12,529
I'm pausing on that because I don't know for an

134
00:06:12,540 --> 00:06:15,179
absolute fact that they use G visor for all containers,

135
00:06:15,190 --> 00:06:19,059
but that's their technology for providing that extra kind of sandbox

136
00:06:19,429 --> 00:06:22,329
VM, like environment for a container.

137
00:06:22,339 --> 00:06:24,570
I'm going to keep us from rattling here as much as possible.

138
00:06:24,940 --> 00:06:26,200
It's a problem. We have

139
00:06:27,790 --> 00:06:27,820
the,

140
00:06:28,049 --> 00:06:31,540
the first thing I thought of those as well. And this is, I, I guess

141
00:06:32,000 --> 00:06:34,809
you do a lot of work with Kubernetes and this

142
00:06:34,820 --> 00:06:36,970
book doesn't have a lot of kubernetes in it.

143
00:06:36,980 --> 00:06:37,609
And I'm curious,

144
00:06:37,619 --> 00:06:40,529
was that deliberate or is that just something that sort

145
00:06:40,540 --> 00:06:42,929
of shook out once you started working on this?

146
00:06:43,380 --> 00:06:48,260
It was really about trying to keep the project of writing the book manageable.

147
00:06:48,269 --> 00:06:52,649
Um So I previously written uh o'reilly Guide to um

148
00:06:52,910 --> 00:06:54,500
Cerne security with Michael Halasz

149
00:06:55,290 --> 00:06:59,239
and that's, that's a relatively short, it doesn't go into so much depth, but

150
00:06:59,369 --> 00:07:02,839
I knew I wanted to go into a lot of detail and a lot

151
00:07:02,850 --> 00:07:06,380
of depth and I would still be writing if I was trying to cover

152
00:07:06,779 --> 00:07:07,679
C as well.

153
00:07:08,529 --> 00:07:13,040
So, yeah, it was more about sort of scoping what I thought I could cover, you know,

154
00:07:13,049 --> 00:07:14,510
it's the first real

155
00:07:14,640 --> 00:07:17,269
sort of proper book that I've written that you know,

156
00:07:17,279 --> 00:07:19,640
you can buy on Amazon and that I'd written by myself.

157
00:07:19,649 --> 00:07:22,839
So I didn't want to go completely war and peace with it.

158
00:07:23,260 --> 00:07:27,000
That's fair. That's what was the big one? It was the Send Mill book. Right.

159
00:07:27,010 --> 00:07:29,290
You could be the person to death with back in the day.

160
00:07:29,779 --> 00:07:30,459
But it was,

161
00:07:30,640 --> 00:07:32,519
it was like 1000 pages long

162
00:07:32,760 --> 00:07:36,399
and it was a perfect example because they covered all the M four syntax and M four.

163
00:07:36,410 --> 00:07:37,980
It's like its own world.

164
00:07:38,119 --> 00:07:39,049
-- Right.
-- Right.

165
00:07:39,269 --> 00:07:43,970
And plus all this, you know, technology is changing very fast and i

166
00:07:44,089 --> 00:07:47,500
it was already a concern to me that by the time it, you know, once,

167
00:07:47,510 --> 00:07:50,899
once I'd finished it, that it would still be relevant and up to date.

168
00:07:50,910 --> 00:07:54,820
And I don't think anything has dramatically changed too much yet,

169
00:07:54,829 --> 00:07:55,899
but bigger the book,

170
00:07:55,910 --> 00:07:59,299
the more the chance of something that will really seem quite dated very quickly.

171
00:07:59,609 --> 00:08:02,959
That's a fair point actually because containers are evolving.

172
00:08:03,299 --> 00:08:05,290
I mean, it, it's less rapid than it used to be,

173
00:08:05,299 --> 00:08:07,940
but I remember probably five years ago it was,

174
00:08:08,170 --> 00:08:12,209
it was bananas, how much would change with every single release of, you know,

175
00:08:12,220 --> 00:08:15,839
be a docker itself or one of the container runtime or the the standards,

176
00:08:15,850 --> 00:08:16,910
whatever it was nuts,

177
00:08:18,040 --> 00:08:20,500
I think coming up, we will see

178
00:08:21,010 --> 00:08:25,510
move to rootless containers, which will be great from a security perspective.

179
00:08:25,519 --> 00:08:27,869
Um You know, so I talked about that in the book,

180
00:08:27,880 --> 00:08:30,549
I guarantee there's listeners who don't know what a rootless container is.

181
00:08:30,559 --> 00:08:31,670
So educate us,

182
00:08:32,239 --> 00:08:36,429
imagine that you are the administrator of shared

183
00:08:36,440 --> 00:08:38,750
computers at a university is a great example.

184
00:08:38,760 --> 00:08:44,010
And students want to run containers on your university machines

185
00:08:44,630 --> 00:08:45,229
and

186
00:08:45,340 --> 00:08:47,140
you don't want to give them

187
00:08:47,640 --> 00:08:52,390
privileges to run Docker because you basically have to be rude to run Docker.

188
00:08:53,140 --> 00:08:56,780
And so you are basically saying, no, I'm,

189
00:08:56,789 --> 00:09:00,900
I'm I don't trust you to run Docker because that's the equivalent of giving you

190
00:09:01,179 --> 00:09:02,950
root access on this shared machine.

191
00:09:04,049 --> 00:09:06,140
So rootless containers basically

192
00:09:06,530 --> 00:09:10,059
make it such that you can run a container without needing

193
00:09:10,330 --> 00:09:11,750
uh root privileges

194
00:09:12,169 --> 00:09:15,510
and therefore anybody, any user can be

195
00:09:15,770 --> 00:09:17,469
permitted to, to do that.

196
00:09:17,559 --> 00:09:19,330
So it makes it more secure from the point of

197
00:09:19,340 --> 00:09:22,510
view of just who do you allow to run containers.

198
00:09:22,520 --> 00:09:28,049
But also once you then start a container, you're not root by default on the inside.

199
00:09:28,159 --> 00:09:28,729
So win,

200
00:09:28,830 --> 00:09:31,969
-- win.
-- You know what this actually really reminds me of is this is going back 20 years.

201
00:09:31,979 --> 00:09:34,549
But when the web started and CG I bin was the thing, you know,

202
00:09:34,559 --> 00:09:37,559
when a user wanted to run AC G I bin, it was kind of like, well poop.

203
00:09:37,570 --> 00:09:40,150
Now you control the web server, right?

204
00:09:40,369 --> 00:09:41,869
And then, you know PHP and my

205
00:09:42,020 --> 00:09:46,640
Q all came along and made it a lot easier to, well,

206
00:09:46,650 --> 00:09:50,950
not basically give users privileges over the web server and it took off.

207
00:09:50,960 --> 00:09:51,179
And,

208
00:09:51,380 --> 00:09:53,719
and this is kind of what I'm seeing here is, yeah, I mean,

209
00:09:53,729 --> 00:09:55,719
I'm cool with whatever the Devs do on their own machines.

210
00:09:55,729 --> 00:09:58,630
Like they can have root containers on their Dev machines. Sure.

211
00:09:58,640 --> 00:10:03,150
But, yeah, in production. No, we just can't have that. Absolutely.

212
00:10:03,289 --> 00:10:05,270
And I think that's one of the things that's been holding back,

213
00:10:05,280 --> 00:10:08,409
container adoption for a lot of people is I can't give all my devs

214
00:10:08,742 --> 00:10:11,802
access to all of production. You know, the auditors are going to scream at me

215
00:10:12,031 --> 00:10:13,252
-- if they
-- know,

216
00:10:14,452 --> 00:10:15,781
I think we're seeing lots of other kind

217
00:10:15,791 --> 00:10:19,661
of ways of keeping production machines at arm's length

218
00:10:19,771 --> 00:10:20,791
in particular. I'm thinking of get

219
00:10:21,231 --> 00:10:24,791
ups essentially saying that human beings don't really get to

220
00:10:25,021 --> 00:10:28,091
run containers at all in production. They're committing

221
00:10:28,281 --> 00:10:29,312
code changes.

222
00:10:29,322 --> 00:10:32,762
Some of those code changes are the specification of what you want,

223
00:10:32,771 --> 00:10:36,512
the state of your production cluster to be and automation

224
00:10:36,614 --> 00:10:39,184
takes it from, get into reality.

225
00:10:39,294 --> 00:10:42,754
-- Well, and
-- I think that's part of the maturity piece here too is like seeing it go from,

226
00:10:42,763 --> 00:10:46,843
you know, we, we, well, we still do a lot of handcrafted it unfortunately, but

227
00:10:47,044 --> 00:10:48,604
more and more people are actually, you know,

228
00:10:48,614 --> 00:10:51,823
building factories that produce the it that they want.

229
00:10:51,833 --> 00:10:52,674
And of course, I think, you know,

230
00:10:52,684 --> 00:10:55,544
containers are a major part of that of actually getting

231
00:10:55,554 --> 00:10:57,604
those binaries to run and do the things they want.

232
00:10:57,614 --> 00:11:00,953
Yeah, I think it's a big part of cloud native in general.

233
00:11:00,963 --> 00:11:04,633
You know, if I think about the CNCF definition of cloud native, which is

234
00:11:04,745 --> 00:11:08,236
about three paragraphs long and, and, you know, not something I've memorized,

235
00:11:08,245 --> 00:11:11,075
but it definitely includes automation.

236
00:11:11,145 --> 00:11:13,306
That's one of the kind of key principles

237
00:11:13,315 --> 00:11:16,736
that in order to have things scale dynamically,

238
00:11:16,745 --> 00:11:18,596
you need to be able to automate

239
00:11:18,885 --> 00:11:22,315
basically everything and that includes security.

240
00:11:22,455 --> 00:11:25,036
Well, and here's a thought because the other thing I keep coming to is is

241
00:11:25,296 --> 00:11:29,135
unless you can properly measure things, how can you fix them in my experience,

242
00:11:29,145 --> 00:11:30,995
measuring things that humans keep touching

243
00:11:31,005 --> 00:11:32,755
versus measuring things that are automated.

244
00:11:33,109 --> 00:11:34,289
And I think that's another big part

245
00:11:34,299 --> 00:11:37,409
of the containers and container orchestration world,

246
00:11:37,419 --> 00:11:37,679
right?

247
00:11:37,690 --> 00:11:41,500
Is that automation piece and that actually measuring piece and knowing, well,

248
00:11:41,510 --> 00:11:42,010
for example,

249
00:11:42,020 --> 00:11:45,650
knowing whether these containers run with root or without root privileges,

250
00:11:46,309 --> 00:11:47,659
right? Yes. Yes.

251
00:11:47,669 --> 00:11:52,080
So the observable in all kinds of dimensions including things

252
00:11:52,090 --> 00:11:56,380
like observing the state of security in your cluster,

253
00:11:56,390 --> 00:11:57,549
which kind of

254
00:11:57,719 --> 00:12:00,630
am I allowed to mention a new project that

255
00:12:00,640 --> 00:12:04,390
we literally just released yesterday because that kind of segues

256
00:12:04,530 --> 00:12:09,219
nicely into it. So uh it's called Starboard. And the idea is that

257
00:12:09,640 --> 00:12:12,969
you have a variety of different security tools that are running in your

258
00:12:13,539 --> 00:12:13,609
cinetis.

259
00:12:13,710 --> 00:12:14,530
Well, either in your

260
00:12:14,880 --> 00:12:18,380
knees cluster or running on artifacts related to what you're running.

261
00:12:18,390 --> 00:12:19,229
So things like

262
00:12:19,469 --> 00:12:22,140
scanning your container images or maybe

263
00:12:22,150 --> 00:12:25,859
checking your nodes against CIS benchmarks.

264
00:12:25,869 --> 00:12:27,659
Essentially the idea of Starboard is to say,

265
00:12:27,669 --> 00:12:30,619
let's take all those reports pull them into

266
00:12:30,940 --> 00:12:33,090
kubernetes, custom resource definition

267
00:12:33,719 --> 00:12:37,340
and then make that information accessible over the

268
00:12:37,849 --> 00:12:42,530
CS API so that security information is right there

269
00:12:42,539 --> 00:12:46,000
next to all of the other information about resources

270
00:12:46,219 --> 00:12:47,820
that are running in your cluster or or

271
00:12:47,830 --> 00:12:50,900
the other states of your production workloads.

272
00:12:50,909 --> 00:12:54,580
So bringing things like your vulnerability reports right

273
00:12:54,590 --> 00:12:56,549
next to the pods that you're looking at.

274
00:12:57,010 --> 00:12:57,530
Josh.

275
00:12:57,539 --> 00:12:58,869
Would you like to talk about container

276
00:12:58,880 --> 00:13:00,820
scanning and vulnerability reports for a bit?

277
00:13:01,119 --> 00:13:03,150
Actually, I was, I

278
00:13:03,330 --> 00:13:05,690
gave Liz a heads up to this before. So

279
00:13:05,909 --> 00:13:09,650
we like Liz a lot and Liz works for Aqua Security

280
00:13:09,659 --> 00:13:11,940
who actually I have a great deal of respect for.

281
00:13:11,950 --> 00:13:12,369
And

282
00:13:12,469 --> 00:13:15,479
I think a couple episodes ago we did quite a lot of complaining

283
00:13:15,489 --> 00:13:20,179
about container scanners and I wrote a very long blog series about them

284
00:13:20,489 --> 00:13:25,500
because it is, I guess what you're describing though is, is heavily related to this.

285
00:13:25,510 --> 00:13:28,510
And so let me explain to you what I see

286
00:13:28,840 --> 00:13:30,570
and I think

287
00:13:30,690 --> 00:13:32,469
you can help clarify some of this.

288
00:13:32,479 --> 00:13:33,119
So what,

289
00:13:33,130 --> 00:13:36,099
what I think I'm seeing today in the universe is

290
00:13:36,179 --> 00:13:38,900
there are lots of people who have lots of different

291
00:13:38,909 --> 00:13:42,590
tools and I think there is often a lack of

292
00:13:42,599 --> 00:13:45,229
understanding of what some of these tools really are.

293
00:13:45,239 --> 00:13:47,200
And so like the easiest example is

294
00:13:47,369 --> 00:13:48,510
I'll have someone

295
00:13:49,049 --> 00:13:52,190
run, I'll, I'll pick on Aqua just because you're here, right? They'll run the

296
00:13:52,299 --> 00:13:54,919
aqua container scanner that looks at all the

297
00:13:54,929 --> 00:13:56,469
stuff in your container and it basically gives

298
00:13:56,479 --> 00:13:59,719
you a report that says here are all the CV ES we found in your container.

299
00:13:59,729 --> 00:14:02,719
And generally speaking, most of these findings are correct.

300
00:14:02,729 --> 00:14:05,719
And I will give Aqua a big plus because

301
00:14:05,729 --> 00:14:07,979
there are obviously different kinds of false positives.

302
00:14:07,989 --> 00:14:11,200
But the one where like the stuff just isn't there and it's getting reported.

303
00:14:11,210 --> 00:14:13,440
I rarely see that with Aqua which is cool because that's a

304
00:14:13,450 --> 00:14:16,760
really hard problem and that's easiest of the hard problems to solve.

305
00:14:16,770 --> 00:14:21,070
I see these people say, ok, this, you know, you need to fix all these problems. That's

306
00:14:21,260 --> 00:14:25,000
that can't be done for a variety of reasons.

307
00:14:25,010 --> 00:14:28,030
I think then they'll also show up with another report that says, oh,

308
00:14:28,039 --> 00:14:30,880
your containers are violating these cis benchmarks.

309
00:14:30,890 --> 00:14:34,989
We have so fix them all. It's like that's also not a reasonable request.

310
00:14:35,000 --> 00:14:36,070
And I feel like what,

311
00:14:36,080 --> 00:14:38,000
what you're describing here is a tool that can kind

312
00:14:38,010 --> 00:14:40,669
of take all of this information in and give you,

313
00:14:40,979 --> 00:14:46,659
I guess a reasonable view of the risk you have in your containers. Is that accurate?

314
00:14:46,729 --> 00:14:47,590
-- Yes,
-- it is.

315
00:14:47,599 --> 00:14:52,789
So I think first of all, what we were saying earlier about understanding what

316
00:14:52,929 --> 00:14:56,659
the security issues really mean, like what are the implications of these,

317
00:14:56,809 --> 00:15:01,039
these different things? What does it mean if an audit says,

318
00:15:01,330 --> 00:15:06,179
I don't know that your note is not configured correctly? Well, how serious is that?

319
00:15:06,190 --> 00:15:08,080
What does that really mean? Yeah, exactly.

320
00:15:08,169 --> 00:15:12,460
And then also with Starboards being able to at least visualize,

321
00:15:12,469 --> 00:15:13,950
I don't know if you've come across a thing called,

322
00:15:14,349 --> 00:15:16,750
which is an open source dashboard for

323
00:15:17,200 --> 00:15:21,200
CS. And so, you know, you can click on your different deployments.

324
00:15:21,210 --> 00:15:22,969
And with Starboard, we've got

325
00:15:23,500 --> 00:15:24,450
tan plugins.

326
00:15:24,460 --> 00:15:30,099
So you can just see, oh, right next to your or as part of your display of the workload,

327
00:15:30,109 --> 00:15:30,580
you can see.

328
00:15:30,590 --> 00:15:35,020
Oh, this workload has three critical vulnerabilities and try to at least

329
00:15:35,219 --> 00:15:40,400
surface that information as part of that kind of holistic view of

330
00:15:40,539 --> 00:15:42,119
what's important about this workload.

331
00:15:42,130 --> 00:15:45,520
Maybe critical vulnerabilities might be an important thing. Sure. Sure, sure.

332
00:15:45,630 --> 00:15:49,599
But I guess then there's, there's further things you might want to be able to do,

333
00:15:49,609 --> 00:15:54,289
for example, in a way you can do things like acknowledge certain reports to say,

334
00:15:54,299 --> 00:15:56,070
well, yeah, I know about that, but it's,

335
00:15:56,309 --> 00:15:59,760
you know, in this particular circumstance, I don't need to know about it anymore.

336
00:15:59,950 --> 00:16:02,969
And that makes a lot of sense to me. I think

337
00:16:03,140 --> 00:16:04,039
it is

338
00:16:04,289 --> 00:16:10,200
partially an education problem and I think it's also a sign of the fact that

339
00:16:10,450 --> 00:16:15,359
containers one and now we're trying to hammer these, these, you know,

340
00:16:15,369 --> 00:16:17,099
square pegs into our round holes.

341
00:16:17,109 --> 00:16:21,190
And I think in some cases that creates unique challenges for these teams,

342
00:16:21,440 --> 00:16:25,789
I think one of the things it really creates is a huge scale issue.

343
00:16:25,799 --> 00:16:29,695
You know, you're not just talking about however many machines you're talking about

344
00:16:29,885 --> 00:16:33,575
all the containers running on all those machines and, and all of the, you know,

345
00:16:33,585 --> 00:16:35,414
operating system dependencies and so on,

346
00:16:35,424 --> 00:16:39,905
it demands new tooling because you can't look at these machines,

347
00:16:39,914 --> 00:16:41,775
we can't look at each container individually.

348
00:16:41,784 --> 00:16:43,015
That's actually a really good point.

349
00:16:43,025 --> 00:16:45,395
And I think that some of the parody I see is where, for example,

350
00:16:45,405 --> 00:16:47,054
if you have an operating system,

351
00:16:47,315 --> 00:16:48,424
you might run a

352
00:16:48,614 --> 00:16:50,804
vulnerability scanner on it and it's going to

353
00:16:50,815 --> 00:16:53,244
say you're missing these four security updates from,

354
00:16:53,255 --> 00:16:54,284
let's say Red Hat.

355
00:16:54,405 --> 00:16:54,955
Right?

356
00:16:55,275 --> 00:16:58,424
And then you run a container scanner on it and now you're looking at

357
00:16:59,070 --> 00:17:00,650
way more stuff,

358
00:17:00,890 --> 00:17:02,150
but they're different, right?

359
00:17:02,159 --> 00:17:04,310
You can't treat them the same and, and that's kind of,

360
00:17:04,319 --> 00:17:05,848
I think that's part of what I'm seeing here.

361
00:17:06,020 --> 00:17:08,709
Yeah. And I think there is scope for better too

362
00:17:08,858 --> 00:17:11,770
and better sort of. You get these sort of remediation

363
00:17:11,910 --> 00:17:15,854
advisories that there's more that can be done to make, to automate that process,

364
00:17:15,864 --> 00:17:16,255
I think.

365
00:17:16,275 --> 00:17:16,655
All right,

366
00:17:16,665 --> 00:17:20,175
we're on the precipice of me just complaining about

367
00:17:20,223 --> 00:17:22,733
container scanners for longer than I want to.

368
00:17:22,743 --> 00:17:24,454
So I, I want, I want to move on. I want to move on.

369
00:17:24,675 --> 00:17:27,015
-- They have good sides as well.
-- Right. They do.

370
00:17:27,364 --> 00:17:31,214
I look, I'm, I will be the first to admit that as much as I complain,

371
00:17:31,569 --> 00:17:32,989
this is the future

372
00:17:33,219 --> 00:17:35,300
and they, they, they get better,

373
00:17:35,310 --> 00:17:37,640
they're constantly getting better and I have no doubt in

374
00:17:37,650 --> 00:17:40,099
five years I'm going to look back and be like,

375
00:17:40,109 --> 00:17:42,949
wow, I was just a grumpy, a hole there for a while, wasn't I?

376
00:17:43,119 --> 00:17:48,829
And I, I cannot wait to be there and I have no doubt it is the answer to

377
00:17:49,050 --> 00:17:51,920
this particular problem. But anyway, anyway, I, I want to move on.

378
00:17:51,930 --> 00:17:52,069
There's,

379
00:17:52,079 --> 00:17:55,125
there's a really cool thing that I have on the top

380
00:17:55,135 --> 00:17:56,735
of my list to ask you about from your book.

381
00:17:56,745 --> 00:17:58,416
It's in chapter six

382
00:17:58,556 --> 00:18:02,456
and it's about the security of layers and the fact that people

383
00:18:02,465 --> 00:18:06,095
think sometimes they're deleting stuff out of their containers and they don't.

384
00:18:06,156 --> 00:18:07,546
And I really, so in fact,

385
00:18:07,556 --> 00:18:11,015
it's funny because a friend just emailed me last night about this exact topic.

386
00:18:11,026 --> 00:18:12,786
And I'm like that's hilarious.

387
00:18:12,796 --> 00:18:14,666
But anyway, why don't you explain to us what that means?

388
00:18:14,741 --> 00:18:20,001
-- Because this is like mind blowing, I think.
-- Yeah. So if you look at a Docker

389
00:18:20,171 --> 00:18:22,222
image, for example, when you do Docker pull,

390
00:18:22,232 --> 00:18:24,401
you can see all these different layers being pulled.

391
00:18:24,411 --> 00:18:28,062
So you kind of know that it's coming in these different layers,

392
00:18:28,072 --> 00:18:29,751
these different parts of the file system,

393
00:18:29,862 --> 00:18:31,161
they're like diffs,

394
00:18:31,171 --> 00:18:33,031
you know what you start with a base image and

395
00:18:33,041 --> 00:18:36,202
then you kind of have diffs for for each separate layer

396
00:18:36,709 --> 00:18:42,609
and one layer might include a file, another layer might remove that file.

397
00:18:42,619 --> 00:18:45,369
But the file is still present in the image. You can

398
00:18:45,560 --> 00:18:48,329
pull out that layer individually, you can unpack it.

399
00:18:48,339 --> 00:18:50,670
It's just a, you know, compressed our file

400
00:18:50,810 --> 00:18:55,810
and you can still find that file. So if that file is you know sensitive data,

401
00:18:56,219 --> 00:18:59,479
you deleting it in a subsequent layer in your Docker file.

402
00:18:59,489 --> 00:19:04,229
This is the other important part of it. Your docker file describes what is

403
00:19:04,339 --> 00:19:06,099
contained in each of those layers.

404
00:19:06,109 --> 00:19:10,319
Like every time you run a command inside a Docker file that creates a new layer.

405
00:19:10,329 --> 00:19:14,719
So one of those commands is delete my sensitive password.

406
00:19:15,005 --> 00:19:18,135
Well, the previous layer has that sensitive password, so

407
00:19:18,344 --> 00:19:20,454
-- I can just extract that
-- stupid question.

408
00:19:20,464 --> 00:19:22,275
Can you extract it from like when you're

409
00:19:22,285 --> 00:19:24,314
logged in within the Docker container or do you

410
00:19:24,324 --> 00:19:26,844
sort of need to be external to it and be able to look at the layers,

411
00:19:26,905 --> 00:19:29,244
you need to be external to it and look at the layers.

412
00:19:29,255 --> 00:19:33,305
Yeah. So once you're running inside the container, it's all been expanded into a

413
00:19:33,625 --> 00:19:35,704
regular file system layout.

414
00:19:35,714 --> 00:19:38,795
I'm not aware of a way I probably shouldn't say you can't, but I,

415
00:19:38,805 --> 00:19:43,974
-- I don't believe that there is a way
-- you, you shouldn't be able to, we'll see.

416
00:19:44,459 --> 00:19:47,680
But I mean, so the the danger here though is obviously if,

417
00:19:47,689 --> 00:19:51,560
if you had a file in one of your layers called Liz's secret passwords and you

418
00:19:51,569 --> 00:19:57,400
delete it in your Docker file and then you push that Docker file into Docker hub.

419
00:19:57,609 --> 00:19:58,880
I can go in

420
00:19:59,020 --> 00:20:03,239
-- and extract that file out of a layer even though you think you deleted it,
-- correct.

421
00:20:03,349 --> 00:20:04,219
Which is

422
00:20:05,589 --> 00:20:07,109
crazy

423
00:20:07,670 --> 00:20:12,670
kind of I mean, I, I think so this, this actually harkens to,

424
00:20:12,680 --> 00:20:14,479
I think it might be the episode right before this

425
00:20:14,489 --> 00:20:18,390
we just released was where there are certain security problems

426
00:20:18,579 --> 00:20:20,989
that we don't always even know about.

427
00:20:21,000 --> 00:20:24,579
And then when people learn, oh yes, it was the last episode because it was like,

428
00:20:24,589 --> 00:20:28,719
for example, your web browser can connect to local hosts with web sockets

429
00:20:28,900 --> 00:20:30,969
and like ebay was using this

430
00:20:31,109 --> 00:20:34,954
to and systems and now that we know it's like holy crap fix that.

431
00:20:35,135 --> 00:20:37,824
And I feel like these darker layers are a similar problem

432
00:20:37,834 --> 00:20:39,994
where most people just don't even know this is a thing.

433
00:20:40,005 --> 00:20:40,454
-- Well,
-- it's,

434
00:20:40,464 --> 00:20:42,204
it's one of those classic security things where it

435
00:20:42,214 --> 00:20:44,584
unless you really explicitly go looking for it,

436
00:20:44,594 --> 00:20:45,435
you're not going to see it.

437
00:20:45,444 --> 00:20:49,744
And it is another thing that some scanners will find for you or at least they will,

438
00:20:49,755 --> 00:20:53,125
they will look for things that look suspiciously like passwords or tokens

439
00:20:53,135 --> 00:20:56,724
or keys or whatever that might be embedded in the layers of a

440
00:20:56,900 --> 00:20:58,239
-- of a container image,
-- right?

441
00:20:58,250 --> 00:21:02,800
Except now the question is how many container images on Docker hub

442
00:21:03,000 --> 00:21:05,280
are full of secrets? And no one even knows.

443
00:21:05,479 --> 00:21:07,040
-- It's
-- a good question.

444
00:21:07,829 --> 00:21:07,920
I

445
00:21:08,099 --> 00:21:08,130
have

446
00:21:08,739 --> 00:21:09,119
a feeling

447
00:21:09,770 --> 00:21:11,439
it's going to be not zero.

448
00:21:11,449 --> 00:21:14,839
I have a feeling that people may have done some research to,

449
00:21:14,849 --> 00:21:17,400
to sort of check out that kind of thing

450
00:21:17,530 --> 00:21:19,140
related story.

451
00:21:19,150 --> 00:21:23,510
We at Aqua our research team just released

452
00:21:23,520 --> 00:21:25,599
a thing that they call dynamic threat analysis

453
00:21:25,875 --> 00:21:29,635
and it takes a container image runs it live in a,

454
00:21:29,645 --> 00:21:34,785
in a sandbox and observes its behavior and it's looking for things that look like

455
00:21:34,895 --> 00:21:38,604
malware, like behavior patterns of, I don't know,

456
00:21:38,614 --> 00:21:41,334
connecting to a Cryptocurrency pool or something.

457
00:21:41,344 --> 00:21:43,375
We did

458
00:21:43,574 --> 00:21:49,454
scan some images on Docker hub and then reported them as good citizens to, to the

459
00:21:49,665 --> 00:21:51,435
well to the Docker security team to,

460
00:21:51,444 --> 00:21:55,479
to let them know that they there were some images that we're not behaving well.

461
00:21:55,489 --> 00:21:56,250
Oh Interesting.

462
00:21:56,260 --> 00:21:57,939
So kind of like the Google Play store thing

463
00:21:57,949 --> 00:22:01,170
where they scan the apps to look for shenanigans.

464
00:22:01,199 --> 00:22:01,510
Yeah.

465
00:22:01,900 --> 00:22:05,469
Yeah. And by running it so not just sort of static analysis but actually

466
00:22:05,599 --> 00:22:08,630
-- dynamically checking the behavior,
-- which is pretty cool.

467
00:22:08,640 --> 00:22:11,030
And I mean with containers obviously that's

468
00:22:11,199 --> 00:22:11,910
trivial.

469
00:22:11,920 --> 00:22:14,510
Sorry, I just because I was like part of me was going to say, well, you know,

470
00:22:14,520 --> 00:22:15,390
for example, on github,

471
00:22:15,520 --> 00:22:17,910
there's a variety of projects that scan github

472
00:22:18,130 --> 00:22:18,579
repos

473
00:22:18,680 --> 00:22:21,810
for like entropy strings look like passwords.

474
00:22:21,819 --> 00:22:24,185
And I kept getting false reports because strings and emails.

475
00:22:24,194 --> 00:22:25,584
But anyways, I just looked at Docker

476
00:22:25,685 --> 00:22:30,324
Hub and there's just over 3.5 million public images now,

477
00:22:30,535 --> 00:22:34,074
like I knew it was going to be a big number but 3.5 million.

478
00:22:34,175 --> 00:22:38,765
That's nothing. How many node modules are there? The lots. Yeah, more than that.

479
00:22:38,775 --> 00:22:41,805
It's definitely an amazingly large number.

480
00:22:41,814 --> 00:22:45,444
-- Just
-- the effort to download all of these and run them all let alone actually,

481
00:22:45,454 --> 00:22:49,125
you know, observe their behavior and qualify it as good, bad or indifferent.

482
00:22:49,135 --> 00:22:51,685
I'm reasonably confident we didn't do all 3.5 million.

483
00:22:54,489 --> 00:22:57,790
I think the lesson we can take from that as well though, is that

484
00:22:58,099 --> 00:23:02,339
one of the things we're notorious for insecurity is our obsession with all or none.

485
00:23:02,569 --> 00:23:03,750
And you don't.

486
00:23:03,760 --> 00:23:05,089
I, I bet you of the,

487
00:23:05,099 --> 00:23:09,630
the 3.9 million probably what a couple of 100,000 Macs are actually

488
00:23:09,640 --> 00:23:12,859
full of like useful and good things that people are running.

489
00:23:12,890 --> 00:23:14,890
-- So literally
-- 51 or darker

490
00:23:15,055 --> 00:23:15,464
five

491
00:23:15,594 --> 00:23:17,994
-- what?
-- 51? That's it?

492
00:23:18,005 --> 00:23:22,385
362 are from verified publishers, which is shockingly low.

493
00:23:22,395 --> 00:23:24,954
And then 163 official images,

494
00:23:24,964 --> 00:23:27,795
which again is shockingly low because I just would assume that

495
00:23:27,805 --> 00:23:30,834
everybody at some point now has their official Docker image.

496
00:23:30,844 --> 00:23:31,005
All right,

497
00:23:31,015 --> 00:23:34,594
these numbers feel questionable and we're not going to hash this out right now.

498
00:23:34,604 --> 00:23:35,545
So,

499
00:23:36,339 --> 00:23:36,489
yeah.

500
00:23:36,500 --> 00:23:38,780
Well, I, I think what I'm seeing is, you know, we're,

501
00:23:38,790 --> 00:23:42,130
we're not at a point where container security is what I would call good yet,

502
00:23:42,140 --> 00:23:44,729
but we're also at the point where it's still rapidly evolving

503
00:23:44,739 --> 00:23:47,569
and not just the security of it but the actual containery

504
00:23:47,670 --> 00:23:51,709
bits of it. Like we never mentioned uni kernels and that's a whole other set of quasi

505
00:23:51,819 --> 00:23:52,880
container issues.

506
00:23:53,130 --> 00:23:56,040
-- Yeah,
-- there's all sorts of different uni kernels.

507
00:23:56,050 --> 00:24:01,199
You can kind of see them as a sort of a sandbox like G visor like firecracker,

508
00:24:01,209 --> 00:24:03,050
that kind of run time environment.

509
00:24:03,280 --> 00:24:06,699
There've been loads of things to harden the container run time over the years.

510
00:24:06,709 --> 00:24:08,219
You know, I think we're, we're finding

511
00:24:08,680 --> 00:24:10,109
serious vulnerability.

512
00:24:10,119 --> 00:24:11,670
I can't remember the last time there was a, you know,

513
00:24:11,680 --> 00:24:13,579
proper regular container escape,

514
00:24:13,589 --> 00:24:16,020
but they don't come up every five minutes for sure.

515
00:24:16,089 --> 00:24:16,939
Yeah, it's been a while.

516
00:24:16,949 --> 00:24:19,099
Vulnerabilities exist and are still found,

517
00:24:19,109 --> 00:24:23,069
I think yesterday or the day before there were a couple of networking related

518
00:24:23,650 --> 00:24:26,444
certis issues that patches were published for so upgrade Jo

519
00:24:26,954 --> 00:24:30,655
-- Bettis,
-- it'll have been almost a week by the time this this comes out. So,

520
00:24:31,064 --> 00:24:34,875
-- yes,
-- let's hope that's been done. No, I mean, that's, that's a good point. It's,

521
00:24:34,984 --> 00:24:38,114
that's one of our challenges as well, right? Is if,

522
00:24:38,444 --> 00:24:40,074
and, and I'll, I'll pick on,

523
00:24:40,314 --> 00:24:40,484
you know,

524
00:24:40,494 --> 00:24:44,104
container scanning here again is the fact that I could scan a container today

525
00:24:44,469 --> 00:24:47,089
and then I could literally scan the same container in a week.

526
00:24:47,329 --> 00:24:50,489
And my results could be quite different because it depends on

527
00:24:50,500 --> 00:24:53,810
what the security issues are that were released between the two scans

528
00:24:54,060 --> 00:24:59,170
for sure. And it's again a reason for automation, you know, you can't be doing that

529
00:24:59,420 --> 00:25:03,000
manually across the whole production cluster all the time.

530
00:25:03,010 --> 00:25:05,719
You know, you really want to be doing it automatically every day.

531
00:25:05,880 --> 00:25:06,239
Yes.

532
00:25:06,469 --> 00:25:06,969
OK.

533
00:25:07,020 --> 00:25:09,979
So we are nearly out of time, but I wanted to kind of there,

534
00:25:09,989 --> 00:25:11,680
there's one other chapter that I love in you

535
00:25:12,011 --> 00:25:14,021
and you talk about secrets management in there.

536
00:25:14,031 --> 00:25:17,621
And I just, I, I want you to briefly explain to us like,

537
00:25:17,631 --> 00:25:20,741
what is the challenge of container secret management?

538
00:25:20,751 --> 00:25:21,682
Because we just learned,

539
00:25:21,692 --> 00:25:23,362
obviously don't put those things in your

540
00:25:23,371 --> 00:25:24,962
container because they're in the layers now.

541
00:25:24,972 --> 00:25:29,891
-- But what does that mean?
-- You have these, you know, secrets that you,

542
00:25:30,082 --> 00:25:33,001
that your application code needs in order to do its job.

543
00:25:33,011 --> 00:25:33,462
You know, like,

544
00:25:33,472 --> 00:25:38,901
let's say it's a database password and there are a limited set of options,

545
00:25:39,053 --> 00:25:40,034
how you could

546
00:25:40,333 --> 00:25:43,593
feasibly get that password into the running container.

547
00:25:43,604 --> 00:25:46,034
And some of those feasible options are really,

548
00:25:46,043 --> 00:25:48,354
really bad ideas from a security perspective.

549
00:25:48,693 --> 00:25:52,333
Like you could build the password into the container image.

550
00:25:52,343 --> 00:25:55,913
And I did a talk, I guess probably a couple of years ago about

551
00:25:56,124 --> 00:26:00,303
secrets management and I gave it maybe two or three times and the first time I gave it,

552
00:26:00,313 --> 00:26:03,793
I thought, you know, I'll just mention in passing the fact that, you know,

553
00:26:03,803 --> 00:26:06,154
it would be a really bad idea to have the

554
00:26:06,345 --> 00:26:08,906
password built into the container image.

555
00:26:08,916 --> 00:26:13,385
And as I said, it thinking nobody will actually be doing that, will they?

556
00:26:13,395 --> 00:26:17,446
And I could see people like taking notes and I, you know, I can see, oh,

557
00:26:17,485 --> 00:26:20,865
a penny has dropped, but that really, they sh they should probably check that.

558
00:26:20,875 --> 00:26:24,926
They haven't got that password just sitting in plain text in a, in a Docker file.

559
00:26:24,936 --> 00:26:27,206
So, you know, that's one thing to avoid.

560
00:26:27,215 --> 00:26:32,245
But then if you, you want to get your secrets inside somehow,

561
00:26:32,255 --> 00:26:33,526
you basically have the option

562
00:26:33,637 --> 00:26:38,317
passing in as a file or as an environment variable and the file, you know,

563
00:26:38,328 --> 00:26:41,498
you're mounting a volume and passing the file through that way.

564
00:26:41,547 --> 00:26:42,057
Essentially,

565
00:26:42,067 --> 00:26:45,537
you're looking for a way of keeping that secret encrypted

566
00:26:45,628 --> 00:26:48,258
whenever it's in transit or at rest right up to

567
00:26:48,267 --> 00:26:50,078
the point where you give it to the application and

568
00:26:50,088 --> 00:26:52,578
then it can decrypt it and hold it in memory.

569
00:26:52,588 --> 00:26:54,728
It's an incredibly hard problem for sure.

570
00:26:54,917 --> 00:27:00,848
And OK, so we are functionally out of time for this chat. And I, I feel like

571
00:27:01,420 --> 00:27:06,510
this is such a complex and nuanced topic. We could probably do 100 shows.

572
00:27:06,520 --> 00:27:11,209
It never run out of content, Liz, I will let you give us the last word on this.

573
00:27:11,219 --> 00:27:14,989
What, what is the thing you want everyone to know other than read your book,

574
00:27:15,000 --> 00:27:16,050
which everyone should do.

575
00:27:16,060 --> 00:27:16,939
I was going to say,

576
00:27:17,130 --> 00:27:19,150
should I just plug my new book?

577
00:27:19,859 --> 00:27:20,160
Yeah.

578
00:27:20,520 --> 00:27:23,489
No, no, I mean, definitely, obviously we'll have a link to it in the show notes and,

579
00:27:23,500 --> 00:27:25,810
and I would highly recommend everyone give it a look.

580
00:27:25,819 --> 00:27:27,630
It's, it's not a super long book,

581
00:27:27,640 --> 00:27:30,449
which is nice because some security books are very long and boring,

582
00:27:30,459 --> 00:27:31,839
but this one definitely is not that.

583
00:27:31,849 --> 00:27:35,130
-- And it's a nice book. I, I
-- enjoyed it. Thank you very much.

584
00:27:35,140 --> 00:27:36,729
That's, that's really nice to hear. Yeah.

585
00:27:36,739 --> 00:27:39,849
So hopefully people will go out and try that,

586
00:27:40,206 --> 00:27:40,906
maybe

587
00:27:41,196 --> 00:27:43,186
get in touch if you have questions and,

588
00:27:43,196 --> 00:27:45,985
and things that you think I haven't covered enough yet

589
00:27:45,995 --> 00:27:48,505
because I want to keep this material up to date.

590
00:27:48,515 --> 00:27:52,015
We, we talked a bit before about, you know, how these things evolve.

591
00:27:52,026 --> 00:27:56,845
And uh you know, II, I want to make sure that as things evolve that the,

592
00:27:56,855 --> 00:28:00,576
the book also gets new additions so really interested to hear what people think.

593
00:28:00,661 --> 00:28:05,482
Awesome. And I will put some links to how to contact Liz in the show notes.

594
00:28:05,491 --> 00:28:08,541
So if you're interested in that, just hit up the show notes. So, all right, awesome.

595
00:28:08,552 --> 00:28:11,781
I'm going to call it then. Thank you, Kurt. Thank you, Liz.

596
00:28:11,791 --> 00:28:13,041
Thank you everyone for listening.

597
00:28:13,052 --> 00:28:15,362
You can go to open social security podcast.com for the

598
00:28:15,371 --> 00:28:17,812
show notes I discussed and you can use the Pound

599
00:28:18,202 --> 00:28:21,001
Oss podcast hashtag to hit us up on social media

600
00:28:21,329 --> 00:28:25,910
-- and Liz and Kurt have fantastic rest of your days. Thanks
-- everybody.

601
00:28:26,000 --> 00:28:27,390
-- Thanks
-- very much for having me.

602
00:28:27,400 --> 00:28:28,959
Marvelous. Thank you so much, Liz.

603
00:28:28,969 --> 00:28:29,989
It has been a pleasure.

604
00:28:30,000 --> 00:28:33,229
As always, you'll have to come back and see us next time you write your next book.

605
00:28:33,510 --> 00:28:36,140
Will do. Wonderful. Thanks, everyone. Bye bye.