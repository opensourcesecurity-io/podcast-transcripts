0
00:00:05,289 --> 00:00:07,969
Hello and welcome to the open source security podcast

1
00:00:08,109 --> 00:00:12,460
episode 169 with myself, Kurt Siefried and my partner in Thought Crime,

2
00:00:12,470 --> 00:00:13,189
Josh Bresser.

3
00:00:13,300 --> 00:00:17,510
Do you ever get sick of doing that intro? I realize you've done that 169 times now,

4
00:00:17,760 --> 00:00:18,760
actually,

5
00:00:18,770 --> 00:00:21,809
more because there was a couple of times it got deleted or scrubbed or whatever.

6
00:00:21,819 --> 00:00:23,110
It's true actually.

7
00:00:23,120 --> 00:00:24,920
And more than once you've done the intro and

8
00:00:24,930 --> 00:00:27,950
we decided to start again for whatever ridiculous reason.

9
00:00:27,959 --> 00:00:31,649
So, yeah, that's true. You've probably done it more than 100 and 80 times. I bet.

10
00:00:31,659 --> 00:00:32,450
Now that's,

11
00:00:32,459 --> 00:00:36,049
that's the worst thing is I've been trying to think of ways to mix it up a bit and I just,

12
00:00:36,060 --> 00:00:37,209
I'm drawing a blank.

13
00:00:37,220 --> 00:00:38,029
Yeah, I hear you.

14
00:00:38,040 --> 00:00:40,959
I think about that too where I think, oh, we need a new theme song because, I mean,

15
00:00:40,970 --> 00:00:44,009
we've had the same, you know, intro theme song for a long time and

16
00:00:44,110 --> 00:00:45,209
-- I, I
-- just,

17
00:00:45,569 --> 00:00:48,189
I love that piece of musical and what it represents, you know,

18
00:00:48,200 --> 00:00:51,090
man's inevitable decline into, to meaningless.

19
00:00:51,389 --> 00:00:55,590
It's really where kind of like a, I started stealing the human jobs. Right.

20
00:00:56,040 --> 00:00:58,200
They can play the piano better than we can.

21
00:00:58,549 --> 00:00:59,750
Yeah. In the 18 hundreds.

22
00:01:01,919 --> 00:01:02,979
That's right.

23
00:01:03,810 --> 00:01:08,069
All right. So, this is another one of those, you won't tell me what the topic is.

24
00:01:08,519 --> 00:01:08,529
I

25
00:01:08,699 --> 00:01:08,879
did

26
00:01:09,120 --> 00:01:09,540
it out.

27
00:01:09,860 --> 00:01:11,489
Just government security.

28
00:01:12,250 --> 00:01:12,699
Right.

29
00:01:14,379 --> 00:01:15,709
That doesn't mean anything.

30
00:01:15,930 --> 00:01:19,879
So, well, we've, we've got a couple of kerfuffles about government security.

31
00:01:19,889 --> 00:01:21,239
So, like the first one is,

32
00:01:21,419 --> 00:01:26,199
is that whole, the Republicans storming a skiff with their electronic devices.

33
00:01:26,559 --> 00:01:32,279
Yeah, I read about that. So I want to start this conversation by saying

34
00:01:32,730 --> 00:01:35,790
neither Kurt nor myself condone

35
00:01:36,080 --> 00:01:42,500
-- any particular political party and I do not want to turn this podcast into,
-- oh,

36
00:01:42,510 --> 00:01:44,989
I know I'll be, I disapprove of all of them.

37
00:01:45,319 --> 00:01:46,790
I, that's true. I hate them all.

38
00:01:46,800 --> 00:01:49,849
No, I straight up, I disapprove of all political parties pretty much.

39
00:01:49,860 --> 00:01:53,580
I, there's not a single one. I'm happy with that and, and to be clear, I'm Canadian.

40
00:01:53,589 --> 00:01:54,419
So I, I also

41
00:01:54,660 --> 00:01:57,080
group of political parties in other countries too and

42
00:01:57,220 --> 00:02:00,440
I'm sorry if that offends you there. I've fulfilled my Canadianness.

43
00:02:00,449 --> 00:02:04,870
It's easier to dislike everybody than it is to pick and choose. So

44
00:02:04,989 --> 00:02:06,519
we will preface it with that.

45
00:02:06,660 --> 00:02:12,389
So I guess why don't tell this story, especially as you're not an American.

46
00:02:12,399 --> 00:02:14,880
-- And so I'm always very interested
-- in,

47
00:02:15,009 --> 00:02:16,509
I'm blameless in this.

48
00:02:17,470 --> 00:02:19,619
No, you're not current. No one is blameless.

49
00:02:20,210 --> 00:02:24,139
-- Everything is everyone's fault. Yeah.
-- Yeah, I guess. Yeah, distributed blame.

50
00:02:24,149 --> 00:02:28,199
So a skiff is a secure compartmentalized information. Facility.

51
00:02:28,210 --> 00:02:31,059
And the idea is it's basically a box

52
00:02:31,289 --> 00:02:33,619
and to be clear, like some of these are literally

53
00:02:33,729 --> 00:02:37,619
like a small, slightly larger than a phone booth sized box.

54
00:02:37,669 --> 00:02:43,589
And some of these are, you know, multiple uh sized uh football fields, you know,

55
00:02:43,600 --> 00:02:45,389
data warehouses and things like that.

56
00:02:46,070 --> 00:02:47,330
So they vary in size.

57
00:02:47,580 --> 00:02:50,860
And the idea is is that you can securely

58
00:02:51,149 --> 00:02:53,649
uh process data within this

59
00:02:53,860 --> 00:02:54,539
box.

60
00:02:54,740 --> 00:02:58,220
And when I say process data, I don't mean just, you know, with computers and whatnot.

61
00:02:58,279 --> 00:02:59,850
But for example, you know,

62
00:03:00,089 --> 00:03:01,250
somebody can

63
00:03:01,729 --> 00:03:05,279
pull out, you know, top secret information and write notes or, and you know,

64
00:03:05,289 --> 00:03:06,639
think about it and work about it or,

65
00:03:06,649 --> 00:03:10,580
or two or three people can have a conversation about the uh the whatever, right?

66
00:03:10,589 --> 00:03:13,490
So apparently the US President travels with like a portable skiff,

67
00:03:13,500 --> 00:03:14,449
which is basically like this

68
00:03:14,580 --> 00:03:17,770
electromagnetically shielded tent that they can all huddle in so that, you know,

69
00:03:17,779 --> 00:03:19,660
nobody can hear them, nobody can see them,

70
00:03:19,850 --> 00:03:20,479
you can't

71
00:03:20,669 --> 00:03:24,440
electronically monitor them things like that. Right? Sure. And so

72
00:03:24,610 --> 00:03:26,139
the idea is

73
00:03:26,429 --> 00:03:26,949
that

74
00:03:27,210 --> 00:03:29,440
obviously you can't be bringing

75
00:03:29,800 --> 00:03:31,600
electronics in and out of these things, right?

76
00:03:31,610 --> 00:03:33,369
Because for two people to discuss, you know,

77
00:03:33,380 --> 00:03:36,710
top secret information in one of these secure boxes,

78
00:03:37,179 --> 00:03:40,559
that kind of defeats the point. If I pull my phone out and hit record

79
00:03:40,929 --> 00:03:42,350
and then wander off with it later

80
00:03:42,750 --> 00:03:44,229
or ignoring that

81
00:03:44,360 --> 00:03:47,259
the reality is with a lot of these people,

82
00:03:47,509 --> 00:03:51,910
they're the target of nation state attacks where they could conceivably have a cell

83
00:03:51,919 --> 00:03:55,929
phone that is literally listening to them all the time by a foreign adversary.

84
00:03:56,330 --> 00:03:56,839
Exactly.

85
00:03:56,850 --> 00:04:01,550
You know, if, for example, you were to set 111111 as your phone passcode,

86
00:04:01,559 --> 00:04:02,750
hypothetically speaking.

87
00:04:02,759 --> 00:04:03,350
Yeah.

88
00:04:03,360 --> 00:04:03,740
You know,

89
00:04:03,750 --> 00:04:07,470
it could be possible for somebody if they physically get a hold

90
00:04:07,479 --> 00:04:10,410
of your phone for even only five or 10 seconds to,

91
00:04:10,419 --> 00:04:11,619
you know, open it up and

92
00:04:11,869 --> 00:04:14,389
go to a web page or something that compromises your phone.

93
00:04:14,399 --> 00:04:15,289
-- Or
-- look, man,

94
00:04:15,300 --> 00:04:21,529
these are the people who buy these zero days that affect Android and Os X and I OS.

95
00:04:21,738 --> 00:04:22,640
Right. I mean,

96
00:04:22,859 --> 00:04:25,690
when, when you hear about selling things on the black market,

97
00:04:25,790 --> 00:04:31,410
-- they end up in the hands of nation state actors. That's where they
-- go even simpler.

98
00:04:31,420 --> 00:04:35,049
You know, these nation states, a lot of them have information security,

99
00:04:35,149 --> 00:04:39,730
the groups that find zero days, like, sure, that's literally their job.

100
00:04:39,739 --> 00:04:43,369
You know, and, and I would be offended if governments weren't doing this because,

101
00:04:43,380 --> 00:04:44,290
you know, it's,

102
00:04:44,640 --> 00:04:46,850
it's like developing weapons. It sucks. But

103
00:04:47,010 --> 00:04:48,209
you got to do it.

104
00:04:48,489 --> 00:04:51,130
Right. Yeah. Exactly. And everyone's doing it.

105
00:04:51,140 --> 00:04:51,470
Any,

106
00:04:51,480 --> 00:04:55,410
any government or anyone who says they're not like they are totally lying to you.

107
00:04:55,420 --> 00:04:56,809
Some are not doing it

108
00:04:57,149 --> 00:04:58,279
very well.

109
00:04:58,790 --> 00:05:00,790
I will say from what I've read and looked, you know,

110
00:05:00,799 --> 00:05:04,109
there's a lot of countries that are not my choice.

111
00:05:04,119 --> 00:05:05,750
No. Exactly. Yeah. Exactly.

112
00:05:05,910 --> 00:05:06,950
But yeah, fundamentally,

113
00:05:06,959 --> 00:05:10,290
this is something pretty much all governments want the capability of end of story.

114
00:05:10,299 --> 00:05:12,660
You know, it's like when governments are like, we don't want to be a nuclear power.

115
00:05:12,670 --> 00:05:12,989
It's like

116
00:05:15,299 --> 00:05:18,350
anyway, so continue the story, we know what a skiff is now.

117
00:05:18,380 --> 00:05:20,399
-- So,
-- so the idea of a skiff is,

118
00:05:20,500 --> 00:05:23,589
you've got this secure box, you need to control what goes into it,

119
00:05:23,600 --> 00:05:25,130
you need to control what comes out of it

120
00:05:25,670 --> 00:05:28,720
and you need to, you know, make sure it's sanitized inside, right?

121
00:05:28,730 --> 00:05:31,059
So there's no, like you can't just have like,

122
00:05:31,070 --> 00:05:33,179
like a desktop phone sitting in one of these,

123
00:05:34,049 --> 00:05:37,339
you know, again, that could be like remotely hacked, you know, like a, like, um,

124
00:05:37,350 --> 00:05:39,000
jeez, I don't even know what brands,

125
00:05:39,130 --> 00:05:42,510
I, I only know the Canadian brands and they all out of business 1015 years ago,

126
00:05:42,700 --> 00:05:43,790
Nortel and whatnot,

127
00:05:43,970 --> 00:05:46,510
I guess Cisco. Cisco makes phones, right? Ok. Let's pick on Cisco for

128
00:05:46,660 --> 00:05:48,339
sure. So, you know, if you had like a Cisco

129
00:05:48,500 --> 00:05:51,679
and when I say a desk phone again, you know, these aren't phones, these are

130
00:05:51,899 --> 00:05:52,459
shooters that

131
00:05:52,739 --> 00:05:54,619
kind of have the appearance of a phone,

132
00:05:55,070 --> 00:05:57,040
you know, they've built in web browsers and stuff now.

133
00:05:57,049 --> 00:06:02,000
So you have to be really careful and control what is in the skiff and, you know,

134
00:06:02,010 --> 00:06:04,119
you don't want people leaving a listening device behind, you know,

135
00:06:04,130 --> 00:06:08,119
either one that transmits or one that can, you know, store and record

136
00:06:08,690 --> 00:06:09,440
and

137
00:06:10,029 --> 00:06:13,059
so my understanding is most skiffs, you know,

138
00:06:13,070 --> 00:06:16,510
it's not like an airport where you have to go through a metal detector and like a

139
00:06:16,670 --> 00:06:18,179
whole bunch of security measures.

140
00:06:18,429 --> 00:06:22,850
It appears that most skiffs kind of run on the honor principle

141
00:06:22,859 --> 00:06:25,809
of essentially the people that have clearance to use these things,

142
00:06:25,820 --> 00:06:26,619
understand that

143
00:06:26,929 --> 00:06:28,190
it's important to,

144
00:06:28,369 --> 00:06:29,750
you know, be secure.

145
00:06:29,890 --> 00:06:30,600
And so, for example,

146
00:06:30,609 --> 00:06:32,380
they'll have like little lockable cabinets outside

147
00:06:32,390 --> 00:06:33,869
where you like dump all your electronics,

148
00:06:33,880 --> 00:06:35,869
your keys, you know, that kind of stuff, you know,

149
00:06:35,880 --> 00:06:37,910
you pat down your pockets and then you go into the skiff,

150
00:06:37,920 --> 00:06:39,309
have your conversation about

151
00:06:39,489 --> 00:06:40,989
aliens in area 51

152
00:06:41,359 --> 00:06:43,950
and then, you know, exit the skiff and get your phone back or whatever.

153
00:06:43,959 --> 00:06:45,549
And apparently

154
00:06:45,730 --> 00:06:49,589
for normal people, at least the penalties for violating,

155
00:06:49,695 --> 00:06:52,315
you know, skiff procedures are quite harsh,

156
00:06:52,464 --> 00:06:54,355
like at a minimum you're going to get that.

157
00:06:54,364 --> 00:06:56,875
I love the word they use is you're going to get counseled,

158
00:06:57,135 --> 00:06:57,915
you know, which is I,

159
00:06:57,924 --> 00:07:01,244
I assume what that means is they're talking to you but not screaming at you.

160
00:07:01,255 --> 00:07:04,825
You know, in the same way I counsel my Children when they do things.

161
00:07:05,565 --> 00:07:08,334
And for example, people were talking about how they don't even wear their,

162
00:07:08,345 --> 00:07:11,815
uh Bluetooth hearing aids into these facilities, which makes sense.

163
00:07:11,825 --> 00:07:12,385
Right. Because, uh,

164
00:07:12,720 --> 00:07:16,010
uh I did some research on hearing aids and, you know, all,

165
00:07:16,019 --> 00:07:17,880
all the modern ones have Bluetooth built into them

166
00:07:17,890 --> 00:07:19,890
so that your phone can ring to your earphone.

167
00:07:19,899 --> 00:07:20,079
And

168
00:07:22,339 --> 00:07:23,130
yeah, and I mean, and,

169
00:07:23,140 --> 00:07:26,109
but that is the literal definition of an audio bugging device is like, well,

170
00:07:26,119 --> 00:07:29,470
it listens to audio, it probably has enough memory chips to record some of it.

171
00:07:29,480 --> 00:07:31,540
And it's got a Bluetooth transmitter receiver on. It

172
00:07:32,359 --> 00:07:33,850
sounds like an audio bug to me.

173
00:07:34,429 --> 00:07:38,059
Ok. So why are you telling us this story about a skiff?

174
00:07:38,109 --> 00:07:42,690
So a bunch of, mostly, I think all Republicans

175
00:07:42,839 --> 00:07:46,019
stormed into a major skiff where there were some hearings going on

176
00:07:46,859 --> 00:07:50,220
and they took their electronics in, not only did they take their electronics in,

177
00:07:50,230 --> 00:07:52,309
but they were apparently live tweeting and taking

178
00:07:52,320 --> 00:07:54,070
video of themselves in the skiff and,

179
00:07:54,079 --> 00:07:55,380
and broadcasting this

180
00:07:55,589 --> 00:07:58,399
and, and apparently they all knew better. Like it wasn't some mistake.

181
00:07:58,410 --> 00:08:02,079
-- Like they didn't know what a skiff was or how to behave in one.
-- Everyone there

182
00:08:02,250 --> 00:08:04,239
should have known better.

183
00:08:04,820 --> 00:08:06,679
Yeah. Well, no, they knew better. And

184
00:08:07,450 --> 00:08:08,279
so

185
00:08:08,649 --> 00:08:10,519
it got me thinking it's, you know,

186
00:08:10,529 --> 00:08:16,279
how do you do security when your users are willfully disobedient, let's say,

187
00:08:16,829 --> 00:08:20,519
because fundamentally to, to implement security that

188
00:08:21,380 --> 00:08:23,549
where you can't even sort of trust your insiders

189
00:08:23,559 --> 00:08:25,760
or the people that are supposed to have access.

190
00:08:25,769 --> 00:08:31,600
-- You, you're kind of up the creek.
-- I would agree completely. And I feel like this story

191
00:08:32,030 --> 00:08:34,719
really helps bring home some of the concepts you

192
00:08:34,729 --> 00:08:38,780
get in the security universe where it's almost like

193
00:08:38,919 --> 00:08:41,390
you think of different socio-economic classes

194
00:08:41,400 --> 00:08:43,030
where obviously someone at the bottom.

195
00:08:43,039 --> 00:08:43,859
Generally,

196
00:08:43,869 --> 00:08:45,650
let's say you have someone at the bottom and someone

197
00:08:45,659 --> 00:08:47,500
at the top and they commit the same crime,

198
00:08:47,510 --> 00:08:49,520
you're going to see drastically different sentences

199
00:08:49,530 --> 00:08:51,159
for them for a variety of reasons.

200
00:08:51,169 --> 00:08:52,940
Mind you and I don't want to get into

201
00:08:53,210 --> 00:08:57,059
kind of the, the esoteric details of that because it's, it's complicated and,

202
00:08:57,070 --> 00:08:57,609
and it's

203
00:08:57,789 --> 00:09:00,659
fair with security, especially, you see this a

204
00:09:00,940 --> 00:09:03,630
lot where somebody who's maybe at the top and this

205
00:09:03,640 --> 00:09:05,710
could be a CEO could be a congress person,

206
00:09:05,719 --> 00:09:08,340
could be a member of the board of directors,

207
00:09:08,460 --> 00:09:09,650
whatever it is.

208
00:09:09,919 --> 00:09:11,409
And they know

209
00:09:11,659 --> 00:09:13,619
they don't have to follow your rules

210
00:09:13,760 --> 00:09:16,989
and it's a very difficult place to be in when they

211
00:09:17,000 --> 00:09:21,409
just willfully disregard what they know to be the right decision

212
00:09:21,599 --> 00:09:23,570
because they just don't feel like it.

213
00:09:23,919 --> 00:09:24,179
Yeah.

214
00:09:24,190 --> 00:09:27,619
And it's worse because often those are the people that are actually the targets.

215
00:09:27,630 --> 00:09:29,979
Well, of course, because the bad guys know and,

216
00:09:29,989 --> 00:09:33,010
and they especially know if that person is, let's face it,

217
00:09:33,020 --> 00:09:35,419
not smart enough to follow the rules.

218
00:09:35,750 --> 00:09:39,549
Well, I mean, a simple example that I can make public, you know, at the, at the CS A,

219
00:09:39,559 --> 00:09:45,400
we often get external phishing attempts, you know, from our CEO saying, hey,

220
00:09:45,409 --> 00:09:47,719
I need you to go talk to this lawyer or oh, you

221
00:09:47,825 --> 00:09:51,484
-- to send $10,000 to this thing right away. And
-- it's like itunes gift cards.

222
00:09:52,215 --> 00:09:54,164
Yeah, pretty much. And I mean,

223
00:09:54,265 --> 00:09:56,575
so for example, if, if we didn't, you know,

224
00:09:56,585 --> 00:09:58,965
we enforced two factor authentication on our email

225
00:09:58,974 --> 00:10:01,255
accounts for this and many other reasons.

226
00:10:01,474 --> 00:10:03,164
But, you know, hypothetically speaking,

227
00:10:03,375 --> 00:10:05,565
I know places. Well, this is a hypothetical. Come

228
00:10:05,684 --> 00:10:08,635
on. You know, we all know that there are places where the CEO or the high levels,

229
00:10:09,205 --> 00:10:11,484
uh, refuse to do

230
00:10:11,919 --> 00:10:13,510
the good security. Right. It's a hassle

231
00:10:14,030 --> 00:10:17,919
and those places. Yeah. How do you force CEO to do something?

232
00:10:17,929 --> 00:10:18,809
You know, I'm lucky in that.

233
00:10:18,820 --> 00:10:20,909
I work for a security organization and our CEO

234
00:10:20,919 --> 00:10:23,020
is quite security minded as it turns out.

235
00:10:23,169 --> 00:10:26,260
But, yeah, I mean, I've heard horror stories of other CEO where they,

236
00:10:26,270 --> 00:10:30,299
they literally have had to put the CEO on like his own instance of an email server,

237
00:10:30,309 --> 00:10:30,940
you know, and

238
00:10:31,150 --> 00:10:33,390
set up a VPN from his phone to the email server

239
00:10:33,400 --> 00:10:35,450
because he refuses to use a good password or something.

240
00:10:35,500 --> 00:10:38,150
I don't know if there's a good answer for that even.

241
00:10:38,440 --> 00:10:42,080
Well, and I would say it's actually worse what they did in that. It sets

242
00:10:42,210 --> 00:10:45,789
an example of, well, the, the higher ups do this and get away with it.

243
00:10:45,799 --> 00:10:47,090
So, is it really that big of a deal?

244
00:10:49,280 --> 00:10:49,510
Yeah.

245
00:10:49,520 --> 00:10:54,169
It's really hard to say, do as I do or it's really hard when somebody says, do, as I say,

246
00:10:54,179 --> 00:10:54,979
not as I do.

247
00:10:55,119 --> 00:10:57,320
I agree with that 100%.

248
00:10:57,330 --> 00:11:01,380
And I think that is a sign of, of bad leadership for what it's worth.

249
00:11:01,390 --> 00:11:03,369
But I, I have a very strong suspicion

250
00:11:03,890 --> 00:11:07,570
that if you're part of an organization with leadership that acts in that way,

251
00:11:07,580 --> 00:11:10,700
you're probably not, that, that organization probably just isn't going to exist

252
00:11:10,909 --> 00:11:13,440
for, for a terribly long period of time.

253
00:11:13,450 --> 00:11:16,250
I mean, it's, it's conceivable, it made it this far,

254
00:11:16,640 --> 00:11:19,820
potentially because of different leadership or, or whatever.

255
00:11:19,830 --> 00:11:22,510
I think you'll eventually reach a point where that becomes

256
00:11:22,770 --> 00:11:24,820
immensely problematic for the future.

257
00:11:24,830 --> 00:11:27,059
Well being of whatever group it is you're a part of.

258
00:11:27,140 --> 00:11:30,539
Well, and in a similar vein, this came out about a couple of days ago,

259
00:11:31,609 --> 00:11:33,979
an internal White House memo published today by AXIOS

260
00:11:33,989 --> 00:11:36,719
reveals that recent changes to the information operations and

261
00:11:36,729 --> 00:11:38,880
security organizations there have left security team in a

262
00:11:38,890 --> 00:11:41,000
tumult with many members headed for the door.

263
00:11:41,489 --> 00:11:44,559
So basically, it sounds like back in the day

264
00:11:44,750 --> 00:11:47,359
by, back in the day, I mean, like in 2014 or something,

265
00:11:47,369 --> 00:11:50,890
they had a breach of an unclassified White House network by Russian intelligence,

266
00:11:50,900 --> 00:11:52,840
a breach discovered by a friendly foreign government.

267
00:11:53,119 --> 00:11:55,109
So, I mean, nice of them to tell you

268
00:11:55,710 --> 00:11:56,479
right.

269
00:11:57,010 --> 00:11:58,590
You know, uh but in July,

270
00:11:59,130 --> 00:12:00,960
in a July reorganization,

271
00:12:00,969 --> 00:12:03,270
this office was dissolved and its duties placed under

272
00:12:03,280 --> 00:12:05,419
the White House office of the Chief Information Officer.

273
00:12:05,429 --> 00:12:06,409
Now in fairness,

274
00:12:06,419 --> 00:12:09,270
I think the White House should absolutely have a Chief Information Officer.

275
00:12:09,280 --> 00:12:09,690
I mean, they,

276
00:12:10,590 --> 00:12:12,840
you know, like they're not using typewriters down there.

277
00:12:13,119 --> 00:12:16,479
-- And um essentially
-- they were even if they were, Kurt,

278
00:12:16,719 --> 00:12:20,260
there was, there's an instant, I'll dig this up and put it in the show notes.

279
00:12:20,270 --> 00:12:20,580
But, like,

280
00:12:20,590 --> 00:12:23,460
the Russians bugged the typewriters at one point

281
00:12:23,469 --> 00:12:25,299
and I think the Moscow Embassy where the,

282
00:12:25,309 --> 00:12:27,940
whatever it was typed, all of the, basically the characters,

283
00:12:27,950 --> 00:12:29,710
it was like a key logger and a typewriter

284
00:12:29,840 --> 00:12:31,130
where it was transmitting

285
00:12:31,380 --> 00:12:35,419
whatever was typed on the particular typewriters. Like, freaking genius. Right.

286
00:12:36,289 --> 00:12:39,789
Yeah. The first electric, uh, the first electronic typewriters. What they

287
00:12:40,969 --> 00:12:42,619
good on them? Clever.

288
00:12:43,520 --> 00:12:44,260
Right.

289
00:12:45,000 --> 00:12:46,119
So,

290
00:12:46,500 --> 00:12:51,729
yeah, I mean, so the, the White House is even if they're not gutting the security

291
00:12:52,049 --> 00:12:53,330
sort of office, the,

292
00:12:53,500 --> 00:12:54,099
when you're,

293
00:12:54,109 --> 00:12:56,619
when you're mixing things up and making it all kind

294
00:12:56,630 --> 00:13:00,099
of messy that's going to impact your security posture.

295
00:13:00,750 --> 00:13:03,000
Unquestionably. Absolutely.

296
00:13:03,429 --> 00:13:05,349
You know, you want a smooth transition, not a,

297
00:13:05,359 --> 00:13:07,739
not a bumpy transition if you are going to make changes.

298
00:13:08,359 --> 00:13:09,820
Exactly. And

299
00:13:09,969 --> 00:13:13,179
so again, I come back to this whole, you know, it, it's kind of hard to,

300
00:13:13,570 --> 00:13:14,460
I, you know,

301
00:13:14,469 --> 00:13:16,500
the US government is always talking about computer security

302
00:13:16,510 --> 00:13:18,280
and how important it is to have computer security.

303
00:13:18,619 --> 00:13:19,479
But in the last

304
00:13:19,630 --> 00:13:22,469
week, I mean, we've seen that the higher ups just,

305
00:13:22,900 --> 00:13:25,330
it's not that they don't care, it's that they're,

306
00:13:25,890 --> 00:13:30,159
you know, actively misbehaving quite badly in some cases.

307
00:13:30,330 --> 00:13:34,929
Well, so let's break this down in kind of a different way first.

308
00:13:34,940 --> 00:13:40,140
-- And let's start with the first story of people infiltrating a skiff with
-- phone

309
00:13:40,609 --> 00:13:43,489
infiltrating it was, they were quite loud about it,

310
00:13:44,900 --> 00:13:49,830
but here's the reality if you or I did that we would probably go to jail.

311
00:13:49,940 --> 00:13:50,549
I'm pretty sure

312
00:13:52,000 --> 00:13:52,070
I,

313
00:13:52,219 --> 00:13:52,590
yeah.

314
00:13:53,119 --> 00:13:55,419
Yeah, we would go to jail. And there are,

315
00:13:55,669 --> 00:14:01,130
if you were an employee of, let's say, some defense contractor and you did this,

316
00:14:01,140 --> 00:14:03,030
you would lose your job immediately.

317
00:14:03,039 --> 00:14:04,969
If you have clearance, it's gone

318
00:14:05,309 --> 00:14:07,359
and you'll probably never work again

319
00:14:07,559 --> 00:14:10,729
in the United States public sector, potentially in any public sector

320
00:14:11,169 --> 00:14:14,010
in basically any of the Western nations.

321
00:14:14,419 --> 00:14:15,280
Because

322
00:14:15,559 --> 00:14:16,109
this, I mean,

323
00:14:16,119 --> 00:14:20,330
this stuff is taken very seriously by the people who are responsible to enforce it.

324
00:14:20,340 --> 00:14:21,409
And as it should be

325
00:14:21,659 --> 00:14:22,489
because

326
00:14:22,820 --> 00:14:25,659
these are the sort of situations where generally speaking,

327
00:14:25,669 --> 00:14:30,729
when these people make mistakes, someone dies like literally someone dies, right?

328
00:14:30,739 --> 00:14:33,729
This isn't like the metaphorical oh ha ha. They're gonna die like

329
00:14:33,835 --> 00:14:35,294
you and I talk about, no, no, this is,

330
00:14:35,304 --> 00:14:37,565
this is the real deal and I think that's what people

331
00:14:37,575 --> 00:14:41,515
forget sometimes is when you're dealing with security at this level,

332
00:14:41,525 --> 00:14:43,895
like lives are literally at stake.

333
00:14:44,025 --> 00:14:47,614
Well, and it's, it's tricky too because you're dealing with, you know,

334
00:14:47,625 --> 00:14:50,854
parties that have to have a high, high degree of trust

335
00:14:51,104 --> 00:14:52,015
to do their job.

336
00:14:52,330 --> 00:14:54,599
You know, you can't have two intelligence officials

337
00:14:54,989 --> 00:14:55,669
having

338
00:14:55,809 --> 00:14:58,869
a proper discussion and you know, they're,

339
00:14:58,880 --> 00:15:01,969
they're afraid to say things because they're afraid they might be listened to,

340
00:15:01,979 --> 00:15:02,210
right?

341
00:15:02,219 --> 00:15:02,429
They,

342
00:15:02,559 --> 00:15:04,549
you know, it's what's a classic thing with you know, the,

343
00:15:04,559 --> 00:15:06,789
the various diplomats that have been,

344
00:15:07,080 --> 00:15:10,679
you know, their communications have been leaked and it's, I mean, part of the,

345
00:15:10,690 --> 00:15:12,549
being a diplomat is to have, you know,

346
00:15:12,559 --> 00:15:16,140
open and honest and frank communications with your government.

347
00:15:16,299 --> 00:15:18,099
You know, the one you work for,

348
00:15:18,359 --> 00:15:20,380
to, to tell them what's going on. Right.

349
00:15:20,450 --> 00:15:23,580
You know, and sometimes these diplomats say things and, and unfortunately,

350
00:15:23,590 --> 00:15:25,030
you know, they, they can't really be

351
00:15:25,349 --> 00:15:26,099
made,

352
00:15:26,580 --> 00:15:28,219
uh, they can't be said in ways that

353
00:15:28,820 --> 00:15:32,409
they inevitably be, inevitably will end up offending somebody. Right.

354
00:15:32,530 --> 00:15:35,989
You know, there's just no nice way to say some things and they, you know,

355
00:15:36,000 --> 00:15:38,489
if they have to worry about what they're saying, going public, they,

356
00:15:38,500 --> 00:15:40,039
they literally can't do their job,

357
00:15:40,530 --> 00:15:40,969
right.

358
00:15:41,200 --> 00:15:45,690
You know, this is, I've read a lot of World War Two history and history in general and,

359
00:15:45,700 --> 00:15:48,169
you know, this is a classic case of where governments don't,

360
00:15:48,650 --> 00:15:52,049
can't have open and honest internal communication.

361
00:15:52,059 --> 00:15:55,630
You know, people start filtering things or censoring things

362
00:15:55,890 --> 00:15:58,039
and things go off the rails real fast.

363
00:15:58,049 --> 00:15:59,590
Like this is one of the reasons the US sr

364
00:15:59,599 --> 00:16:02,390
economy collapsed is because everybody was hiding bad news,

365
00:16:02,400 --> 00:16:04,960
you know, and their, their economy literally was,

366
00:16:05,159 --> 00:16:07,020
you know, shaving some sawdust.

367
00:16:07,159 --> 00:16:08,650
You know, it was just a mess.

368
00:16:09,020 --> 00:16:09,739
You know, these skis

369
00:16:09,849 --> 00:16:11,909
are incredibly crucial

370
00:16:12,150 --> 00:16:12,820
for

371
00:16:13,469 --> 00:16:14,549
the government to operate.

372
00:16:14,969 --> 00:16:16,229
Like there's, there's no,

373
00:16:16,460 --> 00:16:17,929
you can't put too fine a point on it.

374
00:16:17,940 --> 00:16:18,669
But, you know,

375
00:16:18,679 --> 00:16:22,090
these things are absolutely required for people to just do their daily job

376
00:16:22,099 --> 00:16:24,429
and talk to each other and if you take that away from them.

377
00:16:24,919 --> 00:16:27,500
Yeah. I, I can't imagine how the US government would work.

378
00:16:28,239 --> 00:16:29,229
It won't,

379
00:16:29,330 --> 00:16:30,549
that's the answer.

380
00:16:30,729 --> 00:16:35,330
And let's, let's keep going. So then we have the angle of

381
00:16:36,229 --> 00:16:39,729
the White House has gotten rid of most of their security people

382
00:16:39,739 --> 00:16:43,010
and we may never know why that is or what's happened.

383
00:16:43,020 --> 00:16:43,450
They're,

384
00:16:43,460 --> 00:16:46,520
they're getting rid of one office and apparently taking it under another group.

385
00:16:46,530 --> 00:16:49,940
-- But the transition is very ugly.
-- Ok, that's, that's probably fair.

386
00:16:49,950 --> 00:16:54,369
Although it sounds like from the story you sent me that a number of people

387
00:16:54,869 --> 00:16:56,929
have departed due to this.

388
00:16:57,719 --> 00:17:00,059
Well, it sounds like it's gone political. Which,

389
00:17:00,409 --> 00:17:00,630
right,

390
00:17:00,890 --> 00:17:03,099
how could anything at the White House not go politically

391
00:17:04,348 --> 00:17:05,020
maybe.

392
00:17:05,030 --> 00:17:08,848
But at the same time, I think this is one of those situations where, and I mean,

393
00:17:08,858 --> 00:17:10,280
this is true of any organization.

394
00:17:10,290 --> 00:17:10,848
If,

395
00:17:10,989 --> 00:17:15,618
if your security team is trying to play politics in your organization,

396
00:17:15,989 --> 00:17:19,500
you, you're probably going to have a bad day. I mean, that's the reality of it.

397
00:17:19,510 --> 00:17:23,160
-- I
-- think it's inevitable that security teams end up playing politics. But

398
00:17:23,358 --> 00:17:23,739
it,

399
00:17:24,098 --> 00:17:27,328
I mean, there's playing politics and then there's playing politics where,

400
00:17:27,338 --> 00:17:30,399
you know, things are ugly and people are trying to throw each other under the bus and,

401
00:17:30,409 --> 00:17:30,918
you know,

402
00:17:31,619 --> 00:17:35,798
and, and especially then you have your leadership,

403
00:17:35,808 --> 00:17:40,029
not necessarily listening to you and doing things in a secure manner and I guess,

404
00:17:40,279 --> 00:17:42,318
like, that's the sort of environment that look,

405
00:17:42,328 --> 00:17:44,318
anyone who's any good is going to leave.

406
00:17:44,328 --> 00:17:47,318
I mean, this freaking industry has a negative unemployment right now.

407
00:17:47,538 --> 00:17:48,038
It's,

408
00:17:48,168 --> 00:17:51,678
if, if someone wants a new job, they're going to have it by the end of the day.

409
00:17:52,119 --> 00:17:54,160
And so if you're not treating your people right,

410
00:17:54,170 --> 00:17:57,920
and you have a toxic work environment, like, say goodbye to anyone worth keeping.

411
00:17:58,069 --> 00:17:58,689
I mean,

412
00:17:58,829 --> 00:18:00,459
that's, that's what's going to happen.

413
00:18:00,510 --> 00:18:01,099
Well, I think it's,

414
00:18:01,109 --> 00:18:03,250
it's even worse than that because the majority of

415
00:18:03,260 --> 00:18:05,229
people that I know that work for governments,

416
00:18:05,239 --> 00:18:06,140
at least in Canada,

417
00:18:06,420 --> 00:18:10,515
they actually believe like in the government trying to help make life better

418
00:18:10,954 --> 00:18:11,114
for

419
00:18:11,285 --> 00:18:12,324
people. They don't,

420
00:18:12,515 --> 00:18:13,685
I mean, the pay is ok.

421
00:18:13,694 --> 00:18:16,275
But yeah, you can definitely, especially in it,

422
00:18:16,285 --> 00:18:18,045
you can make a lot more money in the private sector.

423
00:18:18,055 --> 00:18:18,734
Absolutely.

424
00:18:18,744 --> 00:18:23,175
I mean, I go back to, I mean, what we talked to, to Dick Clark about the book, right?

425
00:18:23,185 --> 00:18:24,444
The Fifth Domain and

426
00:18:24,775 --> 00:18:26,255
you listen to him talk and I mean,

427
00:18:26,265 --> 00:18:28,905
that's a person who dedicated his career as

428
00:18:28,915 --> 00:18:31,594
being a public servant and like he truly believes

429
00:18:31,604 --> 00:18:33,515
in the mission of the government and that

430
00:18:33,525 --> 00:18:35,045
it's going to make things better for people.

431
00:18:35,055 --> 00:18:35,844
And I know that's,

432
00:18:36,180 --> 00:18:39,560
uh, it'll say a topic that's up for debate in many, many cases.

433
00:18:39,569 --> 00:18:43,739
But I, I respect that that's someone who, who is definitely,

434
00:18:43,910 --> 00:18:45,359
he probably could have made

435
00:18:45,589 --> 00:18:48,479
10 times as much money in the public, in the public at

436
00:18:49,170 --> 00:18:50,000
least.

437
00:18:50,160 --> 00:18:54,280
And he didn't and like that's very respectable. II, I appreciate that.

438
00:18:54,290 --> 00:18:55,719
I think we need people like that.

439
00:18:56,170 --> 00:18:58,920
And, and then there's just the more mundane day to day.

440
00:18:59,130 --> 00:19:00,430
I don't even know what to call it,

441
00:19:00,439 --> 00:19:04,880
stupidity of literally somebody with a passcode on their phone of 111111

442
00:19:04,963 --> 00:19:08,493
and doing it on camera like it was on public TV.

443
00:19:08,503 --> 00:19:11,792
You know, and, and this is literally, you know, as I mentioned in a much earlier show,

444
00:19:11,802 --> 00:19:14,322
this is one of the reasons I got an iphone se is so my son couldn't

445
00:19:14,552 --> 00:19:17,583
surf my password, right? I use my thumbprint to unlock it.

446
00:19:17,593 --> 00:19:21,272
-- And that's a great reason
-- because, you know, Felix is good at that.

447
00:19:21,322 --> 00:19:21,802
Sure.

448
00:19:21,812 --> 00:19:27,213
Well, it, all kids are in, look, if the guy's password was 19462,

449
00:19:27,383 --> 00:19:30,743
we'd be picking on him for that for some reason too.

450
00:19:30,753 --> 00:19:32,713
-- But
-- it would take about 10 seconds to figure it out

451
00:19:32,723 --> 00:19:34,725
as opposed to you just watch the thing and you're like,

452
00:19:34,735 --> 00:19:35,995
seriously, like you just went.

453
00:19:36,145 --> 00:19:39,845
Yeah, I mean, at least you could say then there was an attempt, an attempt was made,

454
00:19:39,946 --> 00:19:41,995
you know, versus no attempt was made.

455
00:19:42,105 --> 00:19:46,026
Although, you know, maybe, maybe he's playing like 3D chess and he's actually,

456
00:19:46,036 --> 00:19:47,046
that's his burner phone.

457
00:19:47,215 --> 00:19:49,086
I doubt it.

458
00:19:49,265 --> 00:19:52,326
Who knows? And he was just checking the weather or ordering a pizza.

459
00:19:52,426 --> 00:19:56,005
So, yeah, I mean, and again, how do you, how do you talk to people and be like,

460
00:19:56,015 --> 00:19:58,686
it's really important to have a good password, you know,

461
00:19:58,865 --> 00:20:02,406
-- when stuff like this happens constantly. No.
-- Look,

462
00:20:03,030 --> 00:20:08,199
I bet you if you took a group of 100 people and you

463
00:20:08,319 --> 00:20:12,229
will say, acquired all of their telephone passwords,

464
00:20:12,250 --> 00:20:16,119
they would be the normal terrible distribution of passwords.

465
00:20:16,130 --> 00:20:20,670
We see in every single password dump that has ever happened where you've got, like,

466
00:20:20,680 --> 00:20:23,640
30% of them are going to be 1234.

467
00:20:24,319 --> 00:20:26,540
And then it's kind of long tail after that.

468
00:20:26,550 --> 00:20:27,979
And, and look the,

469
00:20:27,989 --> 00:20:29,660
the House of Representatives and the

470
00:20:29,670 --> 00:20:31,939
Senate and really all politicians everywhere,

471
00:20:31,949 --> 00:20:36,339
they're probably a pretty accurate representation of the population as a whole.

472
00:20:36,349 --> 00:20:39,579
And so I bet you a nontrivial number of them have won two,

473
00:20:39,655 --> 00:20:43,944
34 as their password and they just always will because that's what people do.

474
00:20:44,045 --> 00:20:46,635
Yeah. But I mean, these people, if nothing else should have been

475
00:20:46,895 --> 00:20:49,555
educated, you know, we both work for Red Hat. Right.

476
00:20:49,564 --> 00:20:52,214
We both went to the thing where you are given your

477
00:20:52,224 --> 00:20:54,775
laptop and told to set a secure password and all that,

478
00:20:55,420 --> 00:20:57,560
you know, and we're told what a secure password is.

479
00:20:57,569 --> 00:20:59,650
They didn't have that when I started at Red Hat.

480
00:21:00,260 --> 00:21:00,520
It was too

481
00:21:00,719 --> 00:21:00,750
late.

482
00:21:01,689 --> 00:21:02,020
Ok.

483
00:21:02,410 --> 00:21:04,719
Well, anyways, they, you know, and, and the built in Linux

484
00:21:04,829 --> 00:21:07,680
tools will filter for

485
00:21:07,910 --> 00:21:10,209
some of the especially terrible passwords, you know,

486
00:21:10,219 --> 00:21:13,510
-- built in the little dictionary thing you
-- can still get around that.

487
00:21:13,520 --> 00:21:15,390
But, I mean, point taken.

488
00:21:15,589 --> 00:21:16,040
Oh, yeah. Yeah.

489
00:21:16,050 --> 00:21:19,489
But, I mean, it's so, I don't know, like,

490
00:21:19,560 --> 00:21:23,180
-- no here
-- because fundamentally how are we going to secure all this stuff when,

491
00:21:23,280 --> 00:21:24,939
you know, when your leadership doesn't, we

492
00:21:25,050 --> 00:21:27,069
don't, that's the reality of it.

493
00:21:27,369 --> 00:21:29,719
This is so, there, there's two problems here. Right.

494
00:21:29,729 --> 00:21:33,949
Let's say we ignore the fact that the people in leadership positions

495
00:21:33,959 --> 00:21:38,229
can do whatever they want with basically zero repercussions for their activities.

496
00:21:38,239 --> 00:21:39,270
I think that is,

497
00:21:39,760 --> 00:21:43,540
that is a symptom of a broken organization is what that is.

498
00:21:43,550 --> 00:21:47,420
And that starts into political talk, which we don't want to do.

499
00:21:47,430 --> 00:21:51,329
So let's just leave that at that and say that is the sad reality of it if you are

500
00:21:51,339 --> 00:21:53,550
in a group and your leadership doesn't follow the

501
00:21:53,560 --> 00:21:56,780
rules because they think that they're special for whatever reason

502
00:21:57,109 --> 00:22:00,369
that is a dysfunctional organization and there is basically no

503
00:22:00,380 --> 00:22:03,010
way to fix it because the leadership is broken,

504
00:22:03,020 --> 00:22:05,380
which means it's going to be broken from the top to the bottom.

505
00:22:05,540 --> 00:22:07,260
Full stop. Now,

506
00:22:07,420 --> 00:22:08,719
let's talk about

507
00:22:08,979 --> 00:22:12,130
crappy passwords on a cell phone. And you're saying, how do we secure that?

508
00:22:12,140 --> 00:22:13,390
-- And the reality is we
-- don't. Oh,

509
00:22:13,500 --> 00:22:16,349
no. I think that you replace it with fingerprints and face.

510
00:22:16,709 --> 00:22:17,530
That's exactly right.

511
00:22:17,540 --> 00:22:20,260
The fact is that passwords are terrible and people suck at password

512
00:22:20,474 --> 00:22:24,625
and they're always going to, and the only way to fix it is to just not use passwords.

513
00:22:24,635 --> 00:22:27,734
And yeah, fingerprint scanners are a great one. The face rec,

514
00:22:27,854 --> 00:22:29,925
what are they? Face ID? I think Apple calls it

515
00:22:30,375 --> 00:22:32,545
like, that's a good one right there. There's,

516
00:22:32,734 --> 00:22:35,055
and, and we're even getting better with things like web often

517
00:22:35,165 --> 00:22:38,905
in web browsers and you're getting like the click to login type

518
00:22:38,915 --> 00:22:41,324
stuff where your phone just pops up a thing that says,

519
00:22:41,334 --> 00:22:42,724
do you want to log in?

520
00:22:42,734 --> 00:22:43,364
and

521
00:22:43,939 --> 00:22:46,319
that's the stuff that's going to matter?

522
00:22:46,339 --> 00:22:50,079
Because if you're relying on humans typing in passcodes, you're going to fail.

523
00:22:50,089 --> 00:22:50,280
Well,

524
00:22:50,290 --> 00:22:53,000
you know what it reminds me of is the difference between anti lock brakes

525
00:22:53,010 --> 00:22:55,699
and teaching everybody to pump their brakes when they get into a slide,

526
00:22:56,760 --> 00:22:57,020
anti

527
00:22:57,140 --> 00:22:58,930
lock brakes will always work better than a human.

528
00:22:59,199 --> 00:23:00,489
II, I

529
00:23:00,699 --> 00:23:03,550
don't even remember. I remember learning about pump your brakes.

530
00:23:03,560 --> 00:23:04,310
But yeah, it's,

531
00:23:04,319 --> 00:23:06,140
I don't even think about it anymore because

532
00:23:06,150 --> 00:23:08,099
everything I know has anti lock brakes now.

533
00:23:08,109 --> 00:23:10,910
So who cares? Now? Now, here's the thing though.

534
00:23:11,089 --> 00:23:11,780
So

535
00:23:11,939 --> 00:23:14,500
we know people have terrible passwords,

536
00:23:14,510 --> 00:23:16,750
which means you need to account for that

537
00:23:16,760 --> 00:23:19,290
when you're architecting any sort of solutions.

538
00:23:19,300 --> 00:23:20,630
And I'm going to pick on,

539
00:23:21,000 --> 00:23:23,030
let's pick on email in this instance. Right.

540
00:23:23,380 --> 00:23:25,719
So you've got your emails and you know

541
00:23:25,810 --> 00:23:28,119
that some of your users have terrible passwords.

542
00:23:28,130 --> 00:23:28,439
Now,

543
00:23:28,449 --> 00:23:30,140
just to be clear you're talking about terrible passwords on

544
00:23:30,150 --> 00:23:32,469
their emails or terrible passwords on their like phone.

545
00:23:32,930 --> 00:23:33,709
Exactly.

546
00:23:34,010 --> 00:23:36,680
That's, this is exactly where I was going with that. Right.

547
00:23:36,930 --> 00:23:39,369
So you can protect the email system with,

548
00:23:39,410 --> 00:23:42,239
let's pick on Gmail in this case because it's easy to understand

549
00:23:42,479 --> 00:23:45,199
with Gmail. You have a pass, you have two factor authentication, right?

550
00:23:45,209 --> 00:23:48,219
User logs in with a password, then they have to type in the,

551
00:23:48,229 --> 00:23:50,369
the TOTP code or they plug in the UI

552
00:23:50,469 --> 00:23:54,900
key or whatever the Titan key and they push a button or now even your phone can

553
00:23:54,910 --> 00:23:58,540
do a little pop up thing that says is this you and you can say yes.

554
00:23:58,550 --> 00:24:02,540
Right. Like there we go. That's great. Now people will log in with their phone

555
00:24:02,650 --> 00:24:04,849
and they might have a password of all ones.

556
00:24:04,859 --> 00:24:06,979
So now someone who has that phone has

557
00:24:06,989 --> 00:24:09,750
the ability to potentially understand what's going on.

558
00:24:09,760 --> 00:24:11,939
But this is also one of those cases where

559
00:24:12,260 --> 00:24:15,719
all of the email is hosted somewhere else and you have

560
00:24:16,199 --> 00:24:19,219
an auditable view into what's happening there.

561
00:24:19,339 --> 00:24:21,489
And so this is a case of you can look at who's

562
00:24:21,500 --> 00:24:25,760
accessing what and how and when and if suddenly one of your users

563
00:24:26,069 --> 00:24:31,209
is we'll say, you know, downloading gigabytes of email. Why is that happening?

564
00:24:31,380 --> 00:24:36,010
-- Like let's talk about this
-- sort of, but I mean, modern email clients download,

565
00:24:36,020 --> 00:24:39,130
you know, kind of a lot of the email stored locally, blah, blah, blah,

566
00:24:39,479 --> 00:24:41,369
but no, definitely you can get behavior,

567
00:24:41,380 --> 00:24:43,569
you can get behavioral stuff based on the server.

568
00:24:43,579 --> 00:24:44,630
Right. Right.

569
00:24:44,640 --> 00:24:48,859
And if you're dealing with a group that, you know, is being actively explored

570
00:24:49,020 --> 00:24:52,630
by known adversaries. That's the kind of stuff you look out for. You look out for

571
00:24:52,750 --> 00:24:54,709
-- well,
-- actively targeted, I think would be a better phrase

572
00:24:55,189 --> 00:24:55,910
either way.

573
00:24:56,099 --> 00:24:58,609
Hopefully they're probably both true.

574
00:24:58,800 --> 00:25:03,050
But you know what I mean? Like this is one of those cases where you have to assume

575
00:25:03,290 --> 00:25:06,250
that the end user devices are corrupt and

576
00:25:06,500 --> 00:25:08,150
they're, they're essentially,

577
00:25:08,160 --> 00:25:11,650
they are the adversaries in a situation like this because

578
00:25:12,150 --> 00:25:14,010
man, I, like I said, I bet 20 per,

579
00:25:14,020 --> 00:25:19,849
20 or 30% of those Congress people have absolutely crap passwords on their phones.

580
00:25:19,859 --> 00:25:23,400
And so what does that mean? Right. And you can architect around that and plan for it.

581
00:25:23,709 --> 00:25:24,260
It's,

582
00:25:24,420 --> 00:25:26,689
I'm not saying it's easy like

583
00:25:27,140 --> 00:25:29,089
it's hard, but this is, I mean,

584
00:25:29,099 --> 00:25:30,680
this is part of the challenge of being a

585
00:25:30,689 --> 00:25:33,305
good security person is rather than telling people,

586
00:25:33,314 --> 00:25:34,415
oh, you need a good password.

587
00:25:34,425 --> 00:25:38,035
-- Well, that, that doesn't work. Right. Let's just pretend that we
-- tried for 50 years

588
00:25:38,224 --> 00:25:38,834
and

589
00:25:38,994 --> 00:25:40,224
-- it didn't work
-- like

590
00:25:40,635 --> 00:25:42,185
we straight up, tried for 50 years and

591
00:25:42,564 --> 00:25:42,584
we

592
00:25:42,694 --> 00:25:44,984
-- are.
-- Right. Exactly. Exactly. And like

593
00:25:45,474 --> 00:25:47,895
I was in, I was in a meeting the other day where they were,

594
00:25:47,905 --> 00:25:50,574
someone was going on and on about training people to be more secure.

595
00:25:50,584 --> 00:25:51,714
And I'm like, you know,

596
00:25:52,030 --> 00:25:56,319
I would love to stand up and just start going nuts on this person, but it's like,

597
00:25:56,329 --> 00:25:59,849
you know what it's not worth my time, I'm just going to let them talk and whatever,

598
00:25:59,859 --> 00:26:01,050
whatever doesn't matter.

599
00:26:01,270 --> 00:26:03,869
But it's the same deal. Right. Like you can't train people to be more secure.

600
00:26:03,880 --> 00:26:06,650
-- People are people, they're going to do what they do.
-- I suspect you.

601
00:26:06,660 --> 00:26:11,469
-- The thing I think more is that the return on investment for that is so low as to be,
-- it's

602
00:26:11,880 --> 00:26:12,810
negative.

603
00:26:13,810 --> 00:26:17,280
Well, once you count in productivity lost. Yeah,

604
00:26:17,699 --> 00:26:18,510
it is. Right.

605
00:26:18,520 --> 00:26:19,920
Well, not only that, most,

606
00:26:19,930 --> 00:26:23,800
a lot of people will misconstrue what they've learned and they will

607
00:26:23,810 --> 00:26:28,369
probably make more mistakes or take up more of someone else's time

608
00:26:28,619 --> 00:26:31,040
-- than they would have in the first place. Well, or
-- worse.

609
00:26:31,050 --> 00:26:34,089
They, you teach them something and then they refuse to forget it like that whole n

610
00:26:34,339 --> 00:26:35,540
guidance on rotating path.

611
00:26:36,729 --> 00:26:38,209
Now we're never going to kill

612
00:26:38,619 --> 00:26:41,099
even though Nist is publicly recanted.

613
00:26:41,109 --> 00:26:46,180
-- And everybody,
-- I still argue about this with people who say

614
00:26:46,329 --> 00:26:49,089
they, they, they believe Nist

615
00:26:49,229 --> 00:26:50,560
was right the first time.

616
00:26:50,569 --> 00:26:55,979
And it's like if you can give me even bad evidence of this, I will agree with you.

617
00:26:55,989 --> 00:26:56,660
And they of course,

618
00:26:56,670 --> 00:26:59,239
have zero evidence of any sort because there is

619
00:26:59,250 --> 00:27:01,319
no evidence because when they actually did the research,

620
00:27:01,329 --> 00:27:03,160
they found out this is a terrible idea.

621
00:27:03,540 --> 00:27:06,339
Who knew anyway. Anyway, we've been,

622
00:27:06,770 --> 00:27:09,000
we've been rambling on and on about this and,

623
00:27:09,410 --> 00:27:14,280
but, but for real, I feel like there's, there's two sides to this coin and I know we,

624
00:27:14,290 --> 00:27:16,479
we, we've beat around the bush a lot and we, we've gone here and there.

625
00:27:16,489 --> 00:27:17,680
But I mean, fundamentally

626
00:27:17,939 --> 00:27:21,810
you can have bad leadership is bad leadership, right? You can't fix it,

627
00:27:21,930 --> 00:27:22,729
don't try.

628
00:27:22,829 --> 00:27:25,250
And I think this is another important thing actually that

629
00:27:25,260 --> 00:27:27,709
I see with security people on a regular basis is

630
00:27:27,989 --> 00:27:29,520
we see bad leadership

631
00:27:29,930 --> 00:27:31,540
and we feel like we can fix it.

632
00:27:31,550 --> 00:27:34,430
We're just, we're not, our message is wrong or we have to try harder.

633
00:27:34,439 --> 00:27:37,949
We should push more. We should do. No. Look, sometimes your leadership just sucks.

634
00:27:37,959 --> 00:27:41,550
Like, get out. That's the, that's the only way to fix that. You will never fix

635
00:27:41,670 --> 00:27:43,780
bad leadership. It is the reality of it.

636
00:27:43,790 --> 00:27:48,550
Well, I think one addendum to this is, is a lot of security people would benefit from

637
00:27:48,760 --> 00:27:49,930
learning how to get,

638
00:27:50,189 --> 00:27:53,150
how to sell to senior management. Yes. I mean,

639
00:27:53,270 --> 00:27:53,770
right. If you can

640
00:27:53,920 --> 00:27:55,709
a compelling argument and sell to them,

641
00:27:55,829 --> 00:27:57,689
you're going to have a much easier time regardless.

642
00:27:57,699 --> 00:28:00,969
-- I mean,
-- I'll agree with that and that's kind of a topic for another day.

643
00:28:01,219 --> 00:28:02,380
But, I mean,

644
00:28:02,390 --> 00:28:06,359
sometimes leadership is just bad and toxic and there's

645
00:28:06,369 --> 00:28:08,219
nothing you can do about it except in,

646
00:28:08,229 --> 00:28:12,739
in the, in the case of industry, go find a new job in the case of your government, like,

647
00:28:12,750 --> 00:28:14,780
you know, boots on the ground, get out there and,

648
00:28:14,790 --> 00:28:17,780
and find someone you can believe in and support them any way you,

649
00:28:18,229 --> 00:28:19,569
because that's how it works.

650
00:28:19,579 --> 00:28:22,510
But anyway, anyway, we've, we've gone on and on about this.

651
00:28:22,520 --> 00:28:25,719
But then the other side of this story as well is

652
00:28:25,900 --> 00:28:28,939
when you're architecting security solutions,

653
00:28:29,020 --> 00:28:33,540
you should do your best to assume the reality of the situation.

654
00:28:33,550 --> 00:28:37,000
And assuming everyone has an Impenetrable cell phone is ridiculous.

655
00:28:37,010 --> 00:28:40,109
A significant number of your people have terrible passwords.

656
00:28:40,229 --> 00:28:41,770
You know what the good news though is,

657
00:28:42,280 --> 00:28:46,359
is that from what I've seen, at least of Apple and the higher end android makers

658
00:28:46,489 --> 00:28:49,680
-- they're shooting for that target. They are.
-- And I appreciate that.

659
00:28:49,900 --> 00:28:53,900
Right. They are actively, you know, security co-processors, security enclaves,

660
00:28:54,119 --> 00:28:57,439
the biometrics based stuff, you know, I like, for example,

661
00:28:57,449 --> 00:29:01,300
I sort of disagree and agree with Google's whole, the new face unlock thing on the,

662
00:29:01,390 --> 00:29:01,859
what is it?

663
00:29:01,869 --> 00:29:02,530
The Android,

664
00:29:03,670 --> 00:29:06,030
whatever. Google's new. Yeah, their new flagship phone.

665
00:29:06,239 --> 00:29:07,689
It still works with your eyes closed.

666
00:29:07,699 --> 00:29:09,979
Like if you're sleeping I can just hold your phone over your face and

667
00:29:10,199 --> 00:29:11,180
it wakes up

668
00:29:11,520 --> 00:29:12,380
well, and I mean,

669
00:29:12,390 --> 00:29:14,689
we've had documented cases where somebody's been sleeping and

670
00:29:14,699 --> 00:29:16,300
somebody used their finger to unlock their phone,

671
00:29:16,589 --> 00:29:17,020
you know.

672
00:29:17,750 --> 00:29:21,300
So, on the one hand, you know, I can sort of see where Google's coming from that.

673
00:29:21,310 --> 00:29:24,410
It's not a security vulnerability, but on the flip side, I love that. They said

674
00:29:24,609 --> 00:29:27,640
-- they're going to work on fixing it.
-- Well, of course, it's a security vulnerability.

675
00:29:27,650 --> 00:29:30,010
They're just, this is potato, potato nonsense.

676
00:29:30,150 --> 00:29:32,650
Yeah. But, uh, but they're actually working on fixing it.

677
00:29:32,660 --> 00:29:33,780
Which is more what I care about,

678
00:29:33,930 --> 00:29:34,260
you know?

679
00:29:34,270 --> 00:29:37,150
And I, I just think it's, I'm kind of wondering, you know,

680
00:29:37,160 --> 00:29:40,020
another five years of this and we might

681
00:29:40,030 --> 00:29:42,739
have Impenetrable phones or something close to it.

682
00:29:42,750 --> 00:29:45,290
Maybe. I mean, I'm not going to hold my breath, but

683
00:29:45,760 --> 00:29:47,119
-- that's good. I think
-- you would agree.

684
00:29:47,599 --> 00:29:48,250
Got a lot better than

685
00:29:48,599 --> 00:29:50,420
they're way better and they're getting better and they're

686
00:29:50,430 --> 00:29:52,359
going to keep getting better and that's good because

687
00:29:52,369 --> 00:29:54,780
these are people that are looking at actual problems

688
00:29:54,790 --> 00:29:57,530
and they're coming up with actual solutions versus the,

689
00:29:57,540 --> 00:30:00,479
I guess historical security precedent of just making

690
00:30:00,719 --> 00:30:02,650
up solutions for problems that don't really

691
00:30:02,660 --> 00:30:04,560
exist and your solutions don't work anyway.

692
00:30:04,569 --> 00:30:07,050
So, like, you're just making everything worse for everybody

693
00:30:07,189 --> 00:30:10,010
anyway. That, that, that's the point I've been guilty of that.

694
00:30:10,219 --> 00:30:13,290
Everyone is we're all guilty of it. If you say you're not, you're lying.

695
00:30:13,300 --> 00:30:16,920
It is easy to fall into that trap. And so, but, but for real,

696
00:30:17,300 --> 00:30:19,180
that, that's kind of all right.

697
00:30:19,189 --> 00:30:22,780
This has been a weird mishmash of, of, I guess, topics in that regard of,

698
00:30:22,790 --> 00:30:23,640
of both ends of it.

699
00:30:23,650 --> 00:30:24,869
But I mean, yeah, it's

700
00:30:25,709 --> 00:30:26,890
all in all.

701
00:30:27,089 --> 00:30:29,819
I would sum all this up as people are gonna

702
00:30:29,829 --> 00:30:32,599
be people and that's just kind of where we land.

703
00:30:34,349 --> 00:30:35,250
Ok.

704
00:30:36,099 --> 00:30:37,989
No, I mean, I just, yeah, I,

705
00:30:38,000 --> 00:30:41,099
-- we still can't teach everybody to use their turn signals
-- and

706
00:30:41,109 --> 00:30:43,920
the solution to that is not to let people drive.

707
00:30:43,930 --> 00:30:46,739
Right. Self driving cars will always use a turn signal

708
00:30:46,930 --> 00:30:49,910
just like maybe, maybe we should build computers to run the government.

709
00:30:49,920 --> 00:30:53,020
That sounds wonderful. Right. What could possibly go wrong?

710
00:30:53,030 --> 00:30:54,250
I think there are some movies about that

711
00:30:56,459 --> 00:30:58,319
anyway, I'm calling it.

712
00:30:58,599 --> 00:31:00,719
All right. Well, thank you, Kurt. Thank you for listening.

713
00:31:00,729 --> 00:31:02,939
You can go to Overs Source Beauty podcast.com. Hit up the show

714
00:31:03,040 --> 00:31:05,589
not to Z Pound Os S podcast. Hashtag to hit us

715
00:31:06,000 --> 00:31:07,050
on social media.

716
00:31:07,229 --> 00:31:09,400
Kurt. Have a fantastic rest of your day.

717
00:31:09,550 --> 00:31:11,839
-- You too. Thanks
-- everybody. Thanks everyone. Bye bye.