0
00:00:05,329 --> 00:00:07,800
Hello and welcome to episode 97 of the Yoga

1
00:00:07,909 --> 00:00:09,770
Source Security podcast with myself,

2
00:00:09,779 --> 00:00:11,939
Kurt Siefried and my partner in Thought Crime, Josh Reser.

3
00:00:12,829 --> 00:00:13,350
All right.

4
00:00:13,359 --> 00:00:17,510
So we were talking before the show and we decided that the,

5
00:00:17,520 --> 00:00:19,389
the title is going to be Automation.

6
00:00:19,399 --> 00:00:21,149
Humans Are Slow and Dumb.

7
00:00:21,530 --> 00:00:22,940
And, and that made my day.

8
00:00:24,149 --> 00:00:26,250
Well, it's provably true in most cases.

9
00:00:29,069 --> 00:00:30,690
It probably is.

10
00:00:31,659 --> 00:00:32,520
Uh,

11
00:00:32,668 --> 00:00:33,330
so. Ok.

12
00:00:33,340 --> 00:00:36,310
Well, yeah, why don't we explain to viewers what we're actually talking about?

13
00:00:36,930 --> 00:00:37,799
Well, it's, it's

14
00:00:38,020 --> 00:00:41,279
the topic is your idea. So, I'm gonna let you take this one.

15
00:00:42,049 --> 00:00:43,560
So, um,

16
00:00:43,970 --> 00:00:47,830
basically what I've noticed is there's been

17
00:00:48,159 --> 00:00:48,169
a,

18
00:00:49,119 --> 00:00:51,500
we're entering an era where there's

19
00:00:51,630 --> 00:00:53,979
a lot more automation

20
00:00:55,110 --> 00:00:59,340
of things that in past were not automated, like driving cars because

21
00:00:59,669 --> 00:01:02,409
it's, you know, quite, actually, quite difficult to do that.

22
00:01:02,909 --> 00:01:07,120
And so, you know, it's one thing to automate an airplane that cost over $100 million.

23
00:01:07,129 --> 00:01:07,260
Right.

24
00:01:07,269 --> 00:01:11,150
Because then you can, you can spend a bit of money on that and more to the point planes,

25
00:01:11,559 --> 00:01:13,800
you know, they don't have to dodge stuff constantly,

26
00:01:14,339 --> 00:01:16,089
maybe a goose or two. Right.

27
00:01:16,269 --> 00:01:18,779
Well, it's, you know, even then Yeah,

28
00:01:18,790 --> 00:01:21,169
even then you don't really dodge it so much as try

29
00:01:21,180 --> 00:01:22,790
not to fall out of the sky when you hit it.

30
00:01:23,360 --> 00:01:27,239
And, and what really piqued my interest was, you know, this whole thing with the,

31
00:01:27,250 --> 00:01:29,730
the Tesla self, they call it self driving

32
00:01:29,879 --> 00:01:31,849
and these things are killing people.

33
00:01:32,449 --> 00:01:36,459
Tesla do they? Is it technically self driving or what do they call it autopilot?

34
00:01:36,470 --> 00:01:36,889
Right.

35
00:01:37,559 --> 00:01:41,230
And it's like human assisted or some crap like that because like the human

36
00:01:41,239 --> 00:01:44,370
is supposed to have their hands on the wheel according to what I've read,

37
00:01:44,800 --> 00:01:46,860
which of course I'm sure nobody does.

38
00:01:47,250 --> 00:01:49,019
Uh, they call it

39
00:01:49,580 --> 00:01:52,620
all Tesla vehicles produced in our factory, including model three,

40
00:01:52,629 --> 00:01:56,459
have the hardware needed for full self driving capability at a safety level,

41
00:01:56,660 --> 00:02:00,620
substantially greater than that of a human driver that is from tesla.com.

42
00:02:01,150 --> 00:02:02,819
So, yeah, they call it self driving.

43
00:02:03,120 --> 00:02:04,339
Ok. Well, that's cool.

44
00:02:04,440 --> 00:02:05,379
Let's be clear.

45
00:02:05,839 --> 00:02:10,470
Statistically on average is even a not great self driving car

46
00:02:10,479 --> 00:02:12,699
probably going to be better than your average human driver.

47
00:02:12,710 --> 00:02:14,860
And the answer is probably, yes.

48
00:02:15,179 --> 00:02:17,160
Right. Humans are pretty terrible at this stuff.

49
00:02:17,169 --> 00:02:21,649
Seriously, man, humans are awful drivers and as a human driver,

50
00:02:21,660 --> 00:02:23,419
I will totally back this up.

51
00:02:23,449 --> 00:02:23,820
Yeah,

52
00:02:23,949 --> 00:02:25,139
but the problem is,

53
00:02:25,589 --> 00:02:26,250
um,

54
00:02:26,750 --> 00:02:30,660
ok. Well, obviously self Tesla self driving is not

55
00:02:31,229 --> 00:02:34,220
perfect and, and quite far from it, right, because for example,

56
00:02:34,229 --> 00:02:36,410
it slammed into the back of a fire engine and,

57
00:02:36,820 --> 00:02:37,210
um,

58
00:02:37,220 --> 00:02:39,919
there was that lane change thing with a barrier

59
00:02:39,929 --> 00:02:42,009
ahead that a guy got slammed into and died

60
00:02:42,770 --> 00:02:43,270
and,

61
00:02:44,250 --> 00:02:47,529
you know, so Tesla's take on this and some people's take on this is, oh, well,

62
00:02:47,539 --> 00:02:47,669
you know,

63
00:02:47,679 --> 00:02:50,869
the human should have spotted that a problem was occurring and intervened and,

64
00:02:50,880 --> 00:02:52,029
you know, saved the day.

65
00:02:53,139 --> 00:02:54,339
And the problem is

66
00:02:54,949 --> 00:02:58,080
that's basically impossible even at the best of times.

67
00:02:58,089 --> 00:03:01,919
And here we have a situation where we've told the human, hey, chill out,

68
00:03:02,850 --> 00:03:04,589
the car is gonna take care of this.

69
00:03:05,389 --> 00:03:10,610
So now you see when you're driving, you're responsible for the vehicle and you know,

70
00:03:10,619 --> 00:03:11,229
this, so you're,

71
00:03:11,240 --> 00:03:14,419
you're kind of looking for problems and you're kind of ready to intervene, you know,

72
00:03:14,429 --> 00:03:17,250
somebody swerves in front of you, you swerve out of their way, whatever, right?

73
00:03:19,070 --> 00:03:25,130
-- I mean, that's the idea. But I think
-- um a good analogy is if you're a passenger in a car

74
00:03:25,550 --> 00:03:29,279
under what circumstances do you lean over, grab the wheel and reef it over?

75
00:03:32,009 --> 00:03:34,000
I've never had to do that.

76
00:03:34,250 --> 00:03:34,839
And

77
00:03:35,190 --> 00:03:35,889
have you ever had

78
00:03:36,289 --> 00:03:37,460
a terrifies me?

79
00:03:40,210 --> 00:03:40,440
Have you

80
00:03:40,600 --> 00:03:40,929
done this

81
00:03:41,070 --> 00:03:41,199
to

82
00:03:41,369 --> 00:03:41,839
somebody?

83
00:03:41,979 --> 00:03:42,520
No, I have not.

84
00:03:43,649 --> 00:03:44,229
Um

85
00:03:44,960 --> 00:03:48,380
And so, and that's essentially the analogy here is that, you know,

86
00:03:48,679 --> 00:03:51,800
when you're in a self driving car that is in self-driving mode, you're,

87
00:03:51,809 --> 00:03:53,399
you're effectively a passenger

88
00:03:54,009 --> 00:03:56,869
and for you to deal with the problem part of the

89
00:03:56,880 --> 00:03:59,240
problem is you first have to realize that there's a problem.

90
00:03:59,250 --> 00:04:02,250
Secondly, you have to then realize that the car is not dealing with it

91
00:04:02,740 --> 00:04:05,080
because that's literally the car's job at

92
00:04:05,380 --> 00:04:06,979
this point. Right. It's self driving.

93
00:04:07,240 --> 00:04:07,830
Right.

94
00:04:08,179 --> 00:04:10,550
And so I think fundamentally, I, I,

95
00:04:10,559 --> 00:04:12,309
because I've been looking at this self driving car

96
00:04:12,320 --> 00:04:13,559
thing and I've been toying with the idea of,

97
00:04:13,570 --> 00:04:14,149
you know, do I,

98
00:04:14,759 --> 00:04:15,679
do I go with a,

99
00:04:15,690 --> 00:04:20,428
a car that has some self driving features or do I wait for like the car with a button?

100
00:04:21,850 --> 00:04:24,010
You know, and, and an app to tell it where to go.

101
00:04:24,019 --> 00:04:28,190
I'm, I'm gonna run my current car into the ground with hopes.

102
00:04:28,200 --> 00:04:31,630
By the time it stops running, I can get a real self driving car.

103
00:04:31,799 --> 00:04:34,559
That's, that's my goal. I'm kind of really on the dice on this one. Yeah.

104
00:04:34,579 --> 00:04:37,510
-- And,
-- and I would agree because from the research I've done now,

105
00:04:39,279 --> 00:04:42,500
if the car is not 100% autonomous self driving,

106
00:04:43,320 --> 00:04:46,579
then as the human being, you, you, you actually,

107
00:04:46,589 --> 00:04:49,540
in some ways need to be more alert and more vigilant

108
00:04:50,420 --> 00:04:53,450
than if you're just driving the damn thing yourself. Because

109
00:04:53,670 --> 00:04:55,809
like I said, you have to not only spot that there's a problem,

110
00:04:55,820 --> 00:04:58,799
but you have to spot that the car is not going to deal with the problem,

111
00:05:00,779 --> 00:05:01,209
right?

112
00:05:01,220 --> 00:05:05,220
-- So that's like two levels of, of reaction and decision making instead of one
-- is,

113
00:05:05,230 --> 00:05:06,869
is that the intent of those?

114
00:05:06,880 --> 00:05:07,899
I mean, so I

115
00:05:08,130 --> 00:05:08,839
think the intent of

116
00:05:09,459 --> 00:05:11,970
this statistically, it's better than people.

117
00:05:12,399 --> 00:05:16,140
It's those corner cases where it will feel worse than a person.

118
00:05:16,149 --> 00:05:17,929
But ideally those corner cases happen

119
00:05:18,350 --> 00:05:19,730
less and less often,

120
00:05:21,619 --> 00:05:22,839
right? I mean,

121
00:05:23,019 --> 00:05:23,559
ok,

122
00:05:24,290 --> 00:05:24,989
maybe

123
00:05:25,299 --> 00:05:31,679
I, I feel like most of the the human augmentation technology I've seen

124
00:05:32,700 --> 00:05:32,799
really

125
00:05:32,989 --> 00:05:33,709
-- about
-- like

126
00:05:33,940 --> 00:05:33,970
this

127
00:05:34,089 --> 00:05:34,109
is

128
00:05:34,380 --> 00:05:34,809
-- self
-- driving.

129
00:05:36,209 --> 00:05:38,540
Some of it is, I mean, like, let me give you an example.

130
00:05:38,549 --> 00:05:41,350
There's the, the things that will stop your car if you,

131
00:05:41,359 --> 00:05:44,230
if you don't stop right where there's something in front of you

132
00:05:44,519 --> 00:05:45,109
and let's face it.

133
00:05:45,119 --> 00:05:48,059
We've all done this where we look at our phone, we look at the radio, we look at,

134
00:05:48,070 --> 00:05:52,230
you know, like the, the weird cat off the side of the road, whatever.

135
00:05:52,720 --> 00:05:56,369
And all of a sudden you look up and the guy in front of you stopped or there's

136
00:05:56,570 --> 00:05:58,799
-- a tree there, whatever. Right? And,
-- and

137
00:05:59,410 --> 00:06:00,649
that sort of technology,

138
00:06:01,570 --> 00:06:04,369
right. As opposed to do you wait for the car to deal with it

139
00:06:04,950 --> 00:06:05,790
by definition,

140
00:06:06,260 --> 00:06:06,290
deal

141
00:06:06,579 --> 00:06:07,630
-- with it. Right. No,
-- no, no.

142
00:06:07,640 --> 00:06:08,309
What I mean is,

143
00:06:08,320 --> 00:06:10,859
is you're in a self driving car and the car is in self driving

144
00:06:10,869 --> 00:06:13,790
mode and you look up and you see there's a large stationary object,

145
00:06:13,799 --> 00:06:15,149
say 200 m away from you.

146
00:06:16,320 --> 00:06:18,859
What do you do? Do you trust that the car will swerve around it

147
00:06:19,119 --> 00:06:19,980
or do you do it?

148
00:06:21,130 --> 00:06:23,859
I don't know the answer to that.

149
00:06:24,440 --> 00:06:26,250
I've never been in it.

150
00:06:28,410 --> 00:06:28,679
Right.

151
00:06:28,690 --> 00:06:29,820
And the answer is, well,

152
00:06:29,829 --> 00:06:32,609
apparently Teslas end up running into a fire truck

153
00:06:32,619 --> 00:06:34,760
at highway speeds when the fire truck is stopped.

154
00:06:35,059 --> 00:06:36,750
-- Uh, that,
-- that did happen, didn't it?

155
00:06:37,250 --> 00:06:39,029
Do you think the person could have

156
00:06:39,140 --> 00:06:39,859
helped it

157
00:06:40,089 --> 00:06:42,480
-- if
-- they'd spotted it soon enough and

158
00:06:42,739 --> 00:06:44,119
not trusted their car?

159
00:06:44,130 --> 00:06:47,230
Because the other prompt too is, you know, in theory with a self driving car,

160
00:06:47,239 --> 00:06:49,600
it should be able to avoid an obstacle by very little.

161
00:06:49,609 --> 00:06:49,859
Right.

162
00:06:49,869 --> 00:06:53,799
So, you know, it's, it's a lot less dangerous to swerve a little than to swerve a lot,

163
00:06:53,809 --> 00:06:54,029
right?

164
00:06:54,040 --> 00:06:56,440
You swerve too much, you might lose control of the car and roll it.

165
00:06:56,940 --> 00:06:57,760
You know. So

166
00:06:57,910 --> 00:06:59,720
in a, in a theoretically perfect world, you know,

167
00:06:59,730 --> 00:07:02,200
it's gonna swerve around the child and miss them by one inch,

168
00:07:02,750 --> 00:07:05,010
right? And scare the bejesus out of that poor kid,

169
00:07:05,209 --> 00:07:05,809
right? In an

170
00:07:06,269 --> 00:07:07,500
imperfect world, right?

171
00:07:07,510 --> 00:07:07,720
You,

172
00:07:07,730 --> 00:07:09,859
you stand on the brakes and swerve and you end up

173
00:07:09,869 --> 00:07:13,279
like rolling the car and rolling over the kid or something horrible

174
00:07:14,119 --> 00:07:15,989
and, and that would be bad. See,

175
00:07:16,230 --> 00:07:19,820
so that's, that's why I'm, you know, because here's the thing,

176
00:07:20,269 --> 00:07:22,649
this is essentially history repeating itself.

177
00:07:22,660 --> 00:07:25,230
Uh And as I mentioned before, you know, um airline

178
00:07:25,369 --> 00:07:26,899
autopilots and automation,

179
00:07:27,070 --> 00:07:30,019
this whole scenario effectively happened with Airbus back

180
00:07:30,029 --> 00:07:31,649
in the day when Airbus introduced the flight,

181
00:07:31,660 --> 00:07:33,170
not only the fly by wire,

182
00:07:33,519 --> 00:07:34,420
but the,

183
00:07:34,730 --> 00:07:36,459
the automation aspect of it and you know,

184
00:07:36,470 --> 00:07:39,940
the joke at the time was uh Airbus planes will come with, you know, a dog

185
00:07:40,140 --> 00:07:43,420
and the dog's job is to prevent, you know, a person from touching the controls.

186
00:07:45,119 --> 00:07:47,079
And, um, so there were cases,

187
00:07:47,350 --> 00:07:49,200
there were cases where, you know,

188
00:07:49,369 --> 00:07:55,179
an Airbus plane got itself into a situation that was completely recoverable.

189
00:07:55,799 --> 00:07:58,660
But because the human thought the computer was going to handle it,

190
00:07:59,630 --> 00:08:01,630
it, it became unrecoverable.

191
00:08:01,809 --> 00:08:02,779
Right. The, um,

192
00:08:03,140 --> 00:08:06,529
the, the one being that slow speed pass where they just

193
00:08:06,670 --> 00:08:09,260
gently descended into the forest and, you know, at

194
00:08:09,869 --> 00:08:11,850
the Paris, was it the Paris Air Show?

195
00:08:12,769 --> 00:08:15,339
I don't know, you pay more attention to this stuff than I do.

196
00:08:15,480 --> 00:08:16,029
Um,

197
00:08:16,720 --> 00:08:19,250
so, ok, so here's,

198
00:08:20,269 --> 00:08:23,850
I'm gonna, I'm gonna unpack a bunch of this here. So

199
00:08:24,589 --> 00:08:28,890
I, I feel like there are a couple of important topics

200
00:08:29,239 --> 00:08:32,289
encased in this conversation there. There's, first of all, the fact that

201
00:08:33,129 --> 00:08:34,638
a, a good

202
00:08:34,979 --> 00:08:36,328
automated system

203
00:08:36,448 --> 00:08:39,217
can outperform a human under most circumstances,

204
00:08:40,359 --> 00:08:41,658
-- there are
-- always going.

205
00:08:42,068 --> 00:08:44,129
Right. Exactly. That's, that's fair.

206
00:08:44,138 --> 00:08:45,968
There are always going to be corner cases where

207
00:08:45,979 --> 00:08:50,218
the automated system may fail or something could happen.

208
00:08:50,229 --> 00:08:50,648
And

209
00:08:51,510 --> 00:08:56,099
today we kind of have the attitude of the human should take over and fix

210
00:08:57,010 --> 00:08:59,280
my comment on that corner case. I think part of the problem here

211
00:08:59,460 --> 00:09:00,140
is that

212
00:09:00,559 --> 00:09:03,539
even statistically if the self driving car is better than a human,

213
00:09:04,140 --> 00:09:06,679
if the corner cases where it fails are ones where

214
00:09:06,690 --> 00:09:09,119
human beings feel like they could have handled it,

215
00:09:09,130 --> 00:09:12,659
then the perception will be probably that the self driving system is worse

216
00:09:13,000 --> 00:09:17,359
because, you know, oh, every 10 million car trips, it makes a mistake.

217
00:09:17,369 --> 00:09:18,840
Even a toddler could have spotted.

218
00:09:19,710 --> 00:09:24,330
And, and I, I think this is where statistics become important and this is where

219
00:09:24,460 --> 00:09:30,250
I, I want to take the conversation kind of to uh up up a level about automation is

220
00:09:30,809 --> 00:09:34,130
there's always going to be corner cases and it's always going to be easy to say

221
00:09:34,260 --> 00:09:35,710
a human could have done better.

222
00:09:35,859 --> 00:09:38,429
But it's quite likely that most of these corner

223
00:09:38,440 --> 00:09:41,140
cases represent a small percentage and given the,

224
00:09:41,150 --> 00:09:44,109
the human error rate being astronomical,

225
00:09:44,640 --> 00:09:47,190
that if you, if you kind of compare the two

226
00:09:47,520 --> 00:09:49,190
in terms of overall safety,

227
00:09:49,590 --> 00:09:51,309
the automation is going to win

228
00:09:51,679 --> 00:09:52,270
every time.

229
00:09:52,580 --> 00:09:52,599
The

230
00:09:52,739 --> 00:09:52,809
problem

231
00:09:52,940 --> 00:09:55,520
-- is in this one,
-- I think with the way we're doing automation,

232
00:09:55,530 --> 00:09:57,809
especially with neural networks, there's no sort of

233
00:09:58,179 --> 00:10:00,219
the neural network is confident in what it's doing.

234
00:10:00,229 --> 00:10:02,580
It can't really signal that it's failing

235
00:10:02,590 --> 00:10:04,320
because it doesn't think it's failing ever.

236
00:10:04,500 --> 00:10:05,919
That's the whole point of it. Right.

237
00:10:06,340 --> 00:10:08,640
Right. They, they never know they're failing. Exactly.

238
00:10:08,940 --> 00:10:10,719
And, and this is where,

239
00:10:11,130 --> 00:10:15,679
where I wanted to go in the context of security especially is

240
00:10:16,150 --> 00:10:20,729
these days when you talk about security and artificial intelligence,

241
00:10:20,739 --> 00:10:22,799
machine learning automation, things like that.

242
00:10:23,260 --> 00:10:26,250
There's still very much the attitude of let the A

243
00:10:26,260 --> 00:10:29,239
I tell the human when something weird is going on

244
00:10:29,820 --> 00:10:30,419
and

245
00:10:30,719 --> 00:10:34,599
you still get an astronomical number of alerts when something like that happens.

246
00:10:35,169 --> 00:10:37,119
And, and I feel like we're,

247
00:10:37,130 --> 00:10:41,179
we're kind of reaching a point where we need to start putting serious thought into

248
00:10:41,489 --> 00:10:45,039
what is our autopilot look like and how can we trust it because it's going

249
00:10:45,049 --> 00:10:50,960
to catch 95% of the actual cases and the 5% that are corner cases.

250
00:10:51,409 --> 00:10:53,750
Those are the ones the humans should be dealing with

251
00:10:54,080 --> 00:10:57,039
as one off, not the, not the 95

252
00:10:57,309 --> 00:10:57,619
percent.

253
00:10:57,859 --> 00:11:01,469
Those are the ones where it should be in a learning opportunity much like,

254
00:11:01,479 --> 00:11:03,309
you know how the airline industry has become

255
00:11:03,969 --> 00:11:08,030
much safer because in theory, every time there's a crash or an incident,

256
00:11:08,039 --> 00:11:11,010
it's investigated, recommendations are made hopefully followed

257
00:11:11,400 --> 00:11:12,710
and we solve that problem,

258
00:11:13,190 --> 00:11:17,039
you know, be it mechanical or operational or some process

259
00:11:17,210 --> 00:11:18,309
or in some cases, you know, it's,

260
00:11:18,320 --> 00:11:20,299
it's like microburst and it's a completely new

261
00:11:20,309 --> 00:11:22,409
set of radar technology and computers and some,

262
00:11:22,599 --> 00:11:23,750
you know, some pretty amazing

263
00:11:23,890 --> 00:11:26,510
and cool technology and process happens to,

264
00:11:26,710 --> 00:11:27,750
yeah, we solve the problem,

265
00:11:28,429 --> 00:11:30,530
-- you know, like, and,
-- and insecurity.

266
00:11:30,539 --> 00:11:34,500
How many times do we do a proper triage of the incident and say

267
00:11:34,510 --> 00:11:37,669
these are the things we should do to make sure this never happens again.

268
00:11:38,250 --> 00:11:38,460
Well,

269
00:11:38,469 --> 00:11:40,140
I think one of the challenges in security is

270
00:11:40,150 --> 00:11:42,359
the majority of incidents are very low level.

271
00:11:42,369 --> 00:11:42,739
Like

272
00:11:43,159 --> 00:11:45,719
uh spam is a great example. How do we solve spam?

273
00:11:45,729 --> 00:11:48,909
Well, we don't, we just statistically try and squish it down so that, you know,

274
00:11:48,919 --> 00:11:50,080
you only get one or two spams.

275
00:11:50,090 --> 00:11:50,409
A day.

276
00:11:50,780 --> 00:11:53,799
-- I, I don't even get that anymore.
-- I still get one.

277
00:11:53,809 --> 00:11:56,650
I, I, it's so weird to me that Google still lets through these.

278
00:11:56,659 --> 00:11:58,849
Would you like to buy a list of blank,

279
00:11:58,969 --> 00:11:59,919
you know, whatever

280
00:12:00,320 --> 00:12:00,539
sap,

281
00:12:01,400 --> 00:12:03,039
whatever technology

282
00:12:03,340 --> 00:12:04,280
users. And it's,

283
00:12:04,650 --> 00:12:04,679
of

284
00:12:04,820 --> 00:12:05,219
course not

285
00:12:05,390 --> 00:12:06,640
one of those in a while.

286
00:12:06,890 --> 00:12:11,750
It's, I used to get them at least two or three a day and I haven't gotten one in a long,

287
00:12:11,760 --> 00:12:14,750
I get about one or two a week and it's just, I don't understand because they're, yeah,

288
00:12:14,760 --> 00:12:16,320
anyways back to the point is

289
00:12:16,969 --> 00:12:21,659
the majority of quote, it's like every time some government or a company says, oh,

290
00:12:21,669 --> 00:12:24,380
we get attacked a million times online every day.

291
00:12:24,700 --> 00:12:28,440
Well, yeah, somebody port scans you and definitely somebody is running like,

292
00:12:28,559 --> 00:12:29,400
you know, some,

293
00:12:29,640 --> 00:12:31,239
like burp suite or,

294
00:12:31,539 --> 00:12:32,760
you know, um,

295
00:12:33,309 --> 00:12:36,280
whatever automated attack suite they are using. Yeah.

296
00:12:36,289 --> 00:12:37,960
Oo, obviously they're doing that

297
00:12:38,099 --> 00:12:40,400
against. Well, probably the whole internet basically.

298
00:12:41,049 --> 00:12:43,380
Does that really count as an attack attack?

299
00:12:43,650 --> 00:12:44,479
You know, it's like,

300
00:12:44,849 --> 00:12:45,489
um,

301
00:12:45,719 --> 00:12:45,950
oh,

302
00:12:45,960 --> 00:12:48,349
apparently in this neighborhood of a few years ago

303
00:12:48,359 --> 00:12:50,229
it was popular among the young kids to,

304
00:12:50,239 --> 00:12:50,250
uh,

305
00:12:50,260 --> 00:12:52,710
from a different neighborhood to come here on their BMX bikes and

306
00:12:52,719 --> 00:12:55,030
try the door handles on cars and if it was unlocked,

307
00:12:55,039 --> 00:12:55,390
you know,

308
00:12:55,520 --> 00:12:57,380
swipe whatever they could from the car.

309
00:12:57,700 --> 00:12:58,780
Now, that is crime,

310
00:12:59,270 --> 00:13:01,710
you know, that's crime. But is that like an attack?

311
00:13:01,719 --> 00:13:02,450
Is that like, no,

312
00:13:02,460 --> 00:13:06,119
it's like people left their car doors open and people took stuff out of their cars.

313
00:13:06,479 --> 00:13:07,250
You know, I, I

314
00:13:07,520 --> 00:13:08,789
don't know what else to say

315
00:13:10,090 --> 00:13:12,409
and, like a lot of quote unquote online attacks, you know,

316
00:13:12,419 --> 00:13:15,890
I like the number of port scans and the number of just

317
00:13:16,080 --> 00:13:18,070
web-based shenanigans.

318
00:13:18,080 --> 00:13:20,909
You know, when I look at the log files, there's still people looking for front page,

319
00:13:21,530 --> 00:13:23,830
you know, trying to exploit old front page instances

320
00:13:26,179 --> 00:13:28,200
and, you know, technically do those count as attacks.

321
00:13:28,210 --> 00:13:30,780
Well, it's, it's like so old and hokey that,

322
00:13:31,280 --> 00:13:31,809
I mean, it's,

323
00:13:31,820 --> 00:13:34,520
it's a tax against technology that I personally

324
00:13:34,530 --> 00:13:37,239
haven't even used in about probably 1520 years.

325
00:13:38,109 --> 00:13:38,400
You know,

326
00:13:38,409 --> 00:13:42,510
this is an interesting point you bring up because in the context of automation,

327
00:13:42,520 --> 00:13:45,330
you could compare this to every time you come to a red light

328
00:13:46,049 --> 00:13:49,270
that you are taking corrective action by not blowing through it.

329
00:13:49,280 --> 00:13:52,099
Be it a human or a, an A I?

330
00:13:52,599 --> 00:13:56,349
And how many red lights have you sat out of humans where there's no people around,

331
00:13:56,479 --> 00:13:58,530
it's like three in the afternoon, sunny day.

332
00:13:58,570 --> 00:14:01,869
You have perfect visibility and there's not a single car you can see.

333
00:14:02,020 --> 00:14:04,099
What do you do? You come up to that red light and you stop

334
00:14:05,059 --> 00:14:05,559
and you wait.

335
00:14:05,719 --> 00:14:06,359
Yes.

336
00:14:06,510 --> 00:14:06,960
Right.

337
00:14:07,440 --> 00:14:07,950
Right. Right.

338
00:14:08,200 --> 00:14:08,539
You know,

339
00:14:08,940 --> 00:14:11,890
because it's, it's illegal. Not exactly. And there's,

340
00:14:12,080 --> 00:14:14,289
there's potentially negative consequences.

341
00:14:14,320 --> 00:14:16,809
Well, and more to the point if people get in the habit of blowing through red lights,

342
00:14:16,820 --> 00:14:19,469
they're gonna get lazy and they're going to start blowing through them when,

343
00:14:19,479 --> 00:14:20,390
you know, they shouldn't be.

344
00:14:21,900 --> 00:14:23,840
That is also very true.

345
00:14:24,349 --> 00:14:25,659
Every time somebody says, you know,

346
00:14:25,669 --> 00:14:28,940
they wanna set up a machine and actually monitor the firewall logs on it.

347
00:14:28,950 --> 00:14:30,570
I'm like, no, you really don't

348
00:14:30,770 --> 00:14:32,700
cause first of all, you're gonna have to sleep eight hours a day.

349
00:14:34,599 --> 00:14:37,140
Ok. No, no, this is a great point though.

350
00:14:37,679 --> 00:14:41,219
Somebody wants to monitor the firewall logs and we

351
00:14:41,229 --> 00:14:42,739
know what those are going to look like.

352
00:14:42,750 --> 00:14:44,179
They're going to be a train wreck.

353
00:14:44,750 --> 00:14:45,979
But here's the thing is,

354
00:14:45,989 --> 00:14:51,020
is this is where things like artificial intelligence and machine learning are,

355
00:14:51,030 --> 00:14:52,619
this is what they were built for

356
00:14:53,250 --> 00:14:54,989
is the fact that they can look at your

357
00:14:55,000 --> 00:14:57,770
firewall logs and they can potentially find the,

358
00:14:57,780 --> 00:14:59,650
the one bad thing

359
00:14:59,960 --> 00:15:04,809
-- out of the 7 million benign things that are in those logs.
-- Right.

360
00:15:04,859 --> 00:15:05,000
Well,

361
00:15:05,010 --> 00:15:06,280
but the next problem this leads to and this

362
00:15:06,289 --> 00:15:08,780
is actually related to that hack back thing is

363
00:15:08,914 --> 00:15:10,794
what do you do? What's the actionable information?

364
00:15:11,255 --> 00:15:13,234
Great. Somebody from China attacked me.

365
00:15:13,585 --> 00:15:16,784
What do I do? Do I attack that? IP back? Well, it's probably some

366
00:15:16,905 --> 00:15:17,945
poor little

367
00:15:18,385 --> 00:15:19,465
camera that,

368
00:15:19,744 --> 00:15:22,835
you know, doesn't have a, has a default user name and password online.

369
00:15:22,844 --> 00:15:24,494
The poor little thing attacking everybody.

370
00:15:25,119 --> 00:15:27,510
See, and that's, that's what honestly, I don't even,

371
00:15:27,549 --> 00:15:29,799
there's so much stuff where I've intentionally stopped

372
00:15:29,809 --> 00:15:32,119
paying attention to the logs because I,

373
00:15:32,130 --> 00:15:34,700
I, even if somebody does do something bad.

374
00:15:34,710 --> 00:15:35,679
II, I can't

375
00:15:35,849 --> 00:15:37,159
do anything with it. It's,

376
00:15:37,710 --> 00:15:40,039
well, I, I think it needs to be context aware.

377
00:15:40,049 --> 00:15:41,520
So in the case of a firewall,

378
00:15:41,530 --> 00:15:45,580
keeping the logs for forensic purposes is quite reasonable.

379
00:15:45,820 --> 00:15:48,500
Right. And, and you can maybe look for certain things

380
00:15:49,280 --> 00:15:51,070
and you could trigger

381
00:15:51,349 --> 00:15:52,909
human response

382
00:15:53,140 --> 00:15:56,109
if there's something that is quite obviously egregious.

383
00:15:56,500 --> 00:16:00,750
But let's, let's, let's use your login server as a better example. Right.

384
00:16:00,840 --> 00:16:04,619
If, if you have Bob from accounting, who only logs in

385
00:16:04,880 --> 00:16:08,539
between the hours of 9 a.m. and 5 p.m. from Omaha Nebraska

386
00:16:09,260 --> 00:16:14,080
and all of a sudden at 2 a.m. he's logging in from Russia, right? Something is wrong.

387
00:16:14,119 --> 00:16:17,289
And ML would be really good at picking that up and then you could just say,

388
00:16:17,299 --> 00:16:18,909
like kill his account, right?

389
00:16:18,919 --> 00:16:20,989
Disable access right now

390
00:16:21,380 --> 00:16:23,919
and then send an email to a human that says,

391
00:16:24,169 --> 00:16:26,799
figure this out, right? This is not Bob

392
00:16:27,210 --> 00:16:29,359
or if it is Bob, you should have told us he's going, you know,

393
00:16:29,530 --> 00:16:33,140
my, uh, my partner has a problem every time we travel, her,

394
00:16:33,570 --> 00:16:36,619
her bank is really aggressive about, you know, oh my God,

395
00:16:36,630 --> 00:16:39,169
you're using your credit card literally outside of city limits.

396
00:16:39,179 --> 00:16:39,659
Nope.

397
00:16:42,460 --> 00:16:44,510
Yeah, like I had the, uh, I actually was

398
00:16:45,409 --> 00:16:47,849
up at the cabin and my credit card wouldn't work in a small town,

399
00:16:47,859 --> 00:16:48,989
but it would work in a big town.

400
00:16:50,679 --> 00:16:54,219
It's like, you know, it's always so annoying, you know,

401
00:16:55,419 --> 00:16:57,380
trying to buy a lot more but um

402
00:16:57,719 --> 00:16:59,640
so it's actually really nice.

403
00:16:59,650 --> 00:17:03,940
I found that the bank I use they send me text messages when I use my card

404
00:17:04,180 --> 00:17:05,319
gets declined somewhere.

405
00:17:05,968 --> 00:17:09,548
Ah yeah, they'll be like was this you text one for? Yes, two for no.

406
00:17:09,838 --> 00:17:10,759
-- Yeah,
-- I've seen that

407
00:17:11,328 --> 00:17:12,548
would love to have that

408
00:17:12,958 --> 00:17:13,868
live in Canada.

409
00:17:15,270 --> 00:17:16,689
It's, it's very nice.

410
00:17:17,339 --> 00:17:18,660
It's always funny too

411
00:17:18,939 --> 00:17:19,890
because you go somewhere.

412
00:17:19,900 --> 00:17:23,260
They're like your card's been declined and I'd be like hang on, I take my phone out,

413
00:17:23,270 --> 00:17:24,550
I texted back, I'm like, alright,

414
00:17:24,560 --> 00:17:26,930
try it again and they look at me like I'm some sort of weirdo

415
00:17:27,439 --> 00:17:29,290
I have magic powers or something. But

416
00:17:30,060 --> 00:17:30,969
yeah, it's great.

417
00:17:31,859 --> 00:17:34,630
So, but back to the, I think that's one of the biggest problems here is, you know,

418
00:17:35,530 --> 00:17:38,439
when you tell a human being, hey, don't worry it's taken care of.

419
00:17:38,449 --> 00:17:40,040
That's what human beings tend to do.

420
00:17:40,790 --> 00:17:40,930
What

421
00:17:41,060 --> 00:17:42,099
I don't understand

422
00:17:42,530 --> 00:17:43,839
like a self driving car,

423
00:17:44,060 --> 00:17:44,640
it's ok.

424
00:17:44,650 --> 00:17:48,839
The car is doing the driving, just chill out, sit back, close your eyes, have a nap.

425
00:17:49,030 --> 00:17:52,560
Uh You know that this guy in Britain just recently like last week got

426
00:17:52,569 --> 00:17:54,770
banned from driving because apparently he was

427
00:17:54,780 --> 00:17:56,680
on the motorway in his self-driving Tesla

428
00:17:56,969 --> 00:17:58,599
and he was sitting in the passenger seat.

429
00:17:59,369 --> 00:17:59,390
I,

430
00:17:59,579 --> 00:18:00,949
I read that

431
00:18:01,719 --> 00:18:03,060
that's hilarious

432
00:18:03,449 --> 00:18:06,400
and yeah, so pretty sure there's that.

433
00:18:06,520 --> 00:18:07,109
Well, I mean,

434
00:18:07,119 --> 00:18:10,650
we're gonna need some really progressive motoring laws before that's legal.

435
00:18:10,869 --> 00:18:13,430
I, I wonder sometimes how close we are to that.

436
00:18:13,439 --> 00:18:16,060
And, and I guess so, here's the other half of it though.

437
00:18:16,209 --> 00:18:17,040
And this is,

438
00:18:17,369 --> 00:18:19,890
this is a problem we suffer from every day

439
00:18:20,050 --> 00:18:20,699
is

440
00:18:21,170 --> 00:18:25,439
humans suck at changing their minds and their attitudes.

441
00:18:25,449 --> 00:18:28,910
And so, for example, a lot of people think, oh, self driving cars aren't safe.

442
00:18:29,020 --> 00:18:31,780
It's always funny because every time someone says, oh, self driving cars,

443
00:18:31,790 --> 00:18:33,520
you trust a computer to drive, I'm looking at him.

444
00:18:33,530 --> 00:18:34,800
I'm like, do you trust me to drive?

445
00:18:35,489 --> 00:18:37,640
They already do trust a computer to drive.

446
00:18:38,160 --> 00:18:40,979
And, and I, I don't, I don't bring that up, but here's,

447
00:18:40,989 --> 00:18:43,670
here's kind of the more important aspect of that is

448
00:18:44,989 --> 00:18:46,930
a, like, especially in security.

449
00:18:47,810 --> 00:18:50,959
There are certain things, people just won't, they don't want to change their minds.

450
00:18:50,969 --> 00:18:52,560
Like passwords are my favorite example.

451
00:18:52,569 --> 00:18:55,140
There are so many people who still think, you know, that,

452
00:18:55,150 --> 00:18:56,699
that horrible password advice ned

453
00:18:56,930 --> 00:18:59,959
handed out in the, in the two thousands is still valid

454
00:19:00,619 --> 00:19:01,400
and it's like

455
00:19:01,739 --> 00:19:06,239
I look here, Nist. Nist wrote down why their advice is terrible.

456
00:19:06,250 --> 00:19:09,439
And there's people who look at that and be like, no, I don't believe them. And,

457
00:19:10,219 --> 00:19:10,500
well,

458
00:19:10,569 --> 00:19:14,369
especially the problem becomes when you have something where it's a statistical,

459
00:19:14,380 --> 00:19:15,199
you need to,

460
00:19:15,390 --> 00:19:18,380
you know, have a statistical model to really determine if it's good or bad.

461
00:19:18,660 --> 00:19:20,880
And people of course, come up with anecdotal data

462
00:19:21,750 --> 00:19:24,189
that disproves the whole model. Of course. Right.

463
00:19:24,199 --> 00:19:26,089
And, and that's just something very human because,

464
00:19:26,589 --> 00:19:28,540
you know, we're our threat model as Bruce Schneier

465
00:19:28,650 --> 00:19:29,209
would say is, you know,

466
00:19:29,219 --> 00:19:32,869
we're hardwired for the African Savannah rustling bushes in the distance.

467
00:19:32,880 --> 00:19:34,930
Is that a lion or just the breeze?

468
00:19:35,709 --> 00:19:36,250
You know,

469
00:19:37,229 --> 00:19:39,130
and, and, but the beauty of it is

470
00:19:39,390 --> 00:19:41,290
regardless of the answer to that,

471
00:19:41,469 --> 00:19:43,770
you lose nothing by running away. Right.

472
00:19:43,910 --> 00:19:47,430
Like if it is a line, you've run away. If it was nothing, you ran away,

473
00:19:48,430 --> 00:19:51,640
potentially, there are long term consequences of, you know, you,

474
00:19:51,650 --> 00:19:53,500
you spend a lot more energy running away

475
00:19:53,510 --> 00:19:55,229
and you lose opportunities for other things.

476
00:19:55,239 --> 00:19:56,650
But generally speaking,

477
00:19:56,930 --> 00:19:59,670
statistically again, yeah, the, the, the,

478
00:19:59,680 --> 00:20:01,469
the people with the genes that make them run away

479
00:20:01,479 --> 00:20:03,579
a lot are probably gonna propagate more than the people.

480
00:20:03,589 --> 00:20:05,060
Like, huh? I wonder what that is.

481
00:20:05,069 --> 00:20:08,069
I should go investigate it or maybe apply a statistical model

482
00:20:08,079 --> 00:20:09,979
to see how likely it is that that's a lion,

483
00:20:10,699 --> 00:20:11,229
you know?

484
00:20:14,390 --> 00:20:15,199
Yes. So

485
00:20:16,099 --> 00:20:16,959
I think for me, what it,

486
00:20:18,479 --> 00:20:18,680
yeah.

487
00:20:18,689 --> 00:20:20,979
So I think what it boils down to really, for me is with, you know,

488
00:20:20,989 --> 00:20:22,829
especially with self driving cars.

489
00:20:23,540 --> 00:20:24,380
I hate to say this,

490
00:20:24,390 --> 00:20:28,520
but I think in some ways we really need to wait for the completely self driving

491
00:20:28,709 --> 00:20:29,609
capability

492
00:20:29,930 --> 00:20:32,430
or, or where the car maker says, you know, at,

493
00:20:32,589 --> 00:20:36,520
um, like highway driving, this will 100%

494
00:20:36,719 --> 00:20:37,880
handle everything,

495
00:20:38,089 --> 00:20:39,280
you know? You don't.

496
00:20:40,489 --> 00:20:41,040
Yeah.

497
00:20:41,250 --> 00:20:44,239
Yeah. Yeah. And, and so I guess let's, let's think about that.

498
00:20:44,250 --> 00:20:47,060
Now, now I think in the context of cars, you're right. But does

499
00:20:47,209 --> 00:20:49,979
does that apply in other places as well?

500
00:20:50,109 --> 00:20:51,349
If you have say

501
00:20:51,569 --> 00:20:53,119
machine learning, looking at log

502
00:20:53,510 --> 00:20:56,040
files, that's not a health and human safety issue, right?

503
00:20:56,050 --> 00:20:57,920
But for example, what about a medical device

504
00:20:58,410 --> 00:20:59,819
in what's the context,

505
00:21:00,050 --> 00:21:03,579
for example, those pacemakers now that have sort of the adaptive

506
00:21:04,060 --> 00:21:05,939
uh control and for example,

507
00:21:05,949 --> 00:21:08,579
the pacemaker will see that you're straining and it will up your heart rate.

508
00:21:08,589 --> 00:21:09,829
So you can like exercise,

509
00:21:09,969 --> 00:21:10,430
like

510
00:21:10,550 --> 00:21:14,599
old timey pacemakers literally were like a grandfather clock, like tick, tick,

511
00:21:14,609 --> 00:21:16,760
tick tick, like they didn't have any intelligence.

512
00:21:17,569 --> 00:21:19,170
You know, the newer ones can sense.

513
00:21:19,180 --> 00:21:20,880
Oh, you're straining, I'm gonna up your heart rate.

514
00:21:20,890 --> 00:21:22,979
So you don't like stroke out or, you know,

515
00:21:23,260 --> 00:21:24,800
run out of blood oxygen.

516
00:21:25,180 --> 00:21:29,989
Um And so there's been cases of uh where those things have gone a little haywire and,

517
00:21:30,000 --> 00:21:31,349
you know, crank the guy, uh

518
00:21:32,189 --> 00:21:33,930
uh heart rate way up,

519
00:21:34,300 --> 00:21:36,109
you know, to the point of almost killing them.

520
00:21:37,689 --> 00:21:39,300
And, and what's your point about that?

521
00:21:39,760 --> 00:21:44,300
That's a case of, well, that's a system that has to be automated uh largely

522
00:21:44,579 --> 00:21:46,329
and, you know, it, it is,

523
00:21:46,459 --> 00:21:49,020
there's very much a health and human safety aspect of it.

524
00:21:49,030 --> 00:21:51,369
And so it damn well better be 100%

525
00:21:51,630 --> 00:21:54,119
or so close to 100% that we can barely tell,

526
00:21:54,329 --> 00:21:56,770
you know, and that's the problem with these self driving cars right there.

527
00:21:56,780 --> 00:22:00,079
There's that poor lady walking her bicycle across the

528
00:22:00,089 --> 00:22:01,729
street that got run over by an Uber,

529
00:22:02,150 --> 00:22:03,969
they, you know, self driving Uber,

530
00:22:04,650 --> 00:22:06,780
you know, there's, there's all these cases where

531
00:22:07,569 --> 00:22:09,140
I'm hoping we have like

532
00:22:09,489 --> 00:22:14,109
an airline, you know, style safety investigation recommendations and a fix.

533
00:22:15,050 --> 00:22:17,699
The problem being, these are like A I systems.

534
00:22:18,569 --> 00:22:21,750
How, how do we even begin to prove that we've improved them,

535
00:22:22,439 --> 00:22:25,339
you know, short of putting them back out on the road and seeing how they do.

536
00:22:28,390 --> 00:22:30,930
I mean, I, I think that's true of everything and

537
00:22:32,099 --> 00:22:32,880
I, I don't,

538
00:22:32,890 --> 00:22:36,900
I don't think there is another way other than essentially real world testing,

539
00:22:36,930 --> 00:22:37,439
right?

540
00:22:37,939 --> 00:22:39,829
And this is true of any sort of automated

541
00:22:39,939 --> 00:22:40,119
system,

542
00:22:40,859 --> 00:22:43,380
the VR based testing of these self driving systems now

543
00:22:43,699 --> 00:22:45,390
and, and for self driving,

544
00:22:45,569 --> 00:22:47,319
OK, you might be able to get away with that.

545
00:22:47,329 --> 00:22:49,609
I, I really don't know, I don't know enough about the technology

546
00:22:50,869 --> 00:22:50,890
the,

547
00:22:52,930 --> 00:22:56,479
because it's just data, right? How would the car know that that data isn't,

548
00:22:56,719 --> 00:22:58,739
is a recording versus is live.

549
00:22:59,310 --> 00:23:00,550
It, it, it wouldn't,

550
00:23:00,670 --> 00:23:00,979
right.

551
00:23:00,989 --> 00:23:03,589
But you also run into, I think some of the problems of,

552
00:23:03,599 --> 00:23:06,339
if you keep feeding it the same things over and over again,

553
00:23:06,780 --> 00:23:10,469
it's gonna be less effective than having it actually out doing real things.

554
00:23:10,479 --> 00:23:11,369
And I guess like th

555
00:23:11,619 --> 00:23:14,859
this is an example I would use, let's say you have, you know,

556
00:23:14,869 --> 00:23:17,969
machine learning or A I monitoring your logs.

557
00:23:18,319 --> 00:23:21,140
It, it would be trivial to have basically look at a human,

558
00:23:21,150 --> 00:23:23,459
look at the A I see which is doing better.

559
00:23:23,469 --> 00:23:27,560
Right? And, and so like that, in that, that case, you can kind of do it side by side.

560
00:23:27,839 --> 00:23:31,300
And I guess even with self driving cars, you can do it side by side where you can say,

561
00:23:31,630 --> 00:23:34,170
let's look at how the cars are doing, let's look at how the people are doing.

562
00:23:34,180 --> 00:23:36,660
But the issue being, if the cars are doing worse,

563
00:23:36,880 --> 00:23:40,410
you've now just like, unnecessarily killed a whole bunch of people, basically.

564
00:23:40,420 --> 00:23:40,780
Right.

565
00:23:41,979 --> 00:23:42,400
Uh,

566
00:23:42,900 --> 00:23:46,579
well, I mean, weren't you looking into industrial disasters and safety and, and,

567
00:23:46,589 --> 00:23:49,239
you know, essentially every single, like,

568
00:23:49,250 --> 00:23:52,680
look at how many people were killed by horses, kicking them in the head or

569
00:23:52,829 --> 00:23:53,890
being run over by

570
00:23:54,099 --> 00:23:55,119
wagons or,

571
00:23:55,589 --> 00:23:56,079
I mean,

572
00:23:56,229 --> 00:23:56,819
just,

573
00:23:57,189 --> 00:24:01,349
you know, how many people get maimed and mangled by farm machinery,

574
00:24:01,550 --> 00:24:05,560
-- you know, like picking,
-- picking industry, like literally every one of them,

575
00:24:05,569 --> 00:24:06,359
it doesn't matter.

576
00:24:06,369 --> 00:24:08,680
And, yeah, I've, I've got a presentation

577
00:24:09,069 --> 00:24:11,099
I put together some time ago. Right.

578
00:24:11,109 --> 00:24:12,989
It basically looks at things like mine safety

579
00:24:13,000 --> 00:24:16,089
and auto safety and industrial safety and every

580
00:24:16,209 --> 00:24:16,329
company

581
00:24:16,449 --> 00:24:20,969
in the US when they file their SCC paperwork has to put in a mine safety statement

582
00:24:21,229 --> 00:24:23,410
or say we don't have any mines,

583
00:24:24,119 --> 00:24:25,359
you know, when you file your, what is it, your

584
00:24:25,579 --> 00:24:27,000
10-K or whatever with the sec?

585
00:24:27,459 --> 00:24:28,439
Right? You know,

586
00:24:28,550 --> 00:24:31,119
and like, because that's literally how bad mine safety was,

587
00:24:31,130 --> 00:24:34,380
is it got so bad that they made all the companies report on it.

588
00:24:35,239 --> 00:24:36,849
Like, that's gotta be pretty terrible.

589
00:24:38,849 --> 00:24:40,239
It's, it's still bad.

590
00:24:40,250 --> 00:24:45,229
In fact, even, even now there's, there's a lot of issues even though mining is,

591
00:24:45,239 --> 00:24:47,500
is fairly regulated in the country.

592
00:24:47,760 --> 00:24:50,030
But, but, I mean, this is where,

593
00:24:50,160 --> 00:24:52,150
I don't know, this is one of the things I think about

594
00:24:52,369 --> 00:24:52,869
is

595
00:24:53,400 --> 00:24:56,800
generally speaking, nobody cares till it gets so bad. You can't ignore it.

596
00:24:57,109 --> 00:25:00,219
But, but like, self driving cars are different,

597
00:25:00,420 --> 00:25:03,020
right? I mean, I think you could argue it is so bad

598
00:25:03,260 --> 00:25:05,060
that people can't ignore it because let's face it,

599
00:25:05,069 --> 00:25:07,930
like thousands of people die a day in auto accidents

600
00:25:08,569 --> 00:25:11,900
and, and even if self driving cars could drop that number in half,

601
00:25:11,910 --> 00:25:13,300
that would be enormous.

602
00:25:13,310 --> 00:25:14,410
-- Right. I have a feeling it's going to
-- be,

603
00:25:14,810 --> 00:25:16,089
you know what I'm thinking is

604
00:25:16,250 --> 00:25:19,900
also the number of people just hurt and mangled in car accidents.

605
00:25:19,910 --> 00:25:22,420
You know how many people are in wheelchairs because of car accidents,

606
00:25:22,800 --> 00:25:27,219
you know, like just the, the, the human suffering is, is, oh, it's astounding.

607
00:25:27,449 --> 00:25:28,099
-- Right.
-- Right.

608
00:25:28,229 --> 00:25:28,400
And

609
00:25:28,569 --> 00:25:29,709
so I guess that's, oh,

610
00:25:29,930 --> 00:25:30,750
man, this,

611
00:25:30,930 --> 00:25:33,660
this makes the automation conversation tricky because

612
00:25:34,550 --> 00:25:36,209
there is some automation

613
00:25:36,319 --> 00:25:38,449
that if it, if it fails people die

614
00:25:38,780 --> 00:25:40,550
and there is other automation that if it,

615
00:25:40,569 --> 00:25:42,839
but I guess this is kind of true of security in general.

616
00:25:42,849 --> 00:25:45,569
Right. And maybe this is one of the reasons security has never,

617
00:25:45,750 --> 00:25:49,760
we, we've struggled to kind of bring the industry to the next level. Because,

618
00:25:50,109 --> 00:25:52,760
I mean, historically speaking, if your company gets hacked,

619
00:25:53,189 --> 00:25:54,530
nobody dies, right.

620
00:25:54,540 --> 00:25:58,849
And that's becoming less true, I think in, in certain industries now. But

621
00:25:58,969 --> 00:26:02,530
I mean, like practically speaking, your website got hacked. What happens?

622
00:26:02,540 --> 00:26:05,329
Nothing. You know, you, you probably restore from backup.

623
00:26:05,719 --> 00:26:07,400
Whereas with like cars in meds

624
00:26:07,699 --> 00:26:08,239
now,

625
00:26:08,930 --> 00:26:12,400
when, when things get hacked, people are literally going to die,

626
00:26:12,510 --> 00:26:14,790
it's going to change some of the rules.

627
00:26:14,800 --> 00:26:18,109
And so I wonder if that's going to make people care more,

628
00:26:18,599 --> 00:26:22,949
but unfortunately they aren't going to care until a lot of people die.

629
00:26:22,959 --> 00:26:24,829
Given historical precedent

630
00:26:25,060 --> 00:26:29,709
of, you know, like rivers literally lighting on fire before people care.

631
00:26:30,099 --> 00:26:32,189
Well, that, that's my favorite one because the people didn't care.

632
00:26:32,199 --> 00:26:35,319
It was the rail company that cared because it was damaging their bridge.

633
00:26:35,550 --> 00:26:39,520
Well, actually you, you, you say that a lot and, and there was that instance,

634
00:26:39,729 --> 00:26:40,839
but there are many,

635
00:26:41,489 --> 00:26:44,270
there are so many rivers that have lit on fire.

636
00:26:44,550 --> 00:26:46,430
My tap water catches fire.

637
00:26:46,979 --> 00:26:49,540
Well, that's still, that's true. That's in Virginia, right? A

638
00:26:50,239 --> 00:26:51,119
couple of place anyway.

639
00:26:51,989 --> 00:26:54,640
But here's the thing. So there have been

640
00:26:55,199 --> 00:26:58,829
a disturbing number of rivers that lit on fire throughout history.

641
00:26:59,079 --> 00:27:04,640
Right. Like you think one is when people should start caring. No, not one, like

642
00:27:05,160 --> 00:27:06,910
more than 20. Right.

643
00:27:06,920 --> 00:27:07,709
And those are the,

644
00:27:07,719 --> 00:27:11,050
those are the incidents that were big enough to make it into the news.

645
00:27:11,239 --> 00:27:11,689
You know,

646
00:27:11,699 --> 00:27:14,829
there were probably hundreds of small rivers out in the

647
00:27:14,839 --> 00:27:17,910
middle of nowhere that had been lit on fire.

648
00:27:18,150 --> 00:27:22,030
But again, like humans suck at changing their minds.

649
00:27:22,119 --> 00:27:24,229
It is, it is the human condition.

650
00:27:24,560 --> 00:27:26,380
I think ultimately what's going to happen is self

651
00:27:26,390 --> 00:27:30,260
driving cars will present especially for the trucking industry.

652
00:27:30,270 --> 00:27:34,199
Uh An, an economically compelling enough case that it's gonna happen.

653
00:27:34,640 --> 00:27:35,479
End of story

654
00:27:35,630 --> 00:27:38,979
like industrialization, right? You had machines mangling people

655
00:27:39,390 --> 00:27:40,699
left, right and center

656
00:27:40,819 --> 00:27:45,000
and well, too bad productivity is way up. We can afford more orphans.

657
00:27:45,290 --> 00:27:47,140
And that's just the brutal truth of it.

658
00:27:47,619 --> 00:27:52,439
It, it, it was and then the, the in fact, the industrial safety on that scale

659
00:27:52,630 --> 00:27:55,479
was, was particularly interesting because it was

660
00:27:56,250 --> 00:27:57,380
in that particular case,

661
00:27:57,390 --> 00:28:02,660
it was driven more so from kind of the unionization of employees than

662
00:28:02,670 --> 00:28:05,310
it was from from government regulations where

663
00:28:05,319 --> 00:28:07,099
then once the workers banded together,

664
00:28:07,109 --> 00:28:10,560
they, they kind of cried to the government to, to change this stuff.

665
00:28:10,949 --> 00:28:13,829
Whereas a lot of other things like environmental, for example,

666
00:28:13,839 --> 00:28:15,709
has been very government driven.

667
00:28:16,089 --> 00:28:17,239
And so it's, it's

668
00:28:17,959 --> 00:28:21,540
more often than not. I think you end up with, uh

669
00:28:21,670 --> 00:28:25,859
government starts to care for some reason or other with, with these things. And,

670
00:28:26,359 --> 00:28:30,489
and I guess cars are also special because the government already cares about cars,

671
00:28:30,729 --> 00:28:31,180
right?

672
00:28:31,329 --> 00:28:34,050
So, I don't know, man, this one's different, it's very different

673
00:28:35,239 --> 00:28:35,280
once

674
00:28:35,520 --> 00:28:35,979
you get

675
00:28:36,420 --> 00:28:39,339
essentially a car fleet, that's like a, let's assume,

676
00:28:40,020 --> 00:28:44,119
uh you know, even 50 or 80% automated

677
00:28:44,400 --> 00:28:48,040
things like I, that's gonna have a huge impact on things like crime,

678
00:28:49,310 --> 00:28:49,560
right.

679
00:28:49,569 --> 00:28:51,530
How do you, how do you get away if,

680
00:28:51,540 --> 00:28:55,069
if you don't have access to a car that you can control?

681
00:28:55,209 --> 00:28:59,250
-- You
-- just, you could probably make a ton of money with a getaway car service, right?

682
00:28:59,260 --> 00:28:59,750
Like

683
00:29:01,750 --> 00:29:02,770
no questions asked,

684
00:29:03,189 --> 00:29:03,420
-- you
-- know,

685
00:29:03,430 --> 00:29:06,089
but all the other cars are tracking you because they all have cameras. Now,

686
00:29:08,040 --> 00:29:09,750
that's what the mask is for.

687
00:29:10,550 --> 00:29:11,959
Right? So,

688
00:29:12,270 --> 00:29:12,469
yeah.

689
00:29:12,479 --> 00:29:17,020
No, I, I suspect that the, just from what I understand of the economics of cars,

690
00:29:17,030 --> 00:29:18,520
the self driving aspect is just

691
00:29:18,680 --> 00:29:20,089
personally, I want it,

692
00:29:20,170 --> 00:29:23,060
but I only want it if it's 100% because I don't have to pay attention

693
00:29:24,150 --> 00:29:24,920
completely.

694
00:29:25,010 --> 00:29:28,439
II I don't like to drive and, and so the,

695
00:29:28,449 --> 00:29:33,359
the concept of being able to just get in a car and not care, sounds amazing to me.

696
00:29:34,010 --> 00:29:35,030
And it was funny too.

697
00:29:35,040 --> 00:29:38,949
I, I was talking to somebody a couple of weeks ago about this and they basically said,

698
00:29:38,959 --> 00:29:40,910
well, what if I just want to go for a drive?

699
00:29:41,119 --> 00:29:41,709
And I said,

700
00:29:42,209 --> 00:29:43,270
-- I don't, I don't
-- go

701
00:29:43,430 --> 00:29:43,449
for,

702
00:29:43,630 --> 00:29:46,489
-- if you just want to hook up your horse to the buggy and go for,
-- uh, or

703
00:29:47,310 --> 00:29:47,520
take

704
00:29:47,939 --> 00:29:48,449
your horse on the

705
00:29:48,650 --> 00:29:51,810
-- state.
-- Well, no more of the point, people still do that but it's a hobby

706
00:29:51,930 --> 00:29:53,630
and you go do it on private land.

707
00:29:54,040 --> 00:29:56,170
Well, not only that man, you got to think, like,

708
00:29:56,180 --> 00:30:00,469
if you want to drive and if you have a controlled enclosed environment to drive on,

709
00:30:00,810 --> 00:30:03,339
you could drive really fast or, or

710
00:30:03,780 --> 00:30:04,510
Kirby's drugs.

711
00:30:05,229 --> 00:30:05,989
Right. Right.

712
00:30:06,160 --> 00:30:06,839
Exactly.

713
00:30:07,420 --> 00:30:09,930
Whereas today you have these idiots who think they're

714
00:30:09,939 --> 00:30:11,310
racing on the road and they end up,

715
00:30:11,319 --> 00:30:12,979
you know, crashing into people.

716
00:30:13,589 --> 00:30:14,079
Yeah.

717
00:30:14,199 --> 00:30:15,949
So, well, I think with that, I guess,

718
00:30:16,540 --> 00:30:21,670
I guess the moral of the story is if, uh, is shoot for 100% automation because, yeah,

719
00:30:21,680 --> 00:30:22,390
like you said,

720
00:30:22,589 --> 00:30:23,790
people are slow and dumb.

721
00:30:24,089 --> 00:30:28,109
Yeah. II, I think that's the key and this is, I think true of any sort of

722
00:30:28,589 --> 00:30:30,189
automated environment.

723
00:30:30,199 --> 00:30:35,650
Cars or airplanes or, well, airplanes are probably different but whatever.

724
00:30:35,790 --> 00:30:38,420
But, but I, I think if you're, if you're deploying automation,

725
00:30:38,880 --> 00:30:39,290
like

726
00:30:39,459 --> 00:30:41,339
airplanes and trains have the exact same issues,

727
00:30:41,349 --> 00:30:43,900
you got a human at the loop who may or may not be paying attention,

728
00:30:44,189 --> 00:30:44,500
maybe

729
00:30:45,000 --> 00:30:47,939
airplanes can't take off or land today, can they?

730
00:30:48,040 --> 00:30:48,849
With automation?

731
00:30:49,310 --> 00:30:50,660
They've been able to do that for years?

732
00:30:50,959 --> 00:30:53,859
Ok. Never mind. Then. I don't know. Again, I don't know what I'm talking about.

733
00:30:53,869 --> 00:30:57,010
Like, you obviously know this particular topic better than I do.

734
00:30:57,020 --> 00:30:58,540
I basically know what I learned from.

735
00:30:58,719 --> 00:30:59,040
-- You
-- know,

736
00:31:01,199 --> 00:31:02,640
a thing called Auto Land.

737
00:31:04,959 --> 00:31:05,109
It

738
00:31:05,250 --> 00:31:08,300
-- sounds like a theme park.
-- Well, think about it.

739
00:31:08,310 --> 00:31:10,099
You have like fog and zero visibility.

740
00:31:11,010 --> 00:31:13,530
You either have a human doing an instrument based landing

741
00:31:13,849 --> 00:31:17,109
or you have a computer doing the instrument based landing personally.

742
00:31:17,119 --> 00:31:18,469
Me, I'm gonna go with the computer.

743
00:31:19,520 --> 00:31:22,079
I, yeah, that's fair. I, I would agree with that.

744
00:31:22,089 --> 00:31:24,729
I don't, I don't trust people, people out of the problem

745
00:31:25,089 --> 00:31:25,640
anyway.

746
00:31:25,880 --> 00:31:27,300
But, no, I, I think your,

747
00:31:27,310 --> 00:31:29,739
your closing point is very true that if you're

748
00:31:29,750 --> 00:31:33,420
going to deploy an automated system go all in because

749
00:31:34,199 --> 00:31:37,239
anything else is going to be unacceptable,

750
00:31:37,500 --> 00:31:37,790
I think.

751
00:31:37,969 --> 00:31:38,949
And, you know, I guess

752
00:31:39,199 --> 00:31:42,089
at the same time, let's, let's think about this for a second as well.

753
00:31:42,319 --> 00:31:45,469
Imagine if you were, say, deploying

754
00:31:46,040 --> 00:31:49,270
a fleet of tractors, do you think they did like half tractors,

755
00:31:49,280 --> 00:31:51,199
half horses trying to work in tandem?

756
00:31:51,709 --> 00:31:52,170
No.

757
00:31:52,339 --> 00:31:52,719
Right.

758
00:31:53,020 --> 00:31:53,270
Well, they

759
00:31:53,560 --> 00:31:56,770
-- did as they, as they could afford tractors. Right. They would buy them.
-- And

760
00:31:57,180 --> 00:32:00,130
my assumption is they do different jobs though. Right.

761
00:32:00,140 --> 00:32:04,290
Where you wouldn't have like one tractor and one horse hooked up to one thing

762
00:32:04,760 --> 00:32:05,680
that's dumb.

763
00:32:06,709 --> 00:32:07,859
No, I suspect, I mean,

764
00:32:08,020 --> 00:32:11,089
I think having the human assistive thing makes sense because you can make

765
00:32:11,099 --> 00:32:14,449
those steps towards full automation and not have to make that giant leap.

766
00:32:14,459 --> 00:32:16,689
You know, and you can actually bring something to market and sell it

767
00:32:16,910 --> 00:32:18,729
and make money to fund your R and D.

768
00:32:19,339 --> 00:32:22,369
But like you said, I think the goal should be not to be like, oh,

769
00:32:22,380 --> 00:32:24,189
we're gonna build a car that's 80% automated.

770
00:32:24,199 --> 00:32:26,290
No, you're, I think the goal needs to be 100%.

771
00:32:26,930 --> 00:32:31,229
I, I agree. I, I think 100%. Automation should be the goal in any system.

772
00:32:31,359 --> 00:32:33,270
And if that's not what you're shooting for,

773
00:32:33,280 --> 00:32:35,910
you're probably just gonna make a bigger now.

774
00:32:35,920 --> 00:32:37,810
Now you have two problems, right? Instead of one.

775
00:32:38,069 --> 00:32:40,750
Well, yeah, you have to have humans figure out when it failed and then what to do.

776
00:32:41,310 --> 00:32:41,959
Right.

777
00:32:42,229 --> 00:32:44,050
Right. All right, man, I dig it.

778
00:32:44,170 --> 00:32:46,400
So I guess. Thank you, Kurt. Thank you everyone for listening.

779
00:32:46,410 --> 00:32:48,520
Go to open source security podcast.com.

780
00:32:48,530 --> 00:32:52,520
Hit up the show notes, go to the pound or, or use a pound Os s podcast.

781
00:32:52,530 --> 00:32:54,319
Hashtag to hit us up on social media.

782
00:32:54,329 --> 00:32:56,959
If nothing else, Kurt have a fabulous rest of your day.

783
00:32:57,270 --> 00:32:58,079
You too. Thanks.

784
00:32:58,979 --> 00:32:59,469
Bye bye.