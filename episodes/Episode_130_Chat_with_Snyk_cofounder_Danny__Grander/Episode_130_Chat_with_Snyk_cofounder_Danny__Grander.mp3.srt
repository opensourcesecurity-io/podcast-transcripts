0
00:00:05,420 --> 00:00:10,020
Hello and welcome to the open source security podcast episode 130 with myself,

1
00:00:10,029 --> 00:00:12,529
Kurt Siefried and my partner in Thought Crime, Josh Pressers.

2
00:00:13,090 --> 00:00:13,640
Hey, Kurt.

3
00:00:13,649 --> 00:00:18,290
And today I am pleased to say we're talking to Danny Grander, the co-founder of SNCC.

4
00:00:18,469 --> 00:00:19,600
Say hello, Danny.

5
00:00:19,799 --> 00:00:22,399
Hello. And thank you so much for having me.

6
00:00:22,889 --> 00:00:25,069
No, thank you, man. We've been trying to get you on this show.

7
00:00:25,079 --> 00:00:27,079
I feel like for, for years at this point.

8
00:00:27,090 --> 00:00:31,030
So I'm, I'm ecstatic that we finally got things to work out. So,

9
00:00:31,379 --> 00:00:32,418
yeah. Awesome, man.

10
00:00:32,430 --> 00:00:36,830
So I, I guess why don't, why don't you give us a little rundown of kind of who you are,

11
00:00:36,840 --> 00:00:39,959
what you do, what Snick and, and that and then we can go from there.

12
00:00:40,889 --> 00:00:45,569
All right. So, um I'm Danny. I'm, I'm, I live in Israel in Tel Aviv.

13
00:00:45,680 --> 00:00:49,720
And as you said, I'm the co-founder and responsible for security at

14
00:00:49,860 --> 00:00:50,990
SNC. So, um

15
00:00:51,270 --> 00:00:54,950
the security be is I'm kind of wearing two hats first would be the

16
00:00:55,169 --> 00:00:56,330
product security and

17
00:00:56,560 --> 00:01:01,669
building our vulnerability database doing all that research as well.

18
00:01:01,799 --> 00:01:05,500
And, and the other part, uh would be also responsible for

19
00:01:05,889 --> 00:01:09,699
SNCC and Home security, keeping, sneak, secure and compliant.

20
00:01:09,790 --> 00:01:13,830
I'm also a member of a AC TF capture the flag team called Pastan.

21
00:01:14,239 --> 00:01:14,839
So

22
00:01:15,019 --> 00:01:21,209
we're an active team and just came back from the CCC event uh in Germany

23
00:01:21,379 --> 00:01:23,410
also played the CTF there.

24
00:01:23,690 --> 00:01:27,730
And uh yeah, so in the past five years where we were actively playing,

25
00:01:27,739 --> 00:01:34,819
we had the honor to win uh uh three Google CTFS and three first play and three cccctfs.

26
00:01:35,470 --> 00:01:36,690
Um Yeah.

27
00:01:36,809 --> 00:01:41,639
and in my past, I was, I was doing uh quite a lot of development in

28
00:01:41,750 --> 00:01:42,980
different start ups.

29
00:01:43,169 --> 00:01:47,959
But I'd say for the last 10 years before founding SNC,

30
00:01:48,199 --> 00:01:52,690
I was focusing on security research, uh vulnerability research in particular

31
00:01:52,959 --> 00:01:55,919
and that was mostly around to low

32
00:01:56,029 --> 00:01:58,699
level stuff like embedded systems and crypto

33
00:01:59,169 --> 00:02:01,069
analysis analysis as well. So

34
00:02:01,480 --> 00:02:05,160
that's, yeah, that's a kind of high level overview.

35
00:02:05,389 --> 00:02:07,099
Nice. That's awesome. Well, in, in SNC,

36
00:02:07,510 --> 00:02:08,380
I think is,

37
00:02:08,389 --> 00:02:12,509
is a bit close to our hearts as obviously this being an open source security podcast.

38
00:02:12,520 --> 00:02:13,949
And, and you guys are,

39
00:02:13,960 --> 00:02:17,699
I feel like every time I'm reading some sort of news about open source security,

40
00:02:17,710 --> 00:02:19,240
like there you guys are, right?

41
00:02:19,250 --> 00:02:21,740
You've been doing some crazy work, which is awesome.

42
00:02:21,929 --> 00:02:22,229
Yeah.

43
00:02:22,240 --> 00:02:26,990
So, so um so it's sneak, you know, like when we found it snake, uh our,

44
00:02:27,000 --> 00:02:28,979
our mission was to

45
00:02:29,279 --> 00:02:34,070
help developers and use open source code and stay secure.

46
00:02:34,289 --> 00:02:34,970
And so

47
00:02:35,339 --> 00:02:39,860
that's uh the major thing for us was to, you know, to

48
00:02:40,089 --> 00:02:43,470
solve that problem for developers and it's different

49
00:02:43,479 --> 00:02:45,979
than solving that problem for security people.

50
00:02:46,110 --> 00:02:50,509
So still we are a security product and we are a security expert experts and you know,

51
00:02:50,520 --> 00:02:55,354
we have uh what we, we need to, to, to help, to solve this problem.

52
00:02:55,365 --> 00:02:55,845
But

53
00:02:56,014 --> 00:02:58,035
the product we're building is

54
00:02:58,324 --> 00:03:02,985
addressed for developers. And that's, you know, we believe that this is,

55
00:03:03,104 --> 00:03:03,535
you know,

56
00:03:03,544 --> 00:03:08,214
open source dependency like the dependency management and the security part of,

57
00:03:08,225 --> 00:03:10,574
of managing your dependencies is something that

58
00:03:10,714 --> 00:03:12,404
should be owned

59
00:03:12,845 --> 00:03:17,585
by the developers as you know, as part of the quality that uh

60
00:03:17,794 --> 00:03:18,994
they, they own.

61
00:03:19,270 --> 00:03:21,750
And uh and that's why we,

62
00:03:21,759 --> 00:03:25,259
we believe that we should build a product that is usable by them, you know,

63
00:03:25,270 --> 00:03:28,369
something that they find useful for them and,

64
00:03:28,380 --> 00:03:32,139
and integrating all their work flows for them to, you know, to,

65
00:03:32,149 --> 00:03:34,759
to be able to reduce that risk.

66
00:03:34,770 --> 00:03:35,759
And of course, this is

67
00:03:35,929 --> 00:03:39,729
something that, you know, the security faults in any organizations want.

68
00:03:40,110 --> 00:03:45,380
But uh ultimately, this is something that we believe is the best place to solve is,

69
00:03:45,389 --> 00:03:46,619
you know, by developers.

70
00:03:46,669 --> 00:03:47,500
So that's why

71
00:03:47,710 --> 00:03:52,690
from day one, we build it as we, we build it, you know, the company as a depth to

72
00:03:52,830 --> 00:03:54,220
company, it comes down

73
00:03:54,360 --> 00:03:56,929
to many aspects, you know, how we build the product,

74
00:03:56,940 --> 00:04:00,339
how we do the product or how we develop it, how we market it.

75
00:04:00,600 --> 00:04:01,500
And um

76
00:04:02,380 --> 00:04:07,800
yeah, so, and of course, like where we also present, you know, like even giving talks

77
00:04:08,009 --> 00:04:10,509
and uh and content we write

78
00:04:10,699 --> 00:04:14,880
it also from day one was very different, you know, from the typical I'd say

79
00:04:15,059 --> 00:04:17,160
uh security cybersecurity company

80
00:04:17,738 --> 00:04:18,619
at least. Well,

81
00:04:19,529 --> 00:04:20,738
but generally nice.

82
00:04:20,980 --> 00:04:22,799
So I was curious, you're talking about open source.

83
00:04:22,809 --> 00:04:23,940
Um And obviously the,

84
00:04:23,950 --> 00:04:28,109
the one most recent one that comes to mind is the zip slip vulnerabilities.

85
00:04:28,119 --> 00:04:30,980
One thing I have to say is I was looking through your advisory on it

86
00:04:31,200 --> 00:04:33,720
and something you've done that not very many people do is you

87
00:04:33,730 --> 00:04:36,220
not only talked about who is vulnerable and how they're vulnerable,

88
00:04:36,230 --> 00:04:37,200
but you actually

89
00:04:37,529 --> 00:04:39,700
gave the example of Ruby and Python where you,

90
00:04:39,709 --> 00:04:42,980
you actually looked through their libraries and source code and

91
00:04:42,989 --> 00:04:46,690
apparently found no vulnerabilities uh specific to zip slip.

92
00:04:46,940 --> 00:04:49,980
And I, and I have to say I really appreciate that because one thing I've noticed is

93
00:04:50,390 --> 00:04:53,290
um with these sort of broad vulnerabilities.

94
00:04:53,299 --> 00:04:56,700
So one of the first ones I remember that I had to deal with was the XML hash dos

95
00:04:56,890 --> 00:04:57,920
like eight years ago.

96
00:04:58,290 --> 00:05:01,609
And we, we definitely knew like a few things that were vulnerable

97
00:05:02,029 --> 00:05:04,700
and then the rest of it was just this giant unknown, right?

98
00:05:04,709 --> 00:05:07,839
And I spent the better part of I think two months digging through

99
00:05:08,029 --> 00:05:11,140
stuff looking for, you know, is this vulnerable or not? So

100
00:05:11,269 --> 00:05:13,320
I have to say I really appreciate

101
00:05:14,100 --> 00:05:14,890
when the security V

102
00:05:15,040 --> 00:05:17,489
I mean, I really appreciate people telling me what is vulnerable.

103
00:05:17,500 --> 00:05:20,489
Like that's, you know, G I Joe now, you know, half the battle,

104
00:05:20,730 --> 00:05:25,329
but telling me what isn't vulnerable is also hugely helpful because,

105
00:05:25,500 --> 00:05:26,890
you know, if I'm running Ruby and Python now,

106
00:05:26,899 --> 00:05:27,929
I know I don't have to spend two months

107
00:05:27,940 --> 00:05:29,690
digging through my source code looking for this.

108
00:05:30,250 --> 00:05:32,760
I just want to say I appreciate that and I wish more vendors would do that.

109
00:05:32,769 --> 00:05:35,290
-- But I know it's a ton of work.
-- Super happy to hear that.

110
00:05:35,299 --> 00:05:38,309
And I think there's an interesting story story behind this.

111
00:05:38,459 --> 00:05:38,480
So,

112
00:05:38,750 --> 00:05:39,809
you know, um

113
00:05:39,970 --> 00:05:40,730
when we

114
00:05:40,859 --> 00:05:45,609
basically the zip slip story started with uh us finding the

115
00:05:46,049 --> 00:05:46,809
the vulnerability.

116
00:05:46,820 --> 00:05:52,350
And so maybe I'll briefly explain what's uh what this, what is this ability is about.

117
00:05:52,529 --> 00:05:55,350
So basically, uh it's, it's um

118
00:05:55,489 --> 00:05:58,839
ultimately, it's a simple directory traversal vulnerability.

119
00:05:58,910 --> 00:06:04,339
But one that happens when we extract archives, not necessarily zips but any kind of

120
00:06:04,489 --> 00:06:05,380
archive.

121
00:06:05,399 --> 00:06:07,480
So what typically a typical code that uh

122
00:06:07,489 --> 00:06:10,290
that extracts a vulnerable code that extracts an archive

123
00:06:10,559 --> 00:06:12,950
into destination folder

124
00:06:13,279 --> 00:06:14,019
would

125
00:06:14,119 --> 00:06:18,279
just iterate over the entries over the files that inside that archive

126
00:06:18,510 --> 00:06:22,450
and and extract them into the destination folder by attending

127
00:06:22,570 --> 00:06:26,670
the name of the entry, the name of the file inside the zip to the to the path,

128
00:06:26,679 --> 00:06:28,029
the target directory.

129
00:06:28,059 --> 00:06:31,709
So if the name inside the zip file contains, you know

130
00:06:32,170 --> 00:06:33,950
dot dot slash dot dot slash,

131
00:06:34,119 --> 00:06:37,859
then the the the final path that we are extracting the file

132
00:06:37,869 --> 00:06:41,350
into and the final path for the folder would uh you know,

133
00:06:41,359 --> 00:06:46,040
might end up being a different path than the one we intended

134
00:06:46,170 --> 00:06:47,089
to extract to.

135
00:06:47,420 --> 00:06:48,040
So

136
00:06:48,450 --> 00:06:52,040
this vulnerability vulnerability is not something new,

137
00:06:52,049 --> 00:06:55,559
like first time mentioned in Frack magazine

138
00:06:55,730 --> 00:06:57,480
in 1991.

139
00:06:57,660 --> 00:06:57,700
So,

140
00:06:58,089 --> 00:07:01,519
you know, when, when, when the internet was, you know, created.

141
00:07:01,529 --> 00:07:05,959
So, so, so that's how long this type of vulnerability was not.

142
00:07:06,220 --> 00:07:10,359
But uh and so when, when we found, you know, when, when, when, when,

143
00:07:10,369 --> 00:07:11,640
when we found the issue

144
00:07:11,769 --> 00:07:12,450
in several open

145
00:07:12,589 --> 00:07:13,730
source projects, it was

146
00:07:13,970 --> 00:07:19,160
uh we've seen it in Jenkins code and several of its plains including one from Amazon

147
00:07:19,540 --> 00:07:21,690
and uh several Apache products.

148
00:07:21,880 --> 00:07:25,450
So it, it just, you know, it was just surprising to see

149
00:07:25,570 --> 00:07:29,329
that kind of, you know, well known, all kind of vulnerability

150
00:07:29,589 --> 00:07:32,519
in, in, in such popular uh projects.

151
00:07:32,790 --> 00:07:38,040
And so we, what we did next is, is and these, all of those were were Java projects.

152
00:07:38,529 --> 00:07:42,119
So what we did next is kind of searched all the

153
00:07:42,250 --> 00:07:42,309
github,

154
00:07:42,600 --> 00:07:43,730
all the open source called on

155
00:07:44,100 --> 00:07:44,359
github

156
00:07:44,890 --> 00:07:48,369
to see whether there are any other vulnerable projects that have, you know,

157
00:07:48,380 --> 00:07:49,739
projects that have code.

158
00:07:49,750 --> 00:07:54,149
And we found plenty, we found a lot of projects, we actually had to kind of filter

159
00:07:54,450 --> 00:07:59,190
to, to look at uh uh analyze only projects that have certain amount of stars.

160
00:07:59,480 --> 00:08:00,450
Uh because, you know,

161
00:08:00,459 --> 00:08:03,820
otherwise there are so many projects that had the vulnerable code.

162
00:08:04,019 --> 00:08:05,779
But one thing that was

163
00:08:06,149 --> 00:08:07,369
obvious

164
00:08:07,799 --> 00:08:08,970
to us quickly is that

165
00:08:09,100 --> 00:08:13,660
we see the same kind of pattern, we see the same kind of code that is vulnerable

166
00:08:14,070 --> 00:08:15,420
in those Java projects.

167
00:08:15,649 --> 00:08:16,700
And it would always be

168
00:08:16,820 --> 00:08:16,829
a

169
00:08:16,980 --> 00:08:18,209
full implementation.

170
00:08:18,220 --> 00:08:21,549
You know, you would see that 60 lines of code that would, you know,

171
00:08:21,559 --> 00:08:26,209
read the create a zip object and then enumerate over the entries and then create,

172
00:08:26,329 --> 00:08:28,609
you know, output streams and write those

173
00:08:28,779 --> 00:08:31,750
instead of this one single line that you would expect to see,

174
00:08:31,760 --> 00:08:34,150
right when you extract a zip archive.

175
00:08:34,440 --> 00:08:35,630
And and so

176
00:08:36,010 --> 00:08:41,799
that's where we actually realize that there is something special about Java.

177
00:08:41,808 --> 00:08:44,369
Something happens in Java because all those projects

178
00:08:44,510 --> 00:08:46,580
and I'm talking about hundreds of projects

179
00:08:46,960 --> 00:08:52,979
uh had uh had that same snippet of code sort of, you know, different variations,

180
00:08:53,299 --> 00:08:57,179
but you know, pretty much the same snippet of code that was vulnerable.

181
00:08:57,309 --> 00:09:00,940
And so actually the documentation for in different uh

182
00:09:01,159 --> 00:09:03,250
uh archive libraries was vulnerable.

183
00:09:04,219 --> 00:09:08,359
And 19 out of 20 questions on stack

184
00:09:08,739 --> 00:09:12,299
overflow had vulnerable implementation, only one had, you know,

185
00:09:12,429 --> 00:09:12,969
good.

186
00:09:13,239 --> 00:09:14,000
So,

187
00:09:14,400 --> 00:09:16,820
so what what happened is that

188
00:09:17,640 --> 00:09:20,500
because and this is very specific to Java

189
00:09:20,940 --> 00:09:22,340
because um

190
00:09:23,349 --> 00:09:28,070
in, in Java, you didn't have the standard library there, the Java standard library

191
00:09:28,580 --> 00:09:30,989
and one of the most popular or the

192
00:09:31,000 --> 00:09:35,440
most popular java and archiving library from Apache Apache

193
00:09:35,450 --> 00:09:39,010
commons compressed didn't give you the simple method

194
00:09:39,020 --> 00:09:41,679
you can call to extract an archive file,

195
00:09:41,690 --> 00:09:42,500
a zip file,

196
00:09:42,729 --> 00:09:45,909
you kind of had to either implement it yourself.

197
00:09:45,919 --> 00:09:49,010
-- Sorry,
-- wait, Java didn't have a built in on zip.

198
00:09:49,020 --> 00:09:49,440
No

199
00:09:49,599 --> 00:09:50,690
downstairs. No,

200
00:09:51,119 --> 00:09:52,039
a single

201
00:09:52,270 --> 00:09:55,549
call. You cannot do a single call for. Yeah. And,

202
00:09:55,750 --> 00:09:55,849
and

203
00:09:56,590 --> 00:09:59,650
so obviously what would happen is that either you

204
00:09:59,659 --> 00:10:02,280
went and did the hard thing which is like,

205
00:10:02,289 --> 00:10:06,599
you know, understand how to do all this zip streams and like, you know, all the

206
00:10:06,739 --> 00:10:08,659
all the enumeration and, and you know,

207
00:10:08,669 --> 00:10:12,679
write your own code and probably still as a developer, not a security person,

208
00:10:12,690 --> 00:10:15,859
you had good chances to implement it, you know,

209
00:10:16,450 --> 00:10:17,549
wrongly, right?

210
00:10:17,559 --> 00:10:21,150
Not to take into account the fact that entries inside the

211
00:10:21,159 --> 00:10:23,500
zip can contain dot dot slashes and all of that,

212
00:10:23,510 --> 00:10:23,789
right?

213
00:10:23,919 --> 00:10:26,909
Or you do the simple thing that is Google

214
00:10:27,159 --> 00:10:29,450
and actually you, this is something you can try.

215
00:10:29,460 --> 00:10:32,460
Now if you write, you go now to Google and you write

216
00:10:32,799 --> 00:10:35,669
Java and zip file, OK?

217
00:10:36,070 --> 00:10:40,489
And click on five, you know, you'll see like several block posts giving you

218
00:10:40,719 --> 00:10:42,719
giving you the implementation, you'll see several stacker

219
00:10:43,130 --> 00:10:43,729
flow answers

220
00:10:43,849 --> 00:10:46,770
and you'll see that all of them are still vulnerable. And so

221
00:10:46,940 --> 00:10:49,840
this is funny to me because I we actually had a discussion

222
00:10:49,849 --> 00:10:52,520
a couple of years ago on the CV E board list about

223
00:10:52,789 --> 00:10:56,090
can we assign CV E documentation? Because there's a couple,

224
00:10:56,280 --> 00:10:59,169
there was a well known case of it was like a my SQL

225
00:10:59,179 --> 00:11:02,570
code snippet in like a textbook of all things or something where,

226
00:11:02,619 --> 00:11:04,969
yeah, it just, it was something horribly, horribly wrong

227
00:11:05,460 --> 00:11:08,099
and people keep using it because, well, it works right.

228
00:11:08,109 --> 00:11:09,859
But it's just insecure but it works.

229
00:11:10,559 --> 00:11:13,030
And, and honestly I've been thinking about this because,

230
00:11:13,460 --> 00:11:17,450
yeah, like, essentially we've got this, well, it's not code per se.

231
00:11:17,460 --> 00:11:19,070
It's code examples

232
00:11:19,469 --> 00:11:22,289
but people consume it as if it was like a library.

233
00:11:22,299 --> 00:11:25,090
They just cut and paste it into their application, which is, well,

234
00:11:25,099 --> 00:11:28,039
much worse because then it can never be updated unless they do.

235
00:11:28,099 --> 00:11:29,890
-- Exactly.
-- And that's, and in zip

236
00:11:30,090 --> 00:11:34,270
slip, you actually see that, you know, you see that vulnerable code that appears in

237
00:11:34,440 --> 00:11:36,890
apache's website. Well, it appeared back then

238
00:11:37,179 --> 00:11:40,594
and, and, and, and you can just see how it was copy pasted.

239
00:11:40,604 --> 00:11:45,005
It's amazing how every Java project that had something like, you know,

240
00:11:45,015 --> 00:11:50,234
had some functionality dealing with archives would have their own zip ut class

241
00:11:50,424 --> 00:11:52,715
that would include and zip, you know, and, and,

242
00:11:52,724 --> 00:11:57,565
and just being copy pasted from stuck overflow other open source projects.

243
00:11:57,854 --> 00:11:58,255
So

244
00:11:58,405 --> 00:12:00,875
the, the, the, the amazing thing is that, you know, when you,

245
00:12:00,885 --> 00:12:04,945
when you compare it to Python, for example, so in Python, in order to

246
00:12:05,299 --> 00:12:09,840
extract the zip archive, you need to do two things. First is do import zip file.

247
00:12:09,849 --> 00:12:12,479
And the second one is called zip file dot extract all.

248
00:12:12,710 --> 00:12:16,539
And you provide a zip file, right? And you provide the destination folder.

249
00:12:16,809 --> 00:12:19,130
And the interesting thing that the implementation of

250
00:12:19,140 --> 00:12:22,580
that function was vulnerable up until 2014.

251
00:12:22,940 --> 00:12:23,700
But

252
00:12:23,919 --> 00:12:28,539
as soon as it was fixed, you know, all the projects that utilize this functional,

253
00:12:28,549 --> 00:12:29,599
this this method

254
00:12:29,820 --> 00:12:31,440
were not vulnerable anymore.

255
00:12:31,950 --> 00:12:32,880
Unlike

256
00:12:33,090 --> 00:12:36,119
the situation we're having right now with Java, right

257
00:12:36,260 --> 00:12:37,169
is that

258
00:12:37,309 --> 00:12:39,619
it's like, so we know about the issue,

259
00:12:39,630 --> 00:12:44,390
we know how widespread it is but and we went and reached out to all those projects.

260
00:12:44,400 --> 00:12:45,929
But the in many of them,

261
00:12:45,940 --> 00:12:49,885
the code is still there and this thing being copy pasted and it's still, you know,

262
00:12:49,895 --> 00:12:50,835
the issue is still there.

263
00:12:50,844 --> 00:12:52,835
So it's like statically linking,

264
00:12:52,945 --> 00:12:53,215
you know,

265
00:12:53,224 --> 00:12:56,734
statically linking a library that is vulnerable and then you don't even know,

266
00:12:56,744 --> 00:12:59,585
have a way to know that you have this right

267
00:12:59,594 --> 00:13:02,054
and vulnerability in your code base unless you know,

268
00:13:02,065 --> 00:13:05,525
somebody knocks on your door or you listen to this podcast,

269
00:13:06,539 --> 00:13:07,070
right?

270
00:13:07,270 --> 00:13:10,419
Yeah. No, I've noticed that with sort of these, these very low level

271
00:13:10,599 --> 00:13:13,650
and I'm making big air quotes here, simple things.

272
00:13:13,659 --> 00:13:15,919
I mean, because this is what frustrates me is a lot of people, you know,

273
00:13:15,929 --> 00:13:20,380
think that unpacking a file is simple and well as you know,

274
00:13:20,630 --> 00:13:21,190
it's not,

275
00:13:21,200 --> 00:13:24,369
it's actually quite horrifically complicated in many cases because there's

276
00:13:24,570 --> 00:13:26,260
was this something I I, well,

277
00:13:26,270 --> 00:13:29,380
when we were working on Tar and looking at tars vulnerabilities, you know,

278
00:13:29,390 --> 00:13:30,700
or just all of these things.

279
00:13:31,260 --> 00:13:31,809
And

280
00:13:31,979 --> 00:13:34,260
I mean, the good news is at least people don't cut and paste tar code.

281
00:13:34,270 --> 00:13:34,809
But I mean,

282
00:13:34,859 --> 00:13:39,880
things like zip and uh XML parsing and I've seen a couple other cases where, yeah,

283
00:13:39,890 --> 00:13:40,690
people

284
00:13:40,950 --> 00:13:44,580
for, yeah, whatever reason, I guess the there's no well known library.

285
00:13:44,590 --> 00:13:46,039
So people do it themselves.

286
00:13:46,210 --> 00:13:49,989
Here's a fun question. Do you think there's an actual solution to this?

287
00:13:50,469 --> 00:13:51,570
Realistically?

288
00:13:51,869 --> 00:13:52,280
Yeah.

289
00:13:52,289 --> 00:13:55,090
So, so, so you know, like we, we actually seen it, seen, it,

290
00:13:55,099 --> 00:13:57,190
seen all kind of different issues.

291
00:13:57,200 --> 00:14:00,969
So one is the one I mentioned is that, you know,

292
00:14:01,059 --> 00:14:03,479
vulnerable code being just copy pasted.

293
00:14:03,489 --> 00:14:05,760
So snippets just, you know, they, they

294
00:14:05,869 --> 00:14:09,960
float around and people take like developers take them from, you know, stacker

295
00:14:10,099 --> 00:14:11,619
for other open source projects.

296
00:14:11,719 --> 00:14:12,169
And so

297
00:14:12,330 --> 00:14:15,849
they are, this is one kind of issue that the solution, you know,

298
00:14:15,859 --> 00:14:20,090
on our side would be to, you know, go and reach out to all of those developers,

299
00:14:20,099 --> 00:14:21,130
notify them

300
00:14:21,400 --> 00:14:24,859
and try to, you know, fix the issue and just get rid of this.

301
00:14:24,869 --> 00:14:28,450
So even when the project was, the vulnerability was not exploitable,

302
00:14:28,460 --> 00:14:30,239
it was it just had the vulnerable code,

303
00:14:30,250 --> 00:14:34,419
but the vulnerable code wasn't reached could not be reached by, you know, by

304
00:14:34,979 --> 00:14:36,200
militia by an attacker.

305
00:14:36,210 --> 00:14:37,729
It just, you know, some internal logic,

306
00:14:37,739 --> 00:14:40,450
we would still inform the project and ask them, you know,

307
00:14:40,780 --> 00:14:45,919
to just to, to add the extra two lines of code that would validate, right?

308
00:14:46,049 --> 00:14:49,719
And, and just to prevent future kind of, you know, misuse of, of that code.

309
00:14:49,909 --> 00:14:55,210
But the other thing we did is looked at, we focused on archiving library.

310
00:14:55,219 --> 00:14:57,419
So we we went to all those ecosystems

311
00:14:57,609 --> 00:15:01,609
and looked at the the libraries that their only

312
00:15:01,619 --> 00:15:03,960
purpose is to help you deal with archives.

313
00:15:04,289 --> 00:15:07,460
And sadly in Java, all of those were vulnerable.

314
00:15:07,469 --> 00:15:09,400
So in Java, not only you didn't have, you know,

315
00:15:09,409 --> 00:15:11,710
like standard library uh that you know,

316
00:15:11,719 --> 00:15:14,469
give you this one function you can call to extract the zip.

317
00:15:14,820 --> 00:15:17,070
But also those libraries that actually

318
00:15:17,250 --> 00:15:19,710
uh were less popular, but still they gave

319
00:15:19,820 --> 00:15:22,320
you this functionality, all of them were just vulnerable,

320
00:15:22,330 --> 00:15:24,580
three or four of them were vulnerable.

321
00:15:24,690 --> 00:15:30,919
And so, and, and, but the good news there is that as soon as those folks fix the issue,

322
00:15:30,929 --> 00:15:34,750
you know, just all the, all the consumers of the library just needed to upgrade.

323
00:15:34,760 --> 00:15:35,229
So that's

324
00:15:35,590 --> 00:15:39,440
an easier thing to do, you know, especially if you're, you know,

325
00:15:39,590 --> 00:15:44,650
using uh if you're managing your dependency with SNCC or with any other tool,

326
00:15:44,659 --> 00:15:46,289
it is something that you can, you know,

327
00:15:46,299 --> 00:15:49,669
you can get notified about immediately and you can fix.

328
00:15:49,679 --> 00:15:53,494
But with the, when compared to, you know, the first case where it's just, you know,

329
00:15:53,505 --> 00:15:58,635
copy pasted snippets in your code base, this is much harder issue to, to fix.

330
00:15:58,755 --> 00:16:00,465
And, and so yeah, and lastly,

331
00:16:00,594 --> 00:16:04,424
you know, there is this the solution also on the ecosystem level.

332
00:16:04,434 --> 00:16:08,664
So, you know, we compared Java and um you know, and Python.

333
00:16:08,960 --> 00:16:10,840
So I think Java and

334
00:16:11,099 --> 00:16:15,500
the one thing that should happen is that developers should have an easy way,

335
00:16:15,539 --> 00:16:17,140
you know, to to to use

336
00:16:17,320 --> 00:16:22,419
to open an archive, right? Sadly, Apache chose not to implement such function.

337
00:16:22,690 --> 00:16:27,950
I'm not sure why it was like, it sounded to me in the beginning like a very you know,

338
00:16:27,960 --> 00:16:30,500
theoretical discussion whether the library the

339
00:16:30,510 --> 00:16:32,789
Apache commons compressed library should do

340
00:16:32,799 --> 00:16:35,440
with compression compressor like is it

341
00:16:35,450 --> 00:16:38,150
the compression library or archiving library?

342
00:16:38,465 --> 00:16:39,554
They are a compression library,

343
00:16:39,565 --> 00:16:42,205
they deal with compression algorithms which is different than

344
00:16:42,344 --> 00:16:44,804
archiving, right, combining files together.

345
00:16:45,034 --> 00:16:49,465
But I think while maybe theoretically you know the definition,

346
00:16:49,474 --> 00:16:54,125
it's the compression library, I still think that such an API is something

347
00:16:54,549 --> 00:16:58,549
really important to have regardless of you know definitions

348
00:16:58,669 --> 00:17:01,169
because otherwise just developers get it wrong.

349
00:17:01,179 --> 00:17:06,260
And as an example, 16 Apache projects and I talk about Apache projects,

350
00:17:06,270 --> 00:17:08,709
not like other open source projects, got it wrong.

351
00:17:08,900 --> 00:17:13,969
Six of them were actually vulnerable. So with their own you know library.

352
00:17:13,979 --> 00:17:17,848
So this is just a good example of you know how how important

353
00:17:17,858 --> 00:17:22,089
is to have secure like good API that is like you know,

354
00:17:22,098 --> 00:17:23,569
secured by default, right?

355
00:17:23,828 --> 00:17:30,218
And so I think that that's a big step for Java to to do. And so oracle actually are

356
00:17:30,448 --> 00:17:33,229
working on, on introducing such a thing.

357
00:17:33,659 --> 00:17:39,318
And yeah, I think that's just, you know, will make the problem go away at some point

358
00:17:39,588 --> 00:17:42,308
like it, you know, like it did in, in in other places,

359
00:17:42,379 --> 00:17:46,298
one thing to note is that so.net actually have a

360
00:17:46,308 --> 00:17:49,788
really good implementation so that the implementation was secure,

361
00:17:49,798 --> 00:17:50,409
was safe,

362
00:17:50,689 --> 00:17:55,380
but the documentation was wrong. So they actually fixed it immediately there.

363
00:17:55,390 --> 00:17:57,640
They had uh they responded really quickly

364
00:17:57,900 --> 00:18:03,459
and uh one thing they did is is add another extra kind of protection

365
00:18:03,560 --> 00:18:04,030
that

366
00:18:04,280 --> 00:18:05,300
no other language,

367
00:18:05,310 --> 00:18:10,280
no other uh ecosystem uh did is to add another protection to actually, you know,

368
00:18:10,290 --> 00:18:12,150
disallow dot dot slashes in,

369
00:18:12,439 --> 00:18:13,750
in, in entry names

370
00:18:13,890 --> 00:18:15,160
uh by default.

371
00:18:15,170 --> 00:18:19,569
So you had to kind of, you know, ask for it if you, if you, if you, you are that, you know,

372
00:18:19,579 --> 00:18:23,410
having that special case, so which is really brave thing to do it,

373
00:18:23,420 --> 00:18:25,290
it's probably breaks some applications.

374
00:18:25,300 --> 00:18:26,339
But I think that's,

375
00:18:26,349 --> 00:18:29,550
that's an interesting and brave choice on their part kind of

376
00:18:29,560 --> 00:18:33,050
quick story about how we went about to disclose this because,

377
00:18:33,060 --> 00:18:33,680
you know, like we find

378
00:18:33,959 --> 00:18:34,729
hundreds

379
00:18:34,949 --> 00:18:36,500
of affected projects.

380
00:18:36,729 --> 00:18:40,630
And so, you know, we have like we have Oracle and Microsoft, like, you know,

381
00:18:40,640 --> 00:18:45,920
big players to, to, to uh to dispose to we have other popular open source projects.

382
00:18:45,930 --> 00:18:48,400
And then we have like a long long list of just open

383
00:18:48,430 --> 00:18:51,300
source projects that all we have of them on them is,

384
00:18:51,310 --> 00:18:54,130
you know, like that in email address, we can actually pull out of

385
00:18:54,280 --> 00:18:54,439
the G,

386
00:18:54,839 --> 00:18:55,219
right?

387
00:18:55,489 --> 00:19:00,609
So what we, we did, we, we chose the Google Project zero disclosure,

388
00:19:00,619 --> 00:19:02,150
the responsible Disclosure model.

389
00:19:02,319 --> 00:19:06,239
We we chose to go for a shorter period of 60 days just

390
00:19:06,250 --> 00:19:08,989
because there are so many projects and all of them are open source.

391
00:19:09,000 --> 00:19:09,550
So, you know,

392
00:19:09,869 --> 00:19:12,750
when they are being fixed, it's visible to everybody.

393
00:19:13,010 --> 00:19:17,640
So we kind of uh chose to make the disclosure window shorter

394
00:19:18,020 --> 00:19:21,890
and we started with uh disclosing to, you know, all the major companies,

395
00:19:21,900 --> 00:19:25,349
the ecosystem like we were calling and, and Microsoft

396
00:19:25,709 --> 00:19:28,089
and, and big companies. Uh and

397
00:19:28,219 --> 00:19:30,890
so, and, and the foundation Apache Foundation

398
00:19:31,180 --> 00:19:32,319
and uh people

399
00:19:32,430 --> 00:19:34,290
also so amazing was like, actually the cooper

400
00:19:34,449 --> 00:19:35,689
with Apache was great.

401
00:19:35,880 --> 00:19:39,569
They immediately created the group of people that, you know, triaged the whole

402
00:19:39,729 --> 00:19:42,089
all the projects on Apache and um

403
00:19:42,630 --> 00:19:44,920
managed the fixes on their part.

404
00:19:45,349 --> 00:19:45,400
People

405
00:19:45,579 --> 00:19:48,979
was, were amazing. We found the issue was found in, in, in the,

406
00:19:49,380 --> 00:19:50,959
in, in spring uh

407
00:19:51,060 --> 00:19:54,729
zip code and, and they just fixed it in within one day.

408
00:19:54,739 --> 00:19:56,900
This was amazing to see it just like one day

409
00:19:57,060 --> 00:20:00,849
including assigning a CV, which is like an amazing feed in itself.

410
00:20:01,160 --> 00:20:06,930
And so many, many big companies just, you know, surprisingly reacted to it quickly.

411
00:20:07,020 --> 00:20:08,810
But, but, but what I didn't

412
00:20:09,074 --> 00:20:11,265
is that we actually started with fixing the library.

413
00:20:11,275 --> 00:20:13,395
So all the libraries, the archiving libraries

414
00:20:13,545 --> 00:20:16,334
that were vulnerable, we, we reached out to them first.

415
00:20:16,344 --> 00:20:18,604
So when we, you know, they would,

416
00:20:18,944 --> 00:20:20,675
we made, we just wanted to make sure that

417
00:20:20,895 --> 00:20:24,094
the actual libraries that are popular that are used

418
00:20:24,104 --> 00:20:27,015
by developers would have a fixed version as,

419
00:20:27,094 --> 00:20:28,454
as soon as we go public.

420
00:20:28,680 --> 00:20:32,310
And I have to say that it, it created some challenges.

421
00:20:32,319 --> 00:20:34,920
Of course, there is quite a lot of work involved with, you know,

422
00:20:34,930 --> 00:20:37,140
managing the disclosure correspondence, you know,

423
00:20:37,150 --> 00:20:38,780
helping fix the issue and all that.

424
00:20:39,050 --> 00:20:41,500
But also some projects are, you know, just, you know,

425
00:20:41,670 --> 00:20:44,060
unmaintained. So some developers just, you know,

426
00:20:44,339 --> 00:20:49,500
they don't see the email, they just busy to, to, to, to actually to attend to it.

427
00:20:49,959 --> 00:20:51,140
And some

428
00:20:51,319 --> 00:20:56,079
developers didn't even know their project is the most popular archiving project,

429
00:20:56,089 --> 00:20:57,030
for example, in go

430
00:20:57,130 --> 00:20:58,219
ecosystem. So

431
00:20:58,410 --> 00:21:02,000
we reached out to a guy, we told them that there is an issue with his code and he's like,

432
00:21:02,010 --> 00:21:05,180
hey, like I wrote this code for myself several years ago.

433
00:21:05,390 --> 00:21:07,589
It shouldn't be, you know, production.

434
00:21:07,599 --> 00:21:08,540
And they're like, hey,

435
00:21:08,550 --> 00:21:13,319
this code is like the most popular goal archiving library now with like 1000 stars or

436
00:21:13,640 --> 00:21:16,500
so, we actually also helped fix the, you know,

437
00:21:16,510 --> 00:21:20,859
opening full request to some project just to make sure that uh when we go public,

438
00:21:20,869 --> 00:21:23,469
the libraries themselves are, are fixed.

439
00:21:23,479 --> 00:21:25,310
So we did that for Z four J

440
00:21:25,489 --> 00:21:28,400
and for archive and several others. So,

441
00:21:28,599 --> 00:21:30,130
so there was like about,

442
00:21:30,140 --> 00:21:34,109
I'd say 15 different archiving libraries among different ecosystems,

443
00:21:34,189 --> 00:21:36,099
most of them in Java, I'd say, but

444
00:21:36,349 --> 00:21:41,310
there were few in.net as well that, that we disclosed to first and help fix.

445
00:21:41,589 --> 00:21:46,689
And then as a last step, I'd say about 30 days before going public,

446
00:21:47,030 --> 00:21:49,739
we just automatically disclosed,

447
00:21:49,750 --> 00:21:53,609
send automatic emails with all the information pointing out to the, you know,

448
00:21:53,619 --> 00:21:54,079
to the github

449
00:21:54,260 --> 00:21:55,650
project with the,

450
00:21:55,660 --> 00:21:59,140
to the exact line having the vulnerability to hundreds of projects.

451
00:21:59,150 --> 00:22:00,060
This is something we did attic,

452
00:22:00,760 --> 00:22:02,609
it backfired a bit because

453
00:22:02,849 --> 00:22:05,050
we use mail gun and, you know,

454
00:22:05,935 --> 00:22:07,905
you know, it was paint like made then in

455
00:22:08,354 --> 00:22:08,954
MI

456
00:22:09,084 --> 00:22:09,854
five like shorten

457
00:22:10,025 --> 00:22:13,944
the URL. So a lot of folks thought we like, you know, we're,

458
00:22:14,194 --> 00:22:14,435
we're,

459
00:22:14,675 --> 00:22:17,905
we're sending this phishing emails and you know,

460
00:22:18,314 --> 00:22:20,805
there was like some, some some challenges about it,

461
00:22:20,814 --> 00:22:22,614
but we learned a lot of lessons from that.

462
00:22:22,625 --> 00:22:25,444
Well, I mean, my, my two thoughts, one on your short disclosure timeline is,

463
00:22:25,454 --> 00:22:29,425
as you said, this has been first publicly written about in Frack in 91 at least.

464
00:22:29,724 --> 00:22:31,974
Uh I quickly checked the CV database for

465
00:22:32,155 --> 00:22:34,295
directory traversal

466
00:22:34,739 --> 00:22:38,030
zip and there's like 100 and three entries going back to 2001.

467
00:22:38,089 --> 00:22:39,680
So, you know, at this point,

468
00:22:40,640 --> 00:22:41,239
yeah, it

469
00:22:41,839 --> 00:22:44,619
people don't know about this obviously or they would have fixed it, but

470
00:22:44,939 --> 00:22:46,180
they should have known about this.

471
00:22:46,189 --> 00:22:48,790
I would say, you know, like, well, and the second thing I find really interesting,

472
00:22:48,800 --> 00:22:50,969
I never really gave this as much thought as maybe I should have.

473
00:22:50,979 --> 00:22:54,199
But the lack of a standard library means obviously,

474
00:22:54,209 --> 00:22:55,410
people need that functionality.

475
00:22:55,420 --> 00:22:56,750
So they're going to implement it themselves.

476
00:22:56,760 --> 00:22:59,160
And if you have one person implement something,

477
00:22:59,170 --> 00:23:01,530
at least if it's wrong you have one place to fix it.

478
00:23:02,290 --> 00:23:06,229
But if 1000 people implement it now you have 1000 places to fix it,

479
00:23:06,339 --> 00:23:08,599
you know, and going to the Java example that, that's,

480
00:23:09,369 --> 00:23:13,040
I never really thought of this as a risk before, but it actually does seem

481
00:23:13,680 --> 00:23:15,680
like a very legitimate risk, you know,

482
00:23:15,900 --> 00:23:19,459
a, a missing sort of commonly needed standard library.

483
00:23:19,800 --> 00:23:20,099
Yeah.

484
00:23:20,270 --> 00:23:20,839
Yeah, exactly.

485
00:23:20,849 --> 00:23:26,520
And, and the thing is that like all of those implementation are exactly the same, not

486
00:23:27,579 --> 00:23:32,000
by a bit, but it's like, functionally, they all do the same thing. Exactly.

487
00:23:32,109 --> 00:23:34,770
You know, like the variable names are slightly different. You know,

488
00:23:35,140 --> 00:23:37,150
there is some slight differences in formatting,

489
00:23:37,160 --> 00:23:40,939
but essentially you're opening a zip file, you're traversing the, you know,

490
00:23:40,949 --> 00:23:43,750
the entries and then you're like writing the files

491
00:23:43,959 --> 00:23:45,560
and to your first point.

492
00:23:45,739 --> 00:23:47,010
So again, there is like,

493
00:23:47,020 --> 00:23:50,599
like the distinction between the type of vulnerability which was, you know, like

494
00:23:50,880 --> 00:23:55,329
it, the first mention of it was like really long ago in the frat magazine.

495
00:23:55,500 --> 00:23:58,180
And then, you know, we had so many CV S and there,

496
00:23:58,189 --> 00:24:00,949
there is like much more products are vulnerable

497
00:24:01,050 --> 00:24:03,800
to this issue than, you know, what's mentioned in CV.

498
00:24:03,949 --> 00:24:07,560
And, and so essentially for us, the disclosure meant, you know,

499
00:24:07,680 --> 00:24:12,180
making public the fact that a specific product is vulnerable, right?

500
00:24:12,189 --> 00:24:16,219
And that's the sensitive bit, that's what wasn't known before our research. So,

501
00:24:16,349 --> 00:24:17,099
so the type of one

502
00:24:17,444 --> 00:24:18,385
was definitely no,

503
00:24:18,665 --> 00:24:22,444
by the way, we chose to kind of we thought about it and it was like, OK,

504
00:24:22,454 --> 00:24:24,035
part of the reason is OK.

505
00:24:24,045 --> 00:24:26,915
So Java missed this part like Java kind of, you know,

506
00:24:26,925 --> 00:24:31,305
missed this bit about having this high level api for constructing archives.

507
00:24:31,314 --> 00:24:32,244
So so

508
00:24:32,364 --> 00:24:37,464
this is like somehow they manage like one of the oldest languages ever, right,

509
00:24:37,474 --> 00:24:38,545
somehow managed to miss it.

510
00:24:38,555 --> 00:24:43,444
But there is also lack of awareness to this kind of issue. So there's like

511
00:24:43,810 --> 00:24:47,310
security folks do know like they do know they

512
00:24:47,319 --> 00:24:49,239
like when they see the step of vulnerability,

513
00:24:49,250 --> 00:24:50,189
they immediately know

514
00:24:50,750 --> 00:24:52,819
but developers not so much. And

515
00:24:53,050 --> 00:24:55,150
and so we we we thought that

516
00:24:55,280 --> 00:24:58,949
we would want to kind of like increase increase awareness to this issue.

517
00:24:59,260 --> 00:24:59,910
And and

518
00:25:00,185 --> 00:25:01,185
one thing that

519
00:25:01,425 --> 00:25:04,964
jumped to mind is what we have with zip bomb, right?

520
00:25:04,974 --> 00:25:08,314
Like this kind of vulnerability that is denial of service vulnerability

521
00:25:08,564 --> 00:25:13,214
like in any kind of compression algorithm. When you know, like you, you compress,

522
00:25:13,405 --> 00:25:16,484
you take a huge chunk of data that is

523
00:25:16,800 --> 00:25:20,619
well compressed like the same character repeated over and over

524
00:25:20,750 --> 00:25:24,640
and then it is being compressed to a small chunk of data.

525
00:25:24,650 --> 00:25:29,949
But when it's being extracted in the server or in the destination, it just explodes,

526
00:25:29,959 --> 00:25:30,260
right?

527
00:25:30,489 --> 00:25:31,160
So this

528
00:25:31,300 --> 00:25:31,400
zip

529
00:25:31,859 --> 00:25:31,890
zip

530
00:25:32,510 --> 00:25:37,290
-- zip bomb like this is something that is, you know, this is a well known cons
-- yeah,

531
00:25:37,300 --> 00:25:38,819
the billion labs attack.

532
00:25:38,829 --> 00:25:43,089
Exactly. So the same thing with, you know, exactly the XML

533
00:25:43,199 --> 00:25:44,540
and, and, and, and so,

534
00:25:44,910 --> 00:25:49,069
and, but this time vulnerability, we felt like it's so prevalent. It's so, you know,

535
00:25:49,180 --> 00:25:50,819
like we see it in so many places.

536
00:25:51,050 --> 00:25:54,250
So it kind of, you know, deserved its own name.

537
00:25:54,550 --> 00:25:57,849
Also, we, like we had to find them, you know, to call this project,

538
00:25:57,859 --> 00:26:00,189
the name to call this project internally.

539
00:26:00,199 --> 00:26:00,449
So

540
00:26:00,770 --> 00:26:01,569
it started with

541
00:26:01,709 --> 00:26:03,619
zip sleep, but we also chose to kind of,

542
00:26:03,810 --> 00:26:07,790
you know, keep it up and just have it. And then the good thing that we already see,

543
00:26:07,890 --> 00:26:11,709
like, uh you know, it's being, it's, it's, it's a much more

544
00:26:11,959 --> 00:26:15,869
uh like, you know, understandable concept than

545
00:26:16,160 --> 00:26:21,349
arbitrary file right through, you know, directory traversal or whatever, like,

546
00:26:21,530 --> 00:26:26,390
and, and there is, if, if we actually looked at those 170 CBS you mentioned

547
00:26:26,930 --> 00:26:31,050
and the descriptions are very, very different, you know, in some cases,

548
00:26:31,060 --> 00:26:33,630
-- it would be like because
-- they're all written by different humans.

549
00:26:33,640 --> 00:26:38,469
That's the dirty secret to CV. It's all, it's all manually. Sorry about that folks.

550
00:26:38,479 --> 00:26:39,349
Exactly.

551
00:26:39,790 --> 00:26:40,630
And, and, and, and,

552
00:26:41,760 --> 00:26:45,180
and, and that, that's actually, you know, that's made us think about

553
00:26:45,410 --> 00:26:49,310
uh also like, how should we, you know, name those issues?

554
00:26:49,569 --> 00:26:50,069
And

555
00:26:50,280 --> 00:26:51,949
by the way, I have to say that. So

556
00:26:52,400 --> 00:26:55,989
thanks to you guys, we became AC N A, the CV numbering authority.

557
00:26:56,170 --> 00:26:56,750
And so

558
00:26:56,890 --> 00:27:01,780
the zip sleep vulnerabilities were the first one we assigned CV S to as

559
00:27:01,890 --> 00:27:05,790
yes, it's part of like being CN A. So that was also exciting for us.

560
00:27:05,800 --> 00:27:06,270
Well, and,

561
00:27:06,280 --> 00:27:08,989
and this is something I think important for people to realize like CV ES are great.

562
00:27:09,000 --> 00:27:10,359
Don't get me wrong. I love CV S

563
00:27:10,930 --> 00:27:13,689
but they're really more for computers than people, right?

564
00:27:13,699 --> 00:27:16,829
People don't talk about CV E dash here, dash whatever,

565
00:27:17,219 --> 00:27:17,750
you know,

566
00:27:17,959 --> 00:27:22,069
and with respect to zip slip, there is CWE the common, you know,

567
00:27:22,079 --> 00:27:24,949
weakness enumeration database, which is the idea is to

568
00:27:25,250 --> 00:27:27,369
classify all the different types of vulnerabilities.

569
00:27:27,380 --> 00:27:29,709
You know what is a buffer overflow versus a buffer underflow?

570
00:27:29,810 --> 00:27:31,380
And I'm just looking through it quickly,

571
00:27:32,079 --> 00:27:34,260
I can't tell which one I'm supposed to use for

572
00:27:34,270 --> 00:27:39,819
this vulnerability because there's CWE 23 35 36 3726 maybe.

573
00:27:40,219 --> 00:27:41,040
And so I,

574
00:27:41,069 --> 00:27:43,209
I think in a way this branding of these

575
00:27:43,219 --> 00:27:46,589
vulnerabilities really helps because the other thing is discoverability,

576
00:27:46,599 --> 00:27:46,750
right?

577
00:27:46,760 --> 00:27:48,770
If you plug zip slip into Google,

578
00:27:49,130 --> 00:27:51,709
you get, well, you get your, your research page,

579
00:27:51,719 --> 00:27:54,660
your FA Q essentially that covers it beautifully

580
00:27:55,729 --> 00:27:57,069
and it, you know,

581
00:27:57,489 --> 00:28:00,060
to put it bluntly, it's really easy to say to a developer.

582
00:28:00,069 --> 00:28:02,650
Please go Google Zip slip and read the first result.

583
00:28:02,660 --> 00:28:03,819
I can prove the point here,

584
00:28:03,829 --> 00:28:06,060
Kurt even what's the CV E for heart bleed

585
00:28:06,069 --> 00:28:08,859
like the most famous security issue of all time.

586
00:28:08,869 --> 00:28:15,310
The only CV I know off by heart is CV E 2016 9 triple five, also known as El Diablo,

587
00:28:15,319 --> 00:28:16,969
it was one of the first protocol vulnerability

588
00:28:17,083 --> 00:28:19,203
and TLS and it's because it broke our reporting

589
00:28:19,213 --> 00:28:21,623
system because we updated the report over 100 times

590
00:28:21,883 --> 00:28:23,503
and it turns out we had a counter for that.

591
00:28:23,792 --> 00:28:24,672
So some poor

592
00:28:24,802 --> 00:28:27,343
schmuck had to re enter all the data manually and then we

593
00:28:27,473 --> 00:28:29,503
updated it like another 60 times.

594
00:28:29,713 --> 00:28:30,782
-- But,
-- but that's

595
00:28:31,072 --> 00:28:31,223
exactly

596
00:28:31,442 --> 00:28:34,343
the reason to know that. Right. Like, no, I agree.

597
00:28:34,353 --> 00:28:37,603
I think naming things is, is good for humans and,

598
00:28:37,613 --> 00:28:41,812
and like this is a crazy issue that like what you say 100 and 70 CV es for this one,

599
00:28:41,822 --> 00:28:42,223
Danny.

600
00:28:42,593 --> 00:28:44,902
So, so these are the historic,

601
00:28:45,306 --> 00:28:48,595
I think you guys mentioned that like looking back at

602
00:28:48,605 --> 00:28:51,676
the C DS from the previous series from this one,

603
00:28:51,845 --> 00:28:56,786
we had about 30 CV S but they are still coming, right? Because

604
00:28:56,916 --> 00:29:01,615
some of those, for example, uh Microsoft just in the last patch,

605
00:29:01,625 --> 00:29:03,365
Tuesday then assigned to

606
00:29:03,786 --> 00:29:06,145
zip slip CV S one in powershell

607
00:29:06,365 --> 00:29:09,536
and another in.in dot net core.

608
00:29:09,546 --> 00:29:12,865
And so it took, it took half a year since the disclosure

609
00:29:13,180 --> 00:29:16,500
and just uh because they uh this is something

610
00:29:16,609 --> 00:29:20,829
actually like the thanks, like they, they found the issue,

611
00:29:21,099 --> 00:29:25,569
but because we kind of alerted them to, to the to the general issue of zip

612
00:29:25,760 --> 00:29:29,000
and several vulnerable projects, but they went and,

613
00:29:29,010 --> 00:29:32,170
and did some internal uh research and found a

614
00:29:32,180 --> 00:29:35,099
few other products that we weren't aware to.

615
00:29:35,380 --> 00:29:41,420
Uh And so they were nice enough to actually accredit us with the CV S. So this is uh

616
00:29:41,560 --> 00:29:45,209
so, so the CV S are still coming. I think we're now at about 30.

617
00:29:45,390 --> 00:29:49,390
But when it comes to number of vulnerable projects

618
00:29:49,560 --> 00:29:50,819
that already kind of

619
00:29:51,040 --> 00:29:53,540
uh you know, confirmed and fixed,

620
00:29:53,650 --> 00:29:58,229
they are much more and it's still kind of, you know, process of assigning those.

621
00:29:58,239 --> 00:30:00,709
So some are CNAs themselves like

622
00:30:01,119 --> 00:30:01,989
apaches. So we have

623
00:30:02,319 --> 00:30:07,500
and seek exploitable projects there. But I think so far, only four CV CV s

624
00:30:07,939 --> 00:30:12,569
but expecting to, to get that gather to assign as well.

625
00:30:12,859 --> 00:30:15,979
And the cool part is that we also created this skid

626
00:30:16,189 --> 00:30:17,689
hub uh page that

627
00:30:17,869 --> 00:30:21,430
basically a collaborative document for anyone to be able to

628
00:30:21,780 --> 00:30:23,130
add new,

629
00:30:23,140 --> 00:30:26,619
affected uh libraries affected the compression libraries

630
00:30:26,630 --> 00:30:28,130
or projects to the list there.

631
00:30:28,709 --> 00:30:29,300
And

632
00:30:29,729 --> 00:30:31,520
we're so happy to see

633
00:30:31,660 --> 00:30:32,800
several requests.

634
00:30:32,810 --> 00:30:35,869
So people found this issue in pearl in the pearl library,

635
00:30:35,880 --> 00:30:38,469
which we didn't actually had even the time to check.

636
00:30:38,770 --> 00:30:41,189
So in D code and D libraries

637
00:30:41,560 --> 00:30:45,229
and several others. So, so this was also a good

638
00:30:45,430 --> 00:30:48,510
sign for us that you know, like we raised raised awareness.

639
00:30:48,520 --> 00:30:49,349
So people actually you know,

640
00:30:49,359 --> 00:30:53,569
looked and see like how prevalent it is and actually did a simple thing like,

641
00:30:53,750 --> 00:30:55,589
you know, just checked the first li

642
00:30:55,819 --> 00:30:55,859
we

643
00:30:55,969 --> 00:30:58,239
stumbled upon that wasn't listed on our

644
00:30:58,569 --> 00:31:00,229
document and just found the

645
00:31:00,380 --> 00:31:02,189
bunch that were vulnerable. So

646
00:31:02,640 --> 00:31:06,560
also kind of some some good collaboration with the community and,

647
00:31:06,810 --> 00:31:12,619
and, and, and one other thing is that we see much more reports since we, you know,

648
00:31:12,630 --> 00:31:14,680
internally we track all those open source

649
00:31:14,689 --> 00:31:16,680
vulnerabilities and add them to our database.

650
00:31:16,689 --> 00:31:21,829
So we also see the zip slips that are, you know, coming not from us. And

651
00:31:22,050 --> 00:31:27,040
there is definitely an increase in in in the zip slips that are reported and fixed and

652
00:31:27,250 --> 00:31:29,130
in other product projects that

653
00:31:29,280 --> 00:31:33,829
unfortunately not code to directly to this github page that I mentioned.

654
00:31:34,119 --> 00:31:37,760
But still, you know, go through the disclosure channels and you know, being fixed.

655
00:31:37,770 --> 00:31:40,214
-- So that's, that's also great.
-- Fantastic. Oh

656
00:31:40,334 --> 00:31:41,935
man, that is so cool.

657
00:31:42,114 --> 00:31:44,694
So I, I guess we're, we're nearly out of time,

658
00:31:44,704 --> 00:31:48,494
but I wanted to ask you one more question and we'll make this one quick is so

659
00:31:48,734 --> 00:31:50,305
the, the other thing I love that SNCC

660
00:31:50,425 --> 00:31:53,734
does is the kind of state of open source security report,

661
00:31:53,744 --> 00:31:55,935
which the the current ones from 2017,

662
00:31:55,944 --> 00:31:58,295
you tell me you're working in your 2018 report and

663
00:31:58,834 --> 00:32:01,885
-- that thing is awesome. I love it.
-- Thank you. Thank you.

664
00:32:01,895 --> 00:32:07,405
And yeah, we are working on, on the next one, the 2018 and the plan is to, to uh

665
00:32:07,660 --> 00:32:09,520
publish it in mid February.

666
00:32:10,400 --> 00:32:10,459
We

667
00:32:10,670 --> 00:32:10,770
have to

668
00:32:10,910 --> 00:32:11,050
keep an eye

669
00:32:11,199 --> 00:32:11,489
out for that

670
00:32:11,609 --> 00:32:13,680
and I guess I want to talk about uh

671
00:32:13,959 --> 00:32:17,650
just, I guess, praise you guys for two important things is first of all,

672
00:32:17,729 --> 00:32:20,459
a lot of what we do in security is kind of voodoo and,

673
00:32:20,469 --> 00:32:23,839
and you guys are giving us some numbers to really look at, you know, which is,

674
00:32:23,849 --> 00:32:26,380
which is fantastic and, and I love that,

675
00:32:26,390 --> 00:32:29,439
but then most importantly is at the bottom of your report,

676
00:32:29,619 --> 00:32:31,800
you have action items people can take

677
00:32:32,020 --> 00:32:32,859
which like

678
00:32:33,020 --> 00:32:34,959
none of the reports I ever see that.

679
00:32:34,969 --> 00:32:37,439
Talk about the state of security, tell people what to do

680
00:32:37,729 --> 00:32:40,609
and, and I applaud you guys for that because it's like, OK, great.

681
00:32:40,619 --> 00:32:42,869
Everything's on fire. What now? Right? Like the end

682
00:32:43,270 --> 00:32:48,550
-- and, and that's awesome. So well
-- done. Thank you. Wow, that's so great to hear.

683
00:32:48,760 --> 00:32:52,119
I'm, I'm definitely passing this message to, to the folks work.

684
00:32:52,140 --> 00:32:55,670
I'm going to say I'm, I'm sure they, they, we're planning to keep it,

685
00:32:55,680 --> 00:32:58,109
but this is so good to hear that, that feedback.

686
00:32:58,180 --> 00:33:01,109
-- Thank you.
-- I love that. Awesome. Awesome. So, I guess,

687
00:33:01,369 --> 00:33:03,189
yeah, let's say any, any clothing

688
00:33:03,422 --> 00:33:05,542
first, Dan, before we, we head out.

689
00:33:05,552 --> 00:33:10,123
Um Wow, this was first of all, like, I really, really enjoyed the conversation.

690
00:33:10,133 --> 00:33:11,142
It took us, indeed.

691
00:33:11,152 --> 00:33:15,463
It took us so long to get to talk, but I definitely hope that's not,

692
00:33:15,473 --> 00:33:17,243
that wouldn't be our last conversation.

693
00:33:17,253 --> 00:33:21,343
So, so uh would be really happy to, to keep on talking,

694
00:33:22,262 --> 00:33:25,503
collaborating on all the, you know, open source security stuff.

695
00:33:25,512 --> 00:33:28,022
Yeah, I think I really had fun. So

696
00:33:28,282 --> 00:33:28,373
uh

697
00:33:28,836 --> 00:33:32,446
-- thank you. Thank you so much.
-- Thank you. It's been fantastic.

698
00:33:32,456 --> 00:33:35,735
I can't wait to have you back, man. So, all right, cool. So, I guess thank you, Danny.

699
00:33:35,745 --> 00:33:38,826
Thank you everyone for listening. You can go to open source security podcast.com.

700
00:33:38,836 --> 00:33:41,086
I'll have show notes for all this stuff. Danny talked about.

701
00:33:41,265 --> 00:33:43,375
I'll have links to things like his Twitter and linkedin and

702
00:33:43,385 --> 00:33:45,485
all the usual suspects and then you can use the pound

703
00:33:45,635 --> 00:33:49,235
to podcast. Hashtag Hit us up on social media and you have nothing else, I guess.

704
00:33:49,245 --> 00:33:52,306
-- Uh, gentlemen, have a fantastic rest of your day.
-- You too.

705
00:33:52,316 --> 00:33:53,416
-- Thank you.
-- Thank you.

706
00:33:53,426 --> 00:33:54,286
Goodbye.