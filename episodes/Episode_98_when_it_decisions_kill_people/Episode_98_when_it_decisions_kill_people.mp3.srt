0
00:00:05,320 --> 00:00:09,539
Hello and welcome to episode 98 of the open source security podcast with myself,

1
00:00:09,550 --> 00:00:11,350
Kurt Siefried and my partner in Thought Crime.

2
00:00:11,359 --> 00:00:12,310
Josh Pressers.

3
00:00:12,569 --> 00:00:15,640
It has just been one of those weeks. You know that?

4
00:00:16,129 --> 00:00:16,659
Oh, yeah.

5
00:00:17,459 --> 00:00:21,969
And everything from the horrible security news to the fact that this is

6
00:00:21,979 --> 00:00:26,129
uh episode 98 take two because I screwed up the first one.

7
00:00:27,709 --> 00:00:28,000
But,

8
00:00:28,100 --> 00:00:30,620
-- um, and
-- I love that when you finally got your real microphone working.

9
00:00:30,629 --> 00:00:32,180
I'm like, wait, what happened to your voice?

10
00:00:32,479 --> 00:00:34,659
Yes, that's right. I sound exciting now.

11
00:00:35,470 --> 00:00:38,409
Oh, my goodness. Anyway, anyway,

12
00:00:38,619 --> 00:00:41,110
I guess the good news is we haven't killed anybody this week

13
00:00:41,240 --> 00:00:41,700
not to make

14
00:00:41,840 --> 00:00:41,900
light.

15
00:00:42,180 --> 00:00:42,610
But

16
00:00:43,360 --> 00:00:46,110
I, I just, ok, we have to lead with this because this,

17
00:00:46,139 --> 00:00:48,090
do you want to read the quote or shall I?

18
00:00:48,279 --> 00:00:49,330
I'll let you do it.

19
00:00:49,540 --> 00:00:54,169
Ok. So this is from the N TSB crash, uh preliminary crash report.

20
00:00:54,180 --> 00:00:55,630
So the N TSB, the National Transport

21
00:00:56,060 --> 00:00:56,139
should

22
00:00:56,259 --> 00:00:59,090
-- clarify.
-- This is the Uber crash. That was

23
00:00:59,470 --> 00:01:05,330
as far as we know the, the first self driving car to like hit in and kill a human.

24
00:01:05,430 --> 00:01:06,209
Well, I,

25
00:01:06,620 --> 00:01:10,129
I would say that it's, well, we'll get into that.

26
00:01:10,379 --> 00:01:10,849
So

27
00:01:11,900 --> 00:01:14,239
according to Uber, the agency said, quote,

28
00:01:14,250 --> 00:01:17,580
emergency braking maneuvers are not enabled while the vehicle is under

29
00:01:17,589 --> 00:01:20,889
computer control to reduce the potential for erratic vehicle behavior.

30
00:01:21,129 --> 00:01:24,809
The vehicle operator is relied on to intervene and take action.

31
00:01:25,029 --> 00:01:28,660
The system is not designed to alert the operator. End quote.

32
00:01:29,779 --> 00:01:31,970
I don't even know what to say about that.

33
00:01:32,120 --> 00:01:35,709
-- Well, they designed a system that will kill somebody is what they did.
-- Seriously.

34
00:01:35,720 --> 00:01:38,970
I mean, I read that three times when you sent it to me and thought this,

35
00:01:38,980 --> 00:01:40,559
this has got to be a typo.

36
00:01:41,300 --> 00:01:42,720
It's crazy.

37
00:01:43,519 --> 00:01:43,930
Yeah.

38
00:01:43,940 --> 00:01:47,699
Well, and what's even worse though is if you read the full uh preliminary report,

39
00:01:48,410 --> 00:01:49,129
um,

40
00:01:49,949 --> 00:01:54,360
they have a system in the console that the, like, so the human operator is,

41
00:01:54,370 --> 00:01:57,500
is responsible for sort of reading output on this console

42
00:01:57,510 --> 00:02:00,110
system because when you see the video of the guy,

43
00:02:00,120 --> 00:02:02,389
he's like looking down and I'm like, is he on his phone,

44
00:02:02,400 --> 00:02:04,620
like going on reddit or something while he's, you know,

45
00:02:04,629 --> 00:02:05,870
supposed to be monitoring the system?

46
00:02:05,879 --> 00:02:07,699
No, he's actually doing his job, which is

47
00:02:07,819 --> 00:02:10,460
looking down at the console and interacting with it in the sense of

48
00:02:10,919 --> 00:02:14,410
he's supposed to flag interesting events for later review and stuff.

49
00:02:14,550 --> 00:02:18,380
So not only so, so you have a system that can fail

50
00:02:18,500 --> 00:02:21,119
and if it fails, it doesn't warn the human

51
00:02:21,429 --> 00:02:26,880
and the human is expected to take over and the human already has a high cognitive load

52
00:02:27,309 --> 00:02:29,080
in that they're supposed to be doing other stuff like

53
00:02:29,089 --> 00:02:31,869
interacting with this console that they have to look down at

54
00:02:32,309 --> 00:02:33,860
like this is crazy.

55
00:02:34,139 --> 00:02:38,740
So like the the human beings, situational awareness cannot be sufficient.

56
00:02:39,009 --> 00:02:40,820
Well, and and and it clearly wasn't right?

57
00:02:40,830 --> 00:02:43,869
Because the poor guy, you see him look up and just the horror on his face, right?

58
00:02:44,139 --> 00:02:45,740
You know, he just doesn't have time

59
00:02:46,259 --> 00:02:46,830
to react.

60
00:02:47,220 --> 00:02:47,229
Oh

61
00:02:47,339 --> 00:02:48,110
my goodness.

62
00:02:48,490 --> 00:02:48,660
And

63
00:02:49,080 --> 00:02:52,600
I, so yeah, this is a, this is a perfect example of like,

64
00:02:52,610 --> 00:02:56,610
literally I read this and I'm like, this has to end in death.

65
00:02:56,619 --> 00:02:59,589
There's, there's statistically there's no other outcome,

66
00:03:00,639 --> 00:03:03,580
but you just can't get lucky enough for the system not to fail at some point.

67
00:03:06,600 --> 00:03:07,580
Yeah. It, I,

68
00:03:08,070 --> 00:03:10,320
I guess this is one of the,

69
00:03:11,050 --> 00:03:12,580
the problems with

70
00:03:12,940 --> 00:03:17,660
putting like real things, interacting with societies, historically speaking,

71
00:03:17,720 --> 00:03:20,279
most of our computer systems have kind of been off in

72
00:03:20,289 --> 00:03:22,649
a server room and they didn't make a huge difference and,

73
00:03:22,660 --> 00:03:24,520
and, you know, putting in my security hat,

74
00:03:24,839 --> 00:03:25,809
if you get hacked,

75
00:03:26,330 --> 00:03:28,550
nobody dies, it doesn't really matter. Right?

76
00:03:28,559 --> 00:03:31,250
But now that we have like things in the world,

77
00:03:31,679 --> 00:03:33,979
it does matter and it is a big deal.

78
00:03:34,179 --> 00:03:34,720
I think Schneier

79
00:03:34,839 --> 00:03:36,770
put it best. These aren't computers

80
00:03:36,880 --> 00:03:40,639
with stuff, this is stuff with a computer. This is a car,

81
00:03:41,000 --> 00:03:44,000
this is a fridge with a computer. This is a chemical plant with a computer,

82
00:03:44,500 --> 00:03:44,800
right?

83
00:03:44,809 --> 00:03:47,910
This isn't a computer just hooked up to some, you know,

84
00:03:47,919 --> 00:03:49,570
fridge doing something cutesy.

85
00:03:49,580 --> 00:03:53,250
No, this is legitimately like, uh, how much does this vehicle weigh?

86
00:03:53,570 --> 00:03:54,449
Um,

87
00:03:55,660 --> 00:04:00,789
yeah, it's, it's a 2017 Volvo XC 90 which is a pretty damn big heavy car.

88
00:04:01,259 --> 00:04:04,320
And, I mean, when you think about the kinetic energy of that thing doing, like,

89
00:04:04,699 --> 00:04:05,899
uh, what was it doing?

90
00:04:06,169 --> 00:04:08,119
47 miles an hour or something?

91
00:04:08,610 --> 00:04:09,830
I, I have no idea.

92
00:04:09,839 --> 00:04:12,929
I, I purposely not looked into this too much just because it's, it's,

93
00:04:12,940 --> 00:04:17,548
it's horrifying to me and, and I don't want to watch any of the videos or,

94
00:04:17,559 --> 00:04:18,950
or learn too much, I guess.

95
00:04:18,959 --> 00:04:19,380
Yeah.

96
00:04:19,709 --> 00:04:21,619
Um, yeah, the speed limit there was 45

97
00:04:22,010 --> 00:04:22,149
MPH.

98
00:04:22,160 --> 00:04:22,730
So, yeah, I mean,

99
00:04:22,739 --> 00:04:26,929
you do the math and the kinetic energy of this thing is considerable.

100
00:04:26,940 --> 00:04:30,869
Right? As well. You look at, well, the, the Toronto uh truck attack,

101
00:04:31,179 --> 00:04:31,410
right?

102
00:04:31,420 --> 00:04:34,790
This guy drove a truck down the sidewalk trying to drive over women and killed,

103
00:04:34,799 --> 00:04:36,070
you know, about a dozen people.

104
00:04:37,019 --> 00:04:37,500
Right.

105
00:04:38,049 --> 00:04:41,179
Um, but looking at this, I mean, this is literally,

106
00:04:42,510 --> 00:04:43,170
you know,

107
00:04:43,660 --> 00:04:47,489
so classical engineers like mechanical engineers and chemical engineers,

108
00:04:47,500 --> 00:04:48,079
you know, they,

109
00:04:48,450 --> 00:04:51,329
there's a reason it's hard to become one of them and there's

110
00:04:51,339 --> 00:04:54,929
a reason you have designations like professional engineer that can then,

111
00:04:54,940 --> 00:04:57,929
you know, sign off on plans that are then built

112
00:04:58,489 --> 00:05:02,140
like bridges and chemical plants, right? Because if those things are built wrong,

113
00:05:02,359 --> 00:05:03,809
they collapse and people die.

114
00:05:04,149 --> 00:05:04,940
Yep. Yep.

115
00:05:05,130 --> 00:05:08,239
This is a perfect example of something where, I don't know what's worse.

116
00:05:08,250 --> 00:05:09,700
Did somebody know that this is like,

117
00:05:09,709 --> 00:05:11,820
did somebody at Uber consciously make this decision

118
00:05:12,029 --> 00:05:14,540
or, you know, was it kind of like the original, uh,

119
00:05:14,549 --> 00:05:16,679
remember the iphone with the external antenna that

120
00:05:16,690 --> 00:05:18,260
had a problem with how you hold it?

121
00:05:18,630 --> 00:05:21,450
Right. No. So was this a case of where, like two different groups?

122
00:05:21,459 --> 00:05:23,600
Like one group is like, oh, let's disable emergency braking.

123
00:05:23,609 --> 00:05:26,260
So we don't keep getting rear ended, right? Because every time like

124
00:05:26,450 --> 00:05:28,660
the computer sees something funny, like a shopping bag,

125
00:05:28,670 --> 00:05:31,709
it's gonna like come to a screeching halt and then you're gonna get rear ended.

126
00:05:31,720 --> 00:05:31,790
Like,

127
00:05:31,799 --> 00:05:34,320
because Google has discovered right now that they're recording

128
00:05:34,329 --> 00:05:36,119
how often they get rear ended at red lights.

129
00:05:37,019 --> 00:05:37,600
Um,

130
00:05:38,070 --> 00:05:38,579
you know,

131
00:05:39,100 --> 00:05:42,109
and conversely then the other group was like, oh, you know,

132
00:05:42,119 --> 00:05:47,950
the operator will take action uh, when something bad happens and, um,

133
00:05:48,119 --> 00:05:48,320
you know,

134
00:05:48,329 --> 00:05:50,760
whoever's working on the U I will probably make

135
00:05:50,769 --> 00:05:52,720
sure that they know that they should be doing something

136
00:05:54,160 --> 00:05:55,459
and, and it just didn't happen.

137
00:05:55,470 --> 00:05:59,339
So I like, I don't know what's worse that they, that they built this system

138
00:05:59,829 --> 00:06:03,089
and consciously made this choice that resulted in a death

139
00:06:03,359 --> 00:06:04,019
or

140
00:06:04,209 --> 00:06:04,630
they

141
00:06:05,299 --> 00:06:07,269
didn't have enough, you know,

142
00:06:08,040 --> 00:06:10,179
control an insight over what they were building to

143
00:06:10,190 --> 00:06:11,980
realize that this was going to be a problem.

144
00:06:12,170 --> 00:06:15,220
It's almost certainly the case of multiple groups

145
00:06:15,230 --> 00:06:17,660
not understanding what the other groups are doing

146
00:06:18,429 --> 00:06:22,140
because let's face it, nobody is going to make a conscious decision

147
00:06:22,250 --> 00:06:23,290
to do this.

148
00:06:23,540 --> 00:06:24,350
This is just, well,

149
00:06:24,359 --> 00:06:27,390
-- they
-- might if they didn't understand it because remember the Challenger disaster,

150
00:06:28,540 --> 00:06:30,399
they made a conscious decision to launch

151
00:06:31,130 --> 00:06:33,700
when the old rings had been subjected to a temperature

152
00:06:33,709 --> 00:06:35,260
that was colder than they were rated for blah,

153
00:06:35,269 --> 00:06:35,989
blah, blah, blah, blah.

154
00:06:36,690 --> 00:06:38,799
And, yeah, they, they made a conscious decision.

155
00:06:38,809 --> 00:06:42,209
You know, there's that one infamous powerpoint slide, you know, oh,

156
00:06:42,220 --> 00:06:43,130
what's the guy's name?

157
00:06:43,140 --> 00:06:45,790
The uh, information display guy Tufty,

158
00:06:46,450 --> 00:06:48,799
right. Edward Tufty. I've got all these books. They're beautiful

159
00:06:48,980 --> 00:06:49,489
and, you know,

160
00:06:49,500 --> 00:06:52,570
like literally one bad powerpoint slide and a decision by

161
00:06:52,579 --> 00:06:55,000
some managers to keep to the schedule and voila.

162
00:06:56,450 --> 00:06:56,899
Right?

163
00:06:57,170 --> 00:07:01,260
And, and it, it, it can happen. But again, that was, that was a mistake,

164
00:07:01,589 --> 00:07:02,579
right? And that was,

165
00:07:03,329 --> 00:07:08,269
this is almost certainly a mistake. I guarantee. Nobody said we need to do this.

166
00:07:08,559 --> 00:07:09,290
This is the result

167
00:07:09,480 --> 00:07:11,880
of poor communication and let's face it.

168
00:07:11,890 --> 00:07:16,160
The vast majority of accidents in the world are the result of poor communication.

169
00:07:16,600 --> 00:07:16,950
Right.

170
00:07:17,119 --> 00:07:17,679
Yeah.

171
00:07:17,690 --> 00:07:21,200
Well, that's, yeah, when I was binge watching all of those airline disaster things,

172
00:07:21,559 --> 00:07:23,779
it, it seems to really boil down to a couple of core things.

173
00:07:23,790 --> 00:07:25,869
Number one, not doing maintenance correctly and,

174
00:07:25,880 --> 00:07:28,649
and quite often the root cause of not doing maintenance correctly is, you know,

175
00:07:28,660 --> 00:07:30,700
people don't know how to do it correctly or they,

176
00:07:31,380 --> 00:07:34,429
in one case they, yeah, they didn't communicate the day shift and the night shift,

177
00:07:34,440 --> 00:07:35,880
the night shift took out a bunch of bolts

178
00:07:36,339 --> 00:07:37,309
and the day shift, like,

179
00:07:37,320 --> 00:07:39,940
literally didn't put them back in because they weren't told that they were taken out

180
00:07:40,440 --> 00:07:43,019
and like the, the, the, the, the rear

181
00:07:43,369 --> 00:07:46,720
Aron of the plane fell off funnily enough because, you know, if it's not bolted on,

182
00:07:46,730 --> 00:07:47,739
it will fall off.

183
00:07:47,750 --> 00:07:48,750
Imagine that.

184
00:07:49,190 --> 00:07:50,040
And so,

185
00:07:50,209 --> 00:07:54,339
you know, and then the next big one seems to be losing situational awareness, right?

186
00:07:54,350 --> 00:07:55,980
Where something happens and they,

187
00:07:55,989 --> 00:07:59,140
they focus on the wrong things like that plane that crashed into the Everglades,

188
00:07:59,529 --> 00:08:03,420
you know, about 60 years ago, because they were fiddling with a broken fuse.

189
00:08:05,019 --> 00:08:05,600
Wow.

190
00:08:05,869 --> 00:08:06,160
Right.

191
00:08:06,170 --> 00:08:07,519
And they spent so much time and effort,

192
00:08:07,529 --> 00:08:09,970
mentally fiddling with this broken fuse and trying to deal with it.

193
00:08:10,339 --> 00:08:12,320
But yeah, they crashed into the Everglades.

194
00:08:12,540 --> 00:08:13,079
Um

195
00:08:14,160 --> 00:08:16,019
Yeah, so, yeah, fundamentally a lot of this is,

196
00:08:16,029 --> 00:08:19,100
is bad communication and lack of situational awareness.

197
00:08:19,109 --> 00:08:19,220
And

198
00:08:19,929 --> 00:08:20,640
yeah, I just

199
00:08:20,760 --> 00:08:23,929
ii I literally don't know what to say at this point because this is a,

200
00:08:23,959 --> 00:08:27,549
a really great example of how not to build

201
00:08:27,850 --> 00:08:31,709
a system because like the system has a failed deadly condition.

202
00:08:32,020 --> 00:08:33,669
You know, it encounters an emergency

203
00:08:33,869 --> 00:08:34,349
and

204
00:08:34,669 --> 00:08:37,369
trusts a human to react to it. But doesn't tell the human,

205
00:08:37,539 --> 00:08:40,030
nobody's going to disagree with you.

206
00:08:40,150 --> 00:08:41,750
That that's a huge problem.

207
00:08:42,150 --> 00:08:45,130
But unfortunately, in many instances like this,

208
00:08:45,140 --> 00:08:48,549
this is what happens is something fails,

209
00:08:48,559 --> 00:08:51,479
it gets studied and you make sure it never happens again.

210
00:08:52,219 --> 00:08:53,429
Well, and to that point, for example,

211
00:08:53,440 --> 00:08:56,330
I'm going to be proposing ac we identifier for this where,

212
00:08:56,340 --> 00:08:57,590
because this is an increasing thing

213
00:08:57,599 --> 00:09:00,450
where we have these human computer interactions

214
00:09:00,969 --> 00:09:02,409
and we don't fully understand them yet

215
00:09:02,669 --> 00:09:03,809
because this is all new.

216
00:09:04,429 --> 00:09:07,450
Yeah, I mean, it's, it's totally accurate, I think, and,

217
00:09:07,460 --> 00:09:08,969
and historically speaking,

218
00:09:09,820 --> 00:09:12,419
most security issues

219
00:09:12,919 --> 00:09:16,880
were, were caused by a computer just sitting there doing nothing specifically.

220
00:09:16,890 --> 00:09:17,729
There's some right.

221
00:09:17,739 --> 00:09:20,419
There's like some cross site scripting and things, but generally speaking,

222
00:09:20,429 --> 00:09:21,760
we still blame the machine,

223
00:09:22,130 --> 00:09:25,099
right? We don't blame the interaction in many instances.

224
00:09:25,219 --> 00:09:28,200
There have been some things with what like URL S showing

225
00:09:28,419 --> 00:09:29,359
the wrong.

226
00:09:29,500 --> 00:09:31,739
Well, I shouldn't say wrong but we'll say confusing

227
00:09:31,890 --> 00:09:34,000
domain names for example. But,

228
00:09:34,239 --> 00:09:38,280
but even then we tend to blame the machine more than the interaction, right?

229
00:09:38,700 --> 00:09:39,000
Yeah.

230
00:09:39,099 --> 00:09:40,929
Well, it's uh there was that recent video,

231
00:09:40,940 --> 00:09:44,039
remember of that ski lift just destroying itself.

232
00:09:44,169 --> 00:09:47,380
And apparently what happened is the uh there was a power outage and

233
00:09:47,390 --> 00:09:50,580
then they didn't kind of bring the ski lift back online correctly.

234
00:09:50,590 --> 00:09:51,979
Like they basically hit the wrong buttons

235
00:09:52,090 --> 00:09:53,469
and somebody pointed out that,

236
00:09:54,390 --> 00:09:56,539
I mean, this is a modern computerized ski lift.

237
00:09:56,549 --> 00:09:58,690
This isn't some like 50 year old piece of garbage.

238
00:09:59,109 --> 00:10:01,650
But if you build a computer system that can experience

239
00:10:01,969 --> 00:10:05,929
a, a reasonably typical fault condition of, you know, the power is lost

240
00:10:06,119 --> 00:10:06,640
because

241
00:10:06,750 --> 00:10:09,570
that is a pretty common fault condition that and if you,

242
00:10:09,580 --> 00:10:12,169
you don't do the exact right steps to bring it back online, it like,

243
00:10:12,179 --> 00:10:13,609
basically destroys itself.

244
00:10:13,700 --> 00:10:15,710
You, you can't really blame the humans for that.

245
00:10:15,719 --> 00:10:19,049
Like somebody built a system that was going to fail at some point,

246
00:10:19,710 --> 00:10:20,210
you know.

247
00:10:20,650 --> 00:10:20,669
Yeah,

248
00:10:21,049 --> 00:10:21,809
totally, man.

249
00:10:22,090 --> 00:10:22,950
Right. And that's why we have,

250
00:10:23,869 --> 00:10:26,729
you know, and, and I get that some systems are so complex.

251
00:10:27,340 --> 00:10:31,929
It's really hard to define a fail safe condition like an oil refinery or, you know,

252
00:10:31,940 --> 00:10:35,299
like things that are just massive, like do you want that valve open or shut?

253
00:10:35,309 --> 00:10:36,950
Right? If you suddenly shut the valve,

254
00:10:37,200 --> 00:10:38,330
the, the, the,

255
00:10:38,340 --> 00:10:41,210
the fluid or whatever flowing towards it might burst

256
00:10:41,219 --> 00:10:42,719
the pipe if it's at a certain speed,

257
00:10:42,729 --> 00:10:42,890
right?

258
00:10:42,900 --> 00:10:46,090
Because it hits that closed valve and you know what, right physics

259
00:10:46,849 --> 00:10:51,710
and so, you know, like things like, for example, self driving cars, yeah, I mean,

260
00:10:51,719 --> 00:10:54,440
it's screeching to a stop, a fail safe condition.

261
00:10:54,450 --> 00:10:54,830
Well,

262
00:10:55,010 --> 00:10:58,590
yet not if you're on the highway that can actually be really bad in daylight,

263
00:10:58,599 --> 00:10:59,159
you know, maybe,

264
00:10:59,500 --> 00:11:02,750
maybe it's better to run over that rabbit, like sucks to be the rabbit, but,

265
00:11:03,150 --> 00:11:03,849
you know, better than

266
00:11:04,080 --> 00:11:05,950
slamming on your brakes and heavy traffic.

267
00:11:06,289 --> 00:11:09,070
So, yeah, defining a fail safe condition can be difficult.

268
00:11:09,080 --> 00:11:11,150
And that maybe that's part of what happened here, right? Is they,

269
00:11:11,630 --> 00:11:12,489
they, you know,

270
00:11:12,500 --> 00:11:14,840
decided that the slamming on your brakes and getting

271
00:11:14,849 --> 00:11:16,770
rear ended constantly was not the way to go.

272
00:11:16,780 --> 00:11:17,109
Well.

273
00:11:17,119 --> 00:11:18,090
No, you know, you know what,

274
00:11:18,099 --> 00:11:22,400
this is actually the first thing I thought of is it was what one or two episodes ago,

275
00:11:22,409 --> 00:11:24,169
we were discussing automation

276
00:11:24,590 --> 00:11:25,070
and

277
00:11:25,270 --> 00:11:27,799
automation basically either has to be all or none.

278
00:11:27,900 --> 00:11:32,919
And expecting humans to be involved in any way is, is failure is the only option.

279
00:11:32,929 --> 00:11:34,570
And this is exactly that

280
00:11:34,739 --> 00:11:38,530
if, if the car had been able to make all of the decisions on its own,

281
00:11:38,619 --> 00:11:40,809
we wouldn't be having this conversation right now.

282
00:11:41,409 --> 00:11:42,229
But because

283
00:11:42,409 --> 00:11:44,400
they decided to let a human interact and

284
00:11:44,409 --> 00:11:46,150
then there was a breakdown in communication.

285
00:11:46,349 --> 00:11:48,989
Now we're having this horrible conversation.

286
00:11:49,510 --> 00:11:51,159
Well, and here's the brutal truth. Right.

287
00:11:51,169 --> 00:11:54,429
They could have Uber could in theory create like a,

288
00:11:54,599 --> 00:11:58,609
you know, create a range for them to test on like a closed circuit

289
00:11:58,830 --> 00:12:02,000
and have, you know, like those, those cardboard things on tracks, you know,

290
00:12:02,010 --> 00:12:03,530
that get pulled out, like, you know, in the old

291
00:12:03,640 --> 00:12:05,500
movies where the kids are doing drivers. Right.

292
00:12:05,510 --> 00:12:07,669
And the little like girl on a bicycle,

293
00:12:07,679 --> 00:12:09,929
cardboard thing pops out and they run over it and they're like,

294
00:12:10,369 --> 00:12:10,580
uh,

295
00:12:10,799 --> 00:12:14,330
but, you know, they could have done that. They could have built a closed range that's

296
00:12:14,580 --> 00:12:16,030
like with no humans on it.

297
00:12:16,440 --> 00:12:17,760
I did. They though, it

298
00:12:17,900 --> 00:12:17,979
wouldn't

299
00:12:18,250 --> 00:12:18,349
surprise

300
00:12:18,489 --> 00:12:19,380
me. They did.

301
00:12:19,849 --> 00:12:22,450
Well, if they did, they certainly didn't test

302
00:12:22,849 --> 00:12:25,940
enough because somebody walking with a bicycle at night

303
00:12:27,239 --> 00:12:30,820
or, I mean, look, I'm, I'm not going to make an assumption here.

304
00:12:30,830 --> 00:12:33,530
II, I agree with you that it seems common

305
00:12:34,030 --> 00:12:36,010
and it's completely possible they,

306
00:12:36,020 --> 00:12:38,880
they tested this and it's also completely possible that this,

307
00:12:38,890 --> 00:12:42,330
this particular change that resulted in disaster was made,

308
00:12:42,549 --> 00:12:44,320
you know, shortly before it happened.

309
00:12:44,890 --> 00:12:45,369
Right.

310
00:12:45,530 --> 00:12:48,570
There's, there's so many unknowns here and I guess fundamentally what,

311
00:12:48,580 --> 00:12:50,849
what I think I'm going to call it as is just

312
00:12:51,309 --> 00:12:55,090
humans can't be involved. It has to be 100% automated.

313
00:12:55,669 --> 00:12:57,690
I, I think that and more than that though,

314
00:12:57,700 --> 00:13:00,789
we really have to look at how we define computer human

315
00:13:00,799 --> 00:13:03,890
interaction because the next topic we're going to bring up,

316
00:13:04,130 --> 00:13:06,049
-- we don't define it. The computer
-- doesn't

317
00:13:06,880 --> 00:13:07,380
trust me.

318
00:13:07,390 --> 00:13:08,770
No, no, no, because, well, no,

319
00:13:08,780 --> 00:13:11,599
because some things you have to have computer human interaction because

320
00:13:11,609 --> 00:13:13,349
so the next topic we're going to talk about was Alexa,

321
00:13:13,659 --> 00:13:14,130
right?

322
00:13:14,659 --> 00:13:15,109
Alexa

323
00:13:15,710 --> 00:13:17,979
email all my information to somebody else

324
00:13:18,340 --> 00:13:19,659
and that's a perfect example. So,

325
00:13:19,780 --> 00:13:22,479
-- so what happened here is somebody got a call
-- from,

326
00:13:22,809 --> 00:13:22,840
I

327
00:13:23,330 --> 00:13:26,299
apologize in advance of what I just said, messed with anyone's Alexa.

328
00:13:26,809 --> 00:13:27,390
But that is

329
00:13:27,609 --> 00:13:27,849
Alexa.

330
00:13:28,090 --> 00:13:29,119
Buy me a dollhouse.

331
00:13:29,500 --> 00:13:30,630
But here's the thing, right?

332
00:13:30,760 --> 00:13:34,070
So what happened is somebody basically got an email or a phone? I forget a phone call.

333
00:13:34,080 --> 00:13:36,380
I forget which from a client saying basically, like, uh you know,

334
00:13:36,390 --> 00:13:38,919
you just emailed me like a recording of a conversation,

335
00:13:38,940 --> 00:13:40,880
uh like that you didn't seem to be aware of.

336
00:13:41,460 --> 00:13:45,830
And what fundamentally happened is this couple was talking in their

337
00:13:46,380 --> 00:13:47,340
domicile

338
00:13:48,169 --> 00:13:49,679
and they triggered their Alexa

339
00:13:49,799 --> 00:13:52,469
accidentally and then Alexa recorded a bit and then,

340
00:13:52,750 --> 00:13:56,250
um essentially they said some words that Alexa interpreted as, you know,

341
00:13:56,590 --> 00:14:00,190
uh send this message to a contact and then it, you know,

342
00:14:00,200 --> 00:14:02,190
waited some more to listen to them and then

343
00:14:02,369 --> 00:14:03,909
chose a contact from what they said.

344
00:14:04,320 --> 00:14:05,409
And see, here's the thing, right?

345
00:14:05,419 --> 00:14:08,190
Typically, when we interact with a computer or a machine,

346
00:14:08,369 --> 00:14:11,270
we are very explicitly interacting with it, right?

347
00:14:11,280 --> 00:14:14,809
Like I'm sitting on my computer and I'm banging away at the keyboard, right?

348
00:14:14,820 --> 00:14:16,140
I'm not going to accidentally do that,

349
00:14:16,690 --> 00:14:19,309
you know, I'm not going to accidentally move my mouse and click stuff, all of them.

350
00:14:19,320 --> 00:14:21,909
Actually, I have accidentally put stuff on the space bar and been like,

351
00:14:21,919 --> 00:14:23,340
why is this video not working

352
00:14:25,330 --> 00:14:25,609
-- or,
-- you know,

353
00:14:25,719 --> 00:14:26,190
the cat,

354
00:14:26,640 --> 00:14:27,059
it just walks

355
00:14:28,280 --> 00:14:31,669
until recently. We've never had machines that opportunistically

356
00:14:32,169 --> 00:14:37,460
wait and watch and watch or listen to us and then take action based on that without

357
00:14:38,460 --> 00:14:41,020
us maybe explicitly being aware that that is happening.

358
00:14:41,750 --> 00:14:44,210
And so what I'm realizing is these aren't like an Alexa

359
00:14:44,340 --> 00:14:46,690
isn't really a computer anymore. It's kind of more like a dog

360
00:14:46,840 --> 00:14:50,250
that's just like sitting there waiting for you to be like, OK, let's go for a walk,

361
00:14:50,419 --> 00:14:53,289
right? And then the dog jumps up and goes and runs to the door and

362
00:14:53,479 --> 00:14:56,320
you're like, oh, no, no, sorry. I was on the phone talking to somebody,

363
00:14:56,500 --> 00:14:57,090
you know,

364
00:14:57,650 --> 00:14:59,390
I'm familiar with that problem.

365
00:14:59,869 --> 00:15:00,260
Oh, yeah.

366
00:15:00,429 --> 00:15:01,929
Yeah, because you have a dog, right.

367
00:15:02,429 --> 00:15:03,330
Um, and so that's,

368
00:15:03,590 --> 00:15:04,640
I think that's the thing. Right.

369
00:15:04,650 --> 00:15:04,690
Is,

370
00:15:04,700 --> 00:15:07,080
is up until now machines have effectively been dumb

371
00:15:07,090 --> 00:15:09,770
and they've only done what we tell them to do

372
00:15:10,049 --> 00:15:10,469
and

373
00:15:10,599 --> 00:15:12,659
the way we tell them to do things has

374
00:15:13,030 --> 00:15:15,140
keyboard and mouse or buttons and switches.

375
00:15:15,150 --> 00:15:18,390
Or I'm sitting in my car and I'm smashing the gas pedal and steering

376
00:15:18,599 --> 00:15:19,179
the, you know,

377
00:15:19,190 --> 00:15:22,820
I explicitly know that I'm dealing with the machine and telling it what to do versus,

378
00:15:22,830 --> 00:15:23,599
you know, if my Alexa

379
00:15:23,719 --> 00:15:27,919
is turned on, right it II I was actually thinking of leaving it on for this episode,

380
00:15:27,929 --> 00:15:29,549
but I decided it would get too annoying

381
00:15:31,059 --> 00:15:31,309
right

382
00:15:31,760 --> 00:15:32,330
with it.

383
00:15:32,719 --> 00:15:34,559
Uh Jumping on and off.

384
00:15:34,840 --> 00:15:35,630
Um

385
00:15:36,520 --> 00:15:37,440
But uh

386
00:15:38,549 --> 00:15:40,539
what, what are you doing? Are you, are you getting your,

387
00:15:40,859 --> 00:15:43,570
I'm actually plugging, I'm just plugging it in because why not?

388
00:15:43,580 --> 00:15:45,609
-- Let's see how bad this
-- is. Oh man.

389
00:15:46,780 --> 00:15:48,090
Uh

390
00:15:48,559 --> 00:15:50,429
Is there an on off one? Oh, there we go.

391
00:15:50,530 --> 00:15:52,239
Ok. It's got a blue ring. It's happy.

392
00:15:53,559 --> 00:15:56,820
Um So yeah, I mean, traditionally

393
00:15:57,030 --> 00:15:59,419
we don't have machine and, and the other thing is, you know,

394
00:15:59,429 --> 00:16:02,630
machines didn't have computer vision systems

395
00:16:02,640 --> 00:16:04,460
or hearing systems that could actually,

396
00:16:04,900 --> 00:16:07,070
you know, with the compute power available. Actually

397
00:16:07,669 --> 00:16:09,820
listen and understand us

398
00:16:10,900 --> 00:16:13,880
like that's fundamentally pretty damn amazing in my mind,

399
00:16:14,020 --> 00:16:14,559
you know.

400
00:16:15,039 --> 00:16:18,640
-- No, it is. It's, it's very impressive.
-- I'm afraid to say a word.

401
00:16:19,770 --> 00:16:19,789
Oh,

402
00:16:19,979 --> 00:16:21,359
it just made its ding dong.

403
00:16:21,369 --> 00:16:26,219
It's a shame you have headphones on because then I could converse with your Alexa.

404
00:16:26,609 --> 00:16:27,049
But

405
00:16:27,250 --> 00:16:30,299
so here's, you know what this made me think of actually is,

406
00:16:30,750 --> 00:16:35,510
have you ever seen those, those kind of examples where someone will, will, like,

407
00:16:35,520 --> 00:16:39,059
teach a machine learning algorithm how to identify numbers, right?

408
00:16:39,750 --> 00:16:41,049
And, and it'll get it right.

409
00:16:41,059 --> 00:16:43,320
It starts doing a really good job and then you show it like

410
00:16:43,330 --> 00:16:46,549
a picture of a dog and it'll say that's a number four.

411
00:16:47,059 --> 00:16:48,359
No, that's a dog.

412
00:16:48,500 --> 00:16:52,890
Well, and that's a good, we now have ac we classification for essentially

413
00:16:53,179 --> 00:16:58,159
giving malicious data while training an A I or ML to like subvert it,

414
00:16:59,729 --> 00:16:59,750
it

415
00:16:59,880 --> 00:17:00,059
doesn't,

416
00:17:01,200 --> 00:17:03,609
it doesn't need malicious data even. I mean, this Alexa

417
00:17:03,760 --> 00:17:06,689
example, like there was nothing malicious going on. It was just Alexa

418
00:17:06,900 --> 00:17:08,500
got confused

419
00:17:08,729 --> 00:17:09,520
and, and it was a

420
00:17:10,390 --> 00:17:10,560
picture of a

421
00:17:10,670 --> 00:17:10,699
dog.

422
00:17:11,920 --> 00:17:12,439
No, Alexa

423
00:17:12,598 --> 00:17:15,839
did what it was supposed to do, which is it listened for its name and then it didn't,

424
00:17:15,969 --> 00:17:18,089
it listened for voice commands.

425
00:17:18,348 --> 00:17:21,848
But the thing is it, see when it does this, it puts the blue ring on

426
00:17:22,000 --> 00:17:23,560
but it doesn't make noise or anything.

427
00:17:23,680 --> 00:17:25,630
So if you're not physically in the room with it,

428
00:17:26,410 --> 00:17:28,469
you wouldn't know as a human being, right?

429
00:17:28,760 --> 00:17:33,030
Um This is what came up with the, with the, so we recently on the CV E board,

430
00:17:33,400 --> 00:17:34,839
there was that issue with Alexa

431
00:17:34,989 --> 00:17:35,479
where

432
00:17:35,880 --> 00:17:38,869
uh there's a repro feature where basically

433
00:17:39,280 --> 00:17:39,910
uh

434
00:17:40,709 --> 00:17:41,050
Alexa

435
00:17:41,150 --> 00:17:42,890
will listen for a command

436
00:17:43,020 --> 00:17:45,569
and if it doesn't hear a command after eight seconds, it can rep prompt,

437
00:17:45,579 --> 00:17:47,449
it can be like, excuse me, I didn't hear you or whatever

438
00:17:48,170 --> 00:17:50,550
and it will listen and wait for you to give it a command

439
00:17:51,000 --> 00:17:52,130
and it turns out that,

440
00:17:52,250 --> 00:17:54,270
that, oh, it just made a funny noise.

441
00:17:54,489 --> 00:17:58,890
Um And so it turns out bad guys could, you know, set up an Alexa skill,

442
00:17:59,449 --> 00:18:02,089
which would hit the rep prompt feature endlessly.

443
00:18:02,099 --> 00:18:05,060
And essentially, thus put Alexa into permanently recording mode.

444
00:18:05,680 --> 00:18:06,540
That's exciting

445
00:18:06,890 --> 00:18:09,099
the device has. So the one I have,

446
00:18:09,310 --> 00:18:11,770
it's the little, it's about the size of a large pop can,

447
00:18:12,050 --> 00:18:14,660
it has seven very sensitive microphones,

448
00:18:15,550 --> 00:18:15,939
right?

449
00:18:15,949 --> 00:18:17,959
So it can not only tell, it can not only listen,

450
00:18:17,969 --> 00:18:19,619
but it can do directional sound and stuff.

451
00:18:20,239 --> 00:18:20,839
And so

452
00:18:20,949 --> 00:18:22,920
I don't have to be in the room for this thing to hear me.

453
00:18:24,810 --> 00:18:29,400
And again, that goes back to that thing of like, typically when we like when I'm

454
00:18:29,699 --> 00:18:33,449
hitting the remote control for my TV, I'm poking away at it,

455
00:18:33,640 --> 00:18:37,520
you know, I'm not accidentally being like, hey, you know, did you see that,

456
00:18:37,760 --> 00:18:39,969
you know, ludicrous show on channel four last night?

457
00:18:39,979 --> 00:18:42,319
And then all of a sudden your TV turns on to channel four, right?

458
00:18:43,000 --> 00:18:44,839
That's the future man, it's coming.

459
00:18:45,760 --> 00:18:46,310
So

460
00:18:46,670 --> 00:18:50,339
I think fundamentally, like I said, it boils down to machines. Used to be dumb.

461
00:18:50,349 --> 00:18:52,479
But now they're about as smart as a dog in

462
00:18:52,489 --> 00:18:54,300
some ways when it comes to paying attention to us.

463
00:18:54,310 --> 00:18:54,739
And so,

464
00:18:55,550 --> 00:18:57,520
you know, they're like, yeah, I mean,

465
00:18:57,530 --> 00:19:01,709
I would love to see what would happen if you yell, you know, treats or, uh,

466
00:19:01,719 --> 00:19:04,489
I know with my, uh, my parents cat, if you, um,

467
00:19:05,170 --> 00:19:07,109
if you crack open a tin,

468
00:19:07,550 --> 00:19:09,869
like, you know, the noise the can opener makes,

469
00:19:10,479 --> 00:19:13,510
yeah, that cat's there in like three seconds and she's old and lazy.

470
00:19:13,520 --> 00:19:15,209
But you know, she hears that noise

471
00:19:15,359 --> 00:19:17,030
and boom, she's in the kitchen.

472
00:19:17,280 --> 00:19:17,949
They know

473
00:19:18,300 --> 00:19:18,829
they know.

474
00:19:19,310 --> 00:19:20,699
But, but so far the Alexa

475
00:19:20,819 --> 00:19:23,869
is unable to run to the kitchen. So we have that going for us.

476
00:19:23,880 --> 00:19:27,319
That's what we need, we need like like the Sony Io with an Alexa

477
00:19:27,459 --> 00:19:28,180
tape to it.

478
00:19:28,709 --> 00:19:32,280
Well, no, the problem is like for example, your Alexa skills could do that.

479
00:19:32,290 --> 00:19:35,609
They could interact with your vacuuming system or whatever, right?

480
00:19:36,339 --> 00:19:36,819
Alexa

481
00:19:37,060 --> 00:19:38,310
vacuum the floor.

482
00:19:38,819 --> 00:19:40,209
Yeah. And it would, yeah,

483
00:19:40,339 --> 00:19:41,969
that, that stuff is, that's the whole point of it

484
00:19:42,349 --> 00:19:44,689
probably works. I'm sure it does it today

485
00:19:45,739 --> 00:19:48,810
Alexa kill, right? Like it's coming.

486
00:19:49,640 --> 00:19:49,900
Yeah.

487
00:19:49,910 --> 00:19:51,770
So I'm I'm really think because for example,

488
00:19:51,780 --> 00:19:54,569
I've disabled Siri on all of my Apple devices.

489
00:19:54,579 --> 00:19:56,000
You remember that one show we did where I was like,

490
00:19:56,010 --> 00:19:58,439
I've disabled Siri on all of my devices and my phone's like,

491
00:19:58,819 --> 00:20:00,170
how can I help you? And I'm like,

492
00:20:00,420 --> 00:20:01,170
because yeah,

493
00:20:01,180 --> 00:20:02,199
because what happened is I did a

494
00:20:02,209 --> 00:20:04,880
software update which reset that setting apparently.

495
00:20:05,069 --> 00:20:06,329
And now that I say that

496
00:20:06,650 --> 00:20:07,560
what is my phone doing?

497
00:20:07,699 --> 00:20:08,040
Right.

498
00:20:08,050 --> 00:20:11,800
And, and, you know, you know what that reminds me of is when, like,

499
00:20:11,810 --> 00:20:14,219
you go into Twitter and Twitter used to be the worst of this.

500
00:20:14,229 --> 00:20:15,239
We'd go into Twitter and, like,

501
00:20:15,250 --> 00:20:19,280
turn off all the stupid alerting functionality and then the Twitter

502
00:20:19,290 --> 00:20:21,839
app would update itself and it would turn everything back on.

503
00:20:21,920 --> 00:20:22,310
I was like, whoa.

504
00:20:24,359 --> 00:20:28,140
And they don't anymore. But like, that was, ah, that was so annoying.

505
00:20:28,619 --> 00:20:31,420
I, I think fundamentally what this really boils down to is

506
00:20:31,630 --> 00:20:33,390
we as in, like,

507
00:20:33,400 --> 00:20:34,979
we as an industry don't have a lot of

508
00:20:34,989 --> 00:20:38,219
experience with this kind of computer human interaction.

509
00:20:38,449 --> 00:20:39,339
Like we just don't

510
00:20:39,510 --> 00:20:42,479
think it's safe to say like humanity doesn't

511
00:20:42,660 --> 00:20:43,010
have

512
00:20:43,930 --> 00:20:45,069
this kind of interaction.

513
00:20:45,550 --> 00:20:48,829
Yeah. And I mean, a great example of this is cellphones, right? Like when cell,

514
00:20:48,949 --> 00:20:50,140
when smartphones came out,

515
00:20:50,920 --> 00:20:53,310
I wouldn't have guessed now that on a regular basis,

516
00:20:53,319 --> 00:20:56,140
I would see people texting and driving while making left hand turns.

517
00:20:57,209 --> 00:20:58,979
I think that was inevitable.

518
00:20:58,989 --> 00:21:02,489
I mean, there was texting and driving was a problem long before smartphones,

519
00:21:03,069 --> 00:21:03,699
right? It's,

520
00:21:04,040 --> 00:21:05,910
and this is why the solution to that.

521
00:21:05,920 --> 00:21:08,530
But, but ok, here's so, here's something to think about though, is

522
00:21:08,729 --> 00:21:10,510
the solution to texting and driving

523
00:21:10,650 --> 00:21:13,869
isn't to find people or to put up signs that say don't text and drive.

524
00:21:13,880 --> 00:21:16,609
The solution is to build self driving cars. Right.

525
00:21:17,560 --> 00:21:20,130
And, and the solution to something like Alexa,

526
00:21:20,500 --> 00:21:23,109
where you have a device listening to you all the time

527
00:21:23,689 --> 00:21:24,300
is

528
00:21:24,479 --> 00:21:28,770
-- this one gets trickier because its job is to listen.
-- Right.

529
00:21:29,079 --> 00:21:30,209
Well, how do

530
00:21:30,540 --> 00:21:32,560
you, for example, do you maybe make it,

531
00:21:32,989 --> 00:21:36,099
you know, see the problem is you watch things like Star Trek, you know,

532
00:21:36,109 --> 00:21:40,170
the computer human interaction by a voice is horrific.

533
00:21:40,319 --> 00:21:42,119
-- It is so bad and
-- painful. What do you

534
00:21:42,229 --> 00:21:42,400
mean? It's

535
00:21:42,939 --> 00:21:45,339
painful that computer does everything it's told to do

536
00:21:45,780 --> 00:21:46,500
well and,

537
00:21:47,469 --> 00:21:49,099
but you have to like explicitly talk to it,

538
00:21:49,109 --> 00:21:51,420
you have to make sure it's paying attention, things like that, right?

539
00:21:51,660 --> 00:21:54,319
Whereas with the Alexa, it just, you know, does its thing.

540
00:21:54,689 --> 00:21:55,319
Um

541
00:21:55,530 --> 00:21:57,579
So I, I think two things will happen.

542
00:21:57,589 --> 00:21:58,319
Number one, you know,

543
00:21:58,329 --> 00:22:02,430
how do we need to be maybe more formal in our interactions with Alexa?

544
00:22:03,239 --> 00:22:07,150
And number two though is things like Alexa and other machines too in general need to,

545
00:22:07,609 --> 00:22:08,150
you know,

546
00:22:08,599 --> 00:22:09,829
I need to know what their state.

547
00:22:09,839 --> 00:22:13,030
I need to know what's going on more intuitively, right? Because

548
00:22:13,160 --> 00:22:15,750
like right now I know fundamentally my car is going to do only

549
00:22:15,760 --> 00:22:17,670
what I tell it to do because I drive a dumb car.

550
00:22:17,689 --> 00:22:20,140
I look at this Uber car and there's no, like you could not,

551
00:22:20,150 --> 00:22:22,239
you literally could not pay me enough money to get in one

552
00:22:22,250 --> 00:22:25,709
of these Uber cars where it's designed to like not emergency brake,

553
00:22:25,719 --> 00:22:28,390
not tell the operator, there's an emergency and hope that,

554
00:22:28,400 --> 00:22:31,150
that human has enough situational awareness to go deal with the problem,

555
00:22:31,510 --> 00:22:32,589
which they don't,

556
00:22:32,770 --> 00:22:33,869
I mean, let's face it.

557
00:22:34,239 --> 00:22:36,770
But I feel like that's still not,

558
00:22:37,390 --> 00:22:38,369
that's not the Alexa

559
00:22:38,540 --> 00:22:41,089
problem though. Right. I mean, this is, this is

560
00:22:41,229 --> 00:22:41,239
a

561
00:22:41,449 --> 00:22:41,630
part

562
00:22:41,890 --> 00:22:44,479
of, but this is going to be. What about your, um,

563
00:22:44,699 --> 00:22:47,979
I mean, some, some devices are so like those IKEA light bulbs

564
00:22:48,209 --> 00:22:50,329
fundamentally, you know what a light bulb is doing

565
00:22:50,619 --> 00:22:54,489
because it's doing its thing, it's either on or off or making a certain color, right?

566
00:22:55,520 --> 00:22:59,270
You know, so in theory it's quote unquote air quotes here, simple,

567
00:22:59,280 --> 00:23:00,280
but something like an Alexa,

568
00:23:00,400 --> 00:23:03,430
which is like very much a, a general purpose, you know,

569
00:23:03,650 --> 00:23:04,229
um Alexa

570
00:23:04,400 --> 00:23:05,829
drop me a beat.

571
00:23:07,160 --> 00:23:08,339
I'm super impressed,

572
00:23:09,199 --> 00:23:09,859
kick it.

573
00:23:12,130 --> 00:23:13,439
There we go. Right. Like,

574
00:23:14,050 --> 00:23:15,099
ok, Alexa stop,

575
00:23:16,760 --> 00:23:18,099
Alexa stop.

576
00:23:20,130 --> 00:23:21,500
So, I mean, that's a great example, right?

577
00:23:21,510 --> 00:23:23,729
Alexa can do something where when it does it, it's,

578
00:23:23,739 --> 00:23:25,630
it's really obvious that it's doing it,

579
00:23:26,150 --> 00:23:27,109
but like Alexa

580
00:23:27,270 --> 00:23:30,109
record everything I'm saying and email it to Josh,

581
00:23:30,390 --> 00:23:33,459
I'm, I'm gonna be super impressed if this works.

582
00:23:33,599 --> 00:23:35,869
Oh, I hope not. I haven't hooked up any email accounts to it.

583
00:23:35,979 --> 00:23:38,010
Well, no wait, it would be attached to my Amazon account

584
00:23:38,280 --> 00:23:39,650
anyways point being right is

585
00:23:39,959 --> 00:23:42,770
the Alexa machine can do things some of which are really obvious,

586
00:23:42,780 --> 00:23:43,579
like dropping a beat

587
00:23:43,969 --> 00:23:45,349
and it can also do things that are like,

588
00:23:45,359 --> 00:23:48,020
really not obvious like unlocking all the doors in my house.

589
00:23:48,300 --> 00:23:49,150
And I just realized,

590
00:23:49,160 --> 00:23:52,800
as I say that I'm really glad I don't have Alexa hooked up to all my doors locks.

591
00:23:52,810 --> 00:23:54,229
Like I don't have smart locks because

592
00:23:54,349 --> 00:23:54,959
again,

593
00:23:55,140 --> 00:23:57,640
there's way too many failure scenarios that I don't understand.

594
00:23:58,160 --> 00:23:59,060
But for example, having

595
00:23:59,339 --> 00:23:59,719
said this,

596
00:24:00,920 --> 00:24:04,459
do you remember the story about Siri where like some guy's neighbor yelled,

597
00:24:04,469 --> 00:24:07,400
Siri unlocked the front door from outside and it did it.

598
00:24:07,900 --> 00:24:08,140
Yeah,

599
00:24:08,329 --> 00:24:09,449
like it.

600
00:24:11,280 --> 00:24:16,260
I, I guess I, I did all this and I believe it all and I don't know,

601
00:24:16,530 --> 00:24:16,560
I,

602
00:24:16,709 --> 00:24:17,939
I feel like

603
00:24:19,170 --> 00:24:21,790
the answer to this isn't something

604
00:24:21,900 --> 00:24:27,010
-- we yet grasp because this is a new paradigm for everybody
-- in theory,

605
00:24:27,020 --> 00:24:29,349
if the device was smart, like for example,

606
00:24:29,750 --> 00:24:31,900
your dog knows uh let me put it this way.

607
00:24:31,910 --> 00:24:34,650
If I walk up to your dog and I say, let's go for a walk,

608
00:24:34,660 --> 00:24:36,560
your dog's probably gonna look at me and

609
00:24:36,729 --> 00:24:38,209
not get super excited.

610
00:24:38,589 --> 00:24:39,729
He'd be totally

611
00:24:40,349 --> 00:24:41,060
-- all right.
-- Well,

612
00:24:41,579 --> 00:24:44,709
but fundamentally, I mean, ideally we need these, the,

613
00:24:44,739 --> 00:24:47,150
the problem is it's kind of like the self driving car situation

614
00:24:47,160 --> 00:24:49,589
where we need the device to be able to handle it all,

615
00:24:49,599 --> 00:24:50,410
but we're not there yet.

616
00:24:50,420 --> 00:24:51,329
And how do we get there?

617
00:24:52,010 --> 00:24:54,989
And that's part of the problem, right? We have to build these intermediary steps,

618
00:24:55,150 --> 00:24:56,189
what we really need.

619
00:24:56,369 --> 00:24:57,650
Basically, here's what I want.

620
00:24:57,660 --> 00:25:00,030
I want a device that's roughly about as smart as a dog and

621
00:25:00,040 --> 00:25:03,349
that it can tell who I am and who is not me.

622
00:25:04,609 --> 00:25:05,040
Right.

623
00:25:05,180 --> 00:25:06,880
But that's only half the problem.

624
00:25:06,890 --> 00:25:07,099
I mean,

625
00:25:07,109 --> 00:25:10,920
like in the case of these people getting their conversation email to a friend,

626
00:25:11,280 --> 00:25:11,719
Alexa

627
00:25:11,859 --> 00:25:12,560
thought

628
00:25:12,930 --> 00:25:14,400
it was doing the right thing.

629
00:25:14,890 --> 00:25:15,439
And

630
00:25:15,729 --> 00:25:18,349
now, now here's, here's the trick though, is

631
00:25:18,510 --> 00:25:19,410
in order for Alexa

632
00:25:19,540 --> 00:25:22,829
to have known they were having a conversation

633
00:25:23,020 --> 00:25:24,609
that was not involving Alexa,

634
00:25:25,390 --> 00:25:29,050
you would have to send literally all of the audio somewhere else.

635
00:25:29,060 --> 00:25:31,699
Have it processed and then have that central place.

636
00:25:31,709 --> 00:25:36,079
Say, OK, situationally, this is a conversation not involving me. Don't respond.

637
00:25:37,020 --> 00:25:38,560
That opens up like a whole another.

638
00:25:38,760 --> 00:25:38,969
That's how

639
00:25:39,349 --> 00:25:40,209
works by the way

640
00:25:40,439 --> 00:25:40,660
you do

641
00:25:41,109 --> 00:25:41,640
-- that.
-- Well,

642
00:25:41,790 --> 00:25:46,469
no, no, I I, yes, but it's supposed to only send things after you say Alexa,

643
00:25:46,800 --> 00:25:50,780
right? In theory, it's not like sending everything you're telling me right now.

644
00:25:51,030 --> 00:25:51,250
Well,

645
00:25:51,859 --> 00:25:52,170
depending on

646
00:25:53,310 --> 00:25:53,770
that's

647
00:25:54,280 --> 00:25:54,939
supposed to do that or whatever

648
00:25:55,900 --> 00:25:58,589
it might be because you just said record everything I say.

649
00:25:59,930 --> 00:26:00,479
But um

650
00:26:01,040 --> 00:26:04,050
so and, and that's an even tougher case because for example,

651
00:26:04,060 --> 00:26:06,510
maybe somebody only wants to have one Alexa in their house

652
00:26:06,520 --> 00:26:08,800
and they do want to yell at it from other rooms versus

653
00:26:08,979 --> 00:26:10,239
maybe like see,

654
00:26:10,250 --> 00:26:12,579
that's what I was thinking is I was going to keep the Alexa in the workroom.

655
00:26:12,589 --> 00:26:15,180
So and it only kind of explicitly use it in here.

656
00:26:15,969 --> 00:26:19,359
But yeah, no, that thing can hear me from like the kitchen. No problem.

657
00:26:19,810 --> 00:26:23,930
Yeah. Right, man. I mean, it's amazing what some of these microphones can pick up.

658
00:26:23,939 --> 00:26:24,439
Oh Yeah.

659
00:26:24,910 --> 00:26:27,030
Um So it becomes,

660
00:26:27,859 --> 00:26:30,339
yeah, it's just how, you know, how does Alexa,

661
00:26:30,449 --> 00:26:31,880
for example, cue

662
00:26:32,209 --> 00:26:35,650
or tell me like, hey, I think you're trying to tell me something, right?

663
00:26:35,660 --> 00:26:38,199
Like your dog, if you say let's go for a walk, your dog's gonna like perk up,

664
00:26:38,209 --> 00:26:39,689
his ears are up, he's looking at you,

665
00:26:40,319 --> 00:26:41,069
you know, because it's a,

666
00:26:41,079 --> 00:26:45,849
it's a thing in the house that that's reacting to the environment where Alexa

667
00:26:46,020 --> 00:26:46,920
is like

668
00:26:47,069 --> 00:26:48,420
it does react to the environment

669
00:26:48,589 --> 00:26:50,920
because it has that color ring on top and it can talk to me,

670
00:26:51,439 --> 00:26:51,900
you know.

671
00:26:52,079 --> 00:26:53,510
Um for example, it,

672
00:26:54,530 --> 00:26:55,829
well, that's what I'm saying, right?

673
00:26:55,839 --> 00:26:59,310
I clearly it isn't because if you're not in the room with it, you don't see the lights,

674
00:26:59,400 --> 00:26:59,790
right?

675
00:27:00,050 --> 00:27:01,229
So for example,

676
00:27:01,410 --> 00:27:04,739
do we need machines to be more explicit like hot? You know,

677
00:27:05,349 --> 00:27:10,630
in some cases it would be good for the machine to be like, hi. I think you want me to do X.

678
00:27:10,780 --> 00:27:13,430
I'm I'm gonna do X. Is that what you really want me to do?

679
00:27:13,439 --> 00:27:16,869
Like you really want me to cook this turkey at 450 degrees for 12 hours?

680
00:27:17,410 --> 00:27:18,869
That sounds super annoying,

681
00:27:21,000 --> 00:27:22,579
right? It would be hellishly annoying,

682
00:27:23,319 --> 00:27:25,709
you know, and again, this is where it boils down to.

683
00:27:25,719 --> 00:27:27,500
I want something smart enough to be like

684
00:27:27,689 --> 00:27:30,869
uh you're telling me to put a turkey in the oven and to heat it for, you know,

685
00:27:30,880 --> 00:27:32,390
12 hours at 450 degrees.

686
00:27:32,400 --> 00:27:34,030
I don't think that's a good idea.

687
00:27:34,560 --> 00:27:37,989
Um, you know, you're telling me to unlock all the doors in the house and

688
00:27:38,109 --> 00:27:39,260
you're not in the house.

689
00:27:40,300 --> 00:27:40,969
Like,

690
00:27:41,260 --> 00:27:42,520
is that what you really want?

691
00:27:42,670 --> 00:27:45,209
Echo, received an important update and must restart.

692
00:27:45,949 --> 00:27:46,160
I'll be ready

693
00:27:46,439 --> 00:27:47,359
again shortly.

694
00:27:48,260 --> 00:27:51,170
Apparently it auto updates and then tells me it's updated

695
00:27:51,619 --> 00:27:52,719
and it's a good thing

696
00:27:53,099 --> 00:27:53,810
and it's a good thing.

697
00:27:53,819 --> 00:27:55,890
I'm not depending on this thing for, you know,

698
00:27:55,900 --> 00:27:58,579
health and safety because apparently, hello, Alexa.

699
00:28:00,020 --> 00:28:00,439
Alexa.

700
00:28:00,599 --> 00:28:02,150
Hello, wake up.

701
00:28:02,959 --> 00:28:03,609
It's up to the

702
00:28:04,170 --> 00:28:04,229
Alexa.

703
00:28:04,540 --> 00:28:06,119
Oh, no, the ring is blue again.

704
00:28:07,020 --> 00:28:09,869
But again, I don't know if this thing is dead or is it doing something?

705
00:28:10,770 --> 00:28:12,099
Maybe it's listening to everything

706
00:28:12,310 --> 00:28:12,329
you

707
00:28:12,430 --> 00:28:14,589
-- say.
-- Does this update take 10 seconds or 10 minutes?

708
00:28:15,079 --> 00:28:15,420
Alexa,

709
00:28:15,989 --> 00:28:16,880
can you hear me?

710
00:28:18,430 --> 00:28:19,869
Alexa? Drop me a beat?

711
00:28:20,880 --> 00:28:22,859
Nope. It's thinking the little blue light is pulsing.

712
00:28:23,160 --> 00:28:24,880
So it's, it's thinking, I guess.

713
00:28:25,520 --> 00:28:26,650
Right. But this is a perfect example,

714
00:28:27,800 --> 00:28:28,119
Alexa

715
00:28:28,310 --> 00:28:30,819
help. I've fallen and I can't get up.

716
00:28:32,349 --> 00:28:33,170
No, I died

717
00:28:34,060 --> 00:28:34,890
now, if

718
00:28:35,339 --> 00:28:35,410
you will

719
00:28:35,719 --> 00:28:37,939
like call 911 for you.

720
00:28:38,290 --> 00:28:42,239
No. And actually in Canada it's illegal to have automated phone systems called 911.

721
00:28:43,180 --> 00:28:43,449
Only

722
00:28:43,589 --> 00:28:47,109
humans are allowed to call 911. Yeah, part of it is that, well, false alarms.

723
00:28:47,260 --> 00:28:51,079
And number two is, you know, a lot of jurisdictions, 911 is not allowed to hang up.

724
00:28:52,390 --> 00:28:54,020
Ah, sure. Right. Right. Right.

725
00:28:54,030 --> 00:28:54,900
Because, I mean,

726
00:28:54,910 --> 00:28:55,989
while there was that case in the US of

727
00:28:56,000 --> 00:28:58,339
that 911 operator hanging up on hundreds of people,

728
00:28:59,079 --> 00:29:01,300
uh, and being told, like, telling people to, like,

729
00:29:01,310 --> 00:29:05,060
deal with it and hanging up on them and she's apparently been sued and fired now.

730
00:29:05,560 --> 00:29:06,140
Um,

731
00:29:06,630 --> 00:29:06,920
Alexa.

732
00:29:07,550 --> 00:29:08,859
Oh, this thing is still updating.

733
00:29:09,390 --> 00:29:09,680
No,

734
00:29:10,020 --> 00:29:13,140
no, we're not, we're not doing this. You're not going to keep talking to your Alexa.

735
00:29:13,790 --> 00:29:14,819
-- I
-- think
-- the challenge.

736
00:29:15,310 --> 00:29:17,300
So I think the challenge fundamentally is we have

737
00:29:17,310 --> 00:29:20,709
machines that are smart enough to basically be dangerous

738
00:29:21,060 --> 00:29:23,660
and not smart enough to like, you know, sit boo boo, sit,

739
00:29:23,880 --> 00:29:24,459
you know what I mean?

740
00:29:26,219 --> 00:29:26,719
And

741
00:29:27,109 --> 00:29:33,109
I agree with you and I guess the thing I keep thinking of is however, this gets fixed

742
00:29:33,589 --> 00:29:36,469
is almost certainly going to be something that doesn't

743
00:29:36,479 --> 00:29:39,890
exist today because I can't think of any existing

744
00:29:40,199 --> 00:29:42,229
methodology or knowledge

745
00:29:42,489 --> 00:29:46,310
that can actually solve this problem without just being super annoying.

746
00:29:46,920 --> 00:29:50,589
And, and I do think it's going to get fixed because I have Alexa

747
00:29:50,689 --> 00:29:55,469
is, is very useful and, and don't get me wrong like I would love to have one. But, but

748
00:29:55,939 --> 00:29:58,660
this nightmare scenario is exactly why I don't,

749
00:29:58,800 --> 00:29:58,810
I

750
00:30:00,219 --> 00:30:00,640
don't.

751
00:30:00,810 --> 00:30:04,359
And I think one thing I think of is I think of trains right back in the day trains,

752
00:30:04,369 --> 00:30:07,260
there was a ton of train disasters and collisions

753
00:30:07,410 --> 00:30:09,479
because we had very poor signaling systems.

754
00:30:09,489 --> 00:30:11,680
So like trains would literally just run into each other,

755
00:30:12,209 --> 00:30:12,640
right?

756
00:30:12,969 --> 00:30:13,520
And

757
00:30:13,819 --> 00:30:16,949
we invented processes and then we invented technology, you know,

758
00:30:16,959 --> 00:30:19,060
where like we segment the track into segments.

759
00:30:19,130 --> 00:30:20,920
You know, the track is green, you can go on the track. Nope.

760
00:30:20,930 --> 00:30:23,489
Now the track is red because there's another train entering that track,

761
00:30:23,790 --> 00:30:24,810
you know, whatever things like that.

762
00:30:24,819 --> 00:30:27,540
We, we invented all these processes and procedures

763
00:30:27,699 --> 00:30:29,109
and then technology and relays.

764
00:30:29,119 --> 00:30:31,430
And like right now here in Edmonton, we have a big problem where

765
00:30:31,650 --> 00:30:34,650
we paid tails some insane amount of money to

766
00:30:34,660 --> 00:30:36,920
build the signaling system for our light rapid transit.

767
00:30:37,349 --> 00:30:39,640
And uh they stuffed it up and the thing can only run

768
00:30:39,650 --> 00:30:42,170
at like half or one third speed of what it's supposed to run

769
00:30:43,310 --> 00:30:48,219
because like to do it safely, you, you, you can't run it at full speed, right?

770
00:30:48,680 --> 00:30:49,209
Um

771
00:30:50,250 --> 00:30:50,910
You know, but,

772
00:30:51,150 --> 00:30:54,400
but we, we know how to deal with that like, oh, the system doesn't work properly,

773
00:30:54,410 --> 00:30:57,280
but we know how to compensate for that even though it sucks,

774
00:30:57,880 --> 00:30:58,310
you know,

775
00:30:58,609 --> 00:31:00,760
and, and there have been actually several cases now,

776
00:31:00,770 --> 00:31:03,109
two or three cases of where trains entered

777
00:31:03,280 --> 00:31:04,229
red track,

778
00:31:05,099 --> 00:31:07,209
right where they, you know, they should, right?

779
00:31:07,219 --> 00:31:10,329
But nothing bad happened because there was other systems that caught that,

780
00:31:10,540 --> 00:31:11,910
you know, resulting in a shutdown, right?

781
00:31:11,920 --> 00:31:15,050
-- The, the system fails close
-- and, and I guess

782
00:31:15,150 --> 00:31:15,989
that's,

783
00:31:16,250 --> 00:31:19,900
that's the lesson here, right? Of, of both Uber and Alexa

784
00:31:20,099 --> 00:31:22,760
is that failure is inevitable.

785
00:31:23,099 --> 00:31:24,709
But as long as we

786
00:31:25,209 --> 00:31:27,680
take the failure and we learn from it

787
00:31:27,900 --> 00:31:31,630
instead of using failure as a reason to give up,

788
00:31:31,640 --> 00:31:34,280
which I there are people obviously decrying

789
00:31:34,420 --> 00:31:39,349
-- failure as don't even try
-- well. And part of it is also is defining what is failure,

790
00:31:39,640 --> 00:31:41,560
right? So for example, is it a failure?

791
00:31:41,569 --> 00:31:43,560
If the Uber car sees something,

792
00:31:43,569 --> 00:31:45,920
it doesn't understand and slams on the brakes to be on the safe side

793
00:31:46,680 --> 00:31:48,619
because I've seen people do that in traffic,

794
00:31:49,410 --> 00:31:50,829
you know, the infamous people,

795
00:31:50,839 --> 00:31:53,660
rubber necking the accident on the other side of the road causing

796
00:31:53,770 --> 00:31:53,780
a

797
00:31:54,170 --> 00:31:54,760
pile up.

798
00:31:54,770 --> 00:31:57,739
Like that's, that's happened where literally, you know,

799
00:31:57,790 --> 00:31:59,560
there's a minor fender bender on one side of the

800
00:31:59,569 --> 00:32:00,979
highway and on the other side of the highway,

801
00:32:01,000 --> 00:32:02,760
there's like a 15 car crash because some

802
00:32:02,770 --> 00:32:05,119
jackass decided it was more important to watch

803
00:32:05,420 --> 00:32:06,780
the show than to pay attention.

804
00:32:07,699 --> 00:32:08,000
Yy.

805
00:32:08,359 --> 00:32:08,780
You know.

806
00:32:08,790 --> 00:32:11,430
So, yeah, these are, these are difficult things, you know,

807
00:32:11,439 --> 00:32:14,420
like a highway speed just slamming on the brakes may not, you know,

808
00:32:14,449 --> 00:32:19,030
when I think about this, I think about self, you know, um, uh, plane autopilots,

809
00:32:20,229 --> 00:32:22,089
you know, because you can't just pull over to the side of the road,

810
00:32:23,079 --> 00:32:24,380
right? You got to deal with it.

811
00:32:24,520 --> 00:32:26,939
And I think that's maybe to the advantage for airplanes is number one,

812
00:32:26,949 --> 00:32:27,810
they're hideously expensive.

813
00:32:27,819 --> 00:32:28,540
And number two,

814
00:32:28,829 --> 00:32:29,089
you,

815
00:32:29,099 --> 00:32:30,959
you have to really think about and define what

816
00:32:30,969 --> 00:32:33,160
the failure scenarios are because otherwise you're losing,

817
00:32:33,209 --> 00:32:33,369
you know,

818
00:32:33,510 --> 00:32:35,189
multi $100 million,

819
00:32:35,500 --> 00:32:38,380
$100 million piece of machinery with people on board.

820
00:32:39,229 --> 00:32:40,290
Right. And

821
00:32:40,770 --> 00:32:45,109
-- II, I feel like we're gonna get there. Right. I, I
-- think we have to,

822
00:32:45,229 --> 00:32:45,839
this is

823
00:32:46,349 --> 00:32:48,099
the genie is out of the bottle.

824
00:32:49,069 --> 00:32:49,609
Like we,

825
00:32:49,619 --> 00:32:52,290
we can't get rid of smartphones and we can't get rid of these home assistants.

826
00:32:52,650 --> 00:32:57,469
We, I think about being 30 or 40 years older from now and having this thing

827
00:32:57,619 --> 00:33:01,530
and having it be able to remind me of things and have it, be able to, you know,

828
00:33:01,790 --> 00:33:03,650
help me with my daily life and you know what?

829
00:33:03,900 --> 00:33:05,000
It sounds awesome.

830
00:33:05,359 --> 00:33:07,300
-- That's like
-- it does, it does.

831
00:33:07,310 --> 00:33:11,170
And, and I guess that's, that's how we're going to close. It is just the point that

832
00:33:11,609 --> 00:33:15,089
complaining about this stuff doesn't help, it's not going to go away.

833
00:33:15,420 --> 00:33:16,270
And so

834
00:33:17,510 --> 00:33:19,969
it's going to fail, it's going to have problems

835
00:33:20,189 --> 00:33:23,010
and, you know, it's very much like if you're not part of the solution,

836
00:33:23,020 --> 00:33:23,969
you're part of the problem.

837
00:33:23,979 --> 00:33:25,359
And, and I think a lot of a lot of,

838
00:33:25,369 --> 00:33:27,839
especially security people and the way they're mocking all this

839
00:33:27,849 --> 00:33:30,400
are definitely part of the problem and they aren't helping.

840
00:33:30,689 --> 00:33:32,680
I was gonna say, yeah, they're definitely not helping.

841
00:33:32,689 --> 00:33:36,729
And I mean, so like I know for myself personally, I'm looking at trying to help,

842
00:33:37,150 --> 00:33:38,920
we're going to look at defining cwes for

843
00:33:38,930 --> 00:33:42,109
this because the common uh weakness enumeration system.

844
00:33:42,119 --> 00:33:43,290
So we can define these problems.

845
00:33:43,300 --> 00:33:47,319
So people are then more aware that, oh, that is one way to feel spectacularly.

846
00:33:47,329 --> 00:33:49,050
Let's maybe try to avoid that,

847
00:33:49,189 --> 00:33:52,209
right? It's, it's like the old saying, right? Once you give something a name,

848
00:33:52,380 --> 00:33:54,869
then you can defeat it essentially.

849
00:33:55,410 --> 00:33:59,329
So awesome. No, I like it, man. That, that's great. So, all right. Thank you, Kurt.

850
00:33:59,339 --> 00:34:02,890
Thank you everyone for listening. You can go to open source security podcast.com

851
00:34:03,420 --> 00:34:06,329
to grab the show notes of which there are many this time and you can

852
00:34:06,339 --> 00:34:10,228
use the Pound Os S podcast hashtag to hit us up on social media.

853
00:34:10,239 --> 00:34:12,918
And yeah, Kurt, you have a fabulous rest of your day.

854
00:34:13,188 --> 00:34:14,050
You too. Thanks.

855
00:34:14,350 --> 00:34:15,438
Thanks everyone. Bye bye.