0
00:00:05,539 --> 00:00:08,939
Hello and welcome to the open source security podcast with myself,

1
00:00:08,949 --> 00:00:12,970
Kurt Siefried and my partner in paying extremely large bonuses to ourselves.

2
00:00:12,979 --> 00:00:13,460
Josh. Press

3
00:00:13,810 --> 00:00:15,039
-- what? You get
-- a bonus.

4
00:00:15,859 --> 00:00:18,319
-- I decided I get a bonus.
-- Do

5
00:00:18,420 --> 00:00:18,889
you for our

6
00:00:19,239 --> 00:00:22,870
huge budget of negative $40 a month?

7
00:00:23,799 --> 00:00:27,610
-- Anyway,
-- it's funny because you, you wanna talk about insider threat, right?

8
00:00:27,809 --> 00:00:28,770
Yes.

9
00:00:28,850 --> 00:00:31,170
-- Well, it was your idea
-- and, well,

10
00:00:31,180 --> 00:00:33,770
and I'm assuming you're thinking more on the technical side, right?

11
00:00:33,860 --> 00:00:35,840
Like, don't click that link because if you click that link,

12
00:00:35,849 --> 00:00:37,020
it'll bring down the whole company.

13
00:00:37,029 --> 00:00:40,369
-- Right? No,
-- I'm just thinking there's many types of insider threats.

14
00:00:40,380 --> 00:00:45,849
I mean, you can have financial insiders doing dodgy things. You can have

15
00:00:46,080 --> 00:00:50,409
rogue employees, you can have everything. I mean, every department,

16
00:00:51,000 --> 00:00:53,389
there is someone in that department that has

17
00:00:53,400 --> 00:00:56,270
some ability to functionally take down your,

18
00:00:56,279 --> 00:00:56,639
well,

19
00:00:56,650 --> 00:01:00,270
I shouldn't say take down your but can definitely cause problems for your business.

20
00:01:00,279 --> 00:01:03,560
Well, and here's my one thought is because this is timely is uh

21
00:01:03,729 --> 00:01:05,989
Netflix shareholders voted on Thursday to reject

22
00:01:06,099 --> 00:01:08,790
multimillion dollar pay packages for the company's top executives,

23
00:01:08,800 --> 00:01:10,029
including the CO CEO S.

24
00:01:10,279 --> 00:01:13,769
What is with these companies that have CO C Os like Blackberry and Netflix.

25
00:01:13,779 --> 00:01:16,199
-- That's insane. It
-- seems to be the hip thing.

26
00:01:16,339 --> 00:01:17,610
I don't know. I don't get it either.

27
00:01:17,620 --> 00:01:21,269
-- Is it
-- like a spare tire situation where they take turns? They take team?

28
00:01:21,500 --> 00:01:24,769
It's probably ridiculous. Internal politics is my suspicion.

29
00:01:24,970 --> 00:01:25,440
But

30
00:01:25,580 --> 00:01:27,059
the thing that gets me is

31
00:01:27,169 --> 00:01:27,199
uh,

32
00:01:27,620 --> 00:01:28,400
number one,

33
00:01:29,069 --> 00:01:32,059
anybody essentially below a sea level

34
00:01:32,290 --> 00:01:33,290
person

35
00:01:33,750 --> 00:01:36,180
should have oversight.

36
00:01:36,940 --> 00:01:38,940
Like they literally should have a manager.

37
00:01:39,139 --> 00:01:44,480
Every, the sea level people should have oversight. Everyone should have oversight

38
00:01:44,910 --> 00:01:48,080
to prevent them. Like at a very lowest, low level,

39
00:01:48,209 --> 00:01:50,599
you know, a person making food.

40
00:01:51,190 --> 00:01:53,970
Maybe somebody else checks that the hot dogs are at the right temperature. Right.

41
00:01:53,980 --> 00:01:55,470
That's one thing I love about Costco is you'll

42
00:01:55,480 --> 00:01:57,559
see them like every 10 or 20 minutes opening

43
00:01:57,569 --> 00:01:59,419
up the hot dog thing and sticking thermometers and

44
00:01:59,430 --> 00:02:01,319
making sure the hot dogs are at a temperature.

45
00:02:01,330 --> 00:02:02,629
Do they? I've never,

46
00:02:02,769 --> 00:02:05,809
I see it all the time at Costco, but I'm also, I believe you conscious

47
00:02:05,930 --> 00:02:06,000
of

48
00:02:06,139 --> 00:02:06,230
it.

49
00:02:06,809 --> 00:02:08,910
Right. So you'll see them stick a thermometer and a hot dog

50
00:02:09,050 --> 00:02:10,660
and then they write a number down on a clipboard.

51
00:02:10,669 --> 00:02:13,630
So I don't think I've ever eaten a Costco hot dog. Do you know that?

52
00:02:13,880 --> 00:02:15,070
Oh, you're in for a treat. My friend.

53
00:02:15,679 --> 00:02:20,630
They just use their hot dogs out of the right. I've eaten those hot dogs,

54
00:02:21,020 --> 00:02:21,630
but it's different.

55
00:02:21,899 --> 00:02:25,910
I agree. It's different because they steam the buns. I agree. They steam the buns.

56
00:02:27,199 --> 00:02:31,820
So my, my example of this is when you buy a hot dog at a ballpark,

57
00:02:31,830 --> 00:02:33,270
baseball in the United States,

58
00:02:33,279 --> 00:02:37,070
like it is magic and it's sold by a man carrying around a

59
00:02:37,080 --> 00:02:41,199
box around his neck and it should be disgusting by all accounts,

60
00:02:41,210 --> 00:02:44,440
-- but it is, it is magical and I can't explain it
-- and I love it.

61
00:02:44,449 --> 00:02:45,720
It's the steaming of the buns,

62
00:02:46,020 --> 00:02:47,320
maybe it's the moisture.

63
00:02:47,639 --> 00:02:48,190
So

64
00:02:48,380 --> 00:02:51,050
anyway, so basically like at, at lower levels,

65
00:02:51,059 --> 00:02:53,940
like if somebody can click a link and that's gonna destroy

66
00:02:53,949 --> 00:02:56,610
your company and result in like a giant ransomware incident that

67
00:02:56,770 --> 00:03:00,539
whatever, then, well, then your it and your infosec and your, your,

68
00:03:00,550 --> 00:03:01,779
your process is bad.

69
00:03:02,000 --> 00:03:04,339
I mean, right, you have incompetent it at that point.

70
00:03:04,559 --> 00:03:05,779
If you have

71
00:03:06,300 --> 00:03:08,119
one bad employee to mcdonald's

72
00:03:08,369 --> 00:03:11,100
that should not result in everybody getting food poisoning and dying

73
00:03:11,250 --> 00:03:11,279
in

74
00:03:11,479 --> 00:03:12,020
the whole

75
00:03:12,160 --> 00:03:12,460
world.

76
00:03:13,259 --> 00:03:13,300
Yeah.

77
00:03:13,509 --> 00:03:16,000
Well, and, and, and uh there's a study, I'll have to find,

78
00:03:16,009 --> 00:03:17,199
I don't know if I can find it in time,

79
00:03:17,210 --> 00:03:21,619
but like a vast majority of food poisoning related outbreaks as it turns

80
00:03:21,630 --> 00:03:24,339
out are related to sick employees coming to work who could have guessed.

81
00:03:24,690 --> 00:03:29,990
I mean, I believe that. Now, now here's something I found interesting. So Cisa has

82
00:03:30,289 --> 00:03:30,309
a,

83
00:03:30,320 --> 00:03:34,770
a page dedicated to like the definition of insider threats

84
00:03:34,850 --> 00:03:37,550
and there's a link in the notes for the show.

85
00:03:37,559 --> 00:03:39,809
Kurt has access to it. I will put a link in the show notes.

86
00:03:39,820 --> 00:03:42,949
So I, I assume Kurt hasn't pulled this up yet. Given the typing I just heard.

87
00:03:43,169 --> 00:03:43,770
But

88
00:03:44,679 --> 00:03:48,229
here's what I love the most about this particular pages it

89
00:03:48,330 --> 00:03:51,899
has is they break down insider threats

90
00:03:51,990 --> 00:03:55,800
into unintentional threats and intentional threats.

91
00:03:55,820 --> 00:03:58,050
And then there's also an other, but I mean,

92
00:03:58,160 --> 00:03:59,259
this is something

93
00:03:59,820 --> 00:04:01,570
and, and this is where I have,

94
00:04:01,580 --> 00:04:04,300
I have a plan for this episode that Kurt doesn't know about.

95
00:04:04,440 --> 00:04:04,770
But

96
00:04:04,994 --> 00:04:06,524
so there is

97
00:04:06,925 --> 00:04:11,145
the unintentional aspect that I think we don't often consider.

98
00:04:11,154 --> 00:04:14,755
There's also a quote here. I want, I want to read this Toot from Leslie Carr

99
00:04:15,035 --> 00:04:17,494
Hacks for Pancakes because it's so good

100
00:04:17,684 --> 00:04:20,545
and it will help frame some of the this discussion.

101
00:04:20,553 --> 00:04:25,065
I run into a lot of orgs these days that are too uncomfortable considering

102
00:04:25,380 --> 00:04:30,250
intentional insiders as a threat vector in their security drills and planning

103
00:04:30,399 --> 00:04:33,239
because it might offend a higher up or ruffle feathers.

104
00:04:33,269 --> 00:04:33,899
Meanwhile,

105
00:04:33,910 --> 00:04:36,059
the cost of living is almost the highest it's

106
00:04:36,070 --> 00:04:38,600
ever been compared to pay banks are failing.

107
00:04:38,630 --> 00:04:40,910
People are being forced back to offices,

108
00:04:40,920 --> 00:04:45,459
homes and cars are almost unaffordable for most people dot dot dot

109
00:04:45,890 --> 00:04:48,480
And I think we can all understand exactly what's,

110
00:04:48,489 --> 00:04:50,859
what's meant by that and that's completely valid, right?

111
00:04:50,869 --> 00:04:52,209
100% valid.

112
00:04:52,220 --> 00:04:56,660
Well, I mean, you look at any security vetting process and they look at things like,

113
00:04:57,010 --> 00:04:58,309
do you have debts

114
00:04:58,760 --> 00:05:00,440
that are maybe not like to

115
00:05:00,579 --> 00:05:01,690
a drink but to like Guido.

116
00:05:02,279 --> 00:05:03,750
Are you like blackmail,

117
00:05:03,970 --> 00:05:05,480
like, for example,

118
00:05:05,660 --> 00:05:09,700
uh well, back in the olden days, if you were uh you know, outside of any social norms,

119
00:05:09,709 --> 00:05:12,470
privately, well, then that's potentially blackmail.

120
00:05:12,670 --> 00:05:14,760
Whereas if you're outside of the social norms

121
00:05:14,875 --> 00:05:16,654
publicly, then, well, you can't be blackmailed for that.

122
00:05:17,154 --> 00:05:17,535
And

123
00:05:17,975 --> 00:05:19,734
yeah, and one of those big things is like, I,

124
00:05:19,744 --> 00:05:24,434
I always love when these people it turns out like they have this lavish lifestyle and

125
00:05:24,445 --> 00:05:26,375
they're working a job that's like 50 grand a year and it's kind of like,

126
00:05:26,385 --> 00:05:27,494
well, hang on a minute, right?

127
00:05:27,505 --> 00:05:29,765
Like, obviously something shenanigans was going on.

128
00:05:29,934 --> 00:05:30,924
Yeah, like,

129
00:05:31,470 --> 00:05:32,679
especially now with the,

130
00:05:32,690 --> 00:05:37,410
the whole organizations cutting off 5 10% of their employees.

131
00:05:37,420 --> 00:05:40,660
Well, if there's a good chance you're gonna get fired or laid off anyways, right?

132
00:05:40,670 --> 00:05:45,529
Like, why not sell access to your email account to some Russian website that'll pay

133
00:05:45,839 --> 00:05:48,570
100 bucks for it and be like, oops, it must have leaked

134
00:05:48,739 --> 00:05:53,769
for sure. Now, now here is where I think the conversation gets truly interesting.

135
00:05:54,170 --> 00:05:54,769
So

136
00:05:55,149 --> 00:06:00,529
when we define who an insider is, right? And, and Sisa, I'm gonna go up to the top and

137
00:06:01,140 --> 00:06:03,279
I'm going to read

138
00:06:03,540 --> 00:06:05,690
one particular aspect

139
00:06:05,859 --> 00:06:07,359
of who an insider is, right?

140
00:06:07,369 --> 00:06:10,799
They say a person to whom the organization has supplied a computer and,

141
00:06:10,809 --> 00:06:12,359
or network access, right?

142
00:06:12,369 --> 00:06:13,079
Which makes sense.

143
00:06:13,429 --> 00:06:16,359
There's a person, the organization trusts, including employees,

144
00:06:16,369 --> 00:06:19,190
whatever and given sensitive information and access.

145
00:06:19,200 --> 00:06:21,459
And then they talk about a person

146
00:06:21,470 --> 00:06:24,369
who develops the organization's products and services.

147
00:06:24,380 --> 00:06:26,720
This group includes those who know the secrets of the

148
00:06:26,730 --> 00:06:29,019
products at p whatever don't care about that part.

149
00:06:29,220 --> 00:06:33,320
So here is the ultimate question I think. Are the open source

150
00:06:33,575 --> 00:06:37,565
developers whose code you pull into your product?

151
00:06:37,584 --> 00:06:41,714
-- Are they insiders in your organization?
-- Yes, they are trusted.

152
00:06:41,934 --> 00:06:42,855
I agree.

153
00:06:43,734 --> 00:06:45,924
And, and for any organization that is like, no,

154
00:06:45,934 --> 00:06:47,625
we review all the code before we use it.

155
00:06:47,975 --> 00:06:49,184
No, you don't, you don't,

156
00:06:50,535 --> 00:06:52,915
you can't, I'll give you a hint because you're running Linux.

157
00:06:54,130 --> 00:06:56,720
No, I'm dead serious. Like if you run Linux

158
00:06:56,829 --> 00:07:01,089
and even remotely pretend like you audited that code before deploying it, nobody,

159
00:07:01,100 --> 00:07:02,079
nobody can understand it.

160
00:07:02,089 --> 00:07:03,390
It's too big and complicated.

161
00:07:03,549 --> 00:07:04,160
This is,

162
00:07:04,170 --> 00:07:09,959
this actually brings up AAA friend of mine sent me a link to a story over the weekend

163
00:07:10,209 --> 00:07:11,570
but I did, of course I did.

164
00:07:12,290 --> 00:07:12,709
It was

165
00:07:12,910 --> 00:07:12,920
a,

166
00:07:13,029 --> 00:07:13,859
it wasn't you.

167
00:07:14,049 --> 00:07:15,230
But uh anyway,

168
00:07:15,959 --> 00:07:16,049
yeah,

169
00:07:16,320 --> 00:07:16,440
that's

170
00:07:16,630 --> 00:07:16,670
right.

171
00:07:16,850 --> 00:07:18,369
I, I trust this other person.

172
00:07:19,130 --> 00:07:19,709
Unlike

173
00:07:20,459 --> 00:07:21,269
links, Kurt.

174
00:07:21,279 --> 00:07:22,329
Kurt sends me,

175
00:07:22,339 --> 00:07:26,109
but it basically said anyone who claimed you shouldn't trust anyone

176
00:07:26,119 --> 00:07:28,299
who claims to know C++ and it was a playoff.

177
00:07:28,309 --> 00:07:30,160
There's an old programming

178
00:07:30,480 --> 00:07:32,429
article that's like you shouldn't trust anyone who

179
00:07:32,440 --> 00:07:34,440
doesn't know C++ or something like that.

180
00:07:34,450 --> 00:07:35,339
Basically, right?

181
00:07:35,559 --> 00:07:38,559
And the angle being this was back when like scripting languages

182
00:07:38,570 --> 00:07:41,589
were becoming a thing and it was seen as like lesser programming

183
00:07:42,019 --> 00:07:42,459
-- and
-- same

184
00:07:42,619 --> 00:07:43,760
thing with A I and programming.

185
00:07:43,769 --> 00:07:46,790
-- Now, same thing with PHP
-- program, it'll never change, it never changes.

186
00:07:47,339 --> 00:07:52,970
But the point now is just saying that like C++ has become so enormous and complicated

187
00:07:53,119 --> 00:07:53,570
that

188
00:07:53,899 --> 00:07:59,369
-- nobody can claim to know. Like
-- C plus people making the standards,

189
00:07:59,540 --> 00:08:00,200
-- they
-- don't know either.

190
00:08:00,899 --> 00:08:00,989
They

191
00:08:01,089 --> 00:08:06,010
don't pretend by definition if there's a bug in the standard or in the thing

192
00:08:06,179 --> 00:08:08,450
and clearly somebody didn't understand it fully.

193
00:08:08,910 --> 00:08:10,170
That's it. Like, that's all I got.

194
00:08:10,179 --> 00:08:11,799
Like, like TCP/IP, we,

195
00:08:11,809 --> 00:08:14,040
you're old enough to know what we tried to do

196
00:08:14,049 --> 00:08:18,079
to fix TCP/IP congestion and network congestion 25 years ago.

197
00:08:18,130 --> 00:08:19,760
And it's like all of that

198
00:08:20,070 --> 00:08:22,149
on paper seemed like a, not a bad idea

199
00:08:22,250 --> 00:08:25,089
and in practice, it was completely worse than useless,

200
00:08:25,920 --> 00:08:30,279
right? Like literally every bit of TCP congestion and flow control from 25 years ago

201
00:08:30,600 --> 00:08:33,919
is actively harmful in a real world scenario

202
00:08:34,210 --> 00:08:37,039
for sure, for sure. So all of this put together, right?

203
00:08:37,049 --> 00:08:39,260
Like this is nice definition of insider threats,

204
00:08:39,558 --> 00:08:41,909
-- hacks or pancakes, insider threat
-- question.

205
00:08:42,010 --> 00:08:45,030
So I, because I've never really thought about the unintentional insider threat,

206
00:08:45,039 --> 00:08:47,239
but that makes sense because people make mistakes and

207
00:08:47,250 --> 00:08:50,159
ideally you have processes in place to catch that.

208
00:08:50,169 --> 00:08:54,590
Like somebody, oh, for example, somebody fat fingers a quote and you know,

209
00:08:54,599 --> 00:08:58,650
drops or adds a zero to a quote and a customer is either very happy or very upset.

210
00:08:59,015 --> 00:08:59,265
Right?

211
00:08:59,835 --> 00:09:03,635
And one thing I've always like, one thing I wanted to actually get into CWE as a,

212
00:09:03,645 --> 00:09:07,325
as a vulnerability was essentially ridiculous price movements.

213
00:09:07,335 --> 00:09:07,674
So

214
00:09:07,955 --> 00:09:08,984
for example, you're,

215
00:09:08,994 --> 00:09:11,744
you're using a crypto wallet and you want to sell or buy

216
00:09:11,755 --> 00:09:15,224
some crypto and you offer or give a price that is like,

217
00:09:15,234 --> 00:09:16,364
well outside the norm,

218
00:09:16,484 --> 00:09:17,184
it should

219
00:09:17,424 --> 00:09:20,445
like all the wallets should be like, whoa, like, uh, even better example is, uh,

220
00:09:20,455 --> 00:09:21,255
the gas fee,

221
00:09:21,265 --> 00:09:22,775
the gas fee should be a small percent of

222
00:09:22,784 --> 00:09:25,705
the transaction and people have swapped those numbers and

223
00:09:25,835 --> 00:09:26,825
lost all their money.

224
00:09:27,119 --> 00:09:28,969
And again, I think the wallet should be like, hey, you know,

225
00:09:28,979 --> 00:09:30,590
if the gas fee is more than like,

226
00:09:30,719 --> 00:09:33,979
5% we should probably throw up a big red warning and like,

227
00:09:33,989 --> 00:09:35,320
just not allow the transaction.

228
00:09:35,330 --> 00:09:40,590
-- So
-- actually I had to move some Bitcoin, uh, maybe a year or two ago now.

229
00:09:40,760 --> 00:09:46,080
It was basically when Coinbase was like, oh, any of the Bitcoin in our system is like,

230
00:09:46,330 --> 00:09:50,184
it is, what, what is it like, uh, uh, debtors can, can go after it.

231
00:09:50,195 --> 00:09:52,094
I was like, yeah, we're taking this out of there.

232
00:09:52,364 --> 00:09:53,895
-- Yeah,
-- that's how corporate debt works.

233
00:09:53,905 --> 00:09:55,744
What did you think Coinbase was a bank or something?

234
00:09:56,215 --> 00:09:57,585
-- That's,
-- no, I'm serious because

235
00:09:57,594 --> 00:09:58,044
like, well,

236
00:09:58,054 --> 00:10:01,065
they're being sued right now by the sec about exactly that.

237
00:10:01,075 --> 00:10:04,265
-- No, no, no,
-- they're being sued for, uh, unlicensed securities.

238
00:10:04,315 --> 00:10:07,585
-- But here's the thing like the, uh, the FTC.
-- Here's a point. Here's the point though.

239
00:10:07,594 --> 00:10:08,104
Ok,

240
00:10:08,530 --> 00:10:12,650
so I put in a much higher transaction fee than normal because I

241
00:10:12,659 --> 00:10:15,830
wanted the coins to move because obviously you can put in like the,

242
00:10:15,840 --> 00:10:19,059
the whatever Bitcoin suggests, but it takes like two days.

243
00:10:19,070 --> 00:10:21,349
And I'm like, I want this money out now

244
00:10:21,830 --> 00:10:25,190
and I made it pretty high and the client was like, hey,

245
00:10:25,229 --> 00:10:27,599
your transaction fee is really high.

246
00:10:27,609 --> 00:10:28,710
Are you sure you want to do this?

247
00:10:28,719 --> 00:10:33,409
And I was like, absolutely, I do like, get that coin out of Coinbase right now.

248
00:10:33,700 --> 00:10:35,760
And so, yeah, like, but that, that's a technical thing,

249
00:10:35,770 --> 00:10:38,460
-- wallets can do well
-- or any software where it should be

250
00:10:39,190 --> 00:10:44,650
like, for example, stock, like if stocks start bouncing up and down too much,

251
00:10:44,659 --> 00:10:46,419
you know, they'll shut down trading on the stock because

252
00:10:46,619 --> 00:10:47,359
even if

253
00:10:47,565 --> 00:10:48,965
is technically wrong,

254
00:10:49,094 --> 00:10:52,375
like we need to maybe take a pause, you know, the circuit breaker idea, right?

255
00:10:52,385 --> 00:10:54,544
-- Where it's maybe less harmful to stall
-- it

256
00:10:54,554 --> 00:10:54,734
out.

257
00:10:54,744 --> 00:10:57,575
But now, I mean, from the context of insider threats,

258
00:10:57,604 --> 00:11:00,955
how many organizations have circuit breaker

259
00:11:00,965 --> 00:11:04,195
type things in place for unintentional

260
00:11:04,445 --> 00:11:06,075
insider activity?

261
00:11:06,234 --> 00:11:08,164
-- Probably not many, a lot
-- of them do,

262
00:11:08,174 --> 00:11:11,905
but it's under the guise of quality control and Six Sigma and not a security thing.

263
00:11:12,284 --> 00:11:12,304
So,

264
00:11:12,484 --> 00:11:12,505
for

265
00:11:13,065 --> 00:11:13,145
example.

266
00:11:13,559 --> 00:11:13,849
Right.

267
00:11:13,859 --> 00:11:16,070
So for example, with the restaurants, uh, they, uh,

268
00:11:16,080 --> 00:11:19,909
good restaurants have a lot of backstops to prevent food

269
00:11:19,919 --> 00:11:21,690
from hurting people or going out bad or whatever.

270
00:11:21,700 --> 00:11:22,070
Sure.

271
00:11:22,080 --> 00:11:26,099
You know, there's a lot of companies that invest a lot of, oh, I was just watching, um,

272
00:11:26,469 --> 00:11:26,929
uh, Der

273
00:11:27,030 --> 00:11:30,270
Bauer and he uh goes to NVIDIA and sees how not NVIDIA,

274
00:11:30,280 --> 00:11:32,809
he goes to a video card manufacturer and how they make video cards.

275
00:11:32,820 --> 00:11:35,929
And for example, you know how they get like all the components on those tape reels,

276
00:11:35,940 --> 00:11:39,090
like say capacitors or little resistors or whatever.

277
00:11:39,229 --> 00:11:40,330
Well, so for example,

278
00:11:40,340 --> 00:11:43,020
if they get a reel with like they have these QC charts and it was like,

279
00:11:43,030 --> 00:11:47,090
if you get a reel with like it's like 1000 or was it like 10,000 of these,

280
00:11:47,099 --> 00:11:48,890
you have to take 200 out and test them

281
00:11:49,049 --> 00:11:51,169
and if one fails out of that 200 you're ok.

282
00:11:51,375 --> 00:11:55,416
If two or more fail, then you have to test a whole bunch more. Sure.

283
00:11:55,666 --> 00:11:58,065
And so they literally buy all these things,

284
00:11:58,075 --> 00:12:00,895
these products like reels of parts and they test

285
00:12:00,906 --> 00:12:03,226
hundreds of them to make sure that they're correct.

286
00:12:03,236 --> 00:12:03,435
Right.

287
00:12:03,445 --> 00:12:05,575
They don't trust the people they're buying from

288
00:12:05,585 --> 00:12:07,966
to not ship them some shoddy product because

289
00:12:08,135 --> 00:12:08,955
if you think about it, right,

290
00:12:08,966 --> 00:12:12,056
if you buy a reel of 10,000 capacitors and they're all off by a few percent,

291
00:12:12,065 --> 00:12:14,445
that's a heck of a lot of broken video cards,

292
00:12:14,616 --> 00:12:15,476
right. You know,

293
00:12:15,676 --> 00:12:15,976
and so,

294
00:12:16,081 --> 00:12:18,752
so that's the thing, like they have every single thing that comes in,

295
00:12:18,762 --> 00:12:21,872
they basically test some statistically relevant sample

296
00:12:21,882 --> 00:12:23,492
of them and if they fail enough,

297
00:12:23,502 --> 00:12:25,142
they test more, they chuck it out or whatever.

298
00:12:25,151 --> 00:12:26,992
So there are companies that do this,

299
00:12:27,002 --> 00:12:29,281
but it's almost never really done as a security thing.

300
00:12:29,291 --> 00:12:30,502
Like banks are a good example. Right?

301
00:12:30,512 --> 00:12:32,432
Every time you go to the bank and you want to do a transaction,

302
00:12:32,442 --> 00:12:36,062
say of over three or $4000 the teller has to go get an override.

303
00:12:36,072 --> 00:12:40,572
-- Ok, so that the tellers can't like do a bunch of shenanigans quickly.
-- That's right.

304
00:12:41,190 --> 00:12:42,809
I guess, I don't know if I've ever done.

305
00:12:42,820 --> 00:12:45,929
-- I, I don't know, I can't think of an instance where go
-- to the bank and,

306
00:12:45,940 --> 00:12:49,130
and ask for $5000 in cash and they're gonna make a manager, like,

307
00:12:49,140 --> 00:12:52,630
look at you and look at your ID and be like, ok, or if you want to transfer like,

308
00:12:52,640 --> 00:12:56,090
some large sum of money between accounts or, or get a cashier's check or whatever.

309
00:12:56,099 --> 00:12:58,650
Right. They're gonna basically get a second set of eyes on it

310
00:12:59,030 --> 00:13:00,989
because there's just too much potential

311
00:13:01,140 --> 00:13:01,940
for shenanigans

312
00:13:02,099 --> 00:13:05,929
and, and also for errors again, back to the unintentional thing. Right.

313
00:13:05,940 --> 00:13:10,200
How many, how many people have, you know, uh, every time I make a bill payment online,

314
00:13:10,210 --> 00:13:11,330
I make sure that I don't, like,

315
00:13:11,340 --> 00:13:13,940
add a zero to it because if I do the company would be like, thank you,

316
00:13:13,950 --> 00:13:15,210
you're paid for the next 10 months.

317
00:13:15,219 --> 00:13:18,130
Right. Right. Exactly. Everything you've said is correct.

318
00:13:18,140 --> 00:13:21,650
And I, I think it seems like it, it makes sense but I,

319
00:13:21,900 --> 00:13:22,760
I still, like, I,

320
00:13:22,770 --> 00:13:26,640
I keep having in my head this idea that all of your open source

321
00:13:26,650 --> 00:13:29,239
is functionally an insider threat that you

322
00:13:29,250 --> 00:13:32,750
have basically little to no mitigation against.

323
00:13:32,760 --> 00:13:35,109
And there's very little you can do about.

324
00:13:35,119 --> 00:13:39,520
Part of the challenge is I think it's the scale we're back to scale and logistics of.

325
00:13:39,760 --> 00:13:43,250
If I give you 10 lines of PHP, you can absolutely code review that.

326
00:13:43,260 --> 00:13:45,770
If I give you the Linux kernel, you, you basically say uh huh

327
00:13:46,070 --> 00:13:46,190
and

328
00:13:46,349 --> 00:13:46,739
no one

329
00:13:46,880 --> 00:13:49,710
-- can review that correctly and couldn't even
-- try.

330
00:13:49,909 --> 00:13:53,210
Like the literally about the only thing you can do with Linux is like,

331
00:13:53,219 --> 00:13:55,409
are we gonna run up to date or like a long term?

332
00:13:55,419 --> 00:13:58,570
That's basically your two options and you pick one and go with it

333
00:13:59,429 --> 00:14:01,349
and, and that's fine. And so

334
00:14:02,239 --> 00:14:03,830
you can outsource that also.

335
00:14:03,840 --> 00:14:05,400
And, and I think there is a big thing is we can,

336
00:14:05,409 --> 00:14:08,599
but you can outsource the risk of the insider threat by, for example,

337
00:14:08,780 --> 00:14:12,450
paying red hat for the kernel instead of just grabbing the random open source one.

338
00:14:12,460 --> 00:14:16,369
-- But,
-- but the kernel is irrelevant in this conversation, Kurt, because

339
00:14:16,760 --> 00:14:18,070
the kernel is

340
00:14:18,340 --> 00:14:19,780
one piece

341
00:14:20,030 --> 00:14:21,799
of all of the software you run.

342
00:14:21,809 --> 00:14:22,169
You're taught,

343
00:14:22,179 --> 00:14:24,520
you're probably my guess is the kernel accounts

344
00:14:24,530 --> 00:14:26,989
for 10% of the code in your infrastructure,

345
00:14:27,000 --> 00:14:30,260
-- maybe less
-- actually by code by line by numbers,

346
00:14:30,270 --> 00:14:31,429
especially because we're mostly serverless.

347
00:14:31,440 --> 00:14:32,210
It's actually

348
00:14:32,479 --> 00:14:33,469
probably a lot.

349
00:14:33,640 --> 00:14:33,919
But,

350
00:14:34,169 --> 00:14:36,010
but here's the thing, right. Here's the thing

351
00:14:36,400 --> 00:14:37,830
and no one's serverless.

352
00:14:37,909 --> 00:14:40,739
The number of companies that are actually serverless is hilariously.

353
00:14:40,750 --> 00:14:42,320
We're not serverless yet, but we're going.

354
00:14:42,619 --> 00:14:43,700
-- But
-- the point is

355
00:14:44,210 --> 00:14:48,729
so we traditionally think of a supplier relationship where we're buying,

356
00:14:48,739 --> 00:14:52,570
say software from Microsoft, we're buying nuts from some company where,

357
00:14:52,580 --> 00:14:53,979
and bolts from this company.

358
00:14:53,989 --> 00:14:58,669
And generally, I think we've stuck our head in the sand and said like, oh,

359
00:14:58,729 --> 00:15:01,469
this isn't an insider threat because

360
00:15:01,590 --> 00:15:03,369
we have a contract in place

361
00:15:03,559 --> 00:15:06,130
and they're going to give us what we asked for and we, we, like,

362
00:15:06,140 --> 00:15:08,020
totally ignore that sort of behavior.

363
00:15:08,030 --> 00:15:08,270
Right.

364
00:15:08,280 --> 00:15:10,190
-- Well,
-- except for the companies that, like, test every, uh,

365
00:15:10,219 --> 00:15:13,570
-- 200 out of every 10,000 capacitors coming in and,
-- and no, no,

366
00:15:13,580 --> 00:15:14,880
that's quality control.

367
00:15:14,890 --> 00:15:18,010
Right? Quality control, I think is a different problem. It's similar.

368
00:15:18,020 --> 00:15:18,919
I won't disagree

369
00:15:19,219 --> 00:15:19,690
but

370
00:15:19,890 --> 00:15:23,369
any time you're building a thing you have to do quality control. I mean,

371
00:15:23,750 --> 00:15:24,280
I remember

372
00:15:26,210 --> 00:15:26,429
you,

373
00:15:26,729 --> 00:15:31,020
anyone creating a quality product is doing quality control. That's the reality.

374
00:15:31,030 --> 00:15:32,130
I know you don't have to.

375
00:15:32,140 --> 00:15:33,690
I know there's plenty of products that don't,

376
00:15:33,700 --> 00:15:35,460
but we're gonna just pretend people do, right?

377
00:15:35,469 --> 00:15:37,119
Because it makes the conversation easier.

378
00:15:37,549 --> 00:15:40,609
Now, when we have open source, we often,

379
00:15:40,679 --> 00:15:42,840
and I shouldn't even just bucket open source into this.

380
00:15:42,849 --> 00:15:44,969
Right. We're gonna, we're gonna take any vendor,

381
00:15:45,109 --> 00:15:47,900
you're using windows, you're using Mac Os, you're using. Linux

382
00:15:48,010 --> 00:15:48,700
doesn't matter.

383
00:15:49,260 --> 00:15:52,750
We don't really do quality control over a lot of this stuff. Right.

384
00:15:52,760 --> 00:15:56,119
We just kind of take it and use it and we say everything is fine.

385
00:15:56,599 --> 00:15:59,080
-- Next,
-- I think there's two challenges here.

386
00:15:59,090 --> 00:16:02,059
One, it's really hard to do quality control

387
00:16:02,440 --> 00:16:05,229
and, and so, and a lot of places I'm actually gonna disagree with you.

388
00:16:05,239 --> 00:16:06,830
A lot of places do, do quality control.

389
00:16:06,840 --> 00:16:08,450
So for example, Microsoft patch, Tuesday,

390
00:16:08,489 --> 00:16:11,159
people don't just blindly apply the updates across the board,

391
00:16:11,349 --> 00:16:14,330
they selectively test them and then decide which patches they're actually

392
00:16:14,340 --> 00:16:16,190
gonna deploy and they put a lot of work into this.

393
00:16:16,979 --> 00:16:18,039
And number two,

394
00:16:18,469 --> 00:16:20,859
here's the ugly truth. You don't have a choice, right?

395
00:16:20,869 --> 00:16:22,880
See, for example, if you're buying capacitors,

396
00:16:23,130 --> 00:16:24,359
you, you have choices,

397
00:16:24,369 --> 00:16:25,830
you probably have more than two or three

398
00:16:25,840 --> 00:16:28,849
vendors that make a functionally equivalent identical capacitor because

399
00:16:29,200 --> 00:16:31,380
they have standards. If you wanna run a Windows app,

400
00:16:31,489 --> 00:16:32,200
you have

401
00:16:32,539 --> 00:16:34,659
realistically one choice which is to run windows.

402
00:16:34,669 --> 00:16:36,489
Now, I know that there's things like wine and

403
00:16:36,690 --> 00:16:37,929
that other stuff, but

404
00:16:38,049 --> 00:16:38,690
realistically,

405
00:16:38,700 --> 00:16:42,840
if you're gonna run Windows in production or run a Windows App in production

406
00:16:43,159 --> 00:16:45,789
and you suggest anything other than running windows,

407
00:16:45,799 --> 00:16:47,229
you're probably gonna get fired.

408
00:16:47,390 --> 00:16:48,650
And, but so,

409
00:16:48,659 --> 00:16:51,250
and I think this is part of the problem is you're trying

410
00:16:51,260 --> 00:16:54,750
to do quality control on something that is at the same time,

411
00:16:54,760 --> 00:16:56,669
both hideously complex

412
00:16:57,219 --> 00:16:59,510
and potentially closed source.

413
00:16:59,799 --> 00:17:01,210
I mean, sure. But, but

414
00:17:01,479 --> 00:17:01,530
I

415
00:17:01,729 --> 00:17:02,030
don't, I

416
00:17:02,479 --> 00:17:03,429
don't wanna go down the closer

417
00:17:03,549 --> 00:17:04,020
path.

418
00:17:04,030 --> 00:17:04,680
No, no, no, no, no,

419
00:17:04,689 --> 00:17:07,380
but I'm just trying to point out when you do quality control on something.

420
00:17:07,390 --> 00:17:11,219
If I gave you a sealed up box that has like an input and an output.

421
00:17:11,229 --> 00:17:12,900
You can check that input and output,

422
00:17:12,910 --> 00:17:14,979
but you're not gonna know that one of the resistors inside is

423
00:17:14,989 --> 00:17:18,305
gonna fail after 10,000 cycles unless you actually cycle it 10,000 times.

424
00:17:18,395 --> 00:17:20,915
Ok? No, this is OK. This is exact. This is a good point.

425
00:17:20,925 --> 00:17:23,223
I think this lends itself nicely into

426
00:17:23,375 --> 00:17:27,665
where I wanted to steer this plane by the end of this conversation. And that is

427
00:17:27,915 --> 00:17:28,464
so

428
00:17:28,594 --> 00:17:32,104
let's say all of open source is an insider threat you have to deal with. Right.

429
00:17:32,520 --> 00:17:34,280
-- Well, it's trusted. So
-- sure

430
00:17:34,520 --> 00:17:37,859
when we think about things like insider threats, we,

431
00:17:37,959 --> 00:17:40,420
and if you read like there's all this guidance that

432
00:17:40,689 --> 00:17:43,699
it has a mitigating insider threats guide somewhere, I'll,

433
00:17:43,709 --> 00:17:45,219
I'll find it and put a link in the show notes.

434
00:17:45,339 --> 00:17:48,579
But basically they talk about like creating all these programs

435
00:17:48,589 --> 00:17:50,040
and putting all this stuff in place to like,

436
00:17:50,050 --> 00:17:53,420
identify threats and watch for bad behavior and, and things like that.

437
00:17:53,430 --> 00:17:56,219
Right? When we talk about things like software,

438
00:17:56,760 --> 00:17:59,819
I think we love to talk about prevention

439
00:18:00,459 --> 00:18:01,459
which doesn't work.

440
00:18:01,469 --> 00:18:04,569
We all know that in the world of software prevention doesn't work.

441
00:18:04,829 --> 00:18:05,420
I'm, I'm not,

442
00:18:06,089 --> 00:18:07,060
you can make arguments.

443
00:18:07,069 --> 00:18:10,060
Oh, but it does in this obscure situation, but fundamentally it doesn't.

444
00:18:10,400 --> 00:18:12,660
So we're running all this software that's

445
00:18:12,670 --> 00:18:15,219
functionally an insider threat to our organization.

446
00:18:15,310 --> 00:18:17,959
We have little to no control over the software

447
00:18:18,170 --> 00:18:19,859
and instead of saying, OK,

448
00:18:19,920 --> 00:18:24,880
let's build our mitigation strategy around this reality.

449
00:18:24,969 --> 00:18:29,550
We obsess over things like, oh, we'll just control all the open source we use

450
00:18:30,030 --> 00:18:30,819
like reproducible.

451
00:18:30,989 --> 00:18:35,280
-- No,
-- you won't, you won't do any of these things. You're going to spend

452
00:18:35,630 --> 00:18:40,119
a gazillion hours talking about how you're going to fix open source.

453
00:18:40,160 --> 00:18:43,300
Instead of saying, let's construct

454
00:18:43,719 --> 00:18:44,020
a

455
00:18:44,510 --> 00:18:49,209
insider threat program. Let's construct security policy. Let's create

456
00:18:49,400 --> 00:18:54,359
our internal security program around these realities.

457
00:18:54,719 --> 00:18:57,619
And it blows my mind sometimes how we have this

458
00:18:57,875 --> 00:19:01,295
session with changing open source instead of changing ourselves.

459
00:19:01,594 --> 00:19:03,854
Well, I mean, I'm, I'm lucky working at the CS A.

460
00:19:03,864 --> 00:19:06,055
I was, we're able to do that because I'm like, hey devs,

461
00:19:06,064 --> 00:19:07,935
you sh you update the website twice a week.

462
00:19:07,944 --> 00:19:09,704
Ok. Keep doing that. That's our security

463
00:19:10,064 --> 00:19:10,694
and that's,

464
00:19:11,405 --> 00:19:14,535
-- that's
-- it. And, and yes, that works for you. And that's lovely.

465
00:19:14,854 --> 00:19:14,984
Yeah.

466
00:19:14,994 --> 00:19:17,895
And I, but I get also a lot of places, you know, if you're making banking software,

467
00:19:17,905 --> 00:19:20,094
you can't just ship an update twice a week.

468
00:19:21,119 --> 00:19:22,699
Like that's just not gonna fly.

469
00:19:22,880 --> 00:19:23,420
Right.

470
00:19:23,939 --> 00:19:25,180
The more I think about this,

471
00:19:25,709 --> 00:19:25,719
I

472
00:19:25,959 --> 00:19:28,439
think this is one of the reasons cloud one is

473
00:19:28,449 --> 00:19:30,829
that it allowed you to outsource this in a way

474
00:19:30,959 --> 00:19:35,209
that you really could strongly ignore it because it was so hidden.

475
00:19:35,219 --> 00:19:38,020
It's like you just get a nice API or a nice website with cornflower blue.

476
00:19:38,030 --> 00:19:39,280
No, I'm completely serious because you

477
00:19:40,250 --> 00:19:40,510
magic

478
00:19:40,650 --> 00:19:40,910
it away

479
00:19:41,510 --> 00:19:43,260
it, yes, the,

480
00:19:43,920 --> 00:19:47,209
you know, it's like going to a gas station and not thinking about, like,

481
00:19:47,219 --> 00:19:49,219
the last 20 years of the war on terror.

482
00:19:49,375 --> 00:19:51,635
That's right. Or the first Gulf War and all the,

483
00:19:52,694 --> 00:19:56,035
it's totally just like a nice facade

484
00:19:56,494 --> 00:19:57,635
and it could be

485
00:19:57,775 --> 00:20:00,135
the most ridiculous crack den behind it.

486
00:20:00,145 --> 00:20:02,824
But as long as it looks nice from the outside, it's fine.

487
00:20:03,094 --> 00:20:05,755
I like the idea of the unintentional threat as well

488
00:20:05,765 --> 00:20:08,344
because I hadn't really ever given that that much thought.

489
00:20:08,354 --> 00:20:11,354
And especially with open source, there's a lot of, well, like people

490
00:20:11,694 --> 00:20:14,839
accidentally introduce bugs or they try and add a new feature.

491
00:20:14,849 --> 00:20:17,640
And I mean, my favorite all time example is the open SSH.

492
00:20:17,650 --> 00:20:18,430
People who are like, hey,

493
00:20:18,439 --> 00:20:21,130
this vendor wants kind of the support for roaming sessions.

494
00:20:21,140 --> 00:20:21,979
Hey, that sounds cool.

495
00:20:21,989 --> 00:20:22,079
You know,

496
00:20:22,089 --> 00:20:24,920
your IP address changes and your connection doesn't poop itself

497
00:20:25,010 --> 00:20:26,260
and you don't have to log back in again.

498
00:20:26,270 --> 00:20:26,719
Cool.

499
00:20:26,729 --> 00:20:29,849
We sort of implemented that server side but the client never got built

500
00:20:29,859 --> 00:20:31,839
and then we had this dead code and we kind of left it there

501
00:20:31,939 --> 00:20:35,589
and then it turns out to be, you know, a key disclosure vulnerability. Oops,

502
00:20:35,849 --> 00:20:36,819
I remember that like

503
00:20:37,064 --> 00:20:39,364
these are the people that are supposedly, you know,

504
00:20:39,375 --> 00:20:41,964
holding themselves to the highest standard and doing one of the

505
00:20:41,974 --> 00:20:45,204
most security critical pieces of code that used to be available.

506
00:20:45,214 --> 00:20:48,405
Like now, honestly open SSH is not as important as it used to be because

507
00:20:48,614 --> 00:20:51,015
we have orchestration management software.

508
00:20:51,314 --> 00:20:55,354
-- And it's still pretty important.
-- I'm not saying it's not important.

509
00:20:55,364 --> 00:20:56,885
I'm saying it's less important, right?

510
00:20:57,005 --> 00:21:00,844
Because it used to be, we used to manage servers by logging in via open as sh because

511
00:21:01,349 --> 00:21:03,069
what else would you do if there was

512
00:21:03,170 --> 00:21:03,229
no

513
00:21:03,420 --> 00:21:04,349
Anzel or Puppet or

514
00:21:05,280 --> 00:21:05,359
an

515
00:21:05,650 --> 00:21:07,020
uses open SS A?

516
00:21:07,319 --> 00:21:07,650
Yeah.

517
00:21:08,709 --> 00:21:12,359
But anyways back to this, but basically even they made

518
00:21:12,640 --> 00:21:13,160
like,

519
00:21:14,020 --> 00:21:16,489
like if you were looking at this and you were paranoid, you'd be like, oh,

520
00:21:16,500 --> 00:21:19,609
that's an insider threat that introduced this bug that allows key disclosure.

521
00:21:19,619 --> 00:21:23,099
Well, no, it's just people being people and not removing dead code. That's bad.

522
00:21:23,109 --> 00:21:24,609
-- I mean.
-- Right. Right. But

523
00:21:25,349 --> 00:21:30,689
you are correct that we often don't think about those things in the same context.

524
00:21:30,699 --> 00:21:32,010
And I think we often

525
00:21:32,359 --> 00:21:35,640
actually, you know, I think in a lot of ways we deal with bugs more correctly

526
00:21:35,900 --> 00:21:40,780
because how many times are, well, there are efforts to ferret out bugs before

527
00:21:41,449 --> 00:21:46,089
the, before it's deployed and most of those don't work very well and we all know that.

528
00:21:46,390 --> 00:21:48,369
And so we've developed these

529
00:21:48,510 --> 00:21:53,449
oftentimes comprehensive and impressive response capabilities to bugs. Right.

530
00:21:53,459 --> 00:21:53,979
And when you,

531
00:21:53,989 --> 00:21:58,229
I think bucket malicious insider threats to unintentional insider threats,

532
00:21:58,239 --> 00:22:02,349
that sort of like quick response is very similar.

533
00:22:02,359 --> 00:22:04,780
Now, I will say though, I think in many instances,

534
00:22:04,790 --> 00:22:08,239
the number of malicious insider threats is very, very low.

535
00:22:08,489 --> 00:22:12,449
The number of unintentional insider threats is much, much higher.

536
00:22:12,459 --> 00:22:18,150
Well, I mean, technically any bug that causes a, a serious detriment is an insider,

537
00:22:18,390 --> 00:22:22,959
-- unintentional insider threat.
-- It, it kind of is, I wouldn't disagree with that.

538
00:22:22,969 --> 00:22:28,050
And I think, but this is where reaction and response are our

539
00:22:28,680 --> 00:22:32,890
behavior in that context. Whereas when we think of malicious insiders,

540
00:22:33,329 --> 00:22:35,729
we try to ferret them out and stop them.

541
00:22:35,739 --> 00:22:38,829
So we focus on prevention, which is often not effective.

542
00:22:39,000 --> 00:22:41,800
I wonder if it kind of goes back to that problem of the intention,

543
00:22:41,810 --> 00:22:46,420
argument around security versus regular bugs where essentially, well, see,

544
00:22:46,430 --> 00:22:49,469
and this works for the military in the sense of, ok, we have a threat

545
00:22:49,880 --> 00:22:52,339
and a threat by definition has an actor.

546
00:22:52,439 --> 00:22:54,339
So if we deal with the actor,

547
00:22:54,839 --> 00:22:56,750
then we take care of the threat.

548
00:22:57,400 --> 00:22:58,069
And

549
00:22:58,849 --> 00:23:03,390
in computer software, we, well, we can't get rid of all the bad actors because

550
00:23:03,560 --> 00:23:04,520
it's a global

551
00:23:04,819 --> 00:23:07,680
world and they can all connect to us via internet.

552
00:23:08,790 --> 00:23:09,930
Whereas, you know,

553
00:23:10,280 --> 00:23:12,479
like my house physical security, for example,

554
00:23:12,489 --> 00:23:15,589
I don't have to worry about people on the internet so much as I have to worry about,

555
00:23:16,229 --> 00:23:18,599
uh, somebody, you know, going through the neighborhood testing,

556
00:23:18,609 --> 00:23:20,239
seeing if all the doors are open or whatever.

557
00:23:20,479 --> 00:23:21,010
Right?

558
00:23:21,209 --> 00:23:22,680
And for example, like,

559
00:23:23,530 --> 00:23:24,109
so

560
00:23:24,349 --> 00:23:27,900
I think maybe that's part of it because the idea and I, you know,

561
00:23:27,910 --> 00:23:29,979
this speaks to a lot of the threat intelligence where, you know,

562
00:23:29,989 --> 00:23:31,469
where they're tracking all these advanced

563
00:23:31,729 --> 00:23:33,069
uh acting groups.

564
00:23:33,079 --> 00:23:33,239
You know,

565
00:23:33,250 --> 00:23:34,550
there was that recent news of the

566
00:23:34,560 --> 00:23:37,030
Chinese one that's going after infrastructure stuff.

567
00:23:37,729 --> 00:23:38,270
And

568
00:23:38,680 --> 00:23:42,380
I think part of the challenge there is a lot of people feel like

569
00:23:42,390 --> 00:23:45,689
and I suspect they're right that we can't boil the ocean and fix,

570
00:23:45,699 --> 00:23:49,189
like we can't fix all our infrastructure providers and get them to be secure.

571
00:23:49,199 --> 00:23:49,930
That is correct.

572
00:23:50,119 --> 00:23:52,030
So for example, maybe if we

573
00:23:52,689 --> 00:23:54,589
and I don't know how exactly, but maybe if we

574
00:23:54,849 --> 00:23:57,380
get all the bad actors to stop being bad actors,

575
00:23:57,689 --> 00:23:59,869
have we tried asking nicely?

576
00:23:59,880 --> 00:24:01,609
I'm not really clear on how we do that,

577
00:24:01,619 --> 00:24:03,790
especially when they're in a foreign jurisdiction

578
00:24:03,900 --> 00:24:05,550
with a government that's ok with it.

579
00:24:05,819 --> 00:24:07,310
But ignoring all that,

580
00:24:07,410 --> 00:24:09,430
you know. Yeah, it's an attractive

581
00:24:09,810 --> 00:24:12,670
and it, it's sort of sexy and it's sort of cool, like, oh, yeah. Well,

582
00:24:12,800 --> 00:24:15,859
you know, we, we found, uh, what was it? Fancy bear and, you know, they're in Russia,

583
00:24:16,589 --> 00:24:18,170
like, cool. Like, what are you gonna like?

584
00:24:18,180 --> 00:24:20,390
The Russian government is quite happy with them.

585
00:24:20,400 --> 00:24:23,339
-- Well, but that's,
-- I mean, that is technically an insider threat,

586
00:24:23,349 --> 00:24:25,550
but I think it's generally not seen as it where

587
00:24:25,560 --> 00:24:29,910
we think of insider threats most commonly as actual employees,

588
00:24:29,920 --> 00:24:30,310
right?

589
00:24:31,069 --> 00:24:33,219
Versus Attackers on the outside.

590
00:24:33,569 --> 00:24:35,939
-- Yeah.
-- Who are buying access? Who are, I

591
00:24:35,959 --> 00:24:37,939
mean, some of them do for sure, for sure.

592
00:24:38,069 --> 00:24:41,630
Not all but, and I, oh man, I guess that's part of the challenge as well, right?

593
00:24:41,640 --> 00:24:45,819
Because if you have an insider threat being coerced by, say a foreign government,

594
00:24:45,829 --> 00:24:46,699
social engineering,

595
00:24:47,750 --> 00:24:50,660
social engineering, somebody who falls for social engineering,

596
00:24:51,469 --> 00:24:51,979
that's

597
00:24:52,260 --> 00:24:54,969
the unintentional insider threat right there because,

598
00:24:55,540 --> 00:24:59,199
right, the external attacker wants insider access and hey, Bob, you know,

599
00:24:59,349 --> 00:25:02,209
uh my laptop's dead and I need you to like, read off, you know, like

600
00:25:02,920 --> 00:25:03,719
whatever. Right?

601
00:25:06,239 --> 00:25:07,410
So,

602
00:25:07,660 --> 00:25:08,079
yeah.

603
00:25:08,969 --> 00:25:13,209
No, I, I like that idea of unintentional insider threat because it explains,

604
00:25:13,219 --> 00:25:13,979
for example,

605
00:25:14,250 --> 00:25:16,489
I think a lot of these efforts that like, oh, well,

606
00:25:16,500 --> 00:25:18,400
we'll train everybody not to click on fishing links.

607
00:25:18,410 --> 00:25:18,890
Well,

608
00:25:20,349 --> 00:25:23,050
except, hey, it's my job to click on links in email. And b

609
00:25:23,920 --> 00:25:26,150
again, I'll be blunt if somebody,

610
00:25:26,160 --> 00:25:28,170
even the CEO clicks the link in an email and

611
00:25:28,180 --> 00:25:30,349
that causes your company to have a really bad day,

612
00:25:30,489 --> 00:25:31,069
then

613
00:25:32,060 --> 00:25:32,229
I mean,

614
00:25:33,140 --> 00:25:35,920
somebody's gonna accidentally click that link at some point or,

615
00:25:36,949 --> 00:25:40,520
or, or, or delete a file they shouldn't have or whatever

616
00:25:40,680 --> 00:25:41,339
100 percent.

617
00:25:41,439 --> 00:25:42,030
And

618
00:25:42,589 --> 00:25:42,989
so,

619
00:25:43,239 --> 00:25:45,400
and here's just a fascinating slight tangent,

620
00:25:45,550 --> 00:25:46,030
but

621
00:25:46,160 --> 00:25:47,910
you're saying that companies don't really have

622
00:25:47,920 --> 00:25:49,380
a way of dealing with insider threats.

623
00:25:49,390 --> 00:25:50,560
So they kind of don't acknowledge it.

624
00:25:50,630 --> 00:25:53,839
And yet every time they like fire a person, they immediately like,

625
00:25:53,849 --> 00:25:56,400
lock them out and then treat them like they're going to be evil right away.

626
00:25:56,420 --> 00:25:58,300
And my thinking on this was always like,

627
00:25:59,599 --> 00:26:01,709
but if that's the kind of person they were, you know,

628
00:26:01,719 --> 00:26:03,699
and you truly think they're gonna be evil, like,

629
00:26:03,709 --> 00:26:05,500
might they not have done something sooner?

630
00:26:05,510 --> 00:26:08,250
-- I
-- mean, I wouldn't think of it in that context. I think

631
00:26:08,430 --> 00:26:12,089
once you fire someone, even if they are a good person,

632
00:26:12,130 --> 00:26:14,739
good people can get angry and do silly things.

633
00:26:14,935 --> 00:26:17,994
And I think it is a way of

634
00:26:18,165 --> 00:26:19,885
hedging your bets

635
00:26:20,094 --> 00:26:21,675
against a good

636
00:26:21,775 --> 00:26:25,104
honest person being extremely upset because it's a,

637
00:26:25,114 --> 00:26:29,844
it's a very emotionally difficult time if you're fired or laid off.

638
00:26:30,314 --> 00:26:35,295
And so I understand from the risk perspective, removing access to

639
00:26:35,435 --> 00:26:39,165
-- infrastructure. And
-- it's funny because the last three places I've left,

640
00:26:39,689 --> 00:26:40,310
they didn't

641
00:26:40,410 --> 00:26:41,989
immediately lock me out.

642
00:26:42,000 --> 00:26:45,589
And it actually really annoyed me because number one, I wanted to be done.

643
00:26:45,599 --> 00:26:48,550
And number two though, is it left me at risk?

644
00:26:48,560 --> 00:26:51,060
If something goes wrong, they might blame me.

645
00:26:51,069 --> 00:26:54,979
Uh Maybe, and I wanted to be locked out and just be like we're done here. That's fair.

646
00:26:54,989 --> 00:26:55,310
Right.

647
00:26:55,319 --> 00:26:56,089
Because I mean,

648
00:26:56,099 --> 00:26:59,030
if something goes wrong and Kurt potentially had access to that system,

649
00:27:00,010 --> 00:27:03,589
-- well, let's blame Kurt. That seems like the easy way out.
-- It would be an easy way out.

650
00:27:04,229 --> 00:27:07,000
Yes. So, anyway, anyway. Ok. Ok.

651
00:27:07,160 --> 00:27:13,810
I want to end this one on the idea of your open source developers are insider threats.

652
00:27:13,880 --> 00:27:14,500
Now,

653
00:27:14,510 --> 00:27:17,800
there are going to be people who immediately think we need

654
00:27:17,810 --> 00:27:21,930
to vet open source developers because obviously they're insider threats.

655
00:27:21,939 --> 00:27:24,709
They're in our organization. That's obviously ridiculous. Right.

656
00:27:24,719 --> 00:27:28,589
-- Completely ridiculous. It's,
-- that's assuming it's even legal,

657
00:27:29,469 --> 00:27:31,689
-- right? Because there's Pir no, I'm serious.
-- Right. Like,

658
00:27:31,859 --> 00:27:33,780
-- probably.
-- Right. Like,

659
00:27:34,260 --> 00:27:36,920
I mean, you can't like, what are you gonna go to github

660
00:27:37,099 --> 00:27:38,770
and demand the identity of

661
00:27:39,050 --> 00:27:39,959
github.com?

662
00:27:40,439 --> 00:27:42,969
I bet that happens to them multiple times a day,

663
00:27:43,109 --> 00:27:47,209
probably hundreds of times a day honestly. But regardless, regardless,

664
00:27:47,420 --> 00:27:48,130
I think

665
00:27:48,609 --> 00:27:51,829
if nothing else, this is an interesting thought experiment

666
00:27:52,030 --> 00:27:55,030
because you have an insider in your organization,

667
00:27:55,199 --> 00:27:56,349
you don't know,

668
00:27:56,760 --> 00:27:58,270
they do not work for you.

669
00:27:58,449 --> 00:28:01,160
You have no control over the software they write,

670
00:28:01,170 --> 00:28:03,989
but it is critical for the running of your company.

671
00:28:04,520 --> 00:28:06,349
What do you do in that situation?

672
00:28:06,459 --> 00:28:07,500
I think number one

673
00:28:07,650 --> 00:28:08,540
looking at it as,

674
00:28:08,849 --> 00:28:10,959
and I've again, I'm, I'm annoyed,

675
00:28:10,969 --> 00:28:13,170
I've never heard of this unintentional insider threat thing.

676
00:28:13,180 --> 00:28:13,989
So I think number one,

677
00:28:14,550 --> 00:28:17,489
you look at them through the lens of the unintentional insider threat

678
00:28:17,500 --> 00:28:20,199
in the sense of they probably don't even know you're running their software

679
00:28:21,000 --> 00:28:22,849
unless they're like curl in which case the assumption is

680
00:28:23,390 --> 00:28:25,489
or the len external, right? No, like really,

681
00:28:25,859 --> 00:28:29,290
I mean, it's safe to assume if you wrote Curl or the lens kernel that

682
00:28:29,640 --> 00:28:30,089
yes.

683
00:28:30,819 --> 00:28:32,859
Um So, so first of all,

684
00:28:32,869 --> 00:28:34,469
I think moving it from the lens of

685
00:28:34,479 --> 00:28:38,119
insider threat to very specifically unintentional insider threat

686
00:28:38,500 --> 00:28:41,569
will help you be more in line with reality.

687
00:28:42,449 --> 00:28:44,130
And then the question becomes

688
00:28:44,530 --> 00:28:45,060
what,

689
00:28:45,479 --> 00:28:48,670
what is possible, what can you do?

690
00:28:48,869 --> 00:28:52,329
And so for example, you might be able to

691
00:28:52,650 --> 00:28:54,359
get involved in the upstream project

692
00:28:55,260 --> 00:28:55,719
and

693
00:28:56,979 --> 00:28:57,140
provide

694
00:28:57,380 --> 00:28:57,530
help

695
00:28:58,560 --> 00:29:00,250
upstream projects and, and well,

696
00:29:00,560 --> 00:29:01,920
that's where I was just about to go with this

697
00:29:02,089 --> 00:29:03,439
but that does not scale.

698
00:29:03,739 --> 00:29:04,709
No, not at all.

699
00:29:05,209 --> 00:29:06,910
You could maybe do it for a few critical things.

700
00:29:06,920 --> 00:29:10,400
And in theory, and this is what we've always hoped is that like, you know,

701
00:29:10,810 --> 00:29:14,270
if 1000 companies each get involved in one open source project boom, now,

702
00:29:14,300 --> 00:29:16,310
1000 open source projects are much healthier

703
00:29:16,609 --> 00:29:18,069
and everybody benefits.

704
00:29:18,969 --> 00:29:19,380
And that

705
00:29:19,810 --> 00:29:20,920
does happen

706
00:29:21,750 --> 00:29:23,369
unintentionally and

707
00:29:23,760 --> 00:29:26,819
unofficially because a lot of companies are paying people who do work on

708
00:29:26,829 --> 00:29:30,329
open source like and not in the red hat way where it's intentional.

709
00:29:30,339 --> 00:29:30,729
But,

710
00:29:30,839 --> 00:29:31,530
but, but I,

711
00:29:31,540 --> 00:29:33,890
I don't think this is a practical solution

712
00:29:33,900 --> 00:29:36,650
because you're running thousands and thousands of packages.

713
00:29:37,260 --> 00:29:40,290
Well, and it also basically depends on the com, it's like the tr the,

714
00:29:40,300 --> 00:29:41,650
the common good and all that.

715
00:29:41,660 --> 00:29:41,930
So

716
00:29:42,420 --> 00:29:45,959
I think the biggest question would be is to figure out what's even possible.

717
00:29:45,969 --> 00:29:47,410
And I hate to say,

718
00:29:47,520 --> 00:29:48,849
I don't think

719
00:29:49,469 --> 00:29:52,650
I, I don't think there's anything possible at scale.

720
00:29:53,439 --> 00:29:54,989
That's it full stop.

721
00:29:55,290 --> 00:29:58,329
And even if something is possible at scale,

722
00:29:58,719 --> 00:30:01,930
you have to get by in like you even if you, oh perfect example,

723
00:30:01,939 --> 00:30:05,810
you build the world's most amazing magical A I that just fixes security

724
00:30:05,819 --> 00:30:07,510
bugs like it looks at a bunch of code and goes boom,

725
00:30:07,520 --> 00:30:08,000
security bug.

726
00:30:08,010 --> 00:30:08,739
Here's a patch.

727
00:30:09,560 --> 00:30:11,709
Not all the upstream are going to accept them or not,

728
00:30:11,719 --> 00:30:14,189
all of the upstream are even alive enough to accept them.

729
00:30:14,199 --> 00:30:17,275
-- Uh
-- Sure. Sure. And that, that's like a different problem for sure.

730
00:30:17,604 --> 00:30:18,234
Well,

731
00:30:18,385 --> 00:30:21,454
no, not in the unintentional insider threat world.

732
00:30:21,464 --> 00:30:24,334
That's, that's part of that unintentional insider threat bucket.

733
00:30:24,344 --> 00:30:27,084
I mean, but we don't know what to do. I, I think that's how we have to end.

734
00:30:27,094 --> 00:30:28,314
This is just the fact that

735
00:30:28,645 --> 00:30:30,175
when we think about

736
00:30:30,415 --> 00:30:31,714
insider threats,

737
00:30:32,689 --> 00:30:37,239
we don't usually think of things like open source as part of that, but it kind of is,

738
00:30:37,250 --> 00:30:40,550
and it makes an a very unique thought experiment

739
00:30:40,680 --> 00:30:42,630
that we don't have answers to

740
00:30:42,780 --> 00:30:46,030
but is definitely probably something we need to think about.

741
00:30:47,469 --> 00:30:48,709
So moving forward,

742
00:30:48,819 --> 00:30:52,229
I have thought about this a lot and my response and my

743
00:30:52,410 --> 00:30:53,790
policy is

744
00:30:54,369 --> 00:30:55,790
I accept it. It's fine.

745
00:30:56,170 --> 00:30:57,589
Like I don't worry about

746
00:30:57,760 --> 00:31:00,989
-- it and
-- that, that is acceptable also. Yes.

747
00:31:01,040 --> 00:31:02,189
And I just use it because

748
00:31:02,319 --> 00:31:05,709
it's, it's like driving on the road. I just sort of hope that that yellow line

749
00:31:06,099 --> 00:31:07,380
magically works

750
00:31:07,900 --> 00:31:10,859
from the other side of the road and I don't get hit in the head on collision or,

751
00:31:10,969 --> 00:31:13,349
you know, like I keep telling my kids the light turned green,

752
00:31:13,939 --> 00:31:17,000
we check that it's safe to proceed. Then we go because

753
00:31:17,250 --> 00:31:17,709
like

754
00:31:17,900 --> 00:31:20,670
right where I live there's like four red light cameras in

755
00:31:20,680 --> 00:31:22,849
a few blocks on a couple of the busier roads.

756
00:31:22,930 --> 00:31:23,760
And like

757
00:31:24,239 --> 00:31:27,949
one guy tried to argue that he got a bunch of speeding tickets from these three

758
00:31:27,959 --> 00:31:31,290
light light cameras that are in a row that it was a single speeding event.

759
00:31:31,300 --> 00:31:34,260
So you should only pay one speeding ticket on three speeding tickets, right?

760
00:31:34,270 --> 00:31:35,359
Because he's speeding the whole time.

761
00:31:35,660 --> 00:31:36,589
But that's the thing, right?

762
00:31:36,599 --> 00:31:41,160
Like we accept these kinds of risks all the time because,

763
00:31:41,329 --> 00:31:41,540
like,

764
00:31:41,550 --> 00:31:42,660
my favorite thing is every time the

765
00:31:42,670 --> 00:31:45,520
Edmonton police service do a commercial vehicle inspection

766
00:31:46,089 --> 00:31:49,000
on, like the hand a so it's like our major ring road freeway thing,

767
00:31:49,650 --> 00:31:50,109
you know,

768
00:31:50,119 --> 00:31:53,510
some massive percentage of all the commercial vehicles have in

769
00:31:53,520 --> 00:31:57,229
some cases horrifically terrible flaws and like they have tow trucks

770
00:31:57,239 --> 00:31:58,880
there that are like taking some of these trucks away

771
00:31:58,890 --> 00:32:00,800
because they are so unsafe that they can't even late,

772
00:32:00,810 --> 00:32:02,369
like, legally let them drive

773
00:32:03,280 --> 00:32:03,670
and

774
00:32:04,390 --> 00:32:06,229
they only do this, like, once or twice a year.

775
00:32:06,239 --> 00:32:09,119
It's not like those trucks all wait for the Oh. Right. Right.

776
00:32:09,380 --> 00:32:11,150
Like this is just every day.

777
00:32:11,609 --> 00:32:16,109
And so there's a lot of this where we accept these risks and threats and

778
00:32:16,780 --> 00:32:16,800
the,

779
00:32:17,589 --> 00:32:21,630
the thing that gets me is from the open source world. I keep coming back to

780
00:32:22,489 --> 00:32:25,150
the value that open source provides me

781
00:32:25,459 --> 00:32:27,510
vastly outweighs

782
00:32:28,520 --> 00:32:31,500
any downside or risk full stop.

783
00:32:31,520 --> 00:32:34,790
I, I think that's exactly how we end the show because I agree.

784
00:32:34,920 --> 00:32:36,349
I agree. That's it good.

785
00:32:36,790 --> 00:32:39,300
Like, even if open source came to my house and burned it down,

786
00:32:39,689 --> 00:32:40,920
we would still use open

787
00:32:41,050 --> 00:32:42,530
source. I would still use open source because

788
00:32:42,630 --> 00:32:46,910
-- what's my alternative
-- Kurt? You had it, you had such a nice ending and then you'd

789
00:32:47,709 --> 00:32:47,810
open

790
00:32:48,530 --> 00:32:48,550
it

791
00:32:48,709 --> 00:32:49,420
up and down my house.

792
00:32:49,719 --> 00:32:52,750
No, I'm leaving this in. This is totally staying in. Thank you, Kurt.

793
00:32:52,760 --> 00:32:54,329
Thank you, everyone for listening. Go to open

794
00:32:54,459 --> 00:32:56,540
source security podcast.com. Head of the genre.

795
00:32:56,640 --> 00:32:56,930
Use the

796
00:32:57,170 --> 00:33:00,420
Found Os S podcast. Hashtag to hit us up on social media.

797
00:33:00,430 --> 00:33:03,630
Let us know if open source burns your house down. Kurt.

798
00:33:03,640 --> 00:33:06,550
-- Have a marvelous rest of your day.
-- You too. Thanks

799
00:33:06,560 --> 00:33:07,829
everybody. Thanks everyone.

800
00:33:07,839 --> 00:33:08,670
Bye bye.

801
00:33:09,449 --> 00:33:11,790
Like you had such a good ending

802
00:33:11,900 --> 00:33:12,469
then you.