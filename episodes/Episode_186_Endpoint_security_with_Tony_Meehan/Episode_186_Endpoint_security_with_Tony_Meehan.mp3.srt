0
00:00:05,530 --> 00:00:09,229
Hello and welcome to the open source security podcast episode 186

1
00:00:09,239 --> 00:00:11,460
with myself Kurt Siefried and my partner in Thought Crime,

2
00:00:11,470 --> 00:00:12,260
Josh Pretzer.

3
00:00:12,300 --> 00:00:16,139
-- Hey,
-- Kurt. And I am so excited today. I've got a co worker of mine.

4
00:00:16,149 --> 00:00:16,420
Actually,

5
00:00:16,430 --> 00:00:22,110
his name is Tony Meehan and he is someone who came to Elastic as part of an acquisition

6
00:00:22,299 --> 00:00:24,430
endgame, which does it end point security.

7
00:00:24,440 --> 00:00:26,299
And I'm, I'm very excited for you to be here, Tony.

8
00:00:26,309 --> 00:00:30,680
-- So say hello and introduce yourself.
-- I am also very excited to be here.

9
00:00:30,690 --> 00:00:33,139
I've been binge listening to the podcast.

10
00:00:33,250 --> 00:00:35,110
I'm so sorry. No, it's great.

11
00:00:35,119 --> 00:00:39,000
I seriously like I even my daughter has been listening to it on the car at home.

12
00:00:40,150 --> 00:00:43,930
-- So make a written apology. Now, y you
-- do, she actually does expect that.

13
00:00:44,150 --> 00:00:48,080
Um So I'm, I'm excited to be here. So I'll give you maybe my background.

14
00:00:48,090 --> 00:00:50,240
I, I came over from endgame, like you said,

15
00:00:50,270 --> 00:00:54,000
I had been there for about six years from 2014 to

16
00:00:54,090 --> 00:00:57,520
I guess October of last year and previous to Endgame,

17
00:00:57,529 --> 00:01:00,110
I was at the National Security Agency

18
00:01:00,215 --> 00:01:04,035
office called Tailored Access Operations for about 10 years there,

19
00:01:04,044 --> 00:01:06,235
we were working on computer network

20
00:01:06,245 --> 00:01:09,074
exploitation tools to collect foreign intelligence.

21
00:01:09,194 --> 00:01:12,915
So it's kind of, it was fun to go from that job to add in game,

22
00:01:12,925 --> 00:01:14,514
kind of sitting on the other side of the table.

23
00:01:14,525 --> 00:01:16,514
Well, actually I think that's one of the most important things.

24
00:01:16,525 --> 00:01:20,455
So I've seen so many computer security people only do either attacker

25
00:01:20,724 --> 00:01:21,675
or defense

26
00:01:22,709 --> 00:01:25,559
and then they don't really have a good understanding of the other side. Yeah.

27
00:01:25,569 --> 00:01:27,849
So I remember my last day

28
00:01:28,019 --> 00:01:32,709
in Tao, I was in Rob Joyce's office. So Rob Joyce at the time

29
00:01:33,029 --> 00:01:37,919
was the chief of Tao. So kind of like the CEO of the company for, for that office.

30
00:01:37,930 --> 00:01:43,199
And by the way, if you, if you don't know who that is, you should go watch his 2016 UN

31
00:01:43,389 --> 00:01:44,199
talk

32
00:01:44,330 --> 00:01:49,139
on uh I forget what the title was, but something about understanding Attackers.

33
00:01:49,690 --> 00:01:52,089
He, he's great. So I remember sitting in his office

34
00:01:52,510 --> 00:01:55,209
and telling him like, it's, this is weird for me

35
00:01:55,330 --> 00:01:58,610
going from 10 years of doing this job

36
00:01:59,239 --> 00:02:03,239
to now kind of being the adversary scaring the

37
00:02:03,459 --> 00:02:07,290
out of myself, basically in my former job. Like that was the transition I was making

38
00:02:07,860 --> 00:02:09,279
and it was tough, right?

39
00:02:09,288 --> 00:02:12,800
Primarily because you're coming from a, you know, highly classified

40
00:02:12,919 --> 00:02:13,880
office. And

41
00:02:14,089 --> 00:02:17,199
so you have to kind of segment in your mind, certain things.

42
00:02:17,210 --> 00:02:21,190
But I just remember him being very gracious and we still keep in touch.

43
00:02:21,199 --> 00:02:24,100
He's always trying to get me to come back. So I, I miss that place.

44
00:02:24,110 --> 00:02:25,279
I, I learned so much there.

45
00:02:25,699 --> 00:02:27,190
-- It was awesome. That's
-- awesome.

46
00:02:27,320 --> 00:02:27,850
Ok.

47
00:02:27,960 --> 00:02:29,509
I wanna start

48
00:02:29,710 --> 00:02:34,100
with Endpoint because anyone who's listened to episodes of this podcast

49
00:02:34,110 --> 00:02:37,550
know that Kurt and I have railed on antivirus a lot

50
00:02:37,880 --> 00:02:39,669
and I would say we, I,

51
00:02:39,679 --> 00:02:43,570
I don't know if we've gone after endpoint specifically at any point in time,

52
00:02:43,580 --> 00:02:48,610
but I will, I, I, I'll kind of, I'll tell you my story and we can, we can start there.

53
00:02:48,619 --> 00:02:51,360
So obviously, I think antivirus is a tire fire.

54
00:02:51,570 --> 00:02:54,110
And I've historically not been,

55
00:02:54,600 --> 00:02:56,229
it's, it's not a secret

56
00:02:56,440 --> 00:02:57,080
and

57
00:02:57,270 --> 00:02:58,940
I've historically not been a huge fan

58
00:02:58,949 --> 00:03:01,009
of Endpoint software because generally speaking,

59
00:03:01,020 --> 00:03:04,160
it's one of those things that in most situations gets in the way

60
00:03:04,270 --> 00:03:08,539
and it uses up a bunch of resources and it's just, it's a huge pain in the butt.

61
00:03:08,550 --> 00:03:12,369
I would compare it to Se Linux is another one of my favorite whipping

62
00:03:12,380 --> 00:03:15,710
boys where it's like this is a technology that in theory is good,

63
00:03:15,720 --> 00:03:18,565
but in reality, often gets in the way more than it doesn't.

64
00:03:18,574 --> 00:03:20,074
And it's actually better now.

65
00:03:20,085 --> 00:03:23,365
I shouldn't say that for any Se Linux devs listening, like you guys are doing great.

66
00:03:23,375 --> 00:03:23,725
Keep it up.

67
00:03:23,735 --> 00:03:26,464
But anyway, so for Endpoint, we got it at elastic and I was like, oh,

68
00:03:26,475 --> 00:03:29,785
this crap and we started out with crowdstrike and it

69
00:03:29,794 --> 00:03:31,764
kind of sucked and it used a lot of resources.

70
00:03:31,774 --> 00:03:34,445
And in fact, when I would take my laptop off the dock,

71
00:03:34,455 --> 00:03:36,884
I saw a noticeable drain in the battery

72
00:03:36,895 --> 00:03:39,565
and then we eventually switched over to endgame,

73
00:03:39,574 --> 00:03:40,365
obviously.

74
00:03:40,375 --> 00:03:41,404
And I,

75
00:03:41,869 --> 00:03:45,770
I don't know, it, it, it's really impressive. It uses very little resources.

76
00:03:45,779 --> 00:03:47,029
I'm on Linux obviously.

77
00:03:47,039 --> 00:03:50,570
And in fact, one of the things I did was I was running this thing called Metric beat,

78
00:03:50,580 --> 00:03:53,029
which just collects all this information about

79
00:03:53,039 --> 00:03:54,869
like running processes on your system.

80
00:03:54,880 --> 00:04:00,570
And it was struggling to graph the CPU use of the endgame agent because it was so low,

81
00:04:00,660 --> 00:04:03,070
which I thought this is, this is madness, right?

82
00:04:03,080 --> 00:04:05,130
So anyway, why don't you kind of let's let,

83
00:04:05,231 --> 00:04:07,042
let's talk about endpoint and what it is

84
00:04:07,231 --> 00:04:10,442
and why it's not antivirus and we'll say it is

85
00:04:10,591 --> 00:04:12,171
not completely terrible.

86
00:04:12,391 --> 00:04:13,572
Yeah. Well,

87
00:04:13,822 --> 00:04:15,731
it's, it's an interesting question.

88
00:04:15,742 --> 00:04:18,372
I, I think it's actually taking a step back,

89
00:04:18,380 --> 00:04:22,652
maybe worth thinking about it kind of in the context of like a broader timeline,

90
00:04:22,661 --> 00:04:24,372
like when I, when I joined Tao

91
00:04:24,492 --> 00:04:25,122
around

92
00:04:25,342 --> 00:04:26,921
2005. So I think

93
00:04:27,171 --> 00:04:28,361
Windows XP service,

94
00:04:28,593 --> 00:04:29,484
he had just come out

95
00:04:29,653 --> 00:04:32,373
like they enabled the fireball by default. I think people probably

96
00:04:32,493 --> 00:04:34,653
use zone alarm. I don't know if you guys remember that

97
00:04:35,334 --> 00:04:36,933
I was a user of zone alarm.

98
00:04:37,223 --> 00:04:38,493
-- Yeah,
-- I did too.

99
00:04:39,283 --> 00:04:40,963
I think they started doing like weird pop ups

100
00:04:40,973 --> 00:04:42,813
and stuff like scaring people into buying more.

101
00:04:42,824 --> 00:04:43,454
But anyway,

102
00:04:43,503 --> 00:04:47,334
so I think it's interesting to think about antivirus kind of in a broader term,

103
00:04:47,343 --> 00:04:51,194
going back, at least around that time frame to now because it's evolved a lot.

104
00:04:51,204 --> 00:04:51,743
I will also

105
00:04:51,955 --> 00:04:56,915
with a sentiment, it's ok to think a, you know, a V as a, as a dumpster fire.

106
00:04:56,925 --> 00:04:59,686
I, I actually think that a lot of security products,

107
00:04:59,696 --> 00:05:01,455
if not all of them have weaknesses,

108
00:05:01,466 --> 00:05:04,055
all of them can be bypassed by a determined adversary.

109
00:05:04,066 --> 00:05:04,776
It doesn't matter

110
00:05:04,976 --> 00:05:06,976
if someone wants to get your data,

111
00:05:06,985 --> 00:05:10,265
it will happen if they care and they have resources to do it.

112
00:05:10,276 --> 00:05:12,455
Kind of putting it to the broader context.

113
00:05:12,466 --> 00:05:15,165
It's interesting to think about the evolution because in the beginning,

114
00:05:15,489 --> 00:05:17,309
antivirus actually was effective, you know,

115
00:05:17,320 --> 00:05:22,429
signatures and engines to find malware that that worked for a while.

116
00:05:23,079 --> 00:05:24,950
It was enough to mitigate some of the risk.

117
00:05:24,959 --> 00:05:28,149
But I also think that maybe people didn't quite understand

118
00:05:28,160 --> 00:05:30,380
just how much of the cake adversaries were eating,

119
00:05:30,390 --> 00:05:33,190
I guess probably the problem wasn't really well known at the time, I guess.

120
00:05:33,200 --> 00:05:34,269
Maybe I would

121
00:05:34,420 --> 00:05:36,190
maybe qualify my answer a little bit.

122
00:05:36,200 --> 00:05:39,010
The antivirus seemed to be ok, but it actually probably wasn't.

123
00:05:39,649 --> 00:05:39,670
I

124
00:05:39,820 --> 00:05:41,970
think one of the big concerns I had with antivirus is

125
00:05:41,980 --> 00:05:44,350
I don't care so much if it's effective or not effective.

126
00:05:44,359 --> 00:05:49,190
But does it actively make my situation worse? Which a lot of antivirus products do?

127
00:05:49,200 --> 00:05:52,769
Like they, they literally, they introduce worse security flaws?

128
00:05:52,809 --> 00:05:53,940
That's absolutely right.

129
00:05:54,049 --> 00:05:57,779
But they're also really good at mitigating sort of the targets of

130
00:05:57,885 --> 00:06:00,394
opportunity where if someone's not really after you,

131
00:06:00,404 --> 00:06:03,404
but instead you're sort of the 100th person targeted, like,

132
00:06:03,415 --> 00:06:05,084
maybe you'd be ok because the first couple that

133
00:06:05,095 --> 00:06:07,554
were attacked antivirus lab signatures for them and,

134
00:06:07,565 --> 00:06:07,904
and

135
00:06:08,184 --> 00:06:10,804
you'll be protected if you're not the first one to get attacked. Yeah.

136
00:06:10,815 --> 00:06:16,065
I mean, yeah, it was obviously pretty easy for Attackers to bypass and get around.

137
00:06:16,394 --> 00:06:18,005
So it's evolved over time, I think now,

138
00:06:18,454 --> 00:06:21,035
you know, if you fast forward to the last couple of years, you know,

139
00:06:21,045 --> 00:06:25,385
Gartner sort of has the, the definitions of endpoint protection platform

140
00:06:25,839 --> 00:06:29,910
and endpoint detection and response. So PP and EDR,

141
00:06:30,279 --> 00:06:33,540
so the idea here is we have products out there today,

142
00:06:33,809 --> 00:06:36,869
some antivirus products, you know, like Kaspersky is in this group,

143
00:06:37,049 --> 00:06:40,130
but you have others in game certainly was in it now elastic

144
00:06:40,399 --> 00:06:42,399
of endpoint protection platforms.

145
00:06:42,410 --> 00:06:47,420
The whole idea there is you just wanna stop known and unknown threats.

146
00:06:47,429 --> 00:06:49,390
You want it to be as automated as possible.

147
00:06:49,399 --> 00:06:51,260
You don't want to, you don't want people touching it

148
00:06:51,519 --> 00:06:54,220
deployed everywhere and solve as much of the problem

149
00:06:54,230 --> 00:06:56,720
as you can just sort of set and forget.

150
00:06:56,730 --> 00:06:59,739
And then the EDR side of it, you almost think of it like

151
00:07:00,059 --> 00:07:04,179
for an attack if, if you have something bad happening and you're not absolutely sure

152
00:07:04,320 --> 00:07:05,920
it's a real threat.

153
00:07:05,929 --> 00:07:09,040
You present that to someone that maybe has some experience,

154
00:07:09,049 --> 00:07:11,779
they've done threat hunting or incident response before and they

155
00:07:11,790 --> 00:07:13,320
can kind of look at an alert and say,

156
00:07:13,329 --> 00:07:14,559
ok, what, what's going on here?

157
00:07:14,570 --> 00:07:15,420
What is this?

158
00:07:15,440 --> 00:07:17,540
Let's look at everything that happened before that,

159
00:07:17,589 --> 00:07:19,140
everything that happened after that,

160
00:07:19,660 --> 00:07:19,799
it,

161
00:07:19,809 --> 00:07:23,929
it kind of gives over some of the control to a person that

162
00:07:23,940 --> 00:07:27,959
has some context and some experience and the market is kind of converging.

163
00:07:27,970 --> 00:07:32,579
So those most like if you say a crowd strike or if you said elastic Endpoint security,

164
00:07:32,739 --> 00:07:36,510
it's sort of meant to do both of those kind of what you cited earlier.

165
00:07:36,519 --> 00:07:38,910
In order to actually have any impact on an endpoint,

166
00:07:38,920 --> 00:07:40,815
you need be a steward of its resources.

167
00:07:40,825 --> 00:07:42,725
You can't use a whole lot of CPU or memory.

168
00:07:42,734 --> 00:07:45,765
Otherwise you, the it team is not going to allow you to be deployed.

169
00:07:45,774 --> 00:07:48,075
So that's sort of your job number one and then job

170
00:07:48,084 --> 00:07:51,565
number two is to not only stop known and unknown threats,

171
00:07:51,575 --> 00:07:52,255
but also

172
00:07:52,364 --> 00:07:54,015
give some tools to

173
00:07:54,165 --> 00:07:58,054
more sophisticated users to kind of do an investigation to kind of understand what,

174
00:07:58,065 --> 00:07:58,774
what's happening.

175
00:07:59,140 --> 00:08:03,079
If you see something that's not entirely easy to convict, but you, you,

176
00:08:03,329 --> 00:08:07,329
you know, have some suspicions. So that was a rambling answer. But I

177
00:08:07,500 --> 00:08:07,649
know

178
00:08:07,839 --> 00:08:11,390
that's great. I guess given my background, it's just sort of security is tough.

179
00:08:11,399 --> 00:08:13,720
I think you had a podcast a couple of weeks ago about

180
00:08:13,730 --> 00:08:16,519
the defender is always going to be behind like you're hopeless.

181
00:08:16,529 --> 00:08:17,410
It's hopeless.

182
00:08:17,579 --> 00:08:18,010
That's right.

183
00:08:18,019 --> 00:08:19,670
Let's all give up you had the authors of

184
00:08:19,679 --> 00:08:21,920
the fifth domain that we're talking about how,

185
00:08:21,929 --> 00:08:23,790
you know, the fifth domain being cyberspace,

186
00:08:24,410 --> 00:08:28,720
humans have some control over when we built this domain.

187
00:08:29,010 --> 00:08:31,690
So we have to have some kind of influence over it to

188
00:08:31,700 --> 00:08:36,030
kind of give us some competitive advantage against an adversary as defenders.

189
00:08:36,039 --> 00:08:38,739
We thought that was an interesting concept. I never thought about that before.

190
00:08:39,840 --> 00:08:43,869
So I I also want to clarify a point about

191
00:08:44,169 --> 00:08:50,130
endpoint detection is that these end points that run on the systems, they're not

192
00:08:50,293 --> 00:08:52,653
kind of old school antivirus.

193
00:08:52,663 --> 00:08:57,223
We've got a huge list of signatures and I'm just going to look for files,

194
00:08:57,232 --> 00:09:02,822
they watch behaviors on systems and then that behavior can be sometimes stopped

195
00:09:02,973 --> 00:09:07,223
or just logged so someone can look at it later or there's, there's kind of a,

196
00:09:07,232 --> 00:09:11,093
a bunch of things that can happen here, which I think is fascinating

197
00:09:11,203 --> 00:09:11,473
where

198
00:09:11,575 --> 00:09:14,536
rather than like looking at, oh, there's a virus on the disk, you're saying?

199
00:09:14,546 --> 00:09:18,265
Oh my goodness, you know, this process like Excel is running powershell.

200
00:09:18,276 --> 00:09:21,656
That should never happen. Like let's explode. Which is, that's cool.

201
00:09:21,666 --> 00:09:24,986
I mean, the classic current example is Jeff Bezos cell phone suddenly using more,

202
00:09:25,125 --> 00:09:25,676
you know, cell

203
00:09:25,846 --> 00:09:25,866
No,

204
00:09:27,005 --> 00:09:27,786
really, right.

205
00:09:27,796 --> 00:09:28,526
When you, you know,

206
00:09:28,536 --> 00:09:32,755
it went from like what a couple 100 kilobytes per day or something to gigabytes,

207
00:09:33,530 --> 00:09:35,349
you know, and that's what always drives me nuts when I,

208
00:09:35,359 --> 00:09:37,109
when I read about these attacks, you know,

209
00:09:37,119 --> 00:09:39,869
where some major company gets attacked and it's like, oh, yeah.

210
00:09:39,880 --> 00:09:41,739
And then we, you know, we looked at our network logs and, yeah,

211
00:09:41,750 --> 00:09:43,780
we saw a couple of gigabytes or terabytes of data

212
00:09:43,789 --> 00:09:46,150
going into this weird IP in Russia or China.

213
00:09:46,309 --> 00:09:46,919
-- Yeah,
-- I mean, EDR

214
00:09:47,109 --> 00:09:49,919
is all about minimizing the time that passes

215
00:09:49,929 --> 00:09:52,669
between getting breached and knowing about it.

216
00:09:52,679 --> 00:09:55,510
Like that's, that's its primary goal. You want that to be as,

217
00:09:55,614 --> 00:09:58,474
that, that window to be as small as possible.

218
00:09:58,484 --> 00:10:01,025
This is a san statistic mind you, but I'll,

219
00:10:01,034 --> 00:10:02,765
I'll try to dig it out and put in the show notes.

220
00:10:02,775 --> 00:10:03,945
But I just saw a graph,

221
00:10:03,955 --> 00:10:06,934
I think yesterday on Twitter where they were showing kind of the,

222
00:10:06,945 --> 00:10:11,705
the dwell time on attacks right now is down from 200 days to 100 days, which is

223
00:10:11,854 --> 00:10:12,375
like,

224
00:10:12,484 --> 00:10:15,474
that's still really bad, but that's progress, right?

225
00:10:15,585 --> 00:10:17,674
So there's actually kind of a cool story here

226
00:10:17,955 --> 00:10:20,044
around 2015

227
00:10:20,294 --> 00:10:21,114
endgame.

228
00:10:21,659 --> 00:10:24,520
So this was around the time when we started

229
00:10:24,710 --> 00:10:26,409
building, building our products,

230
00:10:26,419 --> 00:10:30,039
we had endgames made several pivots in the course of its history.

231
00:10:30,109 --> 00:10:32,190
And sort of the last pivot we made

232
00:10:32,200 --> 00:10:35,239
was to build an endpoint detection response product.

233
00:10:35,250 --> 00:10:35,679
But the,

234
00:10:35,809 --> 00:10:38,630
the story on how we developed, it's kind of interesting, you know,

235
00:10:38,659 --> 00:10:42,099
our history at endgame was sort of we made bullets before we made bulletproof vests.

236
00:10:42,109 --> 00:10:45,169
So we were kind of doing some offense before we were doing defense.

237
00:10:45,179 --> 00:10:47,869
And so the air force would partner with us on the

238
00:10:47,880 --> 00:10:51,280
red team and they would do these massive exercises called red flag

239
00:10:51,650 --> 00:10:53,460
where we would help the red team and the red

240
00:10:53,469 --> 00:10:55,820
team just crushed every time they were very good.

241
00:10:55,830 --> 00:10:58,390
The Air Force sort of started asking us, hey,

242
00:10:58,640 --> 00:11:01,099
we want to start helping the blue team. What can you do?

243
00:11:01,109 --> 00:11:03,450
I just remember sitting in a conference room with,

244
00:11:03,460 --> 00:11:04,979
with some other engineers or sort of like, well,

245
00:11:04,989 --> 00:11:07,239
what can we do that the product that we had built?

246
00:11:07,250 --> 00:11:10,020
You know, it was really good at sort of the detection and response side,

247
00:11:10,030 --> 00:11:11,900
like investigating what had happened.

248
00:11:11,909 --> 00:11:15,229
But if you want to stand up against a really effective red team,

249
00:11:15,239 --> 00:11:17,309
you kind of have to prevent some of the

250
00:11:17,320 --> 00:11:19,299
things that they do and you can't do signatures.

251
00:11:19,309 --> 00:11:19,989
Like that's not,

252
00:11:20,000 --> 00:11:21,559
that's not gonna work because you have no idea what they're going to do.

253
00:11:21,570 --> 00:11:23,820
You have no clue. So you kind of have to think, ok, well,

254
00:11:24,179 --> 00:11:27,219
what are some common things that adversaries like to do

255
00:11:27,320 --> 00:11:29,840
and how do we stop that? So the first thing we thought of

256
00:11:30,219 --> 00:11:33,890
was OK. Well, they're probably going to inject some code into a legitimate process.

257
00:11:33,900 --> 00:11:35,369
They're probably gonna do some process injection.

258
00:11:35,520 --> 00:11:36,719
Well, how do we stop that?

259
00:11:36,729 --> 00:11:40,440
So that, that's what we focus on the, how do we build a feature like that

260
00:11:40,739 --> 00:11:42,679
into a product that would sort of

261
00:11:42,690 --> 00:11:46,659
stop common behaviors or techniques that adversaries employ

262
00:11:47,010 --> 00:11:48,320
without really knowing about

263
00:11:48,450 --> 00:11:50,039
the actual tools that

264
00:11:50,390 --> 00:11:51,400
they were going to use.

265
00:11:52,030 --> 00:11:52,880
That's what we did. And

266
00:11:53,039 --> 00:11:56,460
I just remember I was actually at the exercise kind of helping the tool,

267
00:11:56,469 --> 00:11:59,080
helping the product that we built, um, get used.

268
00:11:59,489 --> 00:12:02,010
And the red team was pissed. They were.

269
00:12:02,280 --> 00:12:02,429
And,

270
00:12:02,630 --> 00:12:05,150
but the thing was that the product was so early

271
00:12:05,349 --> 00:12:08,960
that it was really hard for me and the other folks to kind of say, oh yeah,

272
00:12:08,969 --> 00:12:09,590
it was definitely us.

273
00:12:09,599 --> 00:12:11,010
So during the exercise,

274
00:12:11,020 --> 00:12:13,580
we actually provided an update that would generate an

275
00:12:13,590 --> 00:12:15,539
alert for it whenever it was in prevent mode.

276
00:12:15,849 --> 00:12:19,109
And so we finally got credit for it after a couple of days. But I just,

277
00:12:19,380 --> 00:12:21,989
that was sort of our evolution to this thinking

278
00:12:22,190 --> 00:12:24,520
about this problem is that your signatures aren't going to work because

279
00:12:24,530 --> 00:12:26,010
you have no idea what the adversary is going to do,

280
00:12:26,020 --> 00:12:26,429
no clue.

281
00:12:26,440 --> 00:12:30,429
But there are common techniques that people employ. And it's still true to this day,

282
00:12:30,679 --> 00:12:33,710
you know, a lot of living off the land techniques that people employ where

283
00:12:33,830 --> 00:12:37,390
MS build or cert util on windows like they're installed everywhere.

284
00:12:37,400 --> 00:12:41,830
And so people, you know, adversaries now will instead of bringing over some

285
00:12:42,340 --> 00:12:47,239
exc and dropping it to disk and having that sort of susceptible to standing by a V or

286
00:12:47,460 --> 00:12:47,590
end

287
00:12:47,690 --> 00:12:48,460
point. Instead

288
00:12:49,010 --> 00:12:52,739
they'll drop an XML file and have MS build, you know,

289
00:12:52,750 --> 00:12:55,640
do something in memory that accomplishes the same goal,

290
00:12:55,650 --> 00:12:58,669
but evades most detection So, again, it's sort of,

291
00:12:58,679 --> 00:13:01,419
it's kind of interesting to think about how adversaries think and, you know,

292
00:13:01,429 --> 00:13:02,780
how do you kind of stay ahead?

293
00:13:02,789 --> 00:13:03,840
It's pretty hard.

294
00:13:04,030 --> 00:13:05,969
But one good way is to think about,

295
00:13:06,289 --> 00:13:07,830
you know, what are the common techniques that,

296
00:13:07,840 --> 00:13:10,729
that they'll employ once they get access to a, to an end point?

297
00:13:10,799 --> 00:13:14,270
Right. Right. And there's the additional advantage

298
00:13:14,559 --> 00:13:19,030
of, if you have a system that's logging everything going on,

299
00:13:19,289 --> 00:13:21,270
you might lose the first

300
00:13:21,544 --> 00:13:22,835
endpoint they attack.

301
00:13:22,844 --> 00:13:26,284
But now you have a corpus of data you can use to, you know,

302
00:13:26,294 --> 00:13:29,724
look for more instances like this, which is that's hugely powerful,

303
00:13:29,734 --> 00:13:33,364
getting all of the event data, like process creation, events,

304
00:13:33,455 --> 00:13:36,364
file creation events, registry creation, all that data,

305
00:13:36,804 --> 00:13:39,294
getting that, collecting it and getting it off the endpoint

306
00:13:39,534 --> 00:13:43,565
as fast as possible somewhere safe so that the adversary can't find it

307
00:13:43,765 --> 00:13:46,364
and erase their history. That's really important.

308
00:13:46,405 --> 00:13:49,085
And that's probably one of the most important things about EDR

309
00:13:49,380 --> 00:13:52,640
is making sure you have that data available that flight recorder

310
00:13:52,830 --> 00:13:55,479
so that when something bad happens, you can kind of go back in time,

311
00:13:55,809 --> 00:13:57,960
you know, not just weeks and months, but you know,

312
00:13:57,969 --> 00:14:00,390
imagine going back in time and searching

313
00:14:00,549 --> 00:14:04,840
data that's years old. Like you could have a virtual desktop environment

314
00:14:05,210 --> 00:14:09,520
where you know, that endpoint literally lives for eight hours when you log in.

315
00:14:09,530 --> 00:14:12,359
It is created when you log out, it's destroyed.

316
00:14:12,940 --> 00:14:15,479
And so like a year later if you find out about a breach,

317
00:14:15,580 --> 00:14:19,719
you want data from those end points even though they no longer exist to see. Ok.

318
00:14:19,729 --> 00:14:22,500
Well, how bad was it like, what was the extent

319
00:14:22,609 --> 00:14:23,280
of this breach?

320
00:14:23,289 --> 00:14:25,400
How long have they been around getting that data off the box is

321
00:14:25,409 --> 00:14:28,760
not only important from just making it much harder for an adversary,

322
00:14:28,770 --> 00:14:29,099
but

323
00:14:29,380 --> 00:14:32,859
-- you need that sort of flight data recorder history.
-- Right. Right.

324
00:14:33,090 --> 00:14:36,359
Except there, there's also the issue of years of data

325
00:14:36,559 --> 00:14:40,099
means your product is sponsored by the hard drive manufacturers

326
00:14:40,679 --> 00:14:41,340
-- world.
-- Right.

327
00:14:42,820 --> 00:14:46,409
-- Yes. No,
-- I mean, that, that's a huge problem though. Right? Because there's

328
00:14:47,280 --> 00:14:52,380
data retention is one of those problems that sounds easy until you have to do it.

329
00:14:52,390 --> 00:14:56,179
-- And it's like this is the worst thing I've ever had to
-- do.

330
00:14:56,190 --> 00:14:58,539
-- Well, especially sensitive data.
-- Oh, exactly.

331
00:14:59,020 --> 00:15:02,640
Yeah. And, and that's why sort of the prevention part of it is so important.

332
00:15:02,650 --> 00:15:06,840
Do your best to stop it from ever having to worry about those types of problems.

333
00:15:06,849 --> 00:15:07,650
But if you do,

334
00:15:07,960 --> 00:15:09,539
it'd be great if you had the data somewhere.

335
00:15:10,880 --> 00:15:12,260
That's right. That's right.

336
00:15:12,520 --> 00:15:13,580
Ok. Cool.

337
00:15:13,590 --> 00:15:13,859
We'll,

338
00:15:13,869 --> 00:15:16,989
we'll assume that we've kind of set the table at

339
00:15:17,000 --> 00:15:20,039
this point for some of the history of endpoint detection.

340
00:15:20,049 --> 00:15:22,309
But I guess where's the industry headed?

341
00:15:22,320 --> 00:15:24,739
Because I feel like there's some unexpected

342
00:15:24,750 --> 00:15:26,849
convergences going on that two years ago.

343
00:15:26,859 --> 00:15:30,000
If you'd have asked, you told me this is what's happening, I would have been like,

344
00:15:30,010 --> 00:15:31,210
I don't know about that.

345
00:15:31,239 --> 00:15:35,200
I think elastic and end game coming together is

346
00:15:35,510 --> 00:15:36,409
a big

347
00:15:36,710 --> 00:15:39,500
kind of view into the future of historically.

348
00:15:39,510 --> 00:15:42,289
You've had things like SIMS and you've had endpoint

349
00:15:42,400 --> 00:15:45,460
applications and they haven't been the same and like in this case,

350
00:15:45,869 --> 00:15:47,239
they're coming together, right?

351
00:15:47,250 --> 00:15:51,010
-- So you can literally do everything in one place now, which is wild.
-- Just interrupt.

352
00:15:51,020 --> 00:15:52,549
Can you define what a SIM is?

353
00:15:52,559 --> 00:15:56,770
Because that's, I know I'm not and I'm still sort of vague on the whole concept of SIM,

354
00:15:56,780 --> 00:15:57,409
other than like

355
00:15:57,580 --> 00:15:59,570
dashboard with blinky lights.

356
00:16:01,900 --> 00:16:02,049
Well,

357
00:16:02,059 --> 00:16:05,330
-- Tony is a perfect person to answer that question
-- and I probably

358
00:16:05,340 --> 00:16:09,390
did an absolute poor job of describing what I do now.

359
00:16:09,400 --> 00:16:10,549
So now at elastic,

360
00:16:10,859 --> 00:16:15,099
we have on the security team. So elastic is probably the best way to think about it

361
00:16:15,450 --> 00:16:19,049
is you have the stack that everyone's familiar with Kaban and Elastic search,

362
00:16:19,059 --> 00:16:20,940
but we also have a security solution.

363
00:16:20,950 --> 00:16:22,070
That's, that's my team. And,

364
00:16:22,429 --> 00:16:24,070
and that team, we have an endpoint

365
00:16:24,289 --> 00:16:27,179
that we've been talking about and we have a SIM SI M stands for

366
00:16:27,349 --> 00:16:31,159
security information and event management. The best way to think about it

367
00:16:31,719 --> 00:16:32,789
is most,

368
00:16:33,010 --> 00:16:37,570
you know, enterprises kind of, you know, small or large enterprises have a ton of

369
00:16:37,840 --> 00:16:40,979
security products, networking devices, you know, routers,

370
00:16:40,989 --> 00:16:43,039
firewalls that are all generating logs

371
00:16:43,280 --> 00:16:43,859
and

372
00:16:44,080 --> 00:16:48,760
A SIM pulls all of that together in one place and gives

373
00:16:48,770 --> 00:16:52,570
users the ability to write new detections across all those events.

374
00:16:52,580 --> 00:16:54,640
So if that, if all that data is normalized,

375
00:16:54,650 --> 00:16:57,219
we do that at elastic with something called elastic common scheme.

376
00:16:57,825 --> 00:16:59,604
But there are many other options out there.

377
00:16:59,784 --> 00:17:03,655
So you can kind of pull all this data together and search it and write, you know,

378
00:17:03,664 --> 00:17:06,155
new detections on top of all this desperate data

379
00:17:06,165 --> 00:17:09,015
coming from all of your different products and security devices

380
00:17:09,025 --> 00:17:11,464
so that you can kind of connect the dots across

381
00:17:11,473 --> 00:17:14,025
all of the different places where you have visibility.

382
00:17:14,035 --> 00:17:15,334
That's like that's the main

383
00:17:15,545 --> 00:17:16,564
goal of a sub

384
00:17:17,290 --> 00:17:20,949
and most, you know, like Josh alluded to most S products are Switzerland.

385
00:17:20,989 --> 00:17:25,280
Um they will accept data from anywhere and, and, and we're no different at elastic.

386
00:17:25,420 --> 00:17:27,510
What kind of a cool thing that we're doing with end

387
00:17:27,630 --> 00:17:28,260
point is

388
00:17:28,849 --> 00:17:30,060
we're looking into what are

389
00:17:30,180 --> 00:17:31,569
OK. Well, what if you had

390
00:17:31,750 --> 00:17:34,709
a world where si actually had a very

391
00:17:35,020 --> 00:17:37,010
nice cohesive

392
00:17:37,150 --> 00:17:38,530
almost security solution with S

393
00:17:38,680 --> 00:17:39,260
and, and point together?

394
00:17:39,270 --> 00:17:40,579
Like what are the things that you could do

395
00:17:40,589 --> 00:17:42,949
that maybe others haven't been able to do before?

396
00:17:42,959 --> 00:17:44,000
So one example

397
00:17:44,349 --> 00:17:46,430
is you can imagine a world where

398
00:17:46,939 --> 00:17:49,800
you're creating some new detection in yours

399
00:17:50,400 --> 00:17:52,959
in some language like endpoint query language.

400
00:17:52,969 --> 00:17:55,030
EQL is something that we usually talk about

401
00:17:55,040 --> 00:17:56,569
in this scenario where you're trying to say,

402
00:17:56,579 --> 00:17:59,479
OK, if this happens and this happens over this window of time,

403
00:17:59,489 --> 00:18:00,890
like I want to know about it, show me

404
00:18:01,229 --> 00:18:02,609
and if that ends up being malicious.

405
00:18:02,619 --> 00:18:06,219
You can imagine a world where because of that cohesive integration, you could

406
00:18:06,619 --> 00:18:09,119
immediately pivot and say, OK, this search, I just did,

407
00:18:09,130 --> 00:18:10,910
I now want to turn this into a prevention

408
00:18:11,020 --> 00:18:13,150
and push that down to all my endpoints so

409
00:18:13,160 --> 00:18:15,040
that the endpoints that see the exact same data,

410
00:18:15,400 --> 00:18:16,979
if they see, OK, this process,

411
00:18:17,099 --> 00:18:19,430
this process over this period of time and does something,

412
00:18:19,439 --> 00:18:20,900
a network or whatever the rule is,

413
00:18:21,069 --> 00:18:21,699
it stops it.

414
00:18:22,089 --> 00:18:25,780
So now you can kind of do some research and figure out what's going on in your SIM.

415
00:18:25,790 --> 00:18:27,540
And then as you find new malicious things,

416
00:18:27,550 --> 00:18:28,829
you can push that out to your end point and just

417
00:18:28,839 --> 00:18:30,839
stop it and prevent it from happening in the first place.

418
00:18:30,849 --> 00:18:32,300
I think it's kind of a cool thing to,

419
00:18:32,609 --> 00:18:33,420
to be able to do.

420
00:18:33,430 --> 00:18:35,140
So one question I have so one of the few things

421
00:18:35,150 --> 00:18:38,010
I think that the antivirus industry finally got right was,

422
00:18:38,140 --> 00:18:41,579
you know, automated code submission samples, right? Because

423
00:18:41,880 --> 00:18:45,650
like I literally am old enough to remember when you could email a virus company,

424
00:18:45,660 --> 00:18:46,930
what you thought was a virus

425
00:18:47,510 --> 00:18:50,900
-- like a long time ago and
-- signatures are stupid.

426
00:18:50,910 --> 00:18:53,170
Kurt, no one should be using signatures.

427
00:18:53,569 --> 00:18:55,890
Well, not just signatures but for example, saying, hey, you know,

428
00:18:55,900 --> 00:18:58,630
we're noticing this new pattern where so like miter attack, you know,

429
00:18:58,640 --> 00:19:01,319
has a list of common patterns they've seen in the wild and you know,

430
00:19:01,329 --> 00:19:03,500
no doubt there will be new patterns that we see.

431
00:19:03,510 --> 00:19:06,854
I like there was a one posting on Twitter where the person was trying to hack

432
00:19:06,864 --> 00:19:08,604
into a company and they got caught immediately

433
00:19:08,614 --> 00:19:10,724
and the rule essentially that caught them was,

434
00:19:10,834 --> 00:19:14,685
yeah, outside admins, nobody runs Powershell on their Windows machine.

435
00:19:14,694 --> 00:19:17,555
So like when we see a secretary trying to use Powershell on her machine,

436
00:19:17,765 --> 00:19:21,675
-- we know she got hacked.
-- This is such a hard problem too. I mean, it's,

437
00:19:22,329 --> 00:19:24,910
I guess maybe it's, it's kind of interesting to think about

438
00:19:25,109 --> 00:19:25,949
how

439
00:19:26,130 --> 00:19:29,709
data scientists spend time coming up with

440
00:19:29,910 --> 00:19:31,680
machine learning malware models

441
00:19:31,790 --> 00:19:34,030
because it's all about labeled data

442
00:19:34,250 --> 00:19:37,390
that come from places like virus toll, reversing labs,

443
00:19:37,400 --> 00:19:39,069
other sources that you alluded to.

444
00:19:39,520 --> 00:19:43,589
And the sort of very first thing that is really important to make a

445
00:19:43,599 --> 00:19:48,189
an effective machine learning malware model is to have really good labeled data.

446
00:19:48,709 --> 00:19:52,280
And part of labeling that data is actually reverse engineering a

447
00:19:52,290 --> 00:19:56,130
binary and seeing is this actually bad and that doesn't scale.

448
00:19:56,359 --> 00:20:00,050
So you have a community that works really well together where

449
00:20:00,270 --> 00:20:04,089
you can have confidence if hey these 14

450
00:20:04,219 --> 00:20:08,040
other companies that we really trust, think this is bad.

451
00:20:08,050 --> 00:20:11,040
Then the odds are this thing being bad is probably high.

452
00:20:11,140 --> 00:20:14,050
So there's, there's sort of a labeling of data problem

453
00:20:14,390 --> 00:20:18,170
that I think you're kind of alluding to that again, outside of reverse engineering,

454
00:20:18,180 --> 00:20:19,459
it's it's tough to scale it.

455
00:20:19,469 --> 00:20:21,609
It really is. But once you get that data,

456
00:20:21,810 --> 00:20:24,209
you know, knowing what data to pay attention to,

457
00:20:24,449 --> 00:20:26,050
how to age off that data,

458
00:20:26,060 --> 00:20:28,290
to really make an effective machine learning malware model.

459
00:20:28,300 --> 00:20:31,219
It's really hard and yet you have to do it for windows

460
00:20:31,349 --> 00:20:32,400
pe files, ex

461
00:20:32,510 --> 00:20:37,890
cable files for Mac Os, we support and train models on macros for office documents.

462
00:20:38,140 --> 00:20:40,770
That the whole world to me is fascinating and

463
00:20:40,780 --> 00:20:43,180
we have some data engineers and data scientists that

464
00:20:43,300 --> 00:20:44,589
do amazing work there.

465
00:20:44,599 --> 00:20:47,880
That Bobby Feiler actually a couple of days ago published a new blog that he,

466
00:20:47,890 --> 00:20:50,670
he gave a talk at a data science conference called CLAS

467
00:20:51,329 --> 00:20:52,000
on

468
00:20:52,219 --> 00:20:54,800
how to detect living off the land techniques,

469
00:20:54,810 --> 00:20:57,869
kind of analyzing parent child relationships

470
00:20:57,880 --> 00:20:59,410
using graphs and community detection.

471
00:20:59,420 --> 00:21:00,880
Again, applying ML

472
00:21:01,119 --> 00:21:02,430
to this problem like it's,

473
00:21:02,439 --> 00:21:06,510
it's ripe for those types of those opportunities to use ML.

474
00:21:06,520 --> 00:21:08,390
It's, it's actually kind of cool. And I, I

475
00:21:08,680 --> 00:21:12,140
hate and I'm very sensitive and aware of saying this

476
00:21:12,150 --> 00:21:15,189
because there are so many companies that will just throw

477
00:21:15,339 --> 00:21:17,989
A I and ML at you all day long in our marketing

478
00:21:18,239 --> 00:21:20,349
and it sounds so disingenuous.

479
00:21:20,430 --> 00:21:23,780
And if I'm coming across like that, then I hope you delete this.

480
00:21:24,810 --> 00:21:28,319
No, I think we'll keep it. But yeah, I hear you man. All right.

481
00:21:28,329 --> 00:21:30,380
So we are nearing the end of our time,

482
00:21:30,390 --> 00:21:33,130
but I wanted to kind of make sure we hit on one

483
00:21:33,140 --> 00:21:36,199
other topic that I know is near and dear to your heart

484
00:21:36,449 --> 00:21:39,680
when we first started chatting about coming on the podcast,

485
00:21:39,689 --> 00:21:43,140
you sent me a link to a blog post you have about you,

486
00:21:43,150 --> 00:21:45,160
you are an amputee and you had an accident.

487
00:21:45,170 --> 00:21:47,670
And I think this story is fascinating and I think

488
00:21:47,680 --> 00:21:50,939
it is empowering and important people tell stories like this.

489
00:21:50,949 --> 00:21:53,390
I'll make sure there's a link in the show notes for everyone listening,

490
00:21:53,400 --> 00:21:55,619
but tell us your story, Tony, because it's amazing.

491
00:21:55,910 --> 00:21:58,369
Well, I thank you for the opportunity to share it.

492
00:21:58,380 --> 00:22:02,290
Well, I certainly didn't plan for this to happen. I think 2010,

493
00:22:02,599 --> 00:22:06,290
let me take a step back. So I was a nerd growing up. I wasn't good at sports.

494
00:22:06,300 --> 00:22:09,770
I was terrible at all of the things like I was shocked to learn this.

495
00:22:09,979 --> 00:22:16,160
Yeah, no surprise. I started snowboarding around the age of 11 and I wasn't awful.

496
00:22:16,170 --> 00:22:17,599
I was not terrible.

497
00:22:17,780 --> 00:22:20,880
So it became a huge passion of mine. I was, I was

498
00:22:21,040 --> 00:22:22,969
doing it as often as I could.

499
00:22:22,979 --> 00:22:26,479
I also grew up in a landlocked area in the States called Oklahoma,

500
00:22:26,489 --> 00:22:29,180
but we would drive to Colorado or New Mexico.

501
00:22:29,189 --> 00:22:30,609
So I, again, I, I loved it.

502
00:22:30,619 --> 00:22:33,640
I was super passionate about it and I like to talk about this story of

503
00:22:33,650 --> 00:22:37,569
why I got the amputation because there are a lot of people that deal with

504
00:22:37,910 --> 00:22:40,969
ankle arthritis that it's, it's a real struggle.

505
00:22:40,979 --> 00:22:44,290
It's really painful and debilitating and it's a sort of an unseen injury.

506
00:22:44,300 --> 00:22:48,890
And so I, I had this accident in 2010 where I was in Breckenridge, Colorado.

507
00:22:48,920 --> 00:22:49,699
It's kind of weird.

508
00:22:49,709 --> 00:22:52,650
Like, if you, if you tell it from the moment the accident happened, I just remember,

509
00:22:52,660 --> 00:22:55,680
like right after it happened, I'm sort of like, what's going on here?

510
00:22:55,689 --> 00:22:59,439
Like someone screaming, who is that? I was like, oh, that's

511
00:22:59,556 --> 00:23:01,286
me. I'm screaming.

512
00:23:01,536 --> 00:23:04,735
What happened? What basically happened is I was coming down

513
00:23:04,916 --> 00:23:10,115
a black diamond and the only one on the run that day and my style is kind of all gas.

514
00:23:10,125 --> 00:23:13,125
No break. I was just going straight down. I was wearing a helmet. Mom.

515
00:23:13,286 --> 00:23:13,296
I

516
00:23:13,475 --> 00:23:14,105
hope she knows that.

517
00:23:14,186 --> 00:23:18,086
I remember when, when I learned to snowboard back in the day as a kid as well, like,

518
00:23:18,095 --> 00:23:19,135
yeah, we didn't wear helmets,

519
00:23:19,296 --> 00:23:20,446
nobody wore helmets.

520
00:23:21,202 --> 00:23:24,741
I had just bought the helmet like the day before and I've been snowboarding for like,

521
00:23:24,751 --> 00:23:27,682
you know, I guess at the time I was 27 when we had the accident.

522
00:23:27,692 --> 00:23:28,062
So,

523
00:23:28,291 --> 00:23:29,271
you know, a long time.

524
00:23:29,281 --> 00:23:31,702
So I'm coming off this run and at the bottom it marches

525
00:23:31,712 --> 00:23:34,342
for the screen and there was this young skier that kind of,

526
00:23:34,352 --> 00:23:36,121
she was hugging the tree line on the right,

527
00:23:36,501 --> 00:23:40,732
like cool. I'll go to her left in between her and this tree.

528
00:23:40,741 --> 00:23:42,832
There's this wide open space like no problem.

529
00:23:42,991 --> 00:23:45,901
And, and for those of you that don't snowboard or ski,

530
00:23:45,911 --> 00:23:47,442
everyone in front of you has the right of way.

531
00:23:47,452 --> 00:23:49,942
Like it's your responsibility and they can't see you like, you,

532
00:23:50,219 --> 00:23:52,630
you have to be in control and you kind of have

533
00:23:52,640 --> 00:23:54,859
to make sure you don't cause any problems on the slope.

534
00:23:54,869 --> 00:23:55,369
So

535
00:23:55,550 --> 00:23:57,400
I picked a line kind of to or left

536
00:23:57,550 --> 00:23:59,280
and I was, I was writing switch.

537
00:23:59,290 --> 00:24:02,109
So on snowboarding kind of terms, I was writing basically in reverse.

538
00:24:02,119 --> 00:24:04,280
-- I was practicing that. So,
-- do you normally ride

539
00:24:04,410 --> 00:24:05,959
or? So you're riding goofy?

540
00:24:06,500 --> 00:24:07,020
Yeah. Yeah.

541
00:24:07,180 --> 00:24:07,569
That's right.

542
00:24:07,869 --> 00:24:07,979
Yeah.

543
00:24:08,209 --> 00:24:12,189
And so I lean on my left foot and I'm approaching and she,

544
00:24:12,199 --> 00:24:13,489
the skier in front of me cuts to the left.

545
00:24:13,500 --> 00:24:16,239
Like no problem. I'll go, I'll go around the left of this tree.

546
00:24:16,250 --> 00:24:19,640
I've done it a million times. No, no different this time. But I had forgotten

547
00:24:20,020 --> 00:24:22,800
that I was leading on my left foot. So I just didn't have the same control and

548
00:24:23,089 --> 00:24:25,040
I was probably going about 30 miles an hour.

549
00:24:25,050 --> 00:24:27,180
I realized I'm definitely hitting this tree.

550
00:24:27,410 --> 00:24:31,000
I just got sat down and took the impact on my snowboard and, and,

551
00:24:31,040 --> 00:24:35,930
and the whole impact took place over my right foot kind of underneath the board and

552
00:24:36,109 --> 00:24:40,310
it shoved my foot up into my T BS, just smashed it into 1000 pieces,

553
00:24:40,319 --> 00:24:41,719
snapped my fibula in half.

554
00:24:42,010 --> 00:24:43,930
And again, I just remember like after it happened, like, ok,

555
00:24:43,939 --> 00:24:46,219
so someone is screaming, why is that person screaming?

556
00:24:46,239 --> 00:24:47,530
Like someone should help that person?

557
00:24:47,770 --> 00:24:48,349
And I was like,

558
00:24:48,630 --> 00:24:50,449
oh, that's, that's me. I'm screaming.

559
00:24:50,459 --> 00:24:54,829
So I, I just kind of went through a little bit of a shock at someone that see,

560
00:24:54,839 --> 00:24:57,949
like they saw the whole thing and they, they got ski patrol up there

561
00:24:58,170 --> 00:24:59,500
and as soon as that kind of came out of my

562
00:24:59,510 --> 00:25:02,229
shock that literally the first words out of my mouth were

563
00:25:02,619 --> 00:25:04,630
my wife is going to kill me.

564
00:25:05,319 --> 00:25:08,469
She's like, you know, I was alone that day. She like, just be safe.

565
00:25:08,479 --> 00:25:09,979
I'm like, oh, sure, I will be safe.

566
00:25:10,510 --> 00:25:11,439
And I mean, I

567
00:25:11,560 --> 00:25:11,569
I

568
00:25:11,859 --> 00:25:16,040
long story short, I I went through several surgeries of trying to just fix it.

569
00:25:16,050 --> 00:25:16,290
I mean,

570
00:25:16,300 --> 00:25:18,969
I just remember telling Brooke like I'll be walking again

571
00:25:18,979 --> 00:25:20,599
soon and the doctor overheard me and she was like,

572
00:25:20,609 --> 00:25:23,260
you don't understand something here like you may never walk again

573
00:25:23,979 --> 00:25:26,770
and she showed me the X ray and I'm like, oh, that, that doesn't look good.

574
00:25:26,780 --> 00:25:30,760
That looks bad. So, yeah, tons of surgeries, external fixators.

575
00:25:30,930 --> 00:25:33,229
I even had like a piece of my pelvis

576
00:25:33,369 --> 00:25:38,319
-- taken out and thrown in my ankle. So
-- they tried to, to fix the bone before

577
00:25:38,520 --> 00:25:39,780
you decided to amputate.

578
00:25:40,130 --> 00:25:40,630
That's right.

579
00:25:40,640 --> 00:25:44,119
So uh what happened is I had so many surgeries that

580
00:25:44,130 --> 00:25:47,219
it just wasn't healing and and the options are limited.

581
00:25:47,229 --> 00:25:49,510
If you have ankle arthritis, you can fuse it. But that,

582
00:25:49,760 --> 00:25:52,859
that may only resolve the pain for a limited amount of time.

583
00:25:52,869 --> 00:25:56,469
So yeah, I decided to amputate it and it was actually I was in an airport

584
00:25:56,689 --> 00:26:01,390
and I met a bilateral above the knee amputee. So he had

585
00:26:01,550 --> 00:26:03,630
both of his legs amputated above the knee.

586
00:26:03,890 --> 00:26:07,380
And uh he was really fit. I was like, ok, so what's going on here?

587
00:26:07,390 --> 00:26:09,050
And he sees me actually in a cane.

588
00:26:09,550 --> 00:26:09,569
He

589
00:26:09,670 --> 00:26:12,420
actually came up to me. And so we just started talking.

590
00:26:12,670 --> 00:26:14,180
I was like, yeah, I'm thinking about amputating it like, oh,

591
00:26:14,189 --> 00:26:16,060
you definitely need to do that.

592
00:26:16,069 --> 00:26:17,719
I mean, for an above knee amputee, a

593
00:26:17,979 --> 00:26:21,229
below knee amputation, which is what I have is like a nosebleed. It's nothing

594
00:26:21,640 --> 00:26:25,619
you need to do it. Like there's like no question, this is the right decision for you.

595
00:26:25,630 --> 00:26:26,819
And he was absolutely right.

596
00:26:26,829 --> 00:26:30,469
I think I, I got my amputation scheduled maybe six or seven months later.

597
00:26:30,859 --> 00:26:32,199
And yeah, I haven't looked back.

598
00:26:32,209 --> 00:26:35,359
I can now do everything I could do before I've been snowboarding again.

599
00:26:35,439 --> 00:26:39,599
And it's, you know, not everyone is the same, but II, I have a blog now, a

600
00:26:39,829 --> 00:26:41,310
snowboarder versus tree.

601
00:26:41,839 --> 00:26:42,000
Well,

602
00:26:42,010 --> 00:26:46,010
I talked to people about it and I've met other people that have had similar injuries,

603
00:26:46,260 --> 00:26:48,020
felt like their options were running out.

604
00:26:48,300 --> 00:26:50,260
It's really debilitating and then

605
00:26:50,439 --> 00:26:53,050
they, they have an amputation and they just get their lives back.

606
00:26:53,060 --> 00:26:55,599
Like I was telling you earlier that I know someone that

607
00:26:55,609 --> 00:26:58,180
now he is a Paralympic snowboarder and he's doing amazing.

608
00:26:58,189 --> 00:26:58,630
So

609
00:26:58,780 --> 00:26:59,859
it really is a life changer.

610
00:26:59,869 --> 00:27:02,060
So I, I like and thank you for the opportunity to talk about it.

611
00:27:02,069 --> 00:27:03,540
I like to talk about it because,

612
00:27:03,890 --> 00:27:06,339
you know, if there's anyone out there that has debilitating,

613
00:27:06,349 --> 00:27:08,689
I can't walk arthritis in your ankle.

614
00:27:09,050 --> 00:27:13,349
I'm not saying get an amputation tomorrow, but like, look me up, let's talk

615
00:27:13,560 --> 00:27:17,770
-- because for many people, it's, it's a good option.
-- That's amazing, man.

616
00:27:17,780 --> 00:27:22,150
It's, and, and in all seriousness before you sent me your blog post,

617
00:27:22,160 --> 00:27:25,780
it never even occurred to me that this was a thing where people would like choose

618
00:27:25,880 --> 00:27:26,430
to

619
00:27:26,650 --> 00:27:27,969
amputate part of their life.

620
00:27:28,369 --> 00:27:29,329
But it is,

621
00:27:29,430 --> 00:27:31,630
-- it's awesome.
-- Well, thank you. My,

622
00:27:31,869 --> 00:27:35,219
my orthopedic surgeon was like, no, no, no, no, I'm definitely not going to do that.

623
00:27:35,229 --> 00:27:37,060
So it takes sort of the right

624
00:27:37,250 --> 00:27:39,520
person, the right doctor to kind of say, oh yeah,

625
00:27:39,530 --> 00:27:41,219
this is definitely a good option for you.

626
00:27:41,229 --> 00:27:41,449
Well,

627
00:27:41,459 --> 00:27:43,660
I think in general the human body is sort of the

628
00:27:43,670 --> 00:27:46,979
ultimate extreme example of sunk cost fallacy for most people.

629
00:27:47,369 --> 00:27:49,109
Yes, like really, I mean,

630
00:27:49,439 --> 00:27:51,810
to voluntarily remove parts of your body that is

631
00:27:51,819 --> 00:27:54,020
such a taboo thing to even talk about.

632
00:27:54,099 --> 00:27:58,270
-- That
-- is every orthopedic surgeon on the I'm sorry if you're an orthopedic surgeon.

633
00:27:58,280 --> 00:27:58,920
But you know,

634
00:27:58,930 --> 00:28:02,060
maybe if you hear this next time you talk to a patient about an amputation,

635
00:28:02,069 --> 00:28:04,000
you'll think about some cost fallacy

636
00:28:04,180 --> 00:28:08,290
because that's every orthopedic surgeon wants to salvage, salvage, salvage

637
00:28:08,609 --> 00:28:10,790
and that's not always the best for your quality of life.

638
00:28:10,800 --> 00:28:10,979
Well,

639
00:28:10,989 --> 00:28:13,170
and I can't help but think we have the same problem in Infosec

640
00:28:13,180 --> 00:28:16,349
where we keep trying to salvage old systems and patch them up and,

641
00:28:16,800 --> 00:28:20,010
you know, I'm seeing people just eventually get fed up,

642
00:28:20,020 --> 00:28:21,369
throw stuff out and move to the clown.

643
00:28:21,380 --> 00:28:22,979
It's like, wow, that's so much better.

644
00:28:23,430 --> 00:28:27,550
Yep. Yep. Or, or amputate your A V, you know, like, yeah, absolutely.

645
00:28:27,560 --> 00:28:29,619
And maybe that's a new marketing tagline we can use.

646
00:28:30,349 --> 00:28:31,239
That's awesome.

647
00:28:31,469 --> 00:28:32,109
I love it.

648
00:28:32,369 --> 00:28:35,270
All right. Cool. I, I don't see a better way to end it. Tony.

649
00:28:35,280 --> 00:28:38,449
That was, this has been an awesome conversation and

650
00:28:38,579 --> 00:28:41,689
-- it has been an absolute pleasure to have you. So, thank
-- you.

651
00:28:41,810 --> 00:28:44,569
Thank you, Kurt Josh. This podcast is awesome.

652
00:28:44,579 --> 00:28:47,930
And you guys do a phenomenal job and I hope people that are listening.

653
00:28:47,939 --> 00:28:52,089
If you're just now tuning in, you got to go back and listen to the other podcasts.

654
00:28:52,109 --> 00:28:56,030
I'm surprised that we haven't talked about the prime number thing like that.

655
00:28:56,140 --> 00:28:59,849
Me fascinates me. Like, why haven't we gotten into an argument about prime numbers?

656
00:29:00,050 --> 00:29:05,030
-- I know this podcast. 186. Yeah,
-- because 186 isn't prime.

657
00:29:05,329 --> 00:29:08,709
-- It might be quasi
-- prime though. Well, you know, we could still argue about it.

658
00:29:08,719 --> 00:29:11,209
I feel left out that I didn't get to participate in that,

659
00:29:11,219 --> 00:29:13,040
but you guys do a phenomenal job.

660
00:29:13,050 --> 00:29:15,260
So I'm, I'm honored that could be a guest on it.

661
00:29:15,270 --> 00:29:16,079
Well, I'll tell you what,

662
00:29:16,089 --> 00:29:19,670
you come back again and we can do nothing to argue about prime numbers.

663
00:29:19,680 --> 00:29:20,079
Right.

664
00:29:20,290 --> 00:29:21,790
Yes, I would love

665
00:29:22,650 --> 00:29:27,770
actually. So I do have a joke. I will end on before I do the outro. Is that so,

666
00:29:27,969 --> 00:29:28,790
as

667
00:29:29,089 --> 00:29:32,920
was reported, I think yesterday or the day before Katherine Johnson,

668
00:29:32,930 --> 00:29:34,089
the mathematician

669
00:29:34,209 --> 00:29:38,270
who was the kind of star of the hidden figures, book and movie passed away.

670
00:29:38,280 --> 00:29:42,020
And while anyone could be sad or what, I mean, she's 100 and one years old, like,

671
00:29:42,030 --> 00:29:42,709
good for you.

672
00:29:42,719 --> 00:29:46,439
You've done more than I ever will. The best part I heard was that

673
00:29:46,630 --> 00:29:48,510
she waited till now because she

674
00:29:48,614 --> 00:29:50,635
died at the prime of her life being

675
00:29:50,854 --> 00:29:52,785
100 and one is a prime number.

676
00:29:52,915 --> 00:29:53,454
So

677
00:29:53,744 --> 00:29:54,435
it's awesome.

678
00:29:55,114 --> 00:29:55,734
Anyway,

679
00:29:56,045 --> 00:29:59,074
wonderful. Thank you, Tony. Thank you, Kurt. Thank you everyone for listening.

680
00:29:59,084 --> 00:30:01,334
You can go to open source security podcast.com.

681
00:30:01,344 --> 00:30:04,354
I will put all of the show notes for all of the things Tony talked about in there.

682
00:30:04,364 --> 00:30:04,834
You can use the

683
00:30:04,964 --> 00:30:06,035
Pound Os S podcast.

684
00:30:06,045 --> 00:30:10,714
Hashtag You hit us up on social media and Kurt have a fantastic rest of your day.

685
00:30:10,734 --> 00:30:13,604
You too. Thanks everybody and thank you Tony for being on the show. Yeah.

686
00:30:13,614 --> 00:30:14,275
Thanks guys.