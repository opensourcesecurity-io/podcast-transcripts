0
00:00:05,559 --> 00:00:08,520
Hello and welcome to the open source security podcast with myself,

1
00:00:08,529 --> 00:00:10,289
Kurt Siegfried and my partner in Thought Crime.

2
00:00:10,300 --> 00:00:12,539
-- Josh Pressers. So,
-- what's new and exciting

3
00:00:12,550 --> 00:00:14,550
-- summer's back?
-- Did it ever leave?

4
00:00:14,560 --> 00:00:18,360
Kind of we had like kind of a week or two of not great weather.

5
00:00:18,700 --> 00:00:18,780
Ah,

6
00:00:18,959 --> 00:00:20,850
that's because you live in the Arctic circle.

7
00:00:20,860 --> 00:00:23,590
I think the rest of us have been boiling to death for the most part.

8
00:00:23,600 --> 00:00:26,629
Yeah, we got that stuff now. Fun fact about terrible weather.

9
00:00:26,719 --> 00:00:29,190
I went to a Renaissance fair over the weekend

10
00:00:29,340 --> 00:00:30,020
and I cos

11
00:00:30,200 --> 00:00:31,430
played as Waldo,

12
00:00:31,459 --> 00:00:35,919
many people found me and it was like boiling hot and I thought I was going to die.

13
00:00:36,049 --> 00:00:38,680
And then I spent the next day being pretty much,

14
00:00:38,689 --> 00:00:40,180
it felt like I was extremely hungover.

15
00:00:40,189 --> 00:00:44,220
-- I assume I was very dehydrated even though I drank an enormous amount of liquids.
-- I,

16
00:00:44,380 --> 00:00:45,790
that's one of my memories from Schutz

17
00:00:45,900 --> 00:00:47,919
Fest. And uh I lived in a small town in Germany called

18
00:00:48,110 --> 00:00:48,169
Biberach,

19
00:00:48,340 --> 00:00:49,639
which literally means Beaver.

20
00:00:50,540 --> 00:00:53,189
And they have a Schutz Fest, which is the shooting festival

21
00:00:53,669 --> 00:00:55,849
in, uh usually about June. Now it's moved to July.

22
00:00:55,860 --> 00:00:57,580
So it doesn't interfere with school and

23
00:00:57,750 --> 00:01:00,380
they have like a traditional marching band from the schools, like,

24
00:01:00,389 --> 00:01:02,770
like with the drums and the medieval costumes

25
00:01:03,220 --> 00:01:05,680
that just so hot. Like all that medieval costume.

26
00:01:05,819 --> 00:01:09,180
Even the replica stuff is just, it's like six layers of fabric.

27
00:01:09,610 --> 00:01:12,360
Yeah. Yeah. I saw people wearing, like, night

28
00:01:12,550 --> 00:01:15,779
night suits with metal and obviously you can't just wear metal on skin.

29
00:01:15,790 --> 00:01:17,389
You have to put a thing on under it.

30
00:01:17,860 --> 00:01:18,239
And

31
00:01:18,660 --> 00:01:22,040
I just kept thinking I would have died. There's no way I could have done that

32
00:01:22,190 --> 00:01:23,290
-- just even
-- later. Hosen.

33
00:01:23,480 --> 00:01:26,400
Like, I have a pair of nice later hose and, and man, it gets

34
00:01:26,529 --> 00:01:27,050
like,

35
00:01:27,160 --> 00:01:28,319
they're just, they don't breathe.

36
00:01:28,949 --> 00:01:30,480
Yeah. I'm sure I have no doubt.

37
00:01:30,489 --> 00:01:34,620
That's why I went as Waldo because I put on a t-shirt with some stripes on it and a hat

38
00:01:35,220 --> 00:01:39,029
and I'd wear my hat for like, five minutes just for pictures and stuff.

39
00:01:39,040 --> 00:01:41,360
And then I was like, I'm going to pass out. I take this hat off.

40
00:01:41,779 --> 00:01:43,599
Yeah. And, yeah. Yeah, I couldn't do it.

41
00:01:44,544 --> 00:01:47,995
Yeah. No, people really do. Underestimate. It's, I also find it's,

42
00:01:48,184 --> 00:01:51,084
it's heat plus the sun. I always underestimate that.

43
00:01:51,254 --> 00:01:51,444
Yeah.

44
00:01:51,455 --> 00:01:51,915
Well, well,

45
00:01:51,925 --> 00:01:54,175
so something I actually learned also over the weekend I

46
00:01:54,184 --> 00:01:57,875
didn't realize is when the temperature is measured for the weather

47
00:01:58,175 --> 00:01:59,525
that's measured in the shade.

48
00:01:59,830 --> 00:02:03,250
-- So when you're in the sun it's probably like 20 plus degrees
-- hotter.

49
00:02:03,260 --> 00:02:04,769
Well, I mean, again, we did the math.

50
00:02:04,779 --> 00:02:07,970
Remember I have those solar heaters from my pool. They're 2 ft by 10 ft.

51
00:02:07,980 --> 00:02:11,960
-- There's six of them. So that's 100 and 20 square feet.
-- I thought you lived in Canada.

52
00:02:11,970 --> 00:02:15,449
-- Should you be using meters?
-- No, because we buy stuff from America

53
00:02:15,759 --> 00:02:17,449
anyway. So it's 100 and 20 square feet

54
00:02:17,699 --> 00:02:20,440
and it raises the temperature of my pool by about 1 to 2

55
00:02:20,759 --> 00:02:22,520
Â°C per hour. It's a 9000 L.

56
00:02:22,970 --> 00:02:24,110
So that's basically

57
00:02:24,229 --> 00:02:29,050
not about 18 million calories an hour coming from 100 and 20 square feet.

58
00:02:29,270 --> 00:02:29,300
Right.

59
00:02:29,690 --> 00:02:29,940
Right.

60
00:02:29,949 --> 00:02:31,750
You do the math in, in a single afternoon, if that,

61
00:02:31,759 --> 00:02:34,080
that's enough calories to feed a human for their entire life.

62
00:02:34,089 --> 00:02:36,199
How many hamburgers is that like all of them?

63
00:02:36,419 --> 00:02:39,570
But the point is like, I know the sun is strong and carries a lot of energy.

64
00:02:39,580 --> 00:02:40,880
But, you know, now that I'm actually

65
00:02:41,110 --> 00:02:45,490
harnessing the power of the sun to heat my little pool, it's like holy cow, like two

66
00:02:45,830 --> 00:02:48,009
Â°C an hour, 9000 L of water.

67
00:02:48,179 --> 00:02:48,399
It's a

68
00:02:48,789 --> 00:02:49,000
lot of heat.

69
00:02:49,669 --> 00:02:49,839
It's a,

70
00:02:50,089 --> 00:02:52,470
and, and, and that is not a super efficient system.

71
00:02:52,479 --> 00:02:55,410
Like, it's just black plastic with water running through it.

72
00:02:55,740 --> 00:02:59,210
Yeah, you're probably only capturing like, 10 or 20% of the energy.

73
00:02:59,500 --> 00:03:04,169
Now, I wonder anyway, we, we have a topic, our topic is not pools or the sun.

74
00:03:04,740 --> 00:03:06,190
Well, it's like that. It's data,

75
00:03:06,800 --> 00:03:07,089
it's

76
00:03:07,259 --> 00:03:09,110
-- data.
-- It actually, it is. It is. Ok. It's

77
00:03:09,339 --> 00:03:13,419
valy related. All right. So, let me, let me kick this off. There was a tweet

78
00:03:13,520 --> 00:03:14,600
that I saw

79
00:03:15,080 --> 00:03:17,110
shortly after we recorded the last episode

80
00:03:17,600 --> 00:03:21,179
and I really like this. It's from uh the user name that says Brian in Pittsburgh.

81
00:03:21,460 --> 00:03:26,240
It says the elephant in the room is that we do not have controls, effectiveness,

82
00:03:26,250 --> 00:03:29,039
data controls being like security controls.

83
00:03:29,050 --> 00:03:31,580
Right. Livingston said this is quoting an article

84
00:03:31,690 --> 00:03:35,029
we have shared understanding of what good practices are.

85
00:03:35,039 --> 00:03:35,720
I agree with that,

86
00:03:35,729 --> 00:03:38,820
but the data is yet to come in as to which

87
00:03:38,830 --> 00:03:41,740
ones are bloodletting and leeches and which ones are penicillin.

88
00:03:42,690 --> 00:03:47,880
And I love this. I really like this topic because I have a background in data.

89
00:03:48,009 --> 00:03:48,479
And

90
00:03:48,770 --> 00:03:50,160
I mean, you know, me, like

91
00:03:50,264 --> 00:03:53,175
people get sick of having me say, like, show me your data, show me your data,

92
00:03:53,184 --> 00:03:53,595
-- show
-- me
-- your

93
00:03:53,705 --> 00:03:55,085
data. We don't have any data and we're embarrassed

94
00:03:55,835 --> 00:03:56,904
and that's why people get sick.

95
00:03:57,214 --> 00:03:59,845
But anyway, so I wanted to tie that

96
00:03:59,975 --> 00:04:02,904
then into while I was doing my research for the show that there

97
00:04:02,914 --> 00:04:06,565
were a couple historical events that came to mind around bloodletting and Lee

98
00:04:06,684 --> 00:04:07,535
specifically.

99
00:04:07,544 --> 00:04:07,785
And I,

100
00:04:07,794 --> 00:04:11,725
I actually came across the uh an article written called the

101
00:04:11,735 --> 00:04:14,315
six most common type of bias when working with data.

102
00:04:14,645 --> 00:04:18,363
And I thought this is really good and we should go through some of this

103
00:04:18,464 --> 00:04:18,964
and

104
00:04:19,260 --> 00:04:20,920
it, it's just six things that shouldn't.

105
00:04:20,928 --> 00:04:23,839
Well, I should, I say it shouldn't take us long. We'll see

106
00:04:23,970 --> 00:04:25,880
we don't have a timer right now, but

107
00:04:26,049 --> 00:04:27,040
we'll do our best.

108
00:04:27,250 --> 00:04:29,390
Uh So anyway, let's just let's just start the list.

109
00:04:29,399 --> 00:04:32,529
I think this is a good conversation. Number one is confirmation bias,

110
00:04:32,709 --> 00:04:33,209
right?

111
00:04:33,369 --> 00:04:37,600
And this is the one where I'll just give an example of confirmation bias,

112
00:04:37,609 --> 00:04:38,959
which is where we kind of

113
00:04:39,399 --> 00:04:42,470
we see things we want to see, I guess is how I would describe it.

114
00:04:42,480 --> 00:04:44,190
But like here's, here's our example.

115
00:04:44,369 --> 00:04:46,600
I saw it on Facebook. It was shared by John, right?

116
00:04:46,609 --> 00:04:48,429
Sound familiar social media, blah, blah, blah

117
00:04:48,649 --> 00:04:51,049
and social media obviously is amplifying

118
00:04:51,190 --> 00:04:52,429
the things we want to see.

119
00:04:52,440 --> 00:04:55,309
And so I think social media is literally confirmation bias.

120
00:04:55,320 --> 00:04:58,070
Well and not just that but like social media

121
00:04:58,079 --> 00:05:00,420
is literally amplifying the stuff that you look at.

122
00:05:00,429 --> 00:05:01,510
Like a great example is youtube.

123
00:05:01,519 --> 00:05:05,589
I hate the youtube algorithm because I will click on one video where I'm like, oh,

124
00:05:05,600 --> 00:05:06,649
that looks kind of interesting.

125
00:05:06,750 --> 00:05:10,059
And then it's like, no, I really didn't want to spend the next 17 hours looking at,

126
00:05:10,070 --> 00:05:12,119
you know, listening to air traffic control videos.

127
00:05:12,130 --> 00:05:13,510
I just was curious about this one.

128
00:05:13,630 --> 00:05:14,140
Can you

129
00:05:14,540 --> 00:05:17,859
OK. Do I unlike this video? Don't show me this channel. Like

130
00:05:18,029 --> 00:05:21,529
I accidentally uh every time I accidentally click on a movie preview

131
00:05:21,970 --> 00:05:22,950
and then my

132
00:05:23,119 --> 00:05:24,489
thing is flooded and it's like

133
00:05:24,730 --> 00:05:26,500
I'm antisocial, I don't go to the movies.

134
00:05:26,510 --> 00:05:29,170
I just want to see like one movie preview every four months

135
00:05:29,440 --> 00:05:32,500
mostly for my kids. That's right. Related to this is the batter meh

136
00:05:32,880 --> 00:05:33,410
effect.

137
00:05:33,420 --> 00:05:36,359
Which one is that it's the difference between something actually happening

138
00:05:36,369 --> 00:05:38,950
a lot and something you're starting to detect a lot.

139
00:05:38,959 --> 00:05:42,350
-- Like when you buy a new car and you see them everywhere.
-- Exactly. Right.

140
00:05:42,359 --> 00:05:43,350
That's exactly it.

141
00:05:43,779 --> 00:05:46,309
What is a security example

142
00:05:46,529 --> 00:05:49,049
of confirmation bias?

143
00:05:49,440 --> 00:05:50,790
Oh, you know, two fa works

144
00:05:51,309 --> 00:05:53,339
and it does because here I'll tell you a story.

145
00:05:53,390 --> 00:05:57,660
We've rolled now rolled out hard work E two fa across the CS A and we've had zero hacks.

146
00:05:57,670 --> 00:05:57,980
Now,

147
00:05:58,500 --> 00:06:00,420
let's ignore the fact we had zero hacks that we knew

148
00:06:00,429 --> 00:06:02,920
of before we rolled out the two fa you know,

149
00:06:02,980 --> 00:06:03,029
I,

150
00:06:03,369 --> 00:06:06,820
I'm sure the two fa that, you know, the anti tiger rock is working.

151
00:06:06,950 --> 00:06:08,100
-- All right,
-- we're gonna keep going.

152
00:06:08,450 --> 00:06:12,890
Uh, number two on the list is selection bias. This is my absolute favorite one.

153
00:06:12,899 --> 00:06:17,380
And I think this one exemplifies security perfectly. And selection bias is when

154
00:06:17,880 --> 00:06:21,010
you just have a, a sample, obviously, you can't sample everything.

155
00:06:21,019 --> 00:06:22,839
So you have to sample a subset.

156
00:06:22,869 --> 00:06:26,549
And what happens is oftentimes you'll, you'll accidentally select a

157
00:06:26,929 --> 00:06:32,679
very small subset of something that then skews in one direction or another.

158
00:06:32,709 --> 00:06:36,109
It's not the problem that it's a small subset because you can interview like

159
00:06:36,119 --> 00:06:40,500
what is it like 2000 adults in America and actually get a reasonably representative

160
00:06:40,619 --> 00:06:42,579
opinion of on something.

161
00:06:42,829 --> 00:06:45,230
So, an example of a security selection bias is

162
00:06:45,470 --> 00:06:47,299
I'm asking about password security.

163
00:06:47,769 --> 00:06:51,980
And for example, I'm not even aware of another security measure.

164
00:06:51,989 --> 00:06:54,049
-- Somebody might be using.
-- I have a better one.

165
00:06:54,220 --> 00:06:57,839
I, I would say, let's say I'm doing a survey

166
00:06:58,010 --> 00:06:59,109
and I say,

167
00:07:00,140 --> 00:07:02,790
would you use a two factor token?

168
00:07:03,209 --> 00:07:08,109
And if I survey only security people I'm gonna get like, probably 80 plus percent.

169
00:07:08,119 --> 00:07:08,529
Yes.

170
00:07:08,940 --> 00:07:09,950
But if I survey

171
00:07:10,089 --> 00:07:13,299
the overall population, I suspect you're gonna get like 20%.

172
00:07:13,309 --> 00:07:13,850
-- Yes,
-- you're

173
00:07:13,859 --> 00:07:16,609
-- gonna
-- get about 10%. That actually know what it is. 10%.

174
00:07:16,619 --> 00:07:18,470
That will just say yes. No,

175
00:07:18,730 --> 00:07:22,720
that's fair. Remember that Google video of like, what is the address bar? They went

176
00:07:22,903 --> 00:07:25,542
and interviewing people like what is this thing here?

177
00:07:26,013 --> 00:07:29,403
And most people don't know. And that's like, why would they like it drives me nuts.

178
00:07:29,412 --> 00:07:30,842
So people make such a big deal out of this.

179
00:07:30,852 --> 00:07:31,822
And I'm like, well on mobile,

180
00:07:31,833 --> 00:07:34,483
it doesn't even show it to me by default unless I like look for it.

181
00:07:34,493 --> 00:07:35,923
Tech in general

182
00:07:36,092 --> 00:07:39,602
suffers from selection bias because we think everyone knows what we know

183
00:07:39,782 --> 00:07:43,942
and they don't. That's just the reality of it. All right. Let's keep going.

184
00:07:43,953 --> 00:07:45,673
Number three historical bi.

185
00:07:46,026 --> 00:07:49,966
This is one of my favorites where we kind of use the

186
00:07:50,205 --> 00:07:53,415
things that happened in the past to kind of dictate what we do today.

187
00:07:53,425 --> 00:07:56,316
And, and I'll read the example because I think this is really good. It says in

188
00:07:56,485 --> 00:07:59,966
2013 neural network models transformed the way machines, blah blah, blah,

189
00:07:59,976 --> 00:08:04,246
blah technology allows they they giant sets of written texts, Wikipedia,

190
00:08:04,256 --> 00:08:05,776
Google news, reddit, whatever, right?

191
00:08:05,786 --> 00:08:06,376
And

192
00:08:06,515 --> 00:08:08,536
when you source the

193
00:08:08,850 --> 00:08:10,769
text from a data set,

194
00:08:10,920 --> 00:08:14,700
you end up amplifying a bias that's contained in that data set, right?

195
00:08:14,709 --> 00:08:17,070
So for example, if you, if you train

196
00:08:17,459 --> 00:08:19,660
on the example they give here is machine learning model.

197
00:08:19,670 --> 00:08:23,910
Train at Wikipedia produce gender bias analogies like man, doctor, woman, nurse,

198
00:08:23,920 --> 00:08:27,070
man, commander, woman school teacher, things like that.

199
00:08:27,079 --> 00:08:29,750
And that's where the historical biases

200
00:08:30,100 --> 00:08:32,609
of, of society, right?

201
00:08:32,619 --> 00:08:36,340
Because I mean, I I don't like putting people in these buckets.

202
00:08:36,349 --> 00:08:38,919
-- But if you look historically, that's what happened.
-- Yeah, of course.

203
00:08:38,929 --> 00:08:40,929
I mean, there's, you know, all these stories about a

204
00:08:41,179 --> 00:08:43,429
male nurse. Like what

205
00:08:43,549 --> 00:08:45,609
I think we can see some of this insecurity

206
00:08:45,619 --> 00:08:47,969
and especially in technology because if you look at

207
00:08:48,250 --> 00:08:54,429
some of the old, old just way we did things like for example, I bet you if you took data

208
00:08:54,789 --> 00:08:57,539
and you had I PV four and I PV six data sets,

209
00:08:57,549 --> 00:09:00,890
the I PV four data set is going to vastly outweigh the I PV

210
00:09:00,900 --> 00:09:04,770
six data set just because I PV six was barely used a decade ago.

211
00:09:04,940 --> 00:09:05,530
You know,

212
00:09:05,679 --> 00:09:07,369
I don't want to say it's still barely used, but it's

213
00:09:07,729 --> 00:09:08,859
you're often not exposed.

214
00:09:08,869 --> 00:09:13,010
Like there's huge I PV six networks sitting behind 6 to 4 carrier grade

215
00:09:13,190 --> 00:09:13,409
N A

216
00:09:14,450 --> 00:09:17,140
like every mobile phone it's getting better.

217
00:09:17,210 --> 00:09:21,039
But on the flip side too I don't actually want my mobile phone on the proper internet.

218
00:09:21,049 --> 00:09:24,609
I want to use it as a client only. So I'm actually ok with that, you know, I don't want

219
00:09:24,710 --> 00:09:25,840
real internet for my phone.

220
00:09:27,030 --> 00:09:30,239
And again, that comes back to it, I think it gets even more subtle and it's,

221
00:09:30,330 --> 00:09:33,760
it's not just the data, but it's what we even think of as data.

222
00:09:34,489 --> 00:09:36,669
So, like a great example of this is,

223
00:09:36,679 --> 00:09:39,419
I see people we don't actually really have

224
00:09:39,429 --> 00:09:41,710
a proper definition of what is a vulnerability.

225
00:09:41,719 --> 00:09:43,349
Oh, yeah. Yeah, that's a great one too.

226
00:09:43,359 --> 00:09:47,950
How are we supposed to measure vulnerabilities in software? Oh, wait,

227
00:09:48,090 --> 00:09:50,030
could you define software for me? Josh, I'm serious.

228
00:09:50,039 --> 00:09:52,770
Can you, like in the next 10 words, define software for me,

229
00:09:52,840 --> 00:09:55,520
I would define software in the same way

230
00:09:55,530 --> 00:09:57,809
they define pornography back in the early days.

231
00:09:57,820 --> 00:10:00,200
I can't tell you what it is. It is, but I know it when I see it.

232
00:10:00,369 --> 00:10:01,760
Yeah, exactly. Right.

233
00:10:01,929 --> 00:10:04,179
Like, OK, well, software software. What about hardware?

234
00:10:04,190 --> 00:10:07,429
Well, hardware runs software. OK. What about like business processes?

235
00:10:07,440 --> 00:10:11,000
Well, that kind of software, it's like it's instructions for humans to follow.

236
00:10:11,010 --> 00:10:13,880
Does it have to be a computation machine? Because, well, remember we used to call

237
00:10:14,159 --> 00:10:16,559
humans used to be what we called computers,

238
00:10:16,690 --> 00:10:17,020
you know.

239
00:10:17,030 --> 00:10:20,659
So if we can't even define the word software and vulnerability correctly,

240
00:10:20,669 --> 00:10:22,979
how are we supposed to measure vulnerabilities in software?

241
00:10:23,390 --> 00:10:25,059
All right. That's a whole another conversation.

242
00:10:25,070 --> 00:10:27,650
And we're not going to talk about that today because we have finite time.

243
00:10:27,669 --> 00:10:30,250
If you start going down these rabbit holes, it, it gets worse.

244
00:10:30,369 --> 00:10:33,530
Right. Well, let's, let's go to the next favorite one. Survivorship Bias. Right.

245
00:10:33,739 --> 00:10:36,130
This is kind of my favorite one here is like, oh,

246
00:10:36,140 --> 00:10:38,479
we didn't wear seat belts when I was a kid and I turned out fine.

247
00:10:38,489 --> 00:10:39,400
Well, yes, you did.

248
00:10:39,409 --> 00:10:39,859
But the, you know,

249
00:10:39,869 --> 00:10:43,010
millions of other people who died in horrific car accidents did not.

250
00:10:43,020 --> 00:10:46,530
And I think we see this, especially in the world of security where

251
00:10:46,710 --> 00:10:49,690
it's like, oh, I didn't run antivirus. I'm fine.

252
00:10:49,979 --> 00:10:51,320
And like, ok,

253
00:10:52,229 --> 00:10:54,909
how many small and medium businesses are getting

254
00:10:55,030 --> 00:10:56,940
-- sacked by cyberattacks?
-- We don't

255
00:10:56,950 --> 00:10:57,280
know,

256
00:10:57,390 --> 00:11:00,510
we know it's more than zero and probably less than 100%

257
00:11:00,799 --> 00:11:01,880
somewhere in there.

258
00:11:02,369 --> 00:11:03,200
-- Right.
-- Like,

259
00:11:06,059 --> 00:11:08,520
what an enlightening statistic Kurt. Thank you.

260
00:11:08,590 --> 00:11:10,219
But at least I'm willing to admit my ignorance.

261
00:11:10,229 --> 00:11:14,460
Most people I read reports all the time that, like, talk about

262
00:11:14,750 --> 00:11:18,880
something that's really hard to measure and only kind of pops up or bubbles up.

263
00:11:18,890 --> 00:11:22,200
-- Like, how many cyber attacks don't even get noticed.
-- I mean, right.

264
00:11:22,210 --> 00:11:24,159
Like, so one of my favorites here is

265
00:11:24,390 --> 00:11:26,059
when I was younger I would tell people.

266
00:11:26,070 --> 00:11:29,080
Well, I've never, I've ever been hacked now that I'm older.

267
00:11:29,090 --> 00:11:32,840
I think I'm not saying this out loud ever because, like, it won't be true someday.

268
00:11:32,849 --> 00:11:37,049
I also don't want to be a target but more importantly is it's far more likely

269
00:11:37,239 --> 00:11:40,200
that I just haven't noticed I've been hacked. Right.

270
00:11:40,210 --> 00:11:43,840
But I feel like I was special because I could say, oh, it didn't happen to me.

271
00:11:43,849 --> 00:11:45,760
This is actually what I liked about ransomware is

272
00:11:45,770 --> 00:11:47,479
all of a sudden all these attacks were public,

273
00:11:47,489 --> 00:11:49,799
especially the bigger ones, you know, where they're going to release the data.

274
00:11:50,059 --> 00:11:51,609
And we actually started to, like,

275
00:11:52,090 --> 00:11:55,090
I suspect prior to ransomware there was probably

276
00:11:55,690 --> 00:11:59,239
about as much shenanigans going on. It just we didn't know.

277
00:11:59,400 --> 00:12:00,159
Yeah. Right.

278
00:12:00,169 --> 00:12:02,599
Well, in, in ransomware, it's just so in your face you can't,

279
00:12:02,609 --> 00:12:03,820
you can't pretend it didn't happen.

280
00:12:03,830 --> 00:12:07,440
I mean, how many, how many of us don't? No one needs to tell me this for sure.

281
00:12:07,450 --> 00:12:10,520
But like how many of us work somewhere? We're like something got popped.

282
00:12:10,530 --> 00:12:11,030
We were like,

283
00:12:11,039 --> 00:12:13,320
we'll just turn that off and pretend everything's fine

284
00:12:13,419 --> 00:12:15,520
and we did like no other forensic work.

285
00:12:15,530 --> 00:12:15,750
We

286
00:12:15,859 --> 00:12:17,260
stuck our fingers in our ears.

287
00:12:17,440 --> 00:12:19,599
I was like, everything is awesome.

288
00:12:19,700 --> 00:12:19,770
Yeah.

289
00:12:19,890 --> 00:12:25,559
-- For us
-- it's like hoof and mouth disease. Shoot shovel Barry. We fix the problem.

290
00:12:25,570 --> 00:12:26,950
We're not going to talk about it anymore.

291
00:12:27,090 --> 00:12:31,140
Yeah. Yeah. Anyway, anyway. All right. All right. We'll keep going here.

292
00:12:31,150 --> 00:12:33,429
Uh Number five says availability bias.

293
00:12:33,830 --> 00:12:35,960
This one, I actually like a lot.

294
00:12:36,330 --> 00:12:37,909
This one is explained as.

295
00:12:37,919 --> 00:12:40,669
Have you ever find yourself wondering if crime has increased in your neighborhood?

296
00:12:40,679 --> 00:12:42,580
Because you've been, you've seen a broken car window

297
00:12:42,950 --> 00:12:43,669
right where you see,

298
00:12:43,679 --> 00:12:47,000
like these little clues and this one is the one I want to talk about the most.

299
00:12:47,010 --> 00:12:48,309
And I've been rushing us to get here

300
00:12:48,789 --> 00:12:52,440
because this particular one availability bias, like

301
00:12:52,650 --> 00:12:54,789
heartbleed log for Jay,

302
00:12:54,950 --> 00:12:56,369
whatever the hype Du Jour

303
00:12:56,549 --> 00:13:00,150
is going on right now is the most important

304
00:13:00,159 --> 00:13:02,830
and serious security event that has ever happened.

305
00:13:03,369 --> 00:13:05,989
And then in six months we can't remember the name of it.

306
00:13:06,960 --> 00:13:08,950
No, that's it. Yep. I mean,

307
00:13:09,320 --> 00:13:11,669
I had to fill out so many stupid surveys of like,

308
00:13:11,679 --> 00:13:13,150
how are you dealing with Lawford Chain?

309
00:13:13,159 --> 00:13:15,669
My answer is like we're not because we don't Java.

310
00:13:16,309 --> 00:13:18,799
No, that's like that's my response. Like we don't Java.

311
00:13:19,590 --> 00:13:24,140
I have a, a better example of this is if you look at like the,

312
00:13:24,440 --> 00:13:28,320
the usage and interest in certain security tools during log for J,

313
00:13:28,340 --> 00:13:32,070
like if you look at the uh like in, in good public data source is the github

314
00:13:32,250 --> 00:13:33,260
stars graph

315
00:13:33,369 --> 00:13:35,039
of Sift and Gripe, right?

316
00:13:35,049 --> 00:13:38,489
Which are sift creates s bombs, gripes, cancer vulnerabilities.

317
00:13:38,500 --> 00:13:40,919
And obviously you can imagine there was enormous interest

318
00:13:40,929 --> 00:13:42,700
in these tools during Lock Jake because it was

319
00:13:43,169 --> 00:13:46,390
uh Sift did a really good job of like digging into

320
00:13:46,400 --> 00:13:48,950
the jars to find log for J hidden in there.

321
00:13:49,440 --> 00:13:50,030
And

322
00:13:50,479 --> 00:13:52,770
obviously, like if you look at the Get up Stars graph,

323
00:13:52,780 --> 00:13:55,130
it takes an enormous jump during log

324
00:13:55,250 --> 00:13:56,349
for J and I'll put a link in the show now.

325
00:13:56,359 --> 00:13:58,929
So it's a really cool uh website that graphs this for you.

326
00:13:58,940 --> 00:14:00,429
So it's got this huge jump, right?

327
00:14:00,460 --> 00:14:02,309
And then obviously after a little while it tapers

328
00:14:02,320 --> 00:14:04,169
off and just turns into normal growth again.

329
00:14:04,599 --> 00:14:06,190
And I mean, this is exactly it, right.

330
00:14:06,200 --> 00:14:06,530
This is,

331
00:14:06,539 --> 00:14:09,690
this is literally an example of availability bias where all of a sudden it's like,

332
00:14:09,700 --> 00:14:10,950
oh my goodness, it's super important.

333
00:14:11,280 --> 00:14:14,880
And obviously, if everyone kept thinking this mattered,

334
00:14:15,000 --> 00:14:17,940
the graph would continue up like a rocket ship,

335
00:14:18,030 --> 00:14:20,969
but that's not what's going to happen because we think

336
00:14:20,979 --> 00:14:22,719
it's important and then it ends and then we're like,

337
00:14:22,729 --> 00:14:24,010
eh, whatever next thing.

338
00:14:24,440 --> 00:14:28,590
Well, and that's part of it too is. And next thing like covid's important. Well,

339
00:14:28,840 --> 00:14:30,299
now we got monkeypox.

340
00:14:30,590 --> 00:14:31,549
Fantastic.

341
00:14:32,159 --> 00:14:32,619
Oh my God.

342
00:14:32,820 --> 00:14:33,390
Like,

343
00:14:34,179 --> 00:14:34,890
yes,

344
00:14:35,080 --> 00:14:35,090
I,

345
00:14:35,099 --> 00:14:37,530
I'm seriously looking at buying long sleeve shirts and

346
00:14:37,539 --> 00:14:40,630
pants and not wearing shorts and short sleeve shirts.

347
00:14:40,640 --> 00:14:41,890
Like I, I, what am I

348
00:14:44,250 --> 00:14:45,700
-- anyway?
-- You know,

349
00:14:46,080 --> 00:14:50,140
the problem is we also don't have any way to weight

350
00:14:50,349 --> 00:14:51,099
the data.

351
00:14:51,820 --> 00:14:57,020
Yeah, I think that's part of it is we, we look at all this and it's very difficult to say

352
00:14:57,179 --> 00:15:02,109
what is the larger trend? Well, and I think especially insecurity.

353
00:15:02,119 --> 00:15:03,619
Does this matter to you,

354
00:15:03,770 --> 00:15:05,619
let alone, does this matter to the world?

355
00:15:06,130 --> 00:15:09,260
And we can't even really answer. Does this matter to you very well?

356
00:15:09,960 --> 00:15:12,359
Because based on some of those survey questions, I got like,

357
00:15:12,369 --> 00:15:14,820
they clearly don't like they're not doing, you know,

358
00:15:14,830 --> 00:15:15,830
they don't know what's going on.

359
00:15:15,840 --> 00:15:18,179
-- They literally were asking and,
-- and

360
00:15:18,669 --> 00:15:20,190
I don't think anyone knew what was going on.

361
00:15:20,200 --> 00:15:22,219
I mean, that's kind of part of how this works, right?

362
00:15:22,320 --> 00:15:22,349
It

363
00:15:22,570 --> 00:15:26,440
is one of the challenges when you don't have data, you end up with nothing but biases.

364
00:15:26,450 --> 00:15:27,609
I mean, I would argue that we,

365
00:15:27,719 --> 00:15:30,479
we have security data, we have security biases for the most part.

366
00:15:30,559 --> 00:15:32,450
And I think things like log for J show that

367
00:15:32,789 --> 00:15:36,700
well, and a great example is the data we do have tends to be controlled by companies,

368
00:15:36,710 --> 00:15:38,989
some of which don't want there to be security data.

369
00:15:39,000 --> 00:15:41,789
So they have a, you know, a very small number of vulnerabilities,

370
00:15:41,799 --> 00:15:45,289
even though they have a lot of patches that they say like install now or else.

371
00:15:46,140 --> 00:15:47,309
Yep. That's right. That's right.

372
00:15:47,820 --> 00:15:51,390
-- Oops,
-- it's, it's complicated for sure, for sure. I will say.

373
00:15:51,460 --> 00:15:53,890
So I know we're, we complain a lot on this show,

374
00:15:53,900 --> 00:15:56,719
but I do feel like this is starting to get a little better.

375
00:15:56,729 --> 00:15:58,109
I think there is more

376
00:15:58,289 --> 00:16:01,929
the fact that we're recognizing this is the first step and we

377
00:16:01,940 --> 00:16:04,989
have a long way to go before we can fix it.

378
00:16:05,000 --> 00:16:06,760
But just people acknowledging this,

379
00:16:06,994 --> 00:16:10,974
I feel like is really important and I can't underestimate that.

380
00:16:11,025 --> 00:16:15,755
Well, I think to be blunt, we're still at the frame or the uh the stage of

381
00:16:15,924 --> 00:16:17,864
it's like, what's the name, what's the name?

382
00:16:18,395 --> 00:16:20,054
And I'm going to butcher this name. I apologize.

383
00:16:20,085 --> 00:16:22,585
Ignaz Semmelweis who, you know,

384
00:16:22,594 --> 00:16:26,734
was the guy that pioneered hand washing for doctors and was ridiculed and you know.

385
00:16:26,885 --> 00:16:27,325
Yeah.

386
00:16:27,729 --> 00:16:29,559
Yeah. We're kind of still at that stage.

387
00:16:29,570 --> 00:16:33,580
We are uh actually my other favorite example of that I put in the show notes and I was,

388
00:16:33,590 --> 00:16:35,400
we were going to get to this at the end was

389
00:16:35,500 --> 00:16:36,840
Jon Snow

390
00:16:37,260 --> 00:16:38,919
and the cholera epidemic in London,

391
00:16:39,150 --> 00:16:41,590
which the guy's name is actually Jon Snow.

392
00:16:41,739 --> 00:16:46,174
And I remember I accidentally learned of this guy on a documentary during the

393
00:16:46,184 --> 00:16:50,604
Game of Thrones phenomenon before it was like ground into the dirt and murdered.

394
00:16:50,815 --> 00:16:51,244
But

395
00:16:51,424 --> 00:16:53,335
I was like, oh, that's funny, Jon Snow.

396
00:16:53,385 --> 00:16:57,114
But anyway, like what it came down to this guy used data to figure out

397
00:16:57,385 --> 00:17:01,135
-- C was coming from a
-- pump. Well, not just data but visualization of data.

398
00:17:01,234 --> 00:17:02,655
-- That was, that
-- he did,

399
00:17:02,940 --> 00:17:04,400
he did a map. It was amazing.

400
00:17:04,410 --> 00:17:07,250
He did, he made a map and he created quadrants and he figured out like,

401
00:17:07,260 --> 00:17:08,410
where are people getting sick?

402
00:17:08,420 --> 00:17:10,589
Like what is the central point of all this sickness?

403
00:17:10,829 --> 00:17:14,040
-- And
-- he went to like every house and asked where they got their water. And

404
00:17:14,189 --> 00:17:14,670
that's right.

405
00:17:14,880 --> 00:17:18,439
He did research while the, the scientists and I'm putting scientists in there

406
00:17:18,915 --> 00:17:22,483
said it was, what was it? It was poisonous air or something.

407
00:17:22,895 --> 00:17:24,824
It was no ill humors

408
00:17:24,954 --> 00:17:26,305
or something like that. I

409
00:17:26,464 --> 00:17:26,743
forgot

410
00:17:27,035 --> 00:17:27,425
like

411
00:17:27,675 --> 00:17:30,145
they made that up. That wasn't a thing.

412
00:17:31,074 --> 00:17:33,925
Like my favorite is they invented radio and they're like

413
00:17:34,464 --> 00:17:35,025
ether.

414
00:17:36,010 --> 00:17:38,829
Right. Because you can't transmit a wave without a medium

415
00:17:39,189 --> 00:17:41,030
and electricity doesn't move through air.

416
00:17:41,040 --> 00:17:42,489
Because if you've ever held, like, you know,

417
00:17:42,500 --> 00:17:45,219
you can spark two wires together and the electricity will go through

418
00:17:45,229 --> 00:17:46,630
a little bit of air but not a lot of air.

419
00:17:46,920 --> 00:17:47,589
So, obviously,

420
00:17:47,900 --> 00:17:48,310
well,

421
00:17:48,439 --> 00:17:49,910
you know, radio waves go through either.

422
00:17:49,920 --> 00:17:51,800
Well, no, it's more complicated than that, but,

423
00:17:52,140 --> 00:17:53,829
like, they just made stuff up.

424
00:17:53,939 --> 00:17:54,000
I

425
00:17:54,319 --> 00:17:54,760
mean,

426
00:17:55,239 --> 00:17:57,459
well, ok, look, however, I will say

427
00:17:57,810 --> 00:18:02,530
if you look at the history of science making crap up is generally step less,

428
00:18:02,540 --> 00:18:08,390
but I think you also need to be aware that making crap up isn't where you stop.

429
00:18:08,400 --> 00:18:11,630
Like you need to go test the hypothesis

430
00:18:11,839 --> 00:18:15,819
and then figure out what's going on and, and when Ether was defined,

431
00:18:15,829 --> 00:18:20,270
a lot of experiments happened that disproved it even though everyone was certain,

432
00:18:20,319 --> 00:18:20,750
it's real.

433
00:18:21,170 --> 00:18:24,130
It's like it's the dark matter of our day, right? Like

434
00:18:24,319 --> 00:18:26,589
some day it's all strings, we'll be like, oh ha ha.

435
00:18:26,599 --> 00:18:29,829
Remember we thought dark matter was real and it was just Cheerios or something.

436
00:18:29,839 --> 00:18:30,900
And we're like, oh, yes.

437
00:18:31,040 --> 00:18:33,329
Anyway. All right, one more, one more. And then we'll move on

438
00:18:33,469 --> 00:18:34,819
number six outlier bias.

439
00:18:34,829 --> 00:18:39,300
Uh This one is averages are a great place to hide uncomfortable truths.

440
00:18:39,550 --> 00:18:42,699
And I like this. So the example of outlier bias is,

441
00:18:43,079 --> 00:18:45,229
let's say you are tracking here.

442
00:18:45,239 --> 00:18:47,439
I'm just gonna read this because this is a really good explanation.

443
00:18:47,449 --> 00:18:48,739
It says the start up wants to be sure

444
00:18:48,750 --> 00:18:50,939
that their marketing site feels quick and responsive.

445
00:18:50,949 --> 00:18:53,160
They decide to track their average latency time to

446
00:18:53,170 --> 00:18:55,339
make sure that their site continues to load quickly.

447
00:18:55,349 --> 00:18:58,329
After a few months of roughly consistent average latency values,

448
00:18:58,339 --> 00:19:01,619
they start to see decline in engagement on some of their most important pages.

449
00:19:01,630 --> 00:19:02,180
When they investigate

450
00:19:02,324 --> 00:19:06,094
further, they realized that the latency on those pages has skyrocketed,

451
00:19:06,175 --> 00:19:10,954
the average latency time site wide continued to paint a rosy image.

452
00:19:10,964 --> 00:19:15,354
But those particular pages had outliers that obviously were bad.

453
00:19:15,454 --> 00:19:17,984
That's why things like 99th percentile and 95th

454
00:19:17,994 --> 00:19:21,114
percentile are so critical and also your maximum.

455
00:19:21,880 --> 00:19:24,709
We had a page that took 16 seconds to render. And I'm like,

456
00:19:25,650 --> 00:19:29,869
hey, how did that even happen? Like how did it not get killed and just not render

457
00:19:30,800 --> 00:19:31,989
like seriously, I'm like,

458
00:19:32,000 --> 00:19:35,150
from what I know of our stack that just shouldn't be possible.

459
00:19:35,260 --> 00:19:36,439
Right? Well, something happened.

460
00:19:36,890 --> 00:19:40,310
So yeah, it was like a cosmic glitch, but I'm like 16 seconds and

461
00:19:40,959 --> 00:19:43,699
like the client still waited like wow.

462
00:19:43,810 --> 00:19:46,079
-- Uh
-- I waited a long time when it's something I want.

463
00:19:46,089 --> 00:19:47,890
Well, no, no, I mean like physical client, not you.

464
00:19:47,900 --> 00:19:51,619
-- I don't care about the human meat
-- bake. Oh man, no, web browsers wait like forever.

465
00:19:51,630 --> 00:19:52,819
It's terrible. How bad.

466
00:19:52,920 --> 00:19:55,099
So I, I have a great, I have a good example of this actually.

467
00:19:55,109 --> 00:19:57,969
So when I was at elastic, elastic has

468
00:19:58,229 --> 00:19:58,979
observable

469
00:19:59,119 --> 00:20:01,959
and application, performance monitoring capabilities.

470
00:20:02,270 --> 00:20:07,489
And I didn't understand this before I, I learned from the A PM and observable people.

471
00:20:07,739 --> 00:20:09,520
So what you really want to do

472
00:20:09,650 --> 00:20:11,560
is you want to throw out the average,

473
00:20:11,770 --> 00:20:14,140
like in the bell curve, throw out the middle,

474
00:20:14,260 --> 00:20:16,560
you want to look at the things on the two edges.

475
00:20:16,569 --> 00:20:18,579
You wanna look at the things that are being serviced like

476
00:20:18,589 --> 00:20:22,069
ridiculously fast because that's almost definitely some sort of weird bug.

477
00:20:22,459 --> 00:20:25,280
And you want to look at the things that are being really, really, really slow

478
00:20:25,510 --> 00:20:29,410
because those are the places that the interesting stuff is happening.

479
00:20:29,420 --> 00:20:31,239
And I feel like in the world of security,

480
00:20:31,540 --> 00:20:33,839
it's kind of a similar idea where

481
00:20:33,959 --> 00:20:38,739
we have all this data, we can look at these bell curves and, and throw away the middle,

482
00:20:38,750 --> 00:20:38,869
right?

483
00:20:38,880 --> 00:20:40,760
Like what are on the edges and what are the

484
00:20:40,770 --> 00:20:43,160
things we can do there that can be effective?

485
00:20:43,170 --> 00:20:46,969
-- Well,
-- a perfect example, things with a 0.0 CV SS score, huh?

486
00:20:47,540 --> 00:20:51,280
-- Well, those are mostly from Oracle, right?
-- And so like, what's the deal, you know?

487
00:20:51,430 --> 00:20:53,369
Well, so the reason Oracle does that actually,

488
00:20:53,380 --> 00:20:54,939
I know this because I've talked to them about it.

489
00:20:54,969 --> 00:20:57,959
They obviously there's lots of vulnerability management systems in

490
00:20:57,969 --> 00:21:00,670
the world and usually it's giant companies running them.

491
00:21:00,680 --> 00:21:02,640
And Oracle is a favorite

492
00:21:03,050 --> 00:21:04,630
vendor of giant companies

493
00:21:04,920 --> 00:21:05,829
and so

494
00:21:06,170 --> 00:21:10,729
they would release advisories and they wouldn't assign CV SS scores and then

495
00:21:10,739 --> 00:21:14,689
the vulnerability management tools would pick up their advisories and be like,

496
00:21:14,699 --> 00:21:16,949
oh my goodness, they oracle just fixed a critical issue.

497
00:21:16,959 --> 00:21:18,270
You know, everyone sounded an alarm

498
00:21:18,839 --> 00:21:22,780
and it's just that the thing they ship contains that package

499
00:21:23,010 --> 00:21:24,569
and they might not be using it.

500
00:21:24,800 --> 00:21:27,969
And so now they just give it a 0.0 that says, yes, we ship it.

501
00:21:27,979 --> 00:21:30,459
No, we don't use it, like, stop bothering us.

502
00:21:30,770 --> 00:21:31,199
Totally. Fair.

503
00:21:31,579 --> 00:21:33,989
-- Yeah,
-- I think it's brilliant. Like I love

504
00:21:34,000 --> 00:21:34,130
it.

505
00:21:34,260 --> 00:21:37,290
I kind of wish we had done more of that at Red Hat because there was so much of that,

506
00:21:37,300 --> 00:21:39,160
this problem has existed for a long time.

507
00:21:39,170 --> 00:21:42,489
And I would argue this is one of those outliers, right? Like this is

508
00:21:42,890 --> 00:21:46,650
this falls under the outlier bias category I think.

509
00:21:47,060 --> 00:21:49,119
And this is like what vex is meant to do, right?

510
00:21:49,130 --> 00:21:50,910
The vulnerability exchange format where you can

511
00:21:50,920 --> 00:21:53,150
start specifying like this doesn't affect me

512
00:21:53,160 --> 00:21:57,520
for this reason or this isn't as severe as it's noted for this reason.

513
00:21:57,530 --> 00:21:59,050
And that's like that's a powerful thing.

514
00:21:59,060 --> 00:22:02,630
So now we can kind of pull some of these edge cases into the middle once

515
00:22:02,640 --> 00:22:05,180
we have some of this data and now we can look at the new edge cases,

516
00:22:05,324 --> 00:22:06,974
right? Because there's going to be new things.

517
00:22:06,984 --> 00:22:10,834
I feel like part of the challenge is is data visualization is hard to begin with,

518
00:22:10,844 --> 00:22:11,015
right?

519
00:22:11,025 --> 00:22:13,454
Like I have a stack of books up there, the Tufty books

520
00:22:13,655 --> 00:22:17,314
and data visualization when you have good data is hard data visualization

521
00:22:17,324 --> 00:22:19,964
and understanding it when you have bad data is basically impossible.

522
00:22:19,974 --> 00:22:21,494
-- And I suspect
-- not just that

523
00:22:21,665 --> 00:22:23,454
if you have a malicious

524
00:22:23,849 --> 00:22:24,780
entity

525
00:22:25,030 --> 00:22:27,579
creating the day because what's the Mark Twain quote lies,

526
00:22:27,589 --> 00:22:29,780
damned lies and statistics, right?

527
00:22:29,790 --> 00:22:32,439
Like you can use statistics to lie if you know what you're doing.

528
00:22:32,449 --> 00:22:33,640
-- Well,
-- and I was about to say,

529
00:22:33,650 --> 00:22:36,300
like we can use the statistics to basically make a warm comfy Sainty

530
00:22:36,589 --> 00:22:37,589
blanket. That's like

531
00:22:37,719 --> 00:22:40,829
-- things are not great, but they're ok. Right. That
-- too. Yeah. II,

532
00:22:41,199 --> 00:22:42,599
I mean, I've seen that many times.

533
00:22:42,609 --> 00:22:42,770
I mean,

534
00:22:42,780 --> 00:22:45,770
-- that's like the Enron story is that
-- the average

535
00:22:45,780 --> 00:22:49,020
time a vendor needs to respond to security events.

536
00:22:49,459 --> 00:22:53,219
Well, but wait like half of these are totally minor and they closed them out in a day

537
00:22:54,290 --> 00:22:57,040
which pulls down, you know, their, their 95th percentile

538
00:22:57,140 --> 00:23:00,380
where it's like, oh yeah, it took us like seven years to fix log for Jay. But

539
00:23:00,800 --> 00:23:01,589
yeah, I mean, that's,

540
00:23:01,689 --> 00:23:03,180
that's the average again, right?

541
00:23:03,189 --> 00:23:07,239
When we're, we're hiding in the average 99% of things I respond to.

542
00:23:07,250 --> 00:23:08,349
I respond to in an hour.

543
00:23:08,550 --> 00:23:13,020
I want to end with a tweet from Bob Lord who is uh he was the what?

544
00:23:13,260 --> 00:23:17,359
-- So of the DNC, the Democratic National Committee
-- that has got to be not a fun job.

545
00:23:17,569 --> 00:23:20,989
I can't imagine that job, but that's another story.

546
00:23:21,000 --> 00:23:22,890
So anyway, so the, the FTC,

547
00:23:22,900 --> 00:23:26,140
the United States Federal Trade Commission puts out a tweet that says using public

548
00:23:26,150 --> 00:23:29,489
Wi Fi if the network isn't secure and you log into an unencrypted site,

549
00:23:29,500 --> 00:23:32,160
other users on the network and see what you see and send,

550
00:23:32,410 --> 00:23:35,599
they could hijack your session and log in as you learn how to protect yourself.

551
00:23:35,609 --> 00:23:37,520
And then it's a link to some terrible document.

552
00:23:38,030 --> 00:23:39,229
And then Bob replies,

553
00:23:39,239 --> 00:23:41,849
what exactly are modern browsers doing to create a

554
00:23:41,859 --> 00:23:44,859
condition so unsafe that you have to warn consumers,

555
00:23:44,869 --> 00:23:47,489
what do the browser makers have to change for browsers

556
00:23:47,500 --> 00:23:49,579
to be safe by design and safe by default,

557
00:23:49,589 --> 00:23:51,890
such that you can retire this advice?

558
00:23:51,900 --> 00:23:53,300
Is there a punch list? We can

559
00:23:53,530 --> 00:23:56,670
-- you
-- fun fact, Google actually fixed this for us.

560
00:23:56,680 --> 00:24:00,609
What was it two summers ago when they changed their? So I'd argue it's fixed now.

561
00:24:00,619 --> 00:24:04,119
Yeah. Well, no, what happened is Google changed like they do this rejiggering.

562
00:24:04,130 --> 00:24:06,469
I forget there's like a name for this event where they rejigger,

563
00:24:06,479 --> 00:24:08,920
how they do their search engine optimization rankings.

564
00:24:09,989 --> 00:24:12,439
And two summers ago they made HTTP S matter

565
00:24:13,479 --> 00:24:15,160
and guess what happened within about three months.

566
00:24:15,569 --> 00:24:16,150
Let's, well,

567
00:24:16,160 --> 00:24:18,180
now let's encrypt was key to that

568
00:24:18,189 --> 00:24:19,819
without let's encrypt that couldn't have happened.

569
00:24:19,829 --> 00:24:22,099
Let's encrypt enabled it. But

570
00:24:22,430 --> 00:24:25,660
here's the thing, this is what frustrates me about security. We always,

571
00:24:26,150 --> 00:24:26,630
there's a,

572
00:24:26,640 --> 00:24:30,910
a supply side and a demand side and people really only ever talk about the supply

573
00:24:30,920 --> 00:24:33,810
side because the demand side is boiling the ocean and we've given up on that.

574
00:24:33,819 --> 00:24:35,410
These are all biases, right?

575
00:24:35,540 --> 00:24:38,290
Like it's easy for my confirmation bias on the,

576
00:24:38,300 --> 00:24:41,180
on the supply side because that's where me and my friends like.

577
00:24:41,260 --> 00:24:43,550
But people forget that Google can boil the ocean by oh,

578
00:24:43,640 --> 00:24:45,979
guess what our web browser is now instead of saying

579
00:24:46,262 --> 00:24:47,762
secure is going to say

580
00:24:47,932 --> 00:24:49,162
insecure, that's

581
00:24:49,473 --> 00:24:49,512
all

582
00:24:49,853 --> 00:24:51,562
crap. I need to go fix my website right now,

583
00:24:51,932 --> 00:24:55,542
you know, or oh, my search engine rankings are going to drop like a stone.

584
00:24:55,552 --> 00:24:56,753
If I don't do http S

585
00:24:57,022 --> 00:24:58,942
we're like this is now

586
00:24:59,223 --> 00:24:59,963
a project

587
00:25:00,292 --> 00:25:01,922
and that's the thing is

588
00:25:02,322 --> 00:25:04,172
there are some vendors like

589
00:25:04,312 --> 00:25:06,272
Apple is a good example of having boiled the

590
00:25:06,375 --> 00:25:09,816
o for a few things. Apple has pushed a few standards forwards

591
00:25:09,995 --> 00:25:10,416
but

592
00:25:10,566 --> 00:25:13,355
yeah, like nobody else could have really done that.

593
00:25:13,485 --> 00:25:14,036
Cool.

594
00:25:14,176 --> 00:25:16,995
So between Microsoft Apple Google, you know, with them doing the, the,

595
00:25:17,005 --> 00:25:18,956
the Fido alliance and all that stuff like, yeah,

596
00:25:18,965 --> 00:25:22,166
Fido is finally going to come here because the the demand side will happen.

597
00:25:22,735 --> 00:25:24,345
And that's the thing that always drove me nuts is

598
00:25:24,735 --> 00:25:26,526
if there is demand for something,

599
00:25:26,956 --> 00:25:27,946
there will be a supply.

600
00:25:27,956 --> 00:25:31,536
My case in point being like the global illegal drug trade, right?

601
00:25:31,546 --> 00:25:33,916
This stuff is crazy illegal

602
00:25:34,066 --> 00:25:35,505
in a lot of countries and yet.

603
00:25:35,949 --> 00:25:36,599
Well,

604
00:25:37,270 --> 00:25:37,819
yeah,

605
00:25:37,979 --> 00:25:38,550
you know, yeah,

606
00:25:38,560 --> 00:25:42,380
it amuses me when governments think the solution to a problem is to outlaw it.

607
00:25:42,390 --> 00:25:47,099
Like no, you just made a new problem now instead of the one you just outlawed,

608
00:25:47,260 --> 00:25:49,619
we legalized it and, you know,

609
00:25:50,050 --> 00:25:51,219
there's a tax stamp on it.

610
00:25:51,229 --> 00:25:54,219
Now, when you buy marijuana in Canada and as far as I can tell, nothing changed

611
00:25:55,295 --> 00:25:57,685
of drug enforcement officers went down.

612
00:25:57,694 --> 00:25:58,775
-- We were
-- honestly,

613
00:25:58,785 --> 00:26:01,494
we kind of haven't been doing that for the last three or four decades.

614
00:26:01,625 --> 00:26:01,655
Well,

615
00:26:01,824 --> 00:26:06,175
-- there you go. Then
-- this is a good example of like everything is HTTP S

616
00:26:06,295 --> 00:26:06,704
oh,

617
00:26:06,885 --> 00:26:07,474
ok.

618
00:26:07,645 --> 00:26:08,114
Like the

619
00:26:08,234 --> 00:26:13,064
like, I don't care how insecure the network you use is if it's HTTP S set up properly,

620
00:26:13,285 --> 00:26:15,755
if the attacker can get in there, there are state

621
00:26:16,270 --> 00:26:19,140
-- level actor.
-- But now remember too,

622
00:26:19,349 --> 00:26:23,750
so I think there's some other pieces to this. This is historical bias.

623
00:26:23,760 --> 00:26:27,540
I think that the FTC put together because if you look back 1020 years ago,

624
00:26:27,640 --> 00:26:28,979
wifi was new

625
00:26:29,239 --> 00:26:32,459
and not only that a lot of the protocols on the internet were unencrypted.

626
00:26:32,469 --> 00:26:36,369
You know, you had SMTP, you'd have IRC you'd connect to, you connect to FTP site,

627
00:26:36,380 --> 00:26:37,060
you connect to

628
00:26:37,310 --> 00:26:39,930
mail server. Like none of this stuff was encrypted.

629
00:26:40,060 --> 00:26:46,310
It used to be a vendor choice criteria at the CS A is do they do HTTP S like by default,

630
00:26:46,579 --> 00:26:49,760
that used to be a big deal 10 years ago. And now, of course, it's like,

631
00:26:50,290 --> 00:26:50,310
I

632
00:26:50,469 --> 00:26:53,949
-- don't think I could even find a real, but
-- the point is

633
00:26:54,180 --> 00:26:59,420
the world has gone to HTTP S for everything. And so like literally all of our

634
00:26:59,630 --> 00:27:00,479
all of our email.

635
00:27:00,489 --> 00:27:02,270
Now, all of our communications, all of our,

636
00:27:02,280 --> 00:27:05,699
this freaking podcast is being recorded over http, s like,

637
00:27:05,880 --> 00:27:06,540
it's just,

638
00:27:06,550 --> 00:27:11,560
it's ubiquitous whereas a decade ago it wasn't and there were lots of unencrypted

639
00:27:11,660 --> 00:27:12,339
protocols.

640
00:27:12,369 --> 00:27:13,949
It's funny you mentioned email specifically because

641
00:27:13,959 --> 00:27:15,420
I was actually looking at our logs.

642
00:27:15,520 --> 00:27:19,290
We have a log for how much encrypted and unencrypted email we get and receive

643
00:27:19,300 --> 00:27:22,459
at the CS A and this is encrypted and encrypted at the network level.

644
00:27:22,469 --> 00:27:24,630
-- Right.
-- Right. Like server to server, you're talking, right.

645
00:27:24,640 --> 00:27:25,520
So Google to

646
00:27:25,790 --> 00:27:26,680
whatever else.

647
00:27:26,930 --> 00:27:30,180
-- And it's like, well, over 95%.
-- Oh, really? It's that high.

648
00:27:30,189 --> 00:27:32,920
I wouldn't have expected it to be that high. But that's fantastic.

649
00:27:33,780 --> 00:27:37,369
You can immediately knock out all the major providers like outlook.com,

650
00:27:37,819 --> 00:27:41,489
gmail.com, hotmail.com. Right. They're all, they're all encrypted,

651
00:27:41,939 --> 00:27:43,560
all the real corporate stuff.

652
00:27:43,569 --> 00:27:45,630
Like if you're a corporation with more than 100

653
00:27:45,640 --> 00:27:47,910
people and your email server is not encrypted like

654
00:27:48,150 --> 00:27:49,609
you need new it people.

655
00:27:50,439 --> 00:27:52,359
Like, I'm sorry, there's no nice way to say it.

656
00:27:52,920 --> 00:27:54,239
And as far as I can tell,

657
00:27:54,250 --> 00:27:56,969
we're just kind of dealing with the dribs and drabs of people

658
00:27:56,979 --> 00:27:59,569
who run their own mail servers that haven't set up encryption.

659
00:27:59,599 --> 00:28:00,979
Alright. We're, we're running out of time.

660
00:28:01,250 --> 00:28:05,869
So I, I think I, I love this idea and this is something I'll think about now for a while,

661
00:28:05,880 --> 00:28:06,290
but I,

662
00:28:06,300 --> 00:28:11,000
I think one of our challenges as a security industry is just to start to start

663
00:28:11,010 --> 00:28:13,229
recognizing we have bias to start collecting data

664
00:28:13,239 --> 00:28:14,750
and to start doing something with the data.

665
00:28:14,760 --> 00:28:17,260
And I don't think we're there yet. I think we still make up a lot of crap.

666
00:28:17,270 --> 00:28:18,469
And this is one of my complaints.

667
00:28:18,479 --> 00:28:20,060
It gives me hope that people are starting

668
00:28:20,069 --> 00:28:22,390
to ask questions and people are starting to recognize

669
00:28:22,619 --> 00:28:23,099
that

670
00:28:23,209 --> 00:28:24,150
a lot of what we do

671
00:28:24,880 --> 00:28:27,729
-- isn't necessarily right.
-- Well, and that's the thing.

672
00:28:27,739 --> 00:28:31,369
I, I'm ok with people making up stuff but don't pretend it's correct.

673
00:28:31,489 --> 00:28:34,469
I mean, you know what, I'm ok. II, I think I agree with that.

674
00:28:34,680 --> 00:28:36,640
Like I'm now firmly at the point where I'm making stuff.

675
00:28:36,650 --> 00:28:39,270
Like I literally am building these threat models because I don't have data.

676
00:28:39,280 --> 00:28:40,239
But if I have a threat model,

677
00:28:40,250 --> 00:28:43,880
at least I have something I can poke with a stick and visually show to people

678
00:28:44,079 --> 00:28:47,109
and, and also more importantly not to make sure we're talking about the same thing.

679
00:28:47,390 --> 00:28:49,729
Yeah, I, I think that's a good point too.

680
00:28:49,890 --> 00:28:52,510
The CWE board, we just apparently

681
00:28:52,770 --> 00:28:56,270
rejiggered our definition of vulnerability and weakness that, I mean, that's,

682
00:28:56,280 --> 00:28:57,619
that seems kind of critical for something

683
00:28:57,630 --> 00:28:59,660
that's called the common weakness enumeration.

684
00:29:00,099 --> 00:29:03,770
Wait, the CWE board redefined vulnerability.

685
00:29:03,859 --> 00:29:04,119
Well,

686
00:29:04,130 --> 00:29:05,589
they have a glossary where they define it

687
00:29:05,599 --> 00:29:07,219
and we changed the definition to be actually,

688
00:29:07,229 --> 00:29:08,569
in my opinion a lot better.

689
00:29:08,589 --> 00:29:12,579
-- And does this now line up with other
-- before it specifically mentioned like

690
00:29:12,959 --> 00:29:15,410
that it had like vulnerabilities had to be in software.

691
00:29:15,420 --> 00:29:17,130
And it's like, well, what about services?

692
00:29:17,890 --> 00:29:18,229
OK.

693
00:29:18,239 --> 00:29:19,920
So for example, here's the current definition,

694
00:29:19,930 --> 00:29:21,479
vulnerability in occurrence of a weakness or

695
00:29:21,489 --> 00:29:23,560
multiple weaknesses within a product in which the

696
00:29:23,569 --> 00:29:26,310
weakness can be used by a party to cause the product to modify our access,

697
00:29:26,319 --> 00:29:28,150
unintended data into a proper execution

698
00:29:28,260 --> 00:29:30,239
or perform incorrect actions that were not specifically

699
00:29:30,250 --> 00:29:32,119
granted to the party who uses the weakness.

700
00:29:32,430 --> 00:29:34,300
OK. Well, product, what about services?

701
00:29:34,819 --> 00:29:36,390
The focus there is product,

702
00:29:36,520 --> 00:29:38,689
right? And so there's that problem with it.

703
00:29:38,699 --> 00:29:42,420
But then there's also to modify our access, unintended data, interrupt,

704
00:29:42,430 --> 00:29:44,250
proper execution or performing correct actions

705
00:29:44,369 --> 00:29:47,150
that leaves a whole host of shenanigans unlisted

706
00:29:47,300 --> 00:29:47,699
like,

707
00:29:48,650 --> 00:29:51,479
right? And so it's just, it's a bad definition of the word vulnerability.

708
00:29:51,489 --> 00:29:53,099
I agree, you know, and then we have weakness,

709
00:29:53,109 --> 00:29:55,329
which sort of Venn diagram overlaps a bit with it.

710
00:29:55,339 --> 00:29:55,640
But

711
00:29:55,819 --> 00:29:57,310
again, it talks about a type of

712
00:29:58,255 --> 00:29:59,795
and first of all, a weakness, a mistake.

713
00:29:59,805 --> 00:30:02,515
Well, no, they could be intentional backdoors but ignoring that

714
00:30:02,685 --> 00:30:04,775
improper conditions could contribute to the

715
00:30:04,925 --> 00:30:07,415
improper conditions while they may not be proper,

716
00:30:07,444 --> 00:30:10,045
could contribute to the introduction of vulnerabilities within that product.

717
00:30:10,055 --> 00:30:11,785
Again, product not service.

718
00:30:11,795 --> 00:30:14,334
This term applies to mistakes regardless of whether they occur

719
00:30:14,344 --> 00:30:16,474
in implementation design or other phases of product life cycle.

720
00:30:16,484 --> 00:30:17,665
Again, mistake.

721
00:30:17,675 --> 00:30:21,395
-- No, these things aren't always mistakes like weaknesses back doors.
-- OK?

722
00:30:21,525 --> 00:30:22,635
Now you say that

723
00:30:23,140 --> 00:30:26,910
I remember I, I I'll have to see if it's on a public list or something.

724
00:30:26,920 --> 00:30:29,880
But I remember at one point there was someone asked a question, like,

725
00:30:29,890 --> 00:30:31,640
should backdoors get Cwes?

726
00:30:32,030 --> 00:30:35,890
And Iii, I vaguely recall being like, yes, yes, they should.

727
00:30:36,239 --> 00:30:39,619
And a whole bunch of other people, like, oh, no, those don't get Cwes at all.

728
00:30:39,630 --> 00:30:42,560
Like backdoors aren't weaknesses CV. S you mean?

729
00:30:42,719 --> 00:30:43,380
No, it was,

730
00:30:43,390 --> 00:30:48,400
it was ac we question but I know cbes also don't sign the back doors and this was,

731
00:30:48,410 --> 00:30:49,400
this was all related.

732
00:30:49,410 --> 00:30:50,790
It was part of the miter soup.

733
00:30:50,800 --> 00:30:54,050
And I remember being like, who cares if it's intentional?

734
00:30:54,439 --> 00:30:54,459
I

735
00:30:54,670 --> 00:30:57,920
-- don't want
-- it, do I It's like, can an attacker use this?

736
00:30:57,930 --> 00:31:00,849
And is it actionable data that I can actually make use of? Yes. Yes.

737
00:31:00,859 --> 00:31:02,140
Then give me the damn data.

738
00:31:02,709 --> 00:31:03,290
II

739
00:31:03,410 --> 00:31:05,130
I remember that I was just like

740
00:31:05,380 --> 00:31:07,650
I was shaking my head like I don't even want to be on

741
00:31:07,660 --> 00:31:10,339
this planet anymore after that one because it was like this just,

742
00:31:10,349 --> 00:31:10,829
this is,

743
00:31:11,000 --> 00:31:12,959
this is such a pedantic argument

744
00:31:13,069 --> 00:31:15,849
-- based on a historical bias that like
-- it's

745
00:31:16,130 --> 00:31:16,290
again,

746
00:31:16,459 --> 00:31:18,359
this is one of the reasons I quit the CV board.

747
00:31:18,369 --> 00:31:20,410
It was just, I was tired of sitting in the swamp

748
00:31:22,099 --> 00:31:25,439
-- anyway.
-- All right, we, we should, we should end this one, I guess. Uh

749
00:31:25,650 --> 00:31:26,979
Yeah. III I

750
00:31:27,239 --> 00:31:30,770
love these kind of conversations, man. I think it's fun to talk about data.

751
00:31:30,780 --> 00:31:33,020
I think it's fun to learn new things about data and,

752
00:31:33,430 --> 00:31:34,699
and now I have to think about

753
00:31:35,099 --> 00:31:38,050
what I can do with this list because I have a strong suspicion I

754
00:31:38,060 --> 00:31:40,579
could get a couple of conference talks and blog posts out of this.

755
00:31:40,689 --> 00:31:41,579
You know, I, I just,

756
00:31:41,589 --> 00:31:44,900
what always gets me is when I used to go to RS A is every year was a different flavor.

757
00:31:45,380 --> 00:31:48,500
Like one, like I remember I'm old enough to remember when it went from like

758
00:31:49,140 --> 00:31:52,439
from firewalls and state firewalls to intrusion

759
00:31:52,579 --> 00:31:53,680
detection.

760
00:31:54,390 --> 00:31:55,839
And then the next year was intrusion

761
00:31:55,969 --> 00:31:56,959
prevention.

762
00:31:56,969 --> 00:31:59,359
And I'm like, yeah, because if we can detect this stuff can't, should we be

763
00:32:00,199 --> 00:32:02,550
dunking the connection and like blocking it? Like

764
00:32:02,680 --> 00:32:03,750
that seems self evident.

765
00:32:04,280 --> 00:32:04,589
You know,

766
00:32:04,719 --> 00:32:05,180
that's another

767
00:32:05,369 --> 00:32:08,380
and, and I love this every year. It's like this flavor Du

768
00:32:08,729 --> 00:32:12,010
Jour of Rs A, you know, what was it? Three years ago? It was machine learning.

769
00:32:12,280 --> 00:32:14,630
I don't, how did that pan out for us? I forgot

770
00:32:15,020 --> 00:32:17,569
it's doing great. I mean, every machine learning is awesome.

771
00:32:17,719 --> 00:32:20,160
-- Yeah,
-- I mean, I assume this year is going to be supply chain. Actually.

772
00:32:20,170 --> 00:32:22,550
You know what makes me sad? I was thinking about this this morning

773
00:32:22,709 --> 00:32:25,099
we did an episode on self-driving cars a couple of

774
00:32:25,109 --> 00:32:27,630
years ago and how they're going to revolutionize the world.

775
00:32:27,699 --> 00:32:29,839
And I feel like the self driving car research,

776
00:32:30,310 --> 00:32:34,579
like it's an upside down you where like it was like, it started getting better.

777
00:32:34,589 --> 00:32:37,280
We're like, oh my goodness, it's so close and now we're like, oh, crap.

778
00:32:37,290 --> 00:32:39,599
Like we can't even get this thing to stop running into stuff

779
00:32:39,739 --> 00:32:40,410
like that.

780
00:32:40,420 --> 00:32:40,660
You know,

781
00:32:40,670 --> 00:32:45,040
that recent testing video where the Tesla car just slams over the fake child just,

782
00:32:45,709 --> 00:32:47,540
I didn't even try to stop.

783
00:32:48,089 --> 00:32:51,349
Oh, I know my, my kids sent me that and I was like, uh,

784
00:32:51,739 --> 00:32:52,750
anyway,

785
00:32:53,020 --> 00:32:53,079
yy,

786
00:32:53,810 --> 00:32:56,750
but someday, someday I, I want to,

787
00:32:56,920 --> 00:33:01,430
I, I hope I, I want the day to come when I never drive a car again.

788
00:33:01,439 --> 00:33:03,790
And I don't mean like getting on the train because I love that too.

789
00:33:03,800 --> 00:33:05,630
But I live in America where our trains are terrible.

790
00:33:05,734 --> 00:33:07,875
So my, my hold out now is

791
00:33:08,074 --> 00:33:09,064
self driving cars.

792
00:33:09,364 --> 00:33:12,114
But anyway, anyway, all right, I'm going to call this one. Thank you, Kurt.

793
00:33:12,125 --> 00:33:13,314
Thank you everyone for listening. Go to open

794
00:33:13,415 --> 00:33:13,435
our

795
00:33:13,535 --> 00:33:14,824
security podcast.com. Head up the show,

796
00:33:14,994 --> 00:33:15,214
Not Su

797
00:33:15,324 --> 00:33:15,435
Podos

798
00:33:15,885 --> 00:33:20,114
Podcast. Hashtag Hit us up on social media. Kurt have a marvelous rest of your day.

799
00:33:20,125 --> 00:33:23,094
-- You too. Thanks everybody. Thanks
-- everyone. Bye bye

800
00:33:27,699 --> 00:33:27,760
the