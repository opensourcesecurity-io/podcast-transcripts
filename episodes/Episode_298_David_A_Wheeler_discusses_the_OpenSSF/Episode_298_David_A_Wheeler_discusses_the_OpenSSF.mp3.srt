0
00:00:05,300 --> 00:00:08,439
Hello and welcome to the open source security podcast with myself,

1
00:00:08,449 --> 00:00:10,250
Kurt Siefried and my partner in Thought Crime.

2
00:00:10,260 --> 00:00:10,989
Josh Bresser.

3
00:00:11,180 --> 00:00:14,590
I am ecstatic today. Kurt, we have a guest.

4
00:00:14,600 --> 00:00:19,159
It is a repeat and funny enough, this person, when I publish this episode,

5
00:00:19,170 --> 00:00:21,719
it will be five years to the day

6
00:00:21,920 --> 00:00:23,870
since the last time they were on the show.

7
00:00:23,879 --> 00:00:26,690
So I'm pleased to welcome back, Dr David A Wheeler,

8
00:00:26,760 --> 00:00:29,944
the Director of open source Supply Chain Security at the Linux Foundation.

9
00:00:29,985 --> 00:00:31,495
-- David. Welcome
-- back.

10
00:00:31,715 --> 00:00:34,014
Thank you so very much pleasure to be here.

11
00:00:34,025 --> 00:00:39,055
We are ecstatic to have you, the Linux Foundation with the open SSF has been doing

12
00:00:39,275 --> 00:00:44,895
so much that I thought it is time to bring you back to talk about just the,

13
00:00:44,904 --> 00:00:47,174
the amazing amount of things happening.

14
00:00:47,185 --> 00:00:50,455
So I guess, set the stage for us. What do you, what do you want to talk about?

15
00:00:51,680 --> 00:00:53,939
Well, a whole lot of things, I'm sure.

16
00:00:54,090 --> 00:00:59,580
So I, I guess uh we should start with a quick recap for the last five years,

17
00:01:00,959 --> 00:01:05,339
quick recap uh that we're still having security problems. What a surprise.

18
00:01:05,349 --> 00:01:07,260
I'm shocked. You're shocked.

19
00:01:07,269 --> 00:01:07,660
So,

20
00:01:07,669 --> 00:01:09,940
but I think the good news is that a lot of

21
00:01:09,949 --> 00:01:14,050
people have started to notice that all of society depends on software

22
00:01:14,230 --> 00:01:18,169
and maybe we should start actually making it secure for a change.

23
00:01:18,180 --> 00:01:19,809
That that's a little bit of a, of a,

24
00:01:19,819 --> 00:01:23,309
of a swap because obviously some people have been working on this.

25
00:01:23,319 --> 00:01:23,660
But

26
00:01:24,459 --> 00:01:26,819
nevertheless, there's a lot that needs to be done

27
00:01:27,160 --> 00:01:29,129
so much, much more recently,

28
00:01:29,139 --> 00:01:33,300
the open ssf the Open Source Security Foundation was created.

29
00:01:33,309 --> 00:01:36,440
The challenge was that we were trying within the Linux Foundation,

30
00:01:36,449 --> 00:01:39,190
which is now where I work the Linux Foundation, however,

31
00:01:39,199 --> 00:01:43,629
had a challenge creating a new foundation during the beginning of a pandemic.

32
00:01:43,800 --> 00:01:44,150
Uh

33
00:01:44,720 --> 00:01:48,260
There's no uh there's no script for this.

34
00:01:48,489 --> 00:01:51,830
So they started the foundation but because there are a lot

35
00:01:51,839 --> 00:01:55,363
of work organizations that were not sure what the impacts of the

36
00:01:55,613 --> 00:01:57,143
pandemic were going to be.

37
00:01:57,433 --> 00:01:59,314
I was decided for the first year,

38
00:01:59,323 --> 00:02:02,613
they were going to do it with no member fees or anything like that,

39
00:02:02,804 --> 00:02:05,944
which made it easy to join, but not many resources,

40
00:02:06,543 --> 00:02:09,872
but it was always anticipated, you know what, let's get it started.

41
00:02:09,973 --> 00:02:13,753
And then hopefully in the next year, we'll switch over to a member funded model.

42
00:02:13,764 --> 00:02:16,873
And of course, that happened, maybe they switched over. And

43
00:02:17,048 --> 00:02:17,837
in the meantime,

44
00:02:17,848 --> 00:02:21,908
a whole bunch of other folks noticed how important security was including

45
00:02:21,917 --> 00:02:26,507
the White House cybersecurity executive order put out by the Biden administration

46
00:02:26,807 --> 00:02:28,777
really pressed things forward.

47
00:02:28,787 --> 00:02:31,108
So all of a sudden we've, you know, we,

48
00:02:31,117 --> 00:02:34,277
we started with an open source security foundation and then this,

49
00:02:34,427 --> 00:02:38,027
just recently, there's been an incredible number of folks joining it,

50
00:02:38,037 --> 00:02:39,147
putting in funding.

51
00:02:39,177 --> 00:02:41,908
Frankly, I'm pretty excited to see, uh, what's going to be happening

52
00:02:42,052 --> 00:02:43,472
-- in the next year.
-- Awesome.

53
00:02:43,501 --> 00:02:48,972
That's so exciting and, and actually so fun fact, as we record this just yesterday,

54
00:02:49,251 --> 00:02:52,611
the open SSF voted to what, what, what is that?

55
00:02:52,621 --> 00:02:55,792
I don't know what the exact terminology is, but you basically, like, took sig store

56
00:02:56,011 --> 00:02:56,832
into

57
00:02:57,072 --> 00:03:00,992
the, I guess, into the tent with, with the project. Right.

58
00:03:01,292 --> 00:03:01,962
Right. Right.

59
00:03:01,972 --> 00:03:06,011
Uh Basically the, you know, what a little bit of insult side baseball is,

60
00:03:06,022 --> 00:03:06,811
is kind of helpless

61
00:03:06,936 --> 00:03:08,675
really inside this is all public.

62
00:03:08,686 --> 00:03:11,035
But basically the way the open SSF works

63
00:03:11,046 --> 00:03:14,656
is actually like most Linux Foundation uh foundations,

64
00:03:14,666 --> 00:03:19,195
there's a governing board that oversees, you know, basically decides things like,

65
00:03:19,205 --> 00:03:22,305
like where the money goes and then for the technical decisions,

66
00:03:22,315 --> 00:03:23,235
there's a group called the T

67
00:03:23,535 --> 00:03:27,436
A, the uh technical Advisory Council, I believe. So that's, that stands for.

68
00:03:27,445 --> 00:03:28,845
But when you say t

69
00:03:29,026 --> 00:03:31,755
over and over again, you forget what the abbreviation is. That's right.

70
00:03:32,020 --> 00:03:34,639
But anyway, so the T A voted to bring in

71
00:03:34,880 --> 00:03:36,029
s store and the s

72
00:03:36,240 --> 00:03:38,809
store folks had already uh proposed this. So it's a,

73
00:03:38,990 --> 00:03:40,259
you know, whenever there's a,

74
00:03:40,270 --> 00:03:44,419
there's a ma moving of somebody in both sides have to agree,

75
00:03:44,429 --> 00:03:48,199
but I think this is going to be great long term, it's going to be a lot easier.

76
00:03:48,210 --> 00:03:48,399
Uh S

77
00:03:48,559 --> 00:03:51,080
Store already has some commitments of funding.

78
00:03:51,089 --> 00:03:53,279
I think it'll be a lot easier to raise money.

79
00:03:53,365 --> 00:03:58,145
And there's one organization that people can send money to and they can designate,

80
00:03:58,156 --> 00:04:01,425
hey, some of this funding should go to this specific project if they want to.

81
00:04:01,436 --> 00:04:03,845
But, you know, that doesn't mean that money solves all problems,

82
00:04:03,856 --> 00:04:05,856
but there's a lot of problems that money can help with.

83
00:04:05,955 --> 00:04:08,485
And so it's very, very nice to have some resources.

84
00:04:08,496 --> 00:04:10,505
You know, I just realized I didn't explain what

85
00:04:10,626 --> 00:04:12,305
s Store was. Maybe we should do that.

86
00:04:13,235 --> 00:04:14,225
That's a good idea.

87
00:04:14,712 --> 00:04:14,932
Right.

88
00:04:14,942 --> 00:04:15,511
So, yeah,

89
00:04:15,522 --> 00:04:22,242
so Six Store is a new approach to enabling cryptographic signing and verification.

90
00:04:22,252 --> 00:04:26,951
We've had the technology to do crypto signing for decades.

91
00:04:27,342 --> 00:04:28,971
And in fact, you know, the,

92
00:04:28,981 --> 00:04:33,601
the tools to do signing are a little bit of a pain to use a little, you know what?

93
00:04:33,611 --> 00:04:35,971
That's, I will argue that that's not the main problem.

94
00:04:36,260 --> 00:04:38,119
The problem is, yeah, you're right.

95
00:04:38,130 --> 00:04:40,320
It's, they're not as easy to use, but it doesn't matter

96
00:04:40,450 --> 00:04:44,850
because verifying is, is uh too hard for most people. So no one does it.

97
00:04:44,940 --> 00:04:46,109
And it mean if you don't,

98
00:04:46,279 --> 00:04:48,809
no one verifies signatures, there's no point to it.

99
00:04:48,989 --> 00:04:52,910
Now, there are, you know, specific cases where people do verify,

100
00:04:53,170 --> 00:04:55,820
but we want that to be used all over.

101
00:04:55,829 --> 00:04:58,209
So SIG Store is a very different way

102
00:04:58,220 --> 00:05:01,869
to tackle the cryptographic signing any more importantly,

103
00:05:01,880 --> 00:05:02,880
verification.

104
00:05:02,950 --> 00:05:05,510
You know, people say, hey, does this solve all security problems?

105
00:05:05,519 --> 00:05:05,950
No,

106
00:05:05,959 --> 00:05:08,630
there's no server brought no single thing that people

107
00:05:08,640 --> 00:05:11,049
do is going to solve all security problems.

108
00:05:11,230 --> 00:05:14,309
But if we can get things signed and then verified,

109
00:05:14,559 --> 00:05:18,980
then at least we know where the software comes from now. Is that

110
00:05:19,209 --> 00:05:21,019
ok? Software to install?

111
00:05:21,029 --> 00:05:25,459
Well, maybe, maybe not, but at least I can answer that first question

112
00:05:25,690 --> 00:05:27,070
so that when we're analyzing it,

113
00:05:27,079 --> 00:05:29,350
we know we're talking about the same thing and

114
00:05:29,359 --> 00:05:31,910
then we can do other things to make sure that

115
00:05:32,070 --> 00:05:34,970
that software and which we agree was signed

116
00:05:35,170 --> 00:05:38,149
was in fact, OK to, to bring in.

117
00:05:38,279 --> 00:05:40,950
So we're, we're, we're gonna need multiple things,

118
00:05:40,959 --> 00:05:43,279
not just cryptographic signing but

119
00:05:43,390 --> 00:05:46,970
-- cryptographic signing will help.
-- Well, I, I think, yeah, because uh cryptographic

120
00:05:47,079 --> 00:05:49,529
to me boils down to at least you know

121
00:05:49,839 --> 00:05:53,899
what you're getting. It's not some random, literally pile of bits.

122
00:05:54,109 --> 00:05:57,739
But the one thing I keep coming back to uh ignoring signatures are hard and,

123
00:05:57,750 --> 00:05:59,230
and verification is tricky.

124
00:05:59,410 --> 00:06:01,730
How do you combat this whole mindset of?

125
00:06:01,739 --> 00:06:05,059
Oh, the signature failed, whatever, smash that install button anyway,

126
00:06:05,070 --> 00:06:06,820
like the solar winds situation, right?

127
00:06:06,829 --> 00:06:07,709
Where literally

128
00:06:07,839 --> 00:06:08,390
for months

129
00:06:08,859 --> 00:06:11,470
they had people going, hey, these signatures don't check out what's wrong.

130
00:06:11,480 --> 00:06:12,440
And they're like, yeah, it's fine.

131
00:06:12,450 --> 00:06:14,690
Just, just really push harder, you know,

132
00:06:14,700 --> 00:06:17,940
smash that pig in that hole because I keep coming back to

133
00:06:17,950 --> 00:06:20,769
the fact that like the whole point of these signatures is that

134
00:06:20,980 --> 00:06:22,359
when they do fail,

135
00:06:22,589 --> 00:06:25,019
you have, oh, we, we need to investigate this, like,

136
00:06:25,029 --> 00:06:29,109
either some internal process went really wrong or we were attacked.

137
00:06:29,290 --> 00:06:29,730
Right.

138
00:06:30,010 --> 00:06:33,630
And, uh, how do you kind of overcome this mindset of? Oh, the signatures failed?

139
00:06:33,829 --> 00:06:37,390
-- That's annoying. Not even that, that's like a problem. It's just, that's
-- annoying.

140
00:06:37,399 --> 00:06:40,190
There's a stick. I sometimes like to use that.

141
00:06:40,200 --> 00:06:42,410
Uh, I, I find hilarious because there's truth in it.

142
00:06:42,420 --> 00:06:45,950
It's the, you know, security is hard but with a little effort we can get rid of it.

143
00:06:47,570 --> 00:06:47,630
Yeah.

144
00:06:48,899 --> 00:06:51,940
This actually, I would like to subscribe to your newsletter about this topic.

145
00:06:53,799 --> 00:06:57,470
The thing is, I think there's an answer uh, to that.

146
00:06:57,480 --> 00:07:01,350
I'm not sure it's not a simple answer, but I think it's the right answer

147
00:07:01,559 --> 00:07:07,070
and that is we need to make these things so reliable and so easy to use

148
00:07:07,200 --> 00:07:11,750
that people won't want to reach for that, that hammer that says, ignore it anyway.

149
00:07:11,809 --> 00:07:12,670
If you are.

150
00:07:12,679 --> 00:07:15,325
I think today right now and, and frankly,

151
00:07:15,334 --> 00:07:18,084
some interpretations of like the cookie laws uh,

152
00:07:18,095 --> 00:07:21,364
in Europe are really causing security problems, you know,

153
00:07:21,375 --> 00:07:24,125
we're training users to say, yeah, whatever.

154
00:07:24,135 --> 00:07:25,575
Yeah, whatever. Yeah. Whatever.

155
00:07:25,684 --> 00:07:26,045
OK.

156
00:07:26,054 --> 00:07:26,834
If, if,

157
00:07:26,845 --> 00:07:29,984
if they've never seen an error message before like that

158
00:07:29,994 --> 00:07:32,244
and they don't see anything like that for say,

159
00:07:32,255 --> 00:07:33,845
six months or a year,

160
00:07:34,290 --> 00:07:36,029
that's gonna give him a lot more pause than,

161
00:07:36,170 --> 00:07:39,989
yeah, this is the 3/100 time I've said. Yeah, sure. Whatever today.

162
00:07:40,000 --> 00:07:45,589
So I think we basically have to move to a case where it's reliable. It works.

163
00:07:45,600 --> 00:07:46,579
It's easy.

164
00:07:46,600 --> 00:07:51,790
And man, when those things happen, it's so weird and strange that it gives even,

165
00:07:52,135 --> 00:07:55,674
you know, people who aren't experts pause because it's strange.

166
00:07:55,684 --> 00:07:58,355
I realize that we're not in that world fully today.

167
00:07:58,364 --> 00:08:04,054
But that's the, I think that's the only real answer is it's got to be so easy, so much,

168
00:08:04,065 --> 00:08:06,595
the default that people aren't tempted to.

169
00:08:06,614 --> 00:08:09,864
And I do think actually there are cases where you really do have to, you know,

170
00:08:10,179 --> 00:08:13,779
you know, uh sort of they break you, you know, use hammer, break glass.

171
00:08:13,839 --> 00:08:15,179
There are sometimes where

172
00:08:15,290 --> 00:08:16,600
you do need to do that

173
00:08:16,709 --> 00:08:17,700
but you should,

174
00:08:17,859 --> 00:08:20,609
you should be aware and, and you know,

175
00:08:20,619 --> 00:08:23,920
and probably call in somebody who's an expert before you do that.

176
00:08:23,929 --> 00:08:25,959
And we, we, we need to get to that world.

177
00:08:26,029 --> 00:08:29,279
I'm gonna cut us off because this is not a podcast about

178
00:08:29,619 --> 00:08:30,019
SAR,

179
00:08:30,209 --> 00:08:33,280
but this is, this is a hugely interesting topic for sure.

180
00:08:33,609 --> 00:08:35,587
So I want to steer us back

181
00:08:35,799 --> 00:08:40,499
into the open SSF David, you kind of gave us an overview.

182
00:08:40,638 --> 00:08:41,217
But

183
00:08:41,438 --> 00:08:43,908
I think the real star of the show here are the,

184
00:08:43,919 --> 00:08:47,299
the technical working groups that are part of the open SSF

185
00:08:47,309 --> 00:08:51,388
and there are six technical working groups that I'm aware of.

186
00:08:51,398 --> 00:08:51,968
So

187
00:08:52,258 --> 00:08:57,028
I will not test you to ask you if you can name them all I can name them all. You can.

188
00:08:57,268 --> 00:08:58,028
All right. All right.

189
00:08:58,195 --> 00:09:01,695
All right. You name them. I'm looking at the list. Let's, it's quiz time.

190
00:09:01,705 --> 00:09:02,445
Let's see how Dr

191
00:09:02,585 --> 00:09:03,905
David A Wheeler does.

192
00:09:04,104 --> 00:09:07,434
All right, best practices, vulnerability and disclosures,

193
00:09:07,445 --> 00:09:11,924
identifying security threats, securing critical projects, security tooling

194
00:09:12,054 --> 00:09:15,594
and the recently renamed Supply chain integrity,

195
00:09:15,604 --> 00:09:18,945
which used to be named the digital identity at a station where

196
00:09:19,145 --> 00:09:21,655
I was, I was hoping to catch you on that one.

197
00:09:25,359 --> 00:09:29,059
Yes. Yes, absolutely. So I guess uh we, we'll go by the list.

198
00:09:29,070 --> 00:09:31,919
I'm looking at on the website and let's just start at the top and go down.

199
00:09:31,929 --> 00:09:34,700
So identifying security threats, explain that one to us.

200
00:09:35,210 --> 00:09:38,590
That is probably the, the quirkiest named group.

201
00:09:38,599 --> 00:09:42,950
The idea there is to try to give metrics and measures for

202
00:09:42,960 --> 00:09:47,729
open source software projects to help people decide whether or not to,

203
00:09:47,739 --> 00:09:50,419
you know, bring them on and, and that sort of thing.

204
00:09:50,429 --> 00:09:53,460
And by the way, all these working groups have particular areas,

205
00:09:53,469 --> 00:09:57,075
sometimes specific projects could easily fit multiple groups.

206
00:09:57,085 --> 00:10:01,375
And right now, the goal has been, we're not going to worry so much as long as you know,

207
00:10:01,385 --> 00:10:05,416
there's a home for them and they get moving the security metrics.

208
00:10:05,426 --> 00:10:07,895
Folks have been worried about things like we

209
00:10:07,906 --> 00:10:11,765
want to capture all at least link to every

210
00:10:11,776 --> 00:10:15,926
security evaluation by some third party of open

211
00:10:15,935 --> 00:10:17,895
source software so that you can find it.

212
00:10:17,906 --> 00:10:20,656
You may not agree with their results, you may think,

213
00:10:20,666 --> 00:10:22,755
but at least we can easily find them.

214
00:10:22,875 --> 00:10:26,382
Another one has been trying to create a dashboard so that

215
00:10:26,392 --> 00:10:30,411
you could get some metrics to learn more about specific projects.

216
00:10:30,421 --> 00:10:34,731
Bring in data from things like criticality score and C I best practices

217
00:10:34,742 --> 00:10:38,351
and lots of other things to try to kind of capture the information.

218
00:10:38,361 --> 00:10:43,572
There's a kind of an early draft of an early version of that that exists now.

219
00:10:43,581 --> 00:10:44,122
But right now,

220
00:10:44,132 --> 00:10:47,432
we're trying to figure out how to integrate that with other tooling that exists.

221
00:10:47,442 --> 00:10:50,492
So I, I suspect that there's going to be changes as we go along.

222
00:10:50,502 --> 00:10:53,452
But the goal there is to try to eventually get to the point where

223
00:10:54,028 --> 00:10:57,867
it will be easy to get information about. I'm thinking about using this project.

224
00:10:57,877 --> 00:10:59,177
-- What can you tell me?
-- Yeah, absolutely.

225
00:10:59,187 --> 00:11:03,447
And in fact, we just did a podcast a couple of weeks ago about the, the scorecards

226
00:11:03,588 --> 00:11:06,567
-- for open SS
-- F, right? And they're one of the inputs to this.

227
00:11:06,578 --> 00:11:09,888
So scorecards calculates a lot of stuff and then the

228
00:11:09,898 --> 00:11:12,778
dashboard basically makes it easy to display that information.

229
00:11:12,838 --> 00:11:15,677
That's right. That's right. Awesome. OK. All right. We'll keep going.

230
00:11:15,687 --> 00:11:16,768
Uh Security tooling,

231
00:11:17,038 --> 00:11:19,377
-- security
-- tooling. This is, has

232
00:11:19,507 --> 00:11:22,817
this group has actually kind of had the most challenge. What way

233
00:11:22,943 --> 00:11:24,804
has been one of the more challenged ones?

234
00:11:24,814 --> 00:11:26,164
Uh They've got some things,

235
00:11:26,174 --> 00:11:27,994
probably the more interesting one is something

236
00:11:28,004 --> 00:11:30,713
called the CV E benchmark where basically

237
00:11:30,833 --> 00:11:33,374
they're trying to measure how good tools are

238
00:11:33,383 --> 00:11:36,104
by having a bunch of basically test cases

239
00:11:36,333 --> 00:11:40,203
to figure out well, which tools find them, which ones don't,

240
00:11:40,213 --> 00:11:42,403
in all honesty for the past year,

241
00:11:42,414 --> 00:11:45,943
it's been kind of a rolling conference of tool makers

242
00:11:45,953 --> 00:11:48,674
as they just try to figure out some things.

243
00:11:48,684 --> 00:11:51,713
I think that they're the most recent working

244
00:11:51,723 --> 00:11:54,119
group meeting now that there's some funding available,

245
00:11:54,130 --> 00:11:57,679
they're talking about becoming more aggressive income things they do,

246
00:11:57,960 --> 00:12:01,130
but I don't know yet for certain what that's going to look like.

247
00:12:01,539 --> 00:12:04,260
Totally. All right, best practices.

248
00:12:04,450 --> 00:12:05,309
Ok.

249
00:12:05,320 --> 00:12:08,030
This one's super busy because as you can imagine,

250
00:12:08,039 --> 00:12:09,880
best practice is pretty important and there's a

251
00:12:09,890 --> 00:12:11,739
whole lot of activity going on there.

252
00:12:11,750 --> 00:12:15,239
So let me just list off a couple there, the CIA Best Practices badge,

253
00:12:15,250 --> 00:12:18,260
that's actually a project that I lead probably eventually that's going

254
00:12:18,270 --> 00:12:21,359
to get renamed because technically the ci I doesn't exist anymore.

255
00:12:21,369 --> 00:12:21,640
But

256
00:12:21,890 --> 00:12:25,450
that's its name for now. That's basically a set of criteria.

257
00:12:25,460 --> 00:12:27,830
What should open source software projects do

258
00:12:28,020 --> 00:12:30,989
focusing on, you know, how can they develop secure software,

259
00:12:31,000 --> 00:12:36,570
but it also bleeds into quality and sustainment because low quality software

260
00:12:36,580 --> 00:12:41,109
and software that's not getting sustained probably isn't gonna be secure either.

261
00:12:41,119 --> 00:12:41,669
Right?

262
00:12:41,679 --> 00:12:43,799
So, and I always encourage people, hey,

263
00:12:43,809 --> 00:12:47,020
if you're running an open source software project, please, please try to earn,

264
00:12:47,030 --> 00:12:47,650
earn yourself of

265
00:12:47,780 --> 00:12:49,599
that CIA best practices. Batch.

266
00:12:49,609 --> 00:12:53,789
We've got, I looked at the numbers recently, but we've got over 4000 projects

267
00:12:54,059 --> 00:12:54,880
involved. Yeah.

268
00:12:54,890 --> 00:12:56,830
And it's, we, we actually, what's,

269
00:12:56,840 --> 00:12:59,880
what's cool is that the website automatically generates graphs?

270
00:12:59,940 --> 00:13:02,849
And it's been almost a linear growth.

271
00:13:02,859 --> 00:13:05,650
I don't understand why that's a linear growth, but

272
00:13:05,929 --> 00:13:06,849
that's OK.

273
00:13:06,859 --> 00:13:11,880
We just continually get new people joining and that's great best practices. Badge.

274
00:13:11,969 --> 00:13:14,320
The goal was for that one was one of the

275
00:13:14,330 --> 00:13:17,510
most important questions whether or not they can be automated

276
00:13:17,780 --> 00:13:20,289
and we do automate some

277
00:13:20,390 --> 00:13:20,960
and in fact,

278
00:13:20,969 --> 00:13:25,640
we'll override things that uh that humans claim if we can show that they're not,

279
00:13:25,650 --> 00:13:27,460
they're almost certainly not true.

280
00:13:27,719 --> 00:13:30,440
So, so yeah, there are people who, who, you know,

281
00:13:30,520 --> 00:13:32,669
there are other ways we try to counter that.

282
00:13:32,679 --> 00:13:36,710
But one of them is, is automation. But some questions are hard to answer

283
00:13:36,849 --> 00:13:38,909
or hard to verify through automation.

284
00:13:39,250 --> 00:13:43,830
But sometimes you just like to be able to get some information about an open a project

285
00:13:44,000 --> 00:13:48,309
with full automation. And so scorecards takes that in the other direction.

286
00:13:48,320 --> 00:13:52,309
What can you figure out about a project purely through automation?

287
00:13:52,320 --> 00:13:54,190
And so scorecards tries to do that.

288
00:13:54,330 --> 00:13:57,409
There's a new project that is just getting started.

289
00:13:57,419 --> 00:13:58,989
We're still very much in the planning stage.

290
00:13:59,000 --> 00:14:01,809
But I think this is gonna be interesting and just have a funny name.

291
00:14:01,820 --> 00:14:04,270
It's the great M fa distribution project.

292
00:14:04,450 --> 00:14:04,460
Oh,

293
00:14:04,590 --> 00:14:05,729
yes, this is awesome.

294
00:14:05,840 --> 00:14:06,080
Yeah.

295
00:14:06,090 --> 00:14:07,320
So um first of all,

296
00:14:07,330 --> 00:14:11,245
I do want to give a quick shout out to both Google and github who

297
00:14:11,255 --> 00:14:15,955
have basically offered up to the open SS fa whole bunch of M fa tokens,

298
00:14:15,966 --> 00:14:19,495
uh two fa tokens, you know, the hardware, hardware-based tokens prove who you are.

299
00:14:19,776 --> 00:14:22,145
And the idea is we're going to try to work

300
00:14:22,486 --> 00:14:24,856
or try, we're going to identify some open

301
00:14:24,986 --> 00:14:25,135
source.

302
00:14:25,245 --> 00:14:26,895
So developers of critical projects

303
00:14:26,995 --> 00:14:30,716
offer them free tokens. And I think even more importantly,

304
00:14:31,216 --> 00:14:35,796
point them to very pointed simple tutorials on

305
00:14:35,806 --> 00:14:39,091
how to do typical open source software tasks.

306
00:14:39,101 --> 00:14:40,021
I mean, not just, you know,

307
00:14:40,052 --> 00:14:43,161
you need to do whatever it is to get your your token working,

308
00:14:43,302 --> 00:14:45,581
but then how do you log on to github

309
00:14:45,831 --> 00:14:46,111
or get,

310
00:14:46,721 --> 00:14:49,742
you know, how do you post to PI P I or

311
00:14:49,872 --> 00:14:52,221
to N PM your your packages?

312
00:14:52,231 --> 00:14:56,702
So there's a number of open source packages where the developers are fine

313
00:14:56,872 --> 00:14:59,521
but their passwords got stolen and suddenly

314
00:14:59,531 --> 00:15:03,302
there's uh some malicious bit mining going on

315
00:15:03,481 --> 00:15:06,572
or some other, you know, some other nastiness going on.

316
00:15:06,809 --> 00:15:10,080
Yeah, I mean, the, the last handful of N PM

317
00:15:10,359 --> 00:15:12,109
attacks were literally that

318
00:15:12,210 --> 00:15:16,349
where it was reused credentials and, and I actually just read yesterday as well that

319
00:15:16,590 --> 00:15:19,669
the N PM folks are going to require

320
00:15:19,890 --> 00:15:24,239
multi factor off for, they're going to start with a subset

321
00:15:24,359 --> 00:15:25,650
of N PM packages.

322
00:15:25,659 --> 00:15:28,929
And then obviously, I think the intention is to expand it to all N PM packages,

323
00:15:28,940 --> 00:15:29,869
which is pretty awesome.

324
00:15:30,219 --> 00:15:30,440
Yeah.

325
00:15:30,450 --> 00:15:33,880
Now we're not gonna be able to provide free tokens to everybody,

326
00:15:33,909 --> 00:15:39,479
but we can at least we can at least try to make a very simple docks

327
00:15:39,489 --> 00:15:41,809
for everybody for at least a couple of

328
00:15:41,820 --> 00:15:43,919
common tokens and a couple of common situations.

329
00:15:44,280 --> 00:15:44,869
And

330
00:15:45,059 --> 00:15:50,010
I do think that getting them into people's hands, um, is, is going to help me.

331
00:15:50,059 --> 00:15:53,510
They're not a lot of money, but here I've got it right here.

332
00:15:53,520 --> 00:15:56,440
There, there's something that helps when you have it in hand versus.

333
00:15:56,489 --> 00:15:58,309
Yeah, maybe I should do it someday

334
00:15:59,710 --> 00:16:02,565
now. II I, I think I've talked about it

335
00:16:02,755 --> 00:16:06,375
but you won't easily. If you go hunting, you can find out about it.

336
00:16:06,385 --> 00:16:10,344
But we haven't done anything act in terms of actually sending out tokens yet.

337
00:16:10,505 --> 00:16:13,765
We're working out some details because it's really,

338
00:16:13,775 --> 00:16:17,455
really important that this not become the world's best supply chain attack.

339
00:16:18,405 --> 00:16:18,864
Yeah,

340
00:16:20,169 --> 00:16:24,489
this is something that has, this is something that's been talked about briefly,

341
00:16:24,640 --> 00:16:28,650
but this is one of those things we kind of need to get right the first time.

342
00:16:28,659 --> 00:16:29,859
So, you know, so,

343
00:16:30,789 --> 00:16:32,130
so we're, you know,

344
00:16:32,380 --> 00:16:35,760
we, we are, we do much, we, we are very much going to do this,

345
00:16:35,770 --> 00:16:39,770
but we do want to make sure that we do it in a way that doesn't make things worse.

346
00:16:41,190 --> 00:16:44,859
There's some collaboration with oas particularly on the common requirements,

347
00:16:44,869 --> 00:16:49,200
enumeration and their educational system on the security knowledge framework.

348
00:16:49,369 --> 00:16:52,030
And Oh, yeah. And finally, um

349
00:16:52,270 --> 00:16:52,280
I

350
00:16:52,409 --> 00:16:55,190
probably should have mentioned this first on the best practices, badge,

351
00:16:55,200 --> 00:16:59,739
best practices, working group includes a set of three courses on Ed X that are,

352
00:17:00,049 --> 00:17:02,450
that are free called the Secure Software Development

353
00:17:02,700 --> 00:17:05,608
fundamentals courses. I'm really excited about that.

354
00:17:05,618 --> 00:17:07,959
We've had over 5000 registrants.

355
00:17:07,969 --> 00:17:13,368
Now, I don't understand why we think that our software is going to be secure

356
00:17:13,489 --> 00:17:18,329
when we don't teach the developers how to write secure software. Um

357
00:17:18,459 --> 00:17:18,540
I,

358
00:17:18,729 --> 00:17:24,069
I went to, I, I just came back from the LF uh member summit. My Uber drive

359
00:17:24,788 --> 00:17:30,418
to the summit was a senior in computer Science at Purdue.

360
00:17:30,588 --> 00:17:31,938
I thought that was amazing.

361
00:17:31,948 --> 00:17:33,338
So I asked him, well,

362
00:17:33,348 --> 00:17:35,678
how much have they taught you about how to write secure software?

363
00:17:35,688 --> 00:17:37,619
And the answer is nothing.

364
00:17:37,838 --> 00:17:39,178
Absolutely nothing.

365
00:17:39,188 --> 00:17:43,009
I mean, that's extra shocking as well because like Gene Stafford is at Purdue.

366
00:17:43,019 --> 00:17:45,698
I mean, he's like the grandfather of computer security.

367
00:17:46,089 --> 00:17:48,609
Yeah, they, they've got expertise there,

368
00:17:48,619 --> 00:17:52,709
but that doesn't mean it trickles to the people coming through the school

369
00:17:52,880 --> 00:17:58,180
and of course not everybody who develops software goes to college or universities

370
00:17:58,599 --> 00:18:01,199
or even if they do, they don't necessarily

371
00:18:01,400 --> 00:18:03,469
get a computing related major. So

372
00:18:03,839 --> 00:18:05,390
we've got, we've, we've

373
00:18:05,969 --> 00:18:08,910
um in the long term, we've, we're going to have to change this.

374
00:18:08,920 --> 00:18:13,630
We need to make it so that everyone who writes software knows the basics about how to

375
00:18:13,734 --> 00:18:19,454
help secure software. So this is a free course costs you $0 to learn.

376
00:18:19,464 --> 00:18:22,574
If you want to get a certificate, Edex will, will want to charge you some money.

377
00:18:22,584 --> 00:18:25,734
And that, that's how they make their money, but you don't have to get a cert

378
00:18:25,905 --> 00:18:28,915
to learn the material. And we also post the material on github.

379
00:18:29,084 --> 00:18:33,035
If you want to snag it and use it for other things. It's under a creative commons

380
00:18:33,255 --> 00:18:35,104
attribution license. So

381
00:18:35,265 --> 00:18:35,834
you can,

382
00:18:36,084 --> 00:18:36,295
you know,

383
00:18:36,305 --> 00:18:40,035
if you want to grab some of that material and stick it in a course in your university,

384
00:18:40,045 --> 00:18:41,314
please.

385
00:18:41,880 --> 00:18:44,280
Well, I think, I think one of the challenges.

386
00:18:44,290 --> 00:18:46,119
So from what I've seen and this was actually just

387
00:18:46,130 --> 00:18:48,310
driven home yesterday on a security call with a,

388
00:18:48,329 --> 00:18:48,339
a

389
00:18:48,479 --> 00:18:49,520
security board

390
00:18:49,750 --> 00:18:52,739
that the security people view software engineering

391
00:18:52,910 --> 00:18:55,930
and secure development as totally separate things. And then

392
00:18:56,380 --> 00:19:00,050
sort of like some, I, I don't know, but from the software development point of view,

393
00:19:00,060 --> 00:19:02,810
the one thing I keep coming back to is every developer.

394
00:19:03,290 --> 00:19:04,859
Basically, it boils down to do.

395
00:19:04,869 --> 00:19:07,770
I want to spend time learning how to add value or do I want to spend time

396
00:19:08,199 --> 00:19:09,550
doing security? And

397
00:19:09,670 --> 00:19:10,310
they,

398
00:19:10,630 --> 00:19:13,319
there's not that immediate payoff with security like there is

399
00:19:13,329 --> 00:19:15,270
with adding a feature and making your boss happy.

400
00:19:15,280 --> 00:19:16,589
I think it's part of the challenge like

401
00:19:16,719 --> 00:19:19,229
uh and this was in a previous podcast where I think just a lot of people

402
00:19:19,239 --> 00:19:23,000
don't understand the value of security and kind of that it actually does have value,

403
00:19:23,010 --> 00:19:23,189
right?

404
00:19:23,199 --> 00:19:23,969
Because there's no,

405
00:19:24,160 --> 00:19:26,099
you don't get that immediate payoff of, oh, look,

406
00:19:26,109 --> 00:19:28,260
now the product has spell check and more people will buy it.

407
00:19:28,790 --> 00:19:29,180
Right.

408
00:19:29,630 --> 00:19:31,410
But, but I, but I think, um a

409
00:19:31,739 --> 00:19:36,479
lot of this is one of those, you know, you invest, you invest in learning and you,

410
00:19:36,489 --> 00:19:39,479
they pay dividends from then on a whole lot of the stuff that

411
00:19:39,589 --> 00:19:41,709
involved with developing secure software.

412
00:19:41,949 --> 00:19:44,800
You know, I, I reject the notion that it's always more money.

413
00:19:44,810 --> 00:19:46,359
In fact, you know, what costs you,

414
00:19:46,369 --> 00:19:49,469
more money is trying to retrofit stuff after the fact.

415
00:19:49,479 --> 00:19:53,469
Sequel Injections. For example, if you know how to use prepared statements,

416
00:19:53,640 --> 00:19:58,239
uh, once you learn how they're easier to use, they're faster, they work better.

417
00:19:58,250 --> 00:20:01,640
And, oh, by the way, they're secure as opposed to the nonsense you're doing.

418
00:20:02,729 --> 00:20:07,209
I mean, it's the old saying though David of there's never enough money to do it.

419
00:20:07,219 --> 00:20:10,660
-- Right. But there's always money to do it twice.
-- It's cheaper,

420
00:20:11,359 --> 00:20:13,579
it's cheaper to do the prepared statements.

421
00:20:13,770 --> 00:20:14,729
No, II, I agree

422
00:20:14,839 --> 00:20:14,869
with

423
00:20:14,979 --> 00:20:17,000
you. I agree completely. Absolutely.

424
00:20:17,140 --> 00:20:21,890
-- Yeah.
-- So the, the problem isn't that, gee, it's more costly in development.

425
00:20:21,900 --> 00:20:24,079
The problem is we need to get people to learn it.

426
00:20:24,439 --> 00:20:29,869
And now II, I do have a degree in computer science and information tech,

427
00:20:29,910 --> 00:20:32,319
but I also have a degree in electronics engineering.

428
00:20:32,510 --> 00:20:35,250
It's very interesting for me to compare

429
00:20:35,430 --> 00:20:41,339
my classes for engineering versus the classes for computer science.

430
00:20:41,650 --> 00:20:44,589
I think it's a shame that they're that distinct because

431
00:20:44,739 --> 00:20:48,160
I believe that if you're developing, you know, what is engineering

432
00:20:48,270 --> 00:20:50,760
engineering is solving human problems using

433
00:20:50,770 --> 00:20:52,989
the resources and knowledge available.

434
00:20:53,000 --> 00:20:55,910
And if you're writing software, you're doing engineering,

435
00:20:55,920 --> 00:20:58,750
but we don't treat it like that way so many times.

436
00:20:59,180 --> 00:20:59,790
And

437
00:20:59,930 --> 00:21:01,829
so we, you know, if, if you're,

438
00:21:01,839 --> 00:21:04,459
if before you're allowed to graduate from engineering,

439
00:21:04,469 --> 00:21:09,250
you need to learn about not just how to build dams or make circuits,

440
00:21:09,410 --> 00:21:11,489
you also have to learn about economics

441
00:21:11,680 --> 00:21:16,829
and safety and lots of other things and we should have that same expectation.

442
00:21:16,839 --> 00:21:19,949
You know, what do you, you know, you're gonna learn about software but we're not,

443
00:21:19,959 --> 00:21:22,949
we're not gonna talk about economics, really.

444
00:21:22,989 --> 00:21:26,949
We're not gonna talk about ethics or safety or security.

445
00:21:27,280 --> 00:21:27,949
Really.

446
00:21:28,349 --> 00:21:32,229
You, you don't think that the software will affect society. Of course, it does.

447
00:21:32,239 --> 00:21:32,810
You know, we,

448
00:21:32,819 --> 00:21:37,329
we have to get that in those broader context because

449
00:21:37,339 --> 00:21:41,199
we're building things that impact society just like dams,

450
00:21:41,209 --> 00:21:43,449
just like uh lots of other things.

451
00:21:43,680 --> 00:21:46,650
Absolutely. No, I, I agree 100%. All right. All right.

452
00:21:46,660 --> 00:21:47,770
I want, I want to keep this moving.

453
00:21:47,910 --> 00:21:48,560
OK. Sorry.

454
00:21:48,910 --> 00:21:52,530
No, no, this is, this is why I love you, man. This, this is so much fun.

455
00:21:52,540 --> 00:21:55,255
Uh Next up, we got vulnerability disclosures.

456
00:21:55,426 --> 00:21:56,095
All right.

457
00:21:56,105 --> 00:21:59,135
So the big thing that they've done is they have

458
00:21:59,145 --> 00:22:03,965
released this thing called guide to coordinate vulnerability disclosure for open

459
00:22:04,086 --> 00:22:05,135
source software projects.

460
00:22:05,225 --> 00:22:10,586
And so basically, it's the little, you know, hey, before you get a vulnerability,

461
00:22:10,776 --> 00:22:11,546
uh why

462
00:22:11,666 --> 00:22:11,965
you,

463
00:22:11,975 --> 00:22:13,956
what you should do a little prep work ahead of

464
00:22:13,965 --> 00:22:16,965
times because especially if you're building a larger project,

465
00:22:16,975 --> 00:22:19,182
you're gonna get a vulnerability report sooner or later

466
00:22:19,411 --> 00:22:22,462
and the wrong time to figure out how to handle that

467
00:22:22,702 --> 00:22:24,991
is when you get a vulnerability report.

468
00:22:25,001 --> 00:22:27,881
Because then, well, first of all, nobody knows how to report it.

469
00:22:27,891 --> 00:22:31,401
So they'll spend incredible amount of wasted time just figuring it out

470
00:22:31,582 --> 00:22:34,381
and then you don't have anything prepared to handle those.

471
00:22:34,391 --> 00:22:38,732
Most people want to do co-ordinated uh vulnerable disclosure.

472
00:22:38,741 --> 00:22:40,891
I think usually that's the better default.

473
00:22:40,901 --> 00:22:43,462
I understand the arguments for full disclosure. But,

474
00:22:43,689 --> 00:22:48,000
you know, I think in most cases, it's much better to try if you find a vulnerability

475
00:22:48,209 --> 00:22:53,520
to find the supplier and work with them privately to get it rapidly fixed.

476
00:22:53,709 --> 00:22:57,500
Now, if they're not gonna fix it in a timely way, that's a different issue, then,

477
00:22:57,510 --> 00:23:00,500
then yes, go ahead and tell the world there's a problem here.

478
00:23:00,510 --> 00:23:05,589
But uh try to get it quietly fixed so that the Attackers have less time.

479
00:23:05,709 --> 00:23:08,550
But that turns out to be a challenge. How do you report it quietly?

480
00:23:08,560 --> 00:23:09,989
How do you make sure that,

481
00:23:10,310 --> 00:23:12,989
you know, you can have those private discussions?

482
00:23:13,150 --> 00:23:16,410
So you and, you know, you need to have some things set up ahead of time.

483
00:23:16,420 --> 00:23:19,540
So that's, I think that's probably one of the main things that uh vulnerable.

484
00:23:19,560 --> 00:23:20,089
I mean, I,

485
00:23:20,260 --> 00:23:20,400
I,

486
00:23:20,579 --> 00:23:22,530
I'll, I'll remember later some other things but, you know,

487
00:23:22,540 --> 00:23:24,319
that's one of the main things and they've got a,

488
00:23:24,329 --> 00:23:26,489
they've got some templates and stuff like that.

489
00:23:26,500 --> 00:23:27,599
Probably gonna ask me about

490
00:23:27,739 --> 00:23:31,489
-- securing critical projects next working group. Next,
-- aren't you on my list?

491
00:23:31,500 --> 00:23:32,449
Next up is

492
00:23:32,680 --> 00:23:33,979
supply chain integrity,

493
00:23:33,989 --> 00:23:37,939
which used to be called the digital identity at a station working group.

494
00:23:37,949 --> 00:23:39,140
OK. All right.

495
00:23:39,260 --> 00:23:42,390
You know what, there's a story behind this and I think that would be,

496
00:23:42,400 --> 00:23:45,599
I think a lot of people listening in would be interested in the story.

497
00:23:45,939 --> 00:23:51,819
So this this working group actually um slightly predating the open SSF itself.

498
00:23:51,829 --> 00:23:54,939
There was, it was actually part of a different group that got merged in.

499
00:23:55,510 --> 00:23:59,780
And the, the theory behind this group was, was originally called,

500
00:23:59,790 --> 00:24:00,859
I even had another name.

501
00:24:00,869 --> 00:24:02,300
But you know, the most,

502
00:24:02,630 --> 00:24:06,329
the, the second, the penultimate name is digital identity at a station.

503
00:24:06,339 --> 00:24:07,619
And the notion was, hey,

504
00:24:07,849 --> 00:24:08,119
you know,

505
00:24:08,130 --> 00:24:10,790
everybody seems to be doing digital identity

506
00:24:10,800 --> 00:24:13,170
differently and at testing them differently,

507
00:24:13,180 --> 00:24:16,010
let's have everybody present how they're doing things.

508
00:24:16,020 --> 00:24:20,199
We identify the commonality and then we'll all agree on the common thing.

509
00:24:20,510 --> 00:24:23,199
And so what it turned out to be for a number

510
00:24:23,209 --> 00:24:26,229
of months was a number kind of a rolling conference,

511
00:24:26,510 --> 00:24:29,329
you know, show up every meeting and somebody else,

512
00:24:29,339 --> 00:24:32,209
maybe two people are going to present their approach.

513
00:24:32,219 --> 00:24:34,650
And as a Roman conference, it was interesting,

514
00:24:34,660 --> 00:24:36,969
the Linux kernel folks have one approach.

515
00:24:36,979 --> 00:24:37,869
There's oo uh

516
00:24:38,319 --> 00:24:41,079
there are other folks have other approaches. There's just,

517
00:24:41,359 --> 00:24:41,969
and

518
00:24:42,329 --> 00:24:45,930
you know, it was interesting, but there is a problem as a working group,

519
00:24:45,939 --> 00:24:46,949
the goal was to OK.

520
00:24:46,959 --> 00:24:50,229
Now we've learned we're gonna combine it all and here's the answer.

521
00:24:51,469 --> 00:24:54,520
Yeah, you, you can guess how that worked out from my tone.

522
00:24:55,170 --> 00:24:59,119
The goal of trying to find the commonality and working out that out,

523
00:24:59,130 --> 00:25:01,270
made sense to some people.

524
00:25:01,410 --> 00:25:05,479
But that assumed that there was a commonality and when the Venn diagram has,

525
00:25:05,489 --> 00:25:08,400
has nothing at the intersection, that was a challenge.

526
00:25:08,540 --> 00:25:13,119
So they said, well, we still really are worried about provenance, but

527
00:25:13,520 --> 00:25:13,540
uh

528
00:25:13,719 --> 00:25:17,099
we're kind of struggling with the way we're, we've been talking about this.

529
00:25:17,109 --> 00:25:19,180
So let's shift our gears a little bit.

530
00:25:19,189 --> 00:25:20,430
So they mooted, in fact,

531
00:25:20,439 --> 00:25:24,719
they just recently officially changed over their name to supply chain integrity.

532
00:25:24,729 --> 00:25:26,890
They've also brought in uh a project

533
00:25:26,900 --> 00:25:30,619
called supply chain levels for software artifacts.

534
00:25:30,739 --> 00:25:35,619
And that's also called SALSA. Salsa is basically a set of criteria for um

535
00:25:36,160 --> 00:25:42,680
um uh providing integrity on the supply chain uh both within and without uh

536
00:25:42,930 --> 00:25:48,560
franco. The best thing to go is to do is to go to Salsa dot DEV, SLS A dot DEV.

537
00:25:48,569 --> 00:25:49,420
And you can see,

538
00:25:49,540 --> 00:25:52,339
you know, they've got multiple levels and criteria for each level.

539
00:25:52,469 --> 00:25:56,410
Um It's originally developed ba basically what this is is, it's

540
00:25:56,760 --> 00:25:56,770
a,

541
00:25:57,339 --> 00:25:58,520
it's an attempt to

542
00:25:58,739 --> 00:26:02,420
capture the key criteria originally from Google

543
00:26:02,430 --> 00:26:04,189
because Google does a number of things

544
00:26:04,329 --> 00:26:05,760
now because they're worried about that.

545
00:26:05,979 --> 00:26:07,119
And so, well, you know, what,

546
00:26:07,130 --> 00:26:12,569
there's a lot of things that we Google do that probably lots of folks should be doing.

547
00:26:12,579 --> 00:26:14,719
And the good thing is that we can say that, you know,

548
00:26:14,729 --> 00:26:18,000
these aren't just abstract concepts, these are things people really,

549
00:26:18,010 --> 00:26:19,000
we're really doing.

550
00:26:19,369 --> 00:26:23,310
And so they, they tried to abstract away, OK,

551
00:26:23,319 --> 00:26:27,189
what are the things that make sense for everybody as opposed to just, you know,

552
00:26:27,430 --> 00:26:30,270
some particular organization for their particular situation?

553
00:26:30,650 --> 00:26:33,130
And so Salsa's stone development,

554
00:26:33,140 --> 00:26:37,339
but it's basically a set of criteria to counter a number of those kinds of attacks.

555
00:26:37,589 --> 00:26:39,380
Uh If you're curious about more, go to the website,

556
00:26:39,390 --> 00:26:40,900
it'll give you lots of more details.

557
00:26:40,910 --> 00:26:42,420
What's what have we not talked about?

558
00:26:42,829 --> 00:26:47,020
-- The last one is securing critical projects,
-- critical projects. OK.

559
00:26:47,030 --> 00:26:50,459
The goal here is to identify those critical open source projects.

560
00:26:50,959 --> 00:26:52,930
Um This is so, for example, you know, for,

561
00:26:53,579 --> 00:26:55,900
you know, eventually we'll probably talk about Alpha Mega,

562
00:26:55,910 --> 00:26:59,050
we want to identify some critical projects and work really hard,

563
00:26:59,060 --> 00:27:01,810
especially for those critical open source offer projects.

564
00:27:02,260 --> 00:27:05,900
Um So there's several different things that are involved there,

565
00:27:05,910 --> 00:27:10,780
there's AAA metric that's called criticality score which tries to score out

566
00:27:11,109 --> 00:27:15,239
uh and estimate just from external, a few external measures

567
00:27:15,449 --> 00:27:17,229
uh whether or not software is critical.

568
00:27:17,239 --> 00:27:17,689
Now,

569
00:27:17,699 --> 00:27:20,739
I think there's been some rightful um complaints

570
00:27:20,750 --> 00:27:22,920
about that particular score as it's implemented.

571
00:27:23,229 --> 00:27:24,619
Um For example,

572
00:27:24,819 --> 00:27:28,089
um it really likes projects that are super, super busy.

573
00:27:28,540 --> 00:27:33,750
Uh and, and, and OK, if you get now, I think if there's an argument for it,

574
00:27:34,199 --> 00:27:38,589
um if there's a huge number of commits to a project from a lot of different people,

575
00:27:38,599 --> 00:27:41,569
that must mean it's probably important to a lot of people.

576
00:27:41,660 --> 00:27:42,859
However,

577
00:27:42,920 --> 00:27:46,489
it is true that there are some projects which are

578
00:27:46,500 --> 00:27:49,859
maybe are almost dead or very get very few lib.

579
00:27:49,869 --> 00:27:52,040
J peg. Yeah, we can make a list,

580
00:27:53,630 --> 00:27:57,099
you know, just being dead doesn't mean they're not critical. So

581
00:27:57,250 --> 00:28:00,420
I think the criticality score, I think is helpful.

582
00:28:00,430 --> 00:28:04,339
It takes one slice at a hard problem and gives that a try.

583
00:28:04,760 --> 00:28:09,060
Um Another thing that lives, there is a lot of work that's being done by Harvard.

584
00:28:09,069 --> 00:28:11,219
Uh It's actually a group within Harvard,

585
00:28:11,689 --> 00:28:15,859
Llish. The H is Harvard. I can't remember what the lis states are.

586
00:28:17,510 --> 00:28:23,859
But uh anyway, um they're trying to really dig in and gather dependency data,

587
00:28:23,869 --> 00:28:28,439
do dependency analysis across the entire, across the entire ecosystems

588
00:28:28,760 --> 00:28:31,709
and start from, you know, actual app application,

589
00:28:31,719 --> 00:28:33,869
uh large sets of applications and use that

590
00:28:34,055 --> 00:28:38,255
working with a number of uh sc a tool makers, uh

591
00:28:38,494 --> 00:28:39,594
tool suppliers

592
00:28:39,905 --> 00:28:44,334
um to gather data to basically try to identify critical projects,

593
00:28:44,454 --> 00:28:47,395
including that kind of criticality data that

594
00:28:47,625 --> 00:28:48,635
just looking at, you know,

595
00:28:48,645 --> 00:28:51,824
number of busyness of commits won't necessarily capture.

596
00:28:52,645 --> 00:28:55,244
So um and there's some other things that live in there too.

597
00:28:55,255 --> 00:28:57,484
There's uh package feeds and package analysis,

598
00:28:57,665 --> 00:28:59,694
you know, it's not just identifying critical projects,

599
00:28:59,704 --> 00:29:02,594
they they are trying to do some things to counter some problems.

600
00:29:02,604 --> 00:29:02,984
So

601
00:29:03,260 --> 00:29:07,310
uh they're trying to do some simple identification of malicious code

602
00:29:07,689 --> 00:29:11,810
and warn about it. Now, now they have to be careful about this.

603
00:29:11,819 --> 00:29:14,579
This is just like any virus check or anything else

604
00:29:14,849 --> 00:29:17,540
just because you got code that looks and it

605
00:29:17,550 --> 00:29:20,680
says I don't see anything that doesn't make it ok

606
00:29:20,930 --> 00:29:22,160
if I'm an attacker,

607
00:29:22,170 --> 00:29:25,050
the first thing I'm gonna do is run your tools and see if you find it.

608
00:29:25,944 --> 00:29:26,435
But

609
00:29:26,744 --> 00:29:29,224
there are a number of naive Attackers and this will

610
00:29:29,234 --> 00:29:31,314
at least catch some of those and you know,

611
00:29:31,324 --> 00:29:34,175
catching naive Attackers at least gets rid of some problems.

612
00:29:34,185 --> 00:29:39,625
-- So this is not crazy
-- and, and look, I think in the world of security, we have this

613
00:29:39,864 --> 00:29:42,515
terrible history of all or nothing

614
00:29:42,910 --> 00:29:45,739
where if it's not perfect, don't do it.

615
00:29:46,000 --> 00:29:49,500
And this is a great example of start small

616
00:29:49,729 --> 00:29:51,459
and, and grow into it, right?

617
00:29:51,469 --> 00:29:55,260
Like yes, we know it has problems but you have to start somewhere because you just,

618
00:29:55,270 --> 00:29:57,420
you can't build a perfect solution,

619
00:29:58,300 --> 00:30:02,310
right? And, and, and, and I'm big, big, big, big on risk management.

620
00:30:02,359 --> 00:30:06,589
You know, what are the, what are the biggest risks focus on that?

621
00:30:06,599 --> 00:30:10,089
Uh My phd is on countering malicious compilers.

622
00:30:10,199 --> 00:30:12,800
Do you have how that existed? Yes.

623
00:30:13,020 --> 00:30:15,910
Is that where most attacks are happening? No.

624
00:30:16,079 --> 00:30:19,849
So, so that now that doesn't mean that I think my phd,

625
00:30:19,902 --> 00:30:23,512
the dissertation is a terrible horrible thing if you're interested, go read it.

626
00:30:23,522 --> 00:30:25,892
I've, I tried to make it readable, but

627
00:30:26,142 --> 00:30:31,123
as from the point of view of I'm trying to counter, I, I'm trying to counter attacks,

628
00:30:31,133 --> 00:30:33,282
I'm way more interested right now in

629
00:30:33,412 --> 00:30:38,282
eliminating unintentional vulnerabilities trying to make supply chains so that

630
00:30:38,292 --> 00:30:41,262
-- the top problems like type of squatting are
-- countered.

631
00:30:41,272 --> 00:30:41,682
Actually seen

632
00:30:41,796 --> 00:30:44,215
that happened unintentionally where like

633
00:30:44,225 --> 00:30:46,316
literally the Devs were discussing something

634
00:30:46,326 --> 00:30:49,206
in the shop if I had a package named one thing and

635
00:30:49,375 --> 00:30:53,105
there was a legitimate other package with like an off by one character

636
00:30:53,355 --> 00:30:56,615
and they couldn't figure out why it wasn't working the way it should be.

637
00:30:56,645 --> 00:30:57,735
And it's because somebody,

638
00:30:57,745 --> 00:31:01,546
somebody had just type like because the like the N PM namespace is crowded, right?

639
00:31:01,556 --> 00:31:02,696
All the good names are taken,

640
00:31:02,836 --> 00:31:03,336
you know,

641
00:31:03,985 --> 00:31:06,015
and somebody had made a Typo and it took them, you know,

642
00:31:06,026 --> 00:31:07,416
the better part of an hour to like,

643
00:31:07,975 --> 00:31:10,296
oh, hang on a sec. We're, this is the wrong word.

644
00:31:11,060 --> 00:31:13,089
If you're interested in open

645
00:31:13,219 --> 00:31:14,790
source software supply chain,

646
00:31:14,800 --> 00:31:18,430
there's a couple of papers I would hardly recommend that you look

647
00:31:18,439 --> 00:31:23,280
at sonatype and synopsis have both done uh 2021 reports that are interesting

648
00:31:23,599 --> 00:31:27,599
and for a larger view of, of things and over time, it's,

649
00:31:27,609 --> 00:31:31,739
it's hard to over recommend a paper with a spectacular name.

650
00:31:31,750 --> 00:31:33,209
It's uh I can't remember the full

651
00:31:33,219 --> 00:31:36,310
name but it's Backstabbers Knife Collection which is

652
00:31:37,050 --> 00:31:40,160
um and where they go in and examine every

653
00:31:40,170 --> 00:31:43,180
open source software supply chain attack they can find

654
00:31:43,560 --> 00:31:46,719
and try to categorize them or what's the most common.

655
00:31:46,859 --> 00:31:50,270
And basically what they found was that through the,

656
00:31:50,280 --> 00:31:52,459
through the period that they were looking at the

657
00:31:52,469 --> 00:31:56,150
number one attack by far was type of squatting.

658
00:31:56,880 --> 00:31:57,089
And

659
00:31:57,199 --> 00:31:57,250
it's,

660
00:31:57,890 --> 00:32:02,430
it's, and it's well, exactly type of squatting attacks are super easy to do.

661
00:32:02,439 --> 00:32:05,469
It's trivial to create, to find the common packages

662
00:32:05,660 --> 00:32:08,420
and it's trivial to create other packages with similar names.

663
00:32:08,849 --> 00:32:10,739
And now you mentioned it's trivial,

664
00:32:10,750 --> 00:32:16,349
but it's also trivial to counter as a developer before you bring in a package,

665
00:32:16,359 --> 00:32:18,189
double check the name.

666
00:32:18,229 --> 00:32:20,510
You're gonna have to learn how to use the package.

667
00:32:20,520 --> 00:32:22,270
So, you know, you, you know,

668
00:32:22,280 --> 00:32:25,310
if you're gonna have to read a doc to figure out how to use it,

669
00:32:25,489 --> 00:32:29,989
it won't take you more than a couple of seconds to figure out. Is this the right one?

670
00:32:30,359 --> 00:32:34,310
You know, if this is the package everybody's been using for the last five years,

671
00:32:34,319 --> 00:32:37,270
maybe the package that just was created last month and it

672
00:32:37,280 --> 00:32:40,260
has 20 downloads is not the one you're looking for.

673
00:32:41,750 --> 00:32:44,050
You know, so it's, it's one of those things where you know,

674
00:32:44,060 --> 00:32:47,290
just knowing that this is an attack and knowing, hey,

675
00:32:47,300 --> 00:32:50,310
do this 12th double check can eliminate it.

676
00:32:50,319 --> 00:32:54,260
Now, I will say that that there if the developer makes a mistake,

677
00:32:54,270 --> 00:32:58,170
the US government for example, is starting to demand software building materials.

678
00:32:58,180 --> 00:33:00,010
Tell tell me what's in the software

679
00:33:00,260 --> 00:33:02,810
and, and this will let them also

680
00:33:02,910 --> 00:33:05,250
be able to double check and say now, wait a minute,

681
00:33:05,380 --> 00:33:10,869
you're bringing in, you know, fu with three Os, you probably met Fu with two Os.

682
00:33:11,260 --> 00:33:12,510
This is a problem.

683
00:33:12,520 --> 00:33:13,650
So I, but, you know,

684
00:33:13,660 --> 00:33:19,969
basically asking once developers know this is a common kind of attack, they can

685
00:33:20,369 --> 00:33:23,969
double, they can do that five second uh analysis

686
00:33:24,380 --> 00:33:25,699
and others got

687
00:33:25,819 --> 00:33:26,739
customers can use

688
00:33:27,270 --> 00:33:27,880
software

689
00:33:28,040 --> 00:33:29,810
materials to double check that. That's

690
00:33:29,939 --> 00:33:30,420
-- right.
-- That's

691
00:33:30,589 --> 00:33:33,790
-- right. No, it's, it's,
-- this is one thing that frustrates me is people,

692
00:33:34,400 --> 00:33:37,630
Attackers go for the easy stuff because well, why not?

693
00:33:37,800 --> 00:33:38,369
Like at work

694
00:33:38,520 --> 00:33:39,670
they should,

695
00:33:39,969 --> 00:33:42,579
you know if I, if I'm an attack, if I'm an attacker, I mean,

696
00:33:42,589 --> 00:33:45,829
the Attackers have a cost benefit ratio to look at too.

697
00:33:46,010 --> 00:33:46,250
You know,

698
00:33:46,260 --> 00:33:48,810
Attackers are going to are going to at least the

699
00:33:48,819 --> 00:33:50,790
smart ones are going to take the easy path.

700
00:33:51,040 --> 00:33:54,430
And so what we need to do is make the easy path, not easy for them.

701
00:33:54,439 --> 00:33:58,589
And I realize that there's some people saying, oh my gosh, this will never be solved.

702
00:33:58,599 --> 00:33:59,125
It can't be, I

703
00:33:59,295 --> 00:34:00,545
don't see it that way.

704
00:34:00,655 --> 00:34:03,364
The goal is not really to make it impossible.

705
00:34:03,375 --> 00:34:05,594
The goal is to make it so impractical and so

706
00:34:05,604 --> 00:34:08,333
costly that they will give up and try something else.

707
00:34:08,364 --> 00:34:08,784
-- That's
-- right.

708
00:34:08,905 --> 00:34:09,324
That's right.

709
00:34:09,385 --> 00:34:14,685
Or even if we don't, like, even if it makes it 10 or 20% better at, not a large cost.

710
00:34:14,695 --> 00:34:18,165
Like, for example, the token thing. Right. Like I get it because tokens cost money

711
00:34:18,489 --> 00:34:22,179
and, yeah, you can't just mail out, like, 10 million tokens and eat the cost.

712
00:34:22,360 --> 00:34:25,540
But at the same time, if it makes it 10 or 20% better for, you know,

713
00:34:25,550 --> 00:34:28,438
a reasonable amount of money, you know, like fixing roads.

714
00:34:28,449 --> 00:34:31,708
-- Yeah. Shouldn't we be doing that? Doesn't that make sense?
-- Right. Right.

715
00:34:31,719 --> 00:34:33,510
And you know what, there are roads we,

716
00:34:33,520 --> 00:34:36,429
we focus more on to make sure that they're paved.

717
00:34:36,438 --> 00:34:38,429
Well, I mean, there's infrastructure where,

718
00:34:38,659 --> 00:34:42,620
oh, well, of course, we can talk about Vancouver's lack of roads right now. But,

719
00:34:42,739 --> 00:34:44,070
yeah, seriously.

720
00:34:44,668 --> 00:34:48,428
But you, you know, you know, barring natural disasters and such, you know,

721
00:34:48,438 --> 00:34:52,059
we try to make sure that, uh, our infrastructure works,

722
00:34:52,289 --> 00:34:55,998
um, at least, you know, in, in functioning societies and, you know, I,

723
00:34:56,009 --> 00:34:59,289
I fully get that there's challenges in various parts of the world, but

724
00:34:59,408 --> 00:35:02,448
I, I think we can all agree that it's, it's good to,

725
00:35:02,638 --> 00:35:04,999
you know, have a functioning infrastructure

726
00:35:05,138 --> 00:35:08,688
and since you have limited resources, focus on the ones that matter.

727
00:35:08,698 --> 00:35:09,079
So, you know,

728
00:35:09,089 --> 00:35:11,000
coming back to that m fa they're gonna start

729
00:35:11,010 --> 00:35:13,899
by trying to identify the folks who are the,

730
00:35:13,909 --> 00:35:17,120
like the key maintainers on some of the most important projects.

731
00:35:17,209 --> 00:35:18,149
Let's get those.

732
00:35:18,159 --> 00:35:20,830
And you know what I think that there's also a,

733
00:35:20,889 --> 00:35:24,600
once there's a certain number of people who do it it's a lot more,

734
00:35:24,610 --> 00:35:28,270
there's a lot more incentive for other folks to say, you know, it's not that costly.

735
00:35:28,280 --> 00:35:29,550
I could get one of those.

736
00:35:29,560 --> 00:35:33,229
-- It would be ok
-- also, just to get help because one thing I've noticed is, you know, we,

737
00:35:33,239 --> 00:35:36,149
for example, we rolled out password management at the CS A

738
00:35:36,310 --> 00:35:37,429
and now that

739
00:35:37,790 --> 00:35:40,110
the majority of people are used to it, you know,

740
00:35:40,120 --> 00:35:41,889
I'm no longer the point of contact always.

741
00:35:41,899 --> 00:35:44,469
It's, they can just ask anybody else. Oh, hey, I'm having this, you know,

742
00:35:44,620 --> 00:35:47,850
this doesn't work or it's not behaving. Oh, ok. That's how you make it work, right.

743
00:35:48,080 --> 00:35:51,530
And so that, that knowledge of just how to get this thing, like

744
00:35:51,649 --> 00:35:53,570
with tokens, I'm still,

745
00:35:53,719 --> 00:35:55,889
yeah, like the instructions for actually getting

746
00:35:56,250 --> 00:35:59,919
multiple tokens registered with a provider because people lose their tokens.

747
00:35:59,929 --> 00:36:00,070
You know,

748
00:36:00,080 --> 00:36:02,429
I've got five or six of them in total because I want to have

749
00:36:02,439 --> 00:36:06,600
backups in case I lose my keys and the instructions for getting multiple tokens,

750
00:36:06,610 --> 00:36:09,600
like, uh, some of these providers, they make it really obvious.

751
00:36:09,610 --> 00:36:11,699
Like here registered Token register more than one

752
00:36:11,830 --> 00:36:14,199
and at some, like you gotta go digging.

753
00:36:15,050 --> 00:36:18,129
-- No, like they, for whatever reason they, they hid that option.
-- Yeah.

754
00:36:18,139 --> 00:36:23,780
No, I, I have a two fa token but, uh, you know, I've been using for quite some time and,

755
00:36:23,790 --> 00:36:23,959
you know,

756
00:36:24,469 --> 00:36:27,530
I am sure that I will as we go through this thing, uh,

757
00:36:27,540 --> 00:36:29,909
I'm sure I will learn things and that's great.

758
00:36:29,919 --> 00:36:33,889
And now I agree with you being able to ask other people around is really,

759
00:36:33,899 --> 00:36:36,939
really helpful because, you know, if it's, if it's spread across,

760
00:36:36,949 --> 00:36:38,540
but we also want to provide

761
00:36:38,699 --> 00:36:42,399
some, hey, you type into Google or, you know, some search engine

762
00:36:42,510 --> 00:36:47,070
and poof, there's your answer and it's not a, here's the 300 page doc, it's the,

763
00:36:47,570 --> 00:36:48,139
you know,

764
00:36:48,969 --> 00:36:51,399
I'm gonna go off field. But what the heck, uh

765
00:36:51,679 --> 00:36:55,060
uh there's a recent posting about random number generation

766
00:36:55,070 --> 00:36:58,639
being totally messed up for billions of IOT devices.

767
00:36:58,909 --> 00:36:59,979
And part of it was,

768
00:37:00,189 --> 00:37:04,419
you know, hey, they found out how to use the hardware, it was like page, you know,

769
00:37:04,429 --> 00:37:06,939
3000 and something and such,

770
00:37:07,110 --> 00:37:07,860
you know, and, and,

771
00:37:08,070 --> 00:37:08,280
you know,

772
00:37:08,290 --> 00:37:10,320
I'm sure sure that the developers are going

773
00:37:10,330 --> 00:37:12,679
to read every single page of that nonsense.

774
00:37:12,810 --> 00:37:17,659
Uh No, we, if it's that hard then of course they're not going to do it correctly.

775
00:37:17,669 --> 00:37:22,540
-- So we've got to make it easy. Gotta make it easy.
-- Absolutely. And, and I think

776
00:37:22,860 --> 00:37:25,790
that is the message we should leave on is

777
00:37:26,149 --> 00:37:27,620
if the easy way

778
00:37:28,429 --> 00:37:30,020
isn't the secure way,

779
00:37:30,419 --> 00:37:31,010
then

780
00:37:31,709 --> 00:37:33,810
there's just not going to be a secure way. Like

781
00:37:34,270 --> 00:37:35,510
that's the sad truth.

782
00:37:35,520 --> 00:37:38,469
-- You
-- can post that picture if you remember the gate over the road with

783
00:37:38,479 --> 00:37:40,760
the tire tracks going around either side of the gate and the snow,

784
00:37:42,229 --> 00:37:44,330
like a 20 year old picture. But it's still true.

785
00:37:44,580 --> 00:37:44,860
It's

786
00:37:45,010 --> 00:37:46,510
true. And it's still funny.

787
00:37:47,889 --> 00:37:52,310
All right, David. I want to thank you so much. This has been an absolute treat.

788
00:37:52,320 --> 00:37:53,870
Having you come on the show again.

789
00:37:53,979 --> 00:37:54,669
My pleasure.

790
00:37:54,850 --> 00:37:56,350
I'm happy to come back anytime,

791
00:37:56,520 --> 00:38:00,030
anytime we would love to have you. All right. So thank you everyone for listening.

792
00:38:00,040 --> 00:38:02,870
All the stuff we talked about is going to go into the show notes.

793
00:38:02,879 --> 00:38:05,280
So worry about trying to scribble down and any

794
00:38:05,290 --> 00:38:06,659
of the project names and you can go to open

795
00:38:06,760 --> 00:38:09,040
source security podcast.com. Find those show notes use a Podos

796
00:38:09,540 --> 00:38:11,729
podcast. Hashtag Hit us up on social media.

797
00:38:11,739 --> 00:38:15,580
-- Kurt and David have marvelous rest of your days. Thank you.
-- You too.

798
00:38:15,590 --> 00:38:18,320
-- Thanks
-- everybody. Thanks everyone. Bye bye.